{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import qrcdcnn_VaR_95\n",
    "import qrcdcnn_CoVaR_95\n",
    "import qrcdcnn_VaR_99\n",
    "import qrcdcnn_CoVaR_99\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams['figure.dpi'] = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 10ms/step - loss: 36.3956 - val_loss: 38.7251\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 35.6922 - val_loss: 38.0395\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 34.9454 - val_loss: 36.9038\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 33.5313 - val_loss: 35.5471\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 32.0689 - val_loss: 34.1399\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 30.8373 - val_loss: 32.8435\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 29.5121 - val_loss: 31.5742\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 28.3474 - val_loss: 30.3441\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 27.3471 - val_loss: 29.1752\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 26.4136 - val_loss: 28.0750\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 25.5770 - val_loss: 27.0073\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 24.7430 - val_loss: 26.0153\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 24.2657 - val_loss: 25.1890\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.7796 - val_loss: 24.4763\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.3025 - val_loss: 23.8694\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.0025 - val_loss: 23.3944\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.7735 - val_loss: 22.9670\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.4450 - val_loss: 22.6246\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.4132 - val_loss: 22.3525\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.2166 - val_loss: 22.1322\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.1095 - val_loss: 21.9599\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.0812 - val_loss: 21.8236\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.0018 - val_loss: 21.7166\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9591 - val_loss: 21.6337\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.8623 - val_loss: 21.5606\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.7278 - val_loss: 21.4922\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.8077 - val_loss: 21.4266\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.8028 - val_loss: 21.3662\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.7349 - val_loss: 21.3119\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.6955 - val_loss: 21.2611\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.7037 - val_loss: 21.2110\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.6815 - val_loss: 21.1616\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.6521 - val_loss: 21.1156\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5819 - val_loss: 21.0732\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5608 - val_loss: 21.0333\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5892 - val_loss: 20.9929\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5705 - val_loss: 20.9545\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5414 - val_loss: 20.9178\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.5206 - val_loss: 20.8840\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2331 - val_loss: 20.8581\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.4904 - val_loss: 20.8326\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.4176 - val_loss: 20.8103\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3727 - val_loss: 20.7889\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.4512 - val_loss: 20.7676\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3572 - val_loss: 20.7473\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3932 - val_loss: 20.7277\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3986 - val_loss: 20.7063\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3877 - val_loss: 20.6861\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3792 - val_loss: 20.6656\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3546 - val_loss: 20.6458\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2320 - val_loss: 20.6272\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.3366 - val_loss: 20.6079\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2439 - val_loss: 20.5885\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2713 - val_loss: 20.5694\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2878 - val_loss: 20.5507\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2385 - val_loss: 20.5329\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2292 - val_loss: 20.5147\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2587 - val_loss: 20.4954\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.1399 - val_loss: 20.4790\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.2228 - val_loss: 20.4609\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.1186 - val_loss: 20.4447\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.1744 - val_loss: 20.4270\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.1832 - val_loss: 20.4086\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1620 - val_loss: 20.3910\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1475 - val_loss: 20.3733\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0962 - val_loss: 20.3563\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0897 - val_loss: 20.3408\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9943 - val_loss: 20.3245\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.0911 - val_loss: 20.3083\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.9959 - val_loss: 20.2923\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0711 - val_loss: 20.2759\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.0446 - val_loss: 20.2595\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.0121 - val_loss: 20.2438\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.0288 - val_loss: 20.2284\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.0122 - val_loss: 20.2122\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.9095 - val_loss: 20.1979\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8646 - val_loss: 20.1823\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.9481 - val_loss: 20.1666\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9478 - val_loss: 20.1511\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9408 - val_loss: 20.1356\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8789 - val_loss: 20.1204\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.9217 - val_loss: 20.1047\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8962 - val_loss: 20.0893\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8363 - val_loss: 20.0737\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8678 - val_loss: 20.0584\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8477 - val_loss: 20.0425\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8303 - val_loss: 20.0273\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.8156 - val_loss: 20.0120\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7678 - val_loss: 19.9969\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.7820 - val_loss: 19.9815\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.7768 - val_loss: 19.9665\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.7521 - val_loss: 19.9511\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6652 - val_loss: 19.9358\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6900 - val_loss: 19.9205\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.7173 - val_loss: 19.9050\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.7055 - val_loss: 19.8894\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.6755 - val_loss: 19.8743\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6683 - val_loss: 19.8587\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.5663 - val_loss: 19.8430\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5993 - val_loss: 19.8276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 6, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 26.3820 - val_loss: 25.0464\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5986 - val_loss: 24.4566\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9533 - val_loss: 23.9637\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4665 - val_loss: 23.5427\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0041 - val_loss: 23.1531\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4836 - val_loss: 22.7733\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.0117 - val_loss: 22.4128\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6177 - val_loss: 22.0801\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2289 - val_loss: 21.7560\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7566 - val_loss: 21.4282\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5053 - val_loss: 21.1125\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1357 - val_loss: 20.8309\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7465 - val_loss: 20.5664\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 20.4041 - val_loss: 20.3559\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2409 - val_loss: 20.1802\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0058 - val_loss: 20.0212\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6882 - val_loss: 19.8816\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4229 - val_loss: 19.7756\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3953 - val_loss: 19.6755\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2500 - val_loss: 19.5833\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1276 - val_loss: 19.4958\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0098 - val_loss: 19.4108\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8872 - val_loss: 19.3359\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8654 - val_loss: 19.2748\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7460 - val_loss: 19.2204\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7081 - val_loss: 19.1690\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6924 - val_loss: 19.1201\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6487 - val_loss: 19.0793\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6245 - val_loss: 19.0487\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5566 - val_loss: 19.0204\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3989 - val_loss: 18.9947\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3948 - val_loss: 18.9703\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5026 - val_loss: 18.9454\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4837 - val_loss: 18.9227\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4608 - val_loss: 18.9003\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4320 - val_loss: 18.8792\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3078 - val_loss: 18.8588\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3699 - val_loss: 18.8403\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3904 - val_loss: 18.8216\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3073 - val_loss: 18.8032\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3130 - val_loss: 18.7861\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3021 - val_loss: 18.7689\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2725 - val_loss: 18.7515\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2736 - val_loss: 18.7347\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2908 - val_loss: 18.7171\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2614 - val_loss: 18.7000\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2672 - val_loss: 18.6828\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2518 - val_loss: 18.6662\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2363 - val_loss: 18.6509\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2309 - val_loss: 18.6347\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2058 - val_loss: 18.6184\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1705 - val_loss: 18.6031\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1841 - val_loss: 18.5873\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1737 - val_loss: 18.5713\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1141 - val_loss: 18.5560\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1490 - val_loss: 18.5406\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9897 - val_loss: 18.5256\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1243 - val_loss: 18.5103\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1089 - val_loss: 18.4954\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0795 - val_loss: 18.4803\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0845 - val_loss: 18.4651\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0609 - val_loss: 18.4499\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0089 - val_loss: 18.4354\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0418 - val_loss: 18.4200\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9025 - val_loss: 18.4049\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0086 - val_loss: 18.3897\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9766 - val_loss: 18.3744\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8240 - val_loss: 18.3595\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9685 - val_loss: 18.3445\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9319 - val_loss: 18.3294\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8947 - val_loss: 18.3145\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9010 - val_loss: 18.2991\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8869 - val_loss: 18.2838\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8772 - val_loss: 18.2688\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8754 - val_loss: 18.2534\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8684 - val_loss: 18.2378\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8462 - val_loss: 18.2223\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8229 - val_loss: 18.2065\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8135 - val_loss: 18.1913\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7581 - val_loss: 18.1758\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7323 - val_loss: 18.1609\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7529 - val_loss: 18.1454\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7655 - val_loss: 18.1294\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7181 - val_loss: 18.1138\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6236 - val_loss: 18.0980\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7186 - val_loss: 18.0817\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6654 - val_loss: 18.0655\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6830 - val_loss: 18.0497\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4937 - val_loss: 18.0342\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5937 - val_loss: 18.0181\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6343 - val_loss: 18.0022\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6166 - val_loss: 17.9859\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6111 - val_loss: 17.9693\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5884 - val_loss: 17.9534\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5350 - val_loss: 17.9372\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5628 - val_loss: 17.9209\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5351 - val_loss: 17.9046\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5082 - val_loss: 17.8883\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5157 - val_loss: 17.8722\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5012 - val_loss: 17.8558\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 7, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.07896\n",
      "Model:                       QuantReg   Bandwidth:                    0.004705\n",
      "Method:                 Least Squares   Sparsity:                       0.1960\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:30:09   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0141      0.007      2.010      0.045       0.000       0.028\n",
      "three_month_yield_change     -0.0970      0.179     -0.541      0.589      -0.448       0.255\n",
      "term_spread_change           -0.2263      0.174     -1.298      0.195      -0.568       0.116\n",
      "TED_spread                   -1.3790      0.644     -2.141      0.032      -2.642      -0.116\n",
      "credit_spread_change          0.1997      0.241      0.830      0.407      -0.272       0.671\n",
      "market_return                -0.0307      0.113     -0.273      0.785      -0.252       0.190\n",
      "real_estate_excess_return     0.0082      0.122      0.068      0.946      -0.230       0.247\n",
      "equity_volatility             1.8422      0.177     10.425      0.000       1.496       2.189\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1721\n",
      "Model:                       QuantReg   Bandwidth:                    0.007368\n",
      "Method:                 Least Squares   Sparsity:                       0.9761\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:30:09   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0352      0.015      2.279      0.023       0.005       0.065\n",
      "three_month_yield_change     -0.1741      0.388     -0.449      0.654      -0.935       0.587\n",
      "term_spread_change           -0.5989      0.408     -1.468      0.142      -1.399       0.201\n",
      "TED_spread                    0.6866      1.534      0.448      0.654      -2.322       3.695\n",
      "credit_spread_change         -0.2230      0.506     -0.441      0.659      -1.215       0.769\n",
      "market_return                 0.1486      0.381      0.390      0.696      -0.598       0.895\n",
      "real_estate_excess_return     0.0163      0.322      0.051      0.960      -0.616       0.648\n",
      "equity_volatility             2.7940      0.580      4.815      0.000       1.656       3.932\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4219\n",
      "Model:                       QuantReg   Bandwidth:                    0.002100\n",
      "Method:                 Least Squares   Sparsity:                      0.07287\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:30:09   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0193      0.003      7.538      0.000       0.014       0.024\n",
      "three_month_yield_change     -0.1857      0.074     -2.517      0.012      -0.330      -0.041\n",
      "term_spread_change           -0.2863      0.064     -4.457      0.000      -0.412      -0.160\n",
      "TED_spread                   -0.7598      0.254     -2.995      0.003      -1.257      -0.262\n",
      "credit_spread_change         -0.2385      0.092     -2.589      0.010      -0.419      -0.058\n",
      "market_return                -0.0370      0.038     -0.963      0.335      -0.112       0.038\n",
      "real_estate_excess_return    -0.0819      0.041     -2.000      0.046      -0.162      -0.002\n",
      "equity_volatility             0.6292      0.077      8.202      0.000       0.479       0.780\n",
      "institution                   0.4462      0.034     12.947      0.000       0.379       0.514\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5322\n",
      "Model:                       QuantReg   Bandwidth:                    0.003449\n",
      "Method:                 Least Squares   Sparsity:                       0.3584\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:30:09   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0312      0.005      5.895      0.000       0.021       0.042\n",
      "three_month_yield_change     -0.1889      0.182     -1.040      0.298      -0.545       0.167\n",
      "term_spread_change           -0.4614      0.169     -2.734      0.006      -0.792      -0.130\n",
      "TED_spread                    0.3609      0.671      0.538      0.591      -0.955       1.677\n",
      "credit_spread_change         -0.5292      0.180     -2.932      0.003      -0.883      -0.175\n",
      "market_return                 0.0102      0.112      0.091      0.927      -0.210       0.230\n",
      "real_estate_excess_return    -0.1929      0.103     -1.878      0.061      -0.394       0.009\n",
      "equity_volatility             1.0188      0.208      4.894      0.000       0.611       1.427\n",
      "institution                   0.4499      0.119      3.791      0.000       0.217       0.683\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 41.5829 - val_loss: 39.0542\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 41.1153 - val_loss: 38.3248\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 40.2249 - val_loss: 37.6576\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 39.1830 - val_loss: 36.9699\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 38.4887 - val_loss: 36.1937\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 37.5415 - val_loss: 35.3243\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 36.4172 - val_loss: 34.3831\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 35.1840 - val_loss: 33.3743\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.9216 - val_loss: 32.3137\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.6943 - val_loss: 31.1511\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.5075 - val_loss: 30.0079\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.2525 - val_loss: 28.8058\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.3037 - val_loss: 27.6834\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.2869 - val_loss: 26.6679\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.4530 - val_loss: 25.8562\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.7691 - val_loss: 25.2054\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2726 - val_loss: 24.6128\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8002 - val_loss: 24.1323\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.3107 - val_loss: 23.7881\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.1315 - val_loss: 23.5840\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.8743 - val_loss: 23.4182\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6176 - val_loss: 23.2605\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.5425 - val_loss: 23.1120\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4326 - val_loss: 22.9643\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3138 - val_loss: 22.8295\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1962 - val_loss: 22.7070\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1160 - val_loss: 22.5980\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9492 - val_loss: 22.5189\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9820 - val_loss: 22.4560\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9139 - val_loss: 22.4007\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7910 - val_loss: 22.3563\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9067 - val_loss: 22.3105\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8181 - val_loss: 22.2703\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8176 - val_loss: 22.2309\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8250 - val_loss: 22.1945\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7888 - val_loss: 22.1581\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7819 - val_loss: 22.1224\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7796 - val_loss: 22.0869\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6531 - val_loss: 22.0554\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6018 - val_loss: 22.0269\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7299 - val_loss: 22.0002\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6667 - val_loss: 21.9760\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6933 - val_loss: 21.9519\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6579 - val_loss: 21.9283\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5792 - val_loss: 21.9064\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6548 - val_loss: 21.8843\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5580 - val_loss: 21.8629\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5995 - val_loss: 21.8432\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6233 - val_loss: 21.8238\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5290 - val_loss: 21.8055\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5668 - val_loss: 21.7861\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5878 - val_loss: 21.7684\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5213 - val_loss: 21.7513\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5476 - val_loss: 21.7340\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5367 - val_loss: 21.7177\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5242 - val_loss: 21.7011\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5194 - val_loss: 21.6848\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5005 - val_loss: 21.6689\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4798 - val_loss: 21.6531\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4746 - val_loss: 21.6372\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4290 - val_loss: 21.6220\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4358 - val_loss: 21.6062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4375 - val_loss: 21.5906\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4085 - val_loss: 21.5759\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3820 - val_loss: 21.5607\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3642 - val_loss: 21.5462\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3660 - val_loss: 21.5311\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3716 - val_loss: 21.5166\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3577 - val_loss: 21.5021\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3437 - val_loss: 21.4864\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3216 - val_loss: 21.4714\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9201 - val_loss: 21.4572\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3019 - val_loss: 21.4428\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2624 - val_loss: 21.4275\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1140 - val_loss: 21.4128\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2568 - val_loss: 21.3973\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2087 - val_loss: 21.3825\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1547 - val_loss: 21.3681\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1104 - val_loss: 21.3534\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2024 - val_loss: 21.3381\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0695 - val_loss: 21.3226\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1264 - val_loss: 21.3076\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1610 - val_loss: 21.2918\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1449 - val_loss: 21.2771\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0702 - val_loss: 21.2625\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1253 - val_loss: 21.2471\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0696 - val_loss: 21.2329\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0537 - val_loss: 21.2179\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7989 - val_loss: 21.2029\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9738 - val_loss: 21.1889\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0569 - val_loss: 21.1739\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0009 - val_loss: 21.1585\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9603 - val_loss: 21.1432\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9511 - val_loss: 21.1278\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9777 - val_loss: 21.1124\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9756 - val_loss: 21.0968\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6368 - val_loss: 21.0829\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9349 - val_loss: 21.0684\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9351 - val_loss: 21.0530\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9177 - val_loss: 21.0378\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 3s 16ms/step - loss: 25.9114 - val_loss: 24.5921\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9101 - val_loss: 23.6881\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9603 - val_loss: 23.0419\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2928 - val_loss: 22.4894\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6498 - val_loss: 22.0256\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1607 - val_loss: 21.6038\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5952 - val_loss: 21.2123\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2141 - val_loss: 20.8696\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8107 - val_loss: 20.5695\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5168 - val_loss: 20.3231\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1742 - val_loss: 20.1294\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9609 - val_loss: 19.9716\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7604 - val_loss: 19.8300\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4301 - val_loss: 19.7224\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3947 - val_loss: 19.6342\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2691 - val_loss: 19.5511\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1198 - val_loss: 19.4729\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0388 - val_loss: 19.3965\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8921 - val_loss: 19.3209\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8639 - val_loss: 19.2526\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7050 - val_loss: 19.1937\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6936 - val_loss: 19.1421\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6467 - val_loss: 19.0946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6236 - val_loss: 19.0491\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5707 - val_loss: 19.0062\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5410 - val_loss: 18.9710\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4816 - val_loss: 18.9429\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4902 - val_loss: 18.9177\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4632 - val_loss: 18.8931\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4228 - val_loss: 18.8692\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3987 - val_loss: 18.8461\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3472 - val_loss: 18.8245\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3118 - val_loss: 18.8032\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3400 - val_loss: 18.7831\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2798 - val_loss: 18.7636\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2953 - val_loss: 18.7445\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2904 - val_loss: 18.7260\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2682 - val_loss: 18.7084\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2481 - val_loss: 18.6911\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2344 - val_loss: 18.6740\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2388 - val_loss: 18.6560\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1929 - val_loss: 18.6390\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1307 - val_loss: 18.6224\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1926 - val_loss: 18.6060\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1663 - val_loss: 18.5901\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1386 - val_loss: 18.5744\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0680 - val_loss: 18.5588\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1358 - val_loss: 18.5432\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1215 - val_loss: 18.5279\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1094 - val_loss: 18.5130\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0934 - val_loss: 18.4972\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0660 - val_loss: 18.4820\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0744 - val_loss: 18.4663\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0579 - val_loss: 18.4514\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0521 - val_loss: 18.4363\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0379 - val_loss: 18.4215\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0234 - val_loss: 18.4071\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9188 - val_loss: 18.3923\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9916 - val_loss: 18.3778\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9820 - val_loss: 18.3632\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9555 - val_loss: 18.3487\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9371 - val_loss: 18.3343\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9383 - val_loss: 18.3193\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9144 - val_loss: 18.3043\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7875 - val_loss: 18.2901\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7874 - val_loss: 18.2756\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8884 - val_loss: 18.2604\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8330 - val_loss: 18.2456\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8574 - val_loss: 18.2308\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8417 - val_loss: 18.2154\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8088 - val_loss: 18.2002\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7597 - val_loss: 18.1860\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7979 - val_loss: 18.1713\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7573 - val_loss: 18.1565\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7759 - val_loss: 18.1415\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6884 - val_loss: 18.1267\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7152 - val_loss: 18.1114\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7334 - val_loss: 18.0969\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7220 - val_loss: 18.0816\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6843 - val_loss: 18.0675\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6676 - val_loss: 18.0524\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6526 - val_loss: 18.0376\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6160 - val_loss: 18.0228\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6561 - val_loss: 18.0077\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6367 - val_loss: 17.9923\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6220 - val_loss: 17.9767\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6092 - val_loss: 17.9616\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5780 - val_loss: 17.9465\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5378 - val_loss: 17.9319\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5396 - val_loss: 17.9171\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4630 - val_loss: 17.9025\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5291 - val_loss: 17.8875\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4269 - val_loss: 17.8730\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5051 - val_loss: 17.8578\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4610 - val_loss: 17.8432\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4697 - val_loss: 17.8280\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4529 - val_loss: 17.8126\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4248 - val_loss: 17.7973\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4287 - val_loss: 17.7815\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.3826 - val_loss: 17.7665\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_4 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 7, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1419\n",
      "Model:                       QuantReg   Bandwidth:                    0.005913\n",
      "Method:                 Least Squares   Sparsity:                       0.1974\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:31:05   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0039      0.007      0.545      0.586      -0.010       0.018\n",
      "three_month_yield_change     -0.0903      0.169     -0.533      0.594      -0.423       0.242\n",
      "term_spread_change           -0.1354      0.158     -0.857      0.392      -0.445       0.174\n",
      "TED_spread                   -0.9915      0.676     -1.466      0.143      -2.318       0.335\n",
      "credit_spread_change          0.5070      0.260      1.951      0.051      -0.002       1.016\n",
      "market_return                -0.1400      0.112     -1.248      0.212      -0.360       0.080\n",
      "real_estate_excess_return     0.2139      0.123      1.739      0.082      -0.027       0.455\n",
      "equity_volatility             2.2885      0.199     11.471      0.000       1.897       2.680\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2079\n",
      "Model:                       QuantReg   Bandwidth:                    0.009454\n",
      "Method:                 Least Squares   Sparsity:                       0.6486\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:31:05   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0245      0.010      2.430      0.015       0.005       0.044\n",
      "three_month_yield_change      0.1387      0.258      0.539      0.590      -0.366       0.644\n",
      "term_spread_change           -0.0869      0.287     -0.303      0.762      -0.650       0.476\n",
      "TED_spread                   -1.2589      1.164     -1.082      0.279      -3.541       1.023\n",
      "credit_spread_change         -0.2794      0.392     -0.712      0.477      -1.049       0.490\n",
      "market_return                -0.1299      0.246     -0.528      0.597      -0.612       0.352\n",
      "real_estate_excess_return     0.3453      0.199      1.732      0.083      -0.046       0.736\n",
      "equity_volatility             4.0836      0.373     10.940      0.000       3.352       4.816\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3992\n",
      "Model:                       QuantReg   Bandwidth:                    0.002015\n",
      "Method:                 Least Squares   Sparsity:                      0.07744\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:31:06   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0126      0.003      4.783      0.000       0.007       0.018\n",
      "three_month_yield_change     -0.1202      0.081     -1.490      0.136      -0.278       0.038\n",
      "term_spread_change           -0.1392      0.070     -1.994      0.046      -0.276      -0.002\n",
      "TED_spread                   -0.2101      0.270     -0.778      0.437      -0.740       0.320\n",
      "credit_spread_change         -0.1412      0.084     -1.681      0.093      -0.306       0.024\n",
      "market_return                 0.0105      0.040      0.260      0.795      -0.069       0.089\n",
      "real_estate_excess_return    -0.0294      0.043     -0.682      0.495      -0.114       0.055\n",
      "equity_volatility             0.6866      0.077      8.926      0.000       0.536       0.837\n",
      "institution                   0.3513      0.029     12.244      0.000       0.295       0.408\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5184\n",
      "Model:                       QuantReg   Bandwidth:                    0.003578\n",
      "Method:                 Least Squares   Sparsity:                       0.3796\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:31:06   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0188      0.005      3.816      0.000       0.009       0.028\n",
      "three_month_yield_change     -0.2977      0.176     -1.691      0.091      -0.643       0.048\n",
      "term_spread_change           -0.3452      0.167     -2.063      0.039      -0.673      -0.017\n",
      "TED_spread                    0.0677      0.684      0.099      0.921      -1.273       1.408\n",
      "credit_spread_change         -0.1418      0.161     -0.880      0.379      -0.458       0.174\n",
      "market_return                -0.0597      0.147     -0.406      0.684      -0.348       0.228\n",
      "real_estate_excess_return    -0.1588      0.104     -1.532      0.126      -0.362       0.044\n",
      "equity_volatility             1.4015      0.252      5.566      0.000       0.908       1.895\n",
      "institution                   0.3700      0.093      3.979      0.000       0.188       0.552\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 42.6223 - val_loss: 37.9528\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 42.0267 - val_loss: 37.3122\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 41.0494 - val_loss: 36.2246\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 39.6218 - val_loss: 35.0584\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 38.3700 - val_loss: 33.8338\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 36.8540 - val_loss: 32.6685\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 35.2468 - val_loss: 31.4635\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.7176 - val_loss: 30.2796\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.1962 - val_loss: 29.1866\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.8383 - val_loss: 28.2658\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.6648 - val_loss: 27.4266\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.5780 - val_loss: 26.6660\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.8920 - val_loss: 25.9975\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.0976 - val_loss: 25.4379\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4050 - val_loss: 25.0112\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0095 - val_loss: 24.7519\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6342 - val_loss: 24.5382\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.0866 - val_loss: 24.3422\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.0301 - val_loss: 24.1936\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9239 - val_loss: 24.0620\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.7542 - val_loss: 23.9440\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6311 - val_loss: 23.8453\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.5296 - val_loss: 23.7739\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3448 - val_loss: 23.7229\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3908 - val_loss: 23.6904\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3284 - val_loss: 23.6633\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2672 - val_loss: 23.6392\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1894 - val_loss: 23.6164\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0974 - val_loss: 23.5947\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1118 - val_loss: 23.5762\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0008 - val_loss: 23.5643\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0667 - val_loss: 23.5533\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0444 - val_loss: 23.5423\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8084 - val_loss: 23.5313\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9863 - val_loss: 23.5202\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9570 - val_loss: 23.5090\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9838 - val_loss: 23.4977\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9212 - val_loss: 23.4864\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8989 - val_loss: 23.4750\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8839 - val_loss: 23.4635\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7875 - val_loss: 23.4519\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8812 - val_loss: 23.4402\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8610 - val_loss: 23.4284\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7559 - val_loss: 23.4166\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6655 - val_loss: 23.4047\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8065 - val_loss: 23.3928\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7982 - val_loss: 23.3815\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7466 - val_loss: 23.3715\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6986 - val_loss: 23.3621\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6970 - val_loss: 23.3531\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7152 - val_loss: 23.3441\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6620 - val_loss: 23.3347\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6909 - val_loss: 23.3249\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6066 - val_loss: 23.3148\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6751 - val_loss: 23.3048\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6661 - val_loss: 23.2945\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6505 - val_loss: 23.2838\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6199 - val_loss: 23.2726\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6229 - val_loss: 23.2615\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4804 - val_loss: 23.2503\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2826 - val_loss: 23.2390\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5524 - val_loss: 23.2273\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5581 - val_loss: 23.2157\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5477 - val_loss: 23.2039\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5444 - val_loss: 23.1921\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5257 - val_loss: 23.1801\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5022 - val_loss: 23.1680\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2271 - val_loss: 23.1557\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4483 - val_loss: 23.1433\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4424 - val_loss: 23.1308\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4590 - val_loss: 23.1185\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4028 - val_loss: 23.1058\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3612 - val_loss: 23.0928\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1966 - val_loss: 23.0799\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3881 - val_loss: 23.0669\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3861 - val_loss: 23.0537\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3606 - val_loss: 23.0405\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3039 - val_loss: 23.0270\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3424 - val_loss: 23.0137\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9705 - val_loss: 22.9999\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2677 - val_loss: 22.9861\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2885 - val_loss: 22.9724\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2425 - val_loss: 22.9585\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2516 - val_loss: 22.9445\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2124 - val_loss: 22.9307\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1658 - val_loss: 22.9164\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2159 - val_loss: 22.9025\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1599 - val_loss: 22.8885\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1903 - val_loss: 22.8744\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1695 - val_loss: 22.8602\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1680 - val_loss: 22.8458\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1273 - val_loss: 22.8316\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7920 - val_loss: 22.8171\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0723 - val_loss: 22.8025\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0994 - val_loss: 22.7878\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0188 - val_loss: 22.7734\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0746 - val_loss: 22.7588\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0455 - val_loss: 22.7442\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5538 - val_loss: 22.7291\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0240 - val_loss: 22.7143\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 25.6098 - val_loss: 24.5165\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0424 - val_loss: 23.9489\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4047 - val_loss: 23.4007\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7027 - val_loss: 22.8918\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1273 - val_loss: 22.3745\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4599 - val_loss: 21.9145\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0026 - val_loss: 21.4933\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5315 - val_loss: 21.0948\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9847 - val_loss: 20.7636\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6302 - val_loss: 20.4629\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3044 - val_loss: 20.2388\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1045 - val_loss: 20.0637\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8590 - val_loss: 19.9049\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5931 - val_loss: 19.7803\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4548 - val_loss: 19.6834\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3119 - val_loss: 19.5937\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0844 - val_loss: 19.5114\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0678 - val_loss: 19.4304\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9524 - val_loss: 19.3531\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8906 - val_loss: 19.2830\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7898 - val_loss: 19.2256\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6823 - val_loss: 19.1737\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6773 - val_loss: 19.1256\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6077 - val_loss: 19.0816\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5509 - val_loss: 19.0391\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5740 - val_loss: 19.0047\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4989 - val_loss: 18.9775\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4850 - val_loss: 18.9515\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4289 - val_loss: 18.9275\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3140 - val_loss: 18.9043\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4403 - val_loss: 18.8822\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4159 - val_loss: 18.8612\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3957 - val_loss: 18.8407\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3797 - val_loss: 18.8210\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3565 - val_loss: 18.8016\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2021 - val_loss: 18.7841\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2726 - val_loss: 18.7664\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3070 - val_loss: 18.7488\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3048 - val_loss: 18.7309\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2901 - val_loss: 18.7137\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2764 - val_loss: 18.6966\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2528 - val_loss: 18.6802\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2463 - val_loss: 18.6643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2313 - val_loss: 18.6481\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2040 - val_loss: 18.6324\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2099 - val_loss: 18.6162\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1987 - val_loss: 18.6011\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1794 - val_loss: 18.5863\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1696 - val_loss: 18.5715\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1502 - val_loss: 18.5574\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1452 - val_loss: 18.5439\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1344 - val_loss: 18.5298\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1219 - val_loss: 18.5158\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1107 - val_loss: 18.5022\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0786 - val_loss: 18.4886\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9529 - val_loss: 18.4759\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0453 - val_loss: 18.4621\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0615 - val_loss: 18.4485\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0311 - val_loss: 18.4347\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0005 - val_loss: 18.4211\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0034 - val_loss: 18.4074\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0101 - val_loss: 18.3936\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9927 - val_loss: 18.3798\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9505 - val_loss: 18.3665\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9757 - val_loss: 18.3524\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9582 - val_loss: 18.3389\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9180 - val_loss: 18.3262\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9354 - val_loss: 18.3124\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9224 - val_loss: 18.2985\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8764 - val_loss: 18.2851\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8267 - val_loss: 18.2718\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8810 - val_loss: 18.2575\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8389 - val_loss: 18.2435\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8014 - val_loss: 18.2299\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8249 - val_loss: 18.2158\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8282 - val_loss: 18.2019\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8212 - val_loss: 18.1870\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8031 - val_loss: 18.1730\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7976 - val_loss: 18.1589\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7618 - val_loss: 18.1443\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7452 - val_loss: 18.1303\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7395 - val_loss: 18.1160\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7404 - val_loss: 18.1015\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7035 - val_loss: 18.0874\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7109 - val_loss: 18.0727\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7001 - val_loss: 18.0580\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6825 - val_loss: 18.0432\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6670 - val_loss: 18.0286\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6210 - val_loss: 18.0146\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6319 - val_loss: 18.0005\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6183 - val_loss: 17.9862\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6086 - val_loss: 17.9717\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6018 - val_loss: 17.9568\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5844 - val_loss: 17.9427\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5438 - val_loss: 17.9280\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5449 - val_loss: 17.9133\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5423 - val_loss: 17.8987\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5341 - val_loss: 17.8839\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4982 - val_loss: 17.8692\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4847 - val_loss: 17.8548\n",
      "4/4 [==============================] - 0s 429us/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 7, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1373\n",
      "Model:                       QuantReg   Bandwidth:                    0.005519\n",
      "Method:                 Least Squares   Sparsity:                       0.2016\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:02   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0013      0.007      0.181      0.856      -0.013       0.016\n",
      "three_month_yield_change     -0.0246      0.187     -0.132      0.895      -0.390       0.341\n",
      "term_spread_change           -0.0390      0.183     -0.213      0.832      -0.398       0.320\n",
      "TED_spread                   -0.5072      0.634     -0.800      0.424      -1.750       0.736\n",
      "credit_spread_change          0.4881      0.255      1.916      0.055      -0.011       0.987\n",
      "market_return                 0.0688      0.110      0.626      0.532      -0.147       0.284\n",
      "real_estate_excess_return     0.2281      0.126      1.805      0.071      -0.020       0.476\n",
      "equity_volatility             2.2618      0.180     12.594      0.000       1.910       2.614\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2531\n",
      "Model:                       QuantReg   Bandwidth:                    0.009704\n",
      "Method:                 Least Squares   Sparsity:                        1.114\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:02   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0142      0.017      0.850      0.396      -0.019       0.047\n",
      "three_month_yield_change      0.1044      0.458      0.228      0.820      -0.794       1.003\n",
      "term_spread_change           -0.1303      0.493     -0.264      0.792      -1.098       0.837\n",
      "TED_spread                   -2.1135      1.804     -1.172      0.241      -5.650       1.423\n",
      "credit_spread_change          0.2095      0.580      0.361      0.718      -0.928       1.347\n",
      "market_return                -0.0258      0.408     -0.063      0.950      -0.826       0.774\n",
      "real_estate_excess_return     0.2580      0.367      0.704      0.482      -0.461       0.977\n",
      "equity_volatility             4.9455      0.681      7.257      0.000       3.609       6.282\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4626\n",
      "Model:                       QuantReg   Bandwidth:                    0.001901\n",
      "Method:                 Least Squares   Sparsity:                      0.07013\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:02   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0121      0.003      4.731      0.000       0.007       0.017\n",
      "three_month_yield_change     -0.0672      0.074     -0.908      0.364      -0.212       0.078\n",
      "term_spread_change           -0.1498      0.066     -2.277      0.023      -0.279      -0.021\n",
      "TED_spread                   -0.6904      0.240     -2.882      0.004      -1.160      -0.221\n",
      "credit_spread_change         -0.0815      0.085     -0.954      0.340      -0.249       0.086\n",
      "market_return                -0.0531      0.034     -1.578      0.115      -0.119       0.013\n",
      "real_estate_excess_return    -0.0368      0.041     -0.898      0.369      -0.117       0.044\n",
      "equity_volatility             0.6240      0.066      9.423      0.000       0.494       0.754\n",
      "institution                   0.3683      0.024     15.274      0.000       0.321       0.416\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5812\n",
      "Model:                       QuantReg   Bandwidth:                    0.003085\n",
      "Method:                 Least Squares   Sparsity:                       0.2789\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:02   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0199      0.004      4.632      0.000       0.011       0.028\n",
      "three_month_yield_change     -0.1144      0.140     -0.818      0.414      -0.389       0.160\n",
      "term_spread_change           -0.3459      0.134     -2.588      0.010      -0.608      -0.084\n",
      "TED_spread                   -0.0991      0.588     -0.169      0.866      -1.252       1.054\n",
      "credit_spread_change         -0.1692      0.157     -1.076      0.282      -0.478       0.139\n",
      "market_return                -0.0700      0.092     -0.761      0.447      -0.251       0.110\n",
      "real_estate_excess_return    -0.1882      0.085     -2.218      0.027      -0.355      -0.022\n",
      "equity_volatility             0.9192      0.177      5.192      0.000       0.572       1.266\n",
      "institution                   0.3852      0.064      6.001      0.000       0.259       0.511\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 42.5354 - val_loss: 45.8822\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 41.1239 - val_loss: 44.3581\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 39.2517 - val_loss: 42.4839\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 37.2534 - val_loss: 40.5177\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 35.0933 - val_loss: 38.6508\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.4565 - val_loss: 37.0196\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.6740 - val_loss: 35.5287\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.0649 - val_loss: 34.2365\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.8804 - val_loss: 33.1215\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9644 - val_loss: 32.4232\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.1682 - val_loss: 31.8907\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.5117 - val_loss: 31.5092\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9726 - val_loss: 31.2331\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6132 - val_loss: 31.0252\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2775 - val_loss: 30.8304\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9879 - val_loss: 30.6553\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.8532 - val_loss: 30.5013\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6896 - val_loss: 30.3600\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6119 - val_loss: 30.2294\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4624 - val_loss: 30.1151\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2885 - val_loss: 30.0201\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2737 - val_loss: 29.9426\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3005 - val_loss: 29.8712\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2350 - val_loss: 29.8166\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1234 - val_loss: 29.7667\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9788 - val_loss: 29.7217\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1080 - val_loss: 29.6795\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9123 - val_loss: 29.6372\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0080 - val_loss: 29.5942\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9682 - val_loss: 29.5567\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8702 - val_loss: 29.5224\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5363 - val_loss: 29.4902\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9010 - val_loss: 29.4597\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9153 - val_loss: 29.4293\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7922 - val_loss: 29.4005\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8675 - val_loss: 29.3702\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8520 - val_loss: 29.3418\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7393 - val_loss: 29.3137\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.8329 - val_loss: 29.2888\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7834 - val_loss: 29.2651\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4955 - val_loss: 29.2414\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6568 - val_loss: 29.2209\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7662 - val_loss: 29.1998\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7475 - val_loss: 29.1786\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7207 - val_loss: 29.1594\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7165 - val_loss: 29.1403\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6578 - val_loss: 29.1217\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6968 - val_loss: 29.1016\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6644 - val_loss: 29.0835\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6729 - val_loss: 29.0650\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5631 - val_loss: 29.0481\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5657 - val_loss: 29.0317\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6321 - val_loss: 29.0158\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6268 - val_loss: 29.0004\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5675 - val_loss: 28.9851\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5438 - val_loss: 28.9694\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5314 - val_loss: 28.9549\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2539 - val_loss: 28.9407\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5530 - val_loss: 28.9258\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5448 - val_loss: 28.9115\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4026 - val_loss: 28.8972\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4979 - val_loss: 28.8830\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4570 - val_loss: 28.8696\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3353 - val_loss: 28.8566\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4768 - val_loss: 28.8430\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4670 - val_loss: 28.8285\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4487 - val_loss: 28.8144\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4349 - val_loss: 28.8007\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4101 - val_loss: 28.7860\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3667 - val_loss: 28.7724\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3966 - val_loss: 28.7577\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3712 - val_loss: 28.7436\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2618 - val_loss: 28.7302\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3469 - val_loss: 28.7172\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3521 - val_loss: 28.7030\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2554 - val_loss: 28.6893\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2686 - val_loss: 28.6758\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2982 - val_loss: 28.6615\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2866 - val_loss: 28.6476\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2608 - val_loss: 28.6332\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2587 - val_loss: 28.6186\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2031 - val_loss: 28.6040\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2124 - val_loss: 28.5884\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0893 - val_loss: 28.5758\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1970 - val_loss: 28.5611\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1880 - val_loss: 28.5460\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1407 - val_loss: 28.5314\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1662 - val_loss: 28.5170\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1400 - val_loss: 28.5024\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1164 - val_loss: 28.4879\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0900 - val_loss: 28.4729\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0575 - val_loss: 28.4586\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0359 - val_loss: 28.4436\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0467 - val_loss: 28.4278\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0393 - val_loss: 28.4134\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9260 - val_loss: 28.3993\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9223 - val_loss: 28.3855\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0096 - val_loss: 28.3710\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8672 - val_loss: 28.3560\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9917 - val_loss: 28.3404\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_42 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 25.6900 - val_loss: 24.4325\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9297 - val_loss: 23.8625\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2906 - val_loss: 23.3939\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7688 - val_loss: 22.9730\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1666 - val_loss: 22.5835\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8884 - val_loss: 22.2317\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4119 - val_loss: 21.9189\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8447 - val_loss: 21.6187\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6767 - val_loss: 21.3291\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3650 - val_loss: 21.0541\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0348 - val_loss: 20.8025\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7993 - val_loss: 20.5669\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5099 - val_loss: 20.3659\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3084 - val_loss: 20.1970\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9818 - val_loss: 20.0568\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8540 - val_loss: 19.9323\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6327 - val_loss: 19.8168\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5705 - val_loss: 19.7231\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4058 - val_loss: 19.6449\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1266 - val_loss: 19.5696\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1631 - val_loss: 19.4972\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0101 - val_loss: 19.4287\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9005 - val_loss: 19.3631\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8904 - val_loss: 19.2969\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8238 - val_loss: 19.2352\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7536 - val_loss: 19.1823\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6512 - val_loss: 19.1337\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6246 - val_loss: 19.0884\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6090 - val_loss: 19.0467\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4811 - val_loss: 19.0080\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5437 - val_loss: 18.9694\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5093 - val_loss: 18.9366\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4431 - val_loss: 18.9082\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4554 - val_loss: 18.8826\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4210 - val_loss: 18.8584\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4000 - val_loss: 18.8352\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3617 - val_loss: 18.8131\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2859 - val_loss: 18.7914\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2951 - val_loss: 18.7705\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3133 - val_loss: 18.7499\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2943 - val_loss: 18.7300\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2605 - val_loss: 18.7105\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2529 - val_loss: 18.6917\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2378 - val_loss: 18.6724\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1781 - val_loss: 18.6548\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0957 - val_loss: 18.6380\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1984 - val_loss: 18.6213\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1666 - val_loss: 18.6050\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1603 - val_loss: 18.5885\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1488 - val_loss: 18.5722\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1332 - val_loss: 18.5561\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1345 - val_loss: 18.5400\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0941 - val_loss: 18.5242\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1031 - val_loss: 18.5087\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9450 - val_loss: 18.4943\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0786 - val_loss: 18.4794\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0569 - val_loss: 18.4640\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0586 - val_loss: 18.4486\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0486 - val_loss: 18.4339\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0270 - val_loss: 18.4196\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0217 - val_loss: 18.4046\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9966 - val_loss: 18.3901\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9778 - val_loss: 18.3760\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8936 - val_loss: 18.3621\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8931 - val_loss: 18.3480\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9240 - val_loss: 18.3341\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9249 - val_loss: 18.3201\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9238 - val_loss: 18.3072\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9237 - val_loss: 18.2928\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9082 - val_loss: 18.2786\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8806 - val_loss: 18.2665\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8787 - val_loss: 18.2525\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8726 - val_loss: 18.2380\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8487 - val_loss: 18.2243\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8398 - val_loss: 18.2100\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8377 - val_loss: 18.1959\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7840 - val_loss: 18.1821\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7773 - val_loss: 18.1677\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7259 - val_loss: 18.1543\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7762 - val_loss: 18.1399\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7611 - val_loss: 18.1259\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7530 - val_loss: 18.1116\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7390 - val_loss: 18.0967\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7097 - val_loss: 18.0831\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6874 - val_loss: 18.0690\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6983 - val_loss: 18.0545\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6848 - val_loss: 18.0410\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5102 - val_loss: 18.0271\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6583 - val_loss: 18.0128\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6468 - val_loss: 17.9990\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6201 - val_loss: 17.9857\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6107 - val_loss: 17.9723\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4838 - val_loss: 17.9588\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5893 - val_loss: 17.9444\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5627 - val_loss: 17.9303\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5589 - val_loss: 17.9156\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5415 - val_loss: 17.9013\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4223 - val_loss: 17.8884\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5214 - val_loss: 17.8742\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4848 - val_loss: 17.8595\n",
      "4/4 [==============================] - 1s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 7, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1373\n",
      "Model:                       QuantReg   Bandwidth:                    0.005932\n",
      "Method:                 Least Squares   Sparsity:                       0.1794\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0242      0.006      3.815      0.000       0.012       0.037\n",
      "three_month_yield_change     -0.1800      0.164     -1.098      0.272      -0.501       0.141\n",
      "term_spread_change           -0.6535      0.155     -4.222      0.000      -0.957      -0.350\n",
      "TED_spread                   -1.8725      0.680     -2.755      0.006      -3.205      -0.540\n",
      "credit_spread_change          0.1695      0.232      0.730      0.466      -0.286       0.625\n",
      "market_return                 0.2155      0.110      1.966      0.049       0.001       0.430\n",
      "real_estate_excess_return     0.4149      0.114      3.630      0.000       0.191       0.639\n",
      "equity_volatility             2.1010      0.188     11.176      0.000       1.732       2.470\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2525\n",
      "Model:                       QuantReg   Bandwidth:                    0.009917\n",
      "Method:                 Least Squares   Sparsity:                        1.052\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0782      0.017      4.729      0.000       0.046       0.111\n",
      "three_month_yield_change     -1.6595      0.457     -3.631      0.000      -2.556      -0.763\n",
      "term_spread_change           -2.1920      0.440     -4.983      0.000      -3.055      -1.329\n",
      "TED_spread                    1.0894      1.952      0.558      0.577      -2.739       4.918\n",
      "credit_spread_change         -0.2818      0.542     -0.520      0.603      -1.344       0.781\n",
      "market_return                 0.2706      0.378      0.717      0.474      -0.470       1.011\n",
      "real_estate_excess_return     0.3953      0.332      1.190      0.234      -0.256       1.046\n",
      "equity_volatility             3.0882      0.602      5.129      0.000       1.908       4.269\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_99 27\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3986\n",
      "Model:                       QuantReg   Bandwidth:                    0.002223\n",
      "Method:                 Least Squares   Sparsity:                      0.07275\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0138      0.003      5.422      0.000       0.009       0.019\n",
      "three_month_yield_change     -0.1574      0.074     -2.113      0.035      -0.303      -0.011\n",
      "term_spread_change           -0.2334      0.069     -3.387      0.001      -0.368      -0.098\n",
      "TED_spread                   -0.5072      0.266     -1.904      0.057      -1.029       0.015\n",
      "credit_spread_change         -0.1100      0.088     -1.244      0.214      -0.283       0.063\n",
      "market_return                -0.0266      0.036     -0.748      0.454      -0.096       0.043\n",
      "real_estate_excess_return    -0.0591      0.044     -1.339      0.181      -0.146       0.027\n",
      "equity_volatility             0.8186      0.071     11.603      0.000       0.680       0.957\n",
      "institution                   0.3481      0.024     14.272      0.000       0.300       0.396\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5110\n",
      "Model:                       QuantReg   Bandwidth:                    0.003859\n",
      "Method:                 Least Squares   Sparsity:                       0.2558\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:32:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0318      0.003      9.183      0.000       0.025       0.039\n",
      "three_month_yield_change     -0.5414      0.131     -4.129      0.000      -0.798      -0.284\n",
      "term_spread_change           -0.4764      0.113     -4.224      0.000      -0.698      -0.255\n",
      "TED_spread                   -0.5762      0.461     -1.249      0.212      -1.481       0.329\n",
      "credit_spread_change         -0.5319      0.117     -4.534      0.000      -0.762      -0.302\n",
      "market_return                -0.2290      0.094     -2.442      0.015      -0.413      -0.045\n",
      "real_estate_excess_return    -0.1816      0.091     -2.000      0.046      -0.360      -0.004\n",
      "equity_volatility             1.4921      0.154      9.686      0.000       1.190       1.794\n",
      "institution                   0.3710      0.064      5.794      0.000       0.245       0.497\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 41.1218 - val_loss: 40.0367\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 40.1731 - val_loss: 39.2100\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 39.4815 - val_loss: 38.4409\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 38.7325 - val_loss: 37.5018\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 37.7130 - val_loss: 36.3336\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 36.4839 - val_loss: 34.9424\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 34.8177 - val_loss: 33.2372\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 33.1326 - val_loss: 31.2802\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 31.3024 - val_loss: 29.2196\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 29.4703 - val_loss: 27.5168\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 27.9051 - val_loss: 26.2023\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 26.6595 - val_loss: 25.1969\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 25.7969 - val_loss: 24.6105\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.9735 - val_loss: 24.2123\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.7475 - val_loss: 23.8415\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.4090 - val_loss: 23.5395\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.1459 - val_loss: 23.3359\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.8952 - val_loss: 23.1947\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.8420 - val_loss: 23.0864\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.7673 - val_loss: 23.0117\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.6924 - val_loss: 22.9519\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.6150 - val_loss: 22.9094\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4126 - val_loss: 22.8751\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4975 - val_loss: 22.8464\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3542 - val_loss: 22.8205\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4091 - val_loss: 22.7978\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3728 - val_loss: 22.7779\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4730 - val_loss: 22.7589\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3603 - val_loss: 22.7417\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4507 - val_loss: 22.7255\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4360 - val_loss: 22.7116\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4097 - val_loss: 22.6981\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4170 - val_loss: 22.6848\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3304 - val_loss: 22.6721\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4040 - val_loss: 22.6598\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3903 - val_loss: 22.6476\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3773 - val_loss: 22.6353\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1858 - val_loss: 22.6230\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3421 - val_loss: 22.6106\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3102 - val_loss: 22.5981\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.3036 - val_loss: 22.5861\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2188 - val_loss: 22.5742\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1563 - val_loss: 22.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2191 - val_loss: 22.5504\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2920 - val_loss: 22.5382\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2313 - val_loss: 22.5262\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2362 - val_loss: 22.5142\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0926 - val_loss: 22.5024\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2366 - val_loss: 22.4908\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1485 - val_loss: 22.4792\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.2288 - val_loss: 22.4666\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1055 - val_loss: 22.4549\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1891 - val_loss: 22.4427\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9858 - val_loss: 22.4302\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0912 - val_loss: 22.4180\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1642 - val_loss: 22.4055\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1590 - val_loss: 22.3930\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1365 - val_loss: 22.3804\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1235 - val_loss: 22.3677\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.1007 - val_loss: 22.3549\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0464 - val_loss: 22.3421\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0939 - val_loss: 22.3294\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0783 - val_loss: 22.3162\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0598 - val_loss: 22.3034\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9286 - val_loss: 22.2908\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0304 - val_loss: 22.2778\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0321 - val_loss: 22.2648\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.0194 - val_loss: 22.2514\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9719 - val_loss: 22.2384\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8971 - val_loss: 22.2257\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9620 - val_loss: 22.2125\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8734 - val_loss: 22.1993\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9383 - val_loss: 22.1862\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9040 - val_loss: 22.1730\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9241 - val_loss: 22.1592\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9078 - val_loss: 22.1456\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8426 - val_loss: 22.1321\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8836 - val_loss: 22.1184\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8386 - val_loss: 22.1049\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7620 - val_loss: 22.0914\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.8264 - val_loss: 22.0777\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7364 - val_loss: 22.0638\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7549 - val_loss: 22.0502\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7531 - val_loss: 22.0365\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7763 - val_loss: 22.0225\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7762 - val_loss: 22.0083\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7655 - val_loss: 21.9943\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6548 - val_loss: 21.9804\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6561 - val_loss: 21.9663\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7187 - val_loss: 21.9519\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.7033 - val_loss: 21.9377\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6820 - val_loss: 21.9234\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6692 - val_loss: 21.9088\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.5432 - val_loss: 21.8949\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6214 - val_loss: 21.8804\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6116 - val_loss: 21.8657\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6117 - val_loss: 21.8511\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.6067 - val_loss: 21.8366\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.5990 - val_loss: 21.8221\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.4464 - val_loss: 21.8079\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_60 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_62 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 22ms/step - loss: 25.7868 - val_loss: 24.5450\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.8952 - val_loss: 23.7086\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.9057 - val_loss: 22.8602\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.9875 - val_loss: 22.1623\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1750 - val_loss: 21.5911\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5205 - val_loss: 21.0696\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9819 - val_loss: 20.6400\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5278 - val_loss: 20.3192\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.1590 - val_loss: 20.0869\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.8361 - val_loss: 19.8960\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.5726 - val_loss: 19.7684\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.3287 - val_loss: 19.6526\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.1623 - val_loss: 19.5482\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9749 - val_loss: 19.4474\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9589 - val_loss: 19.3601\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8776 - val_loss: 19.2911\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7980 - val_loss: 19.2287\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7542 - val_loss: 19.1703\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7051 - val_loss: 19.1214\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6406 - val_loss: 19.0855\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5815 - val_loss: 19.0556\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5130 - val_loss: 19.0288\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5105 - val_loss: 19.0054\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.5183 - val_loss: 18.9830\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4924 - val_loss: 18.9621\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4583 - val_loss: 18.9415\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4881 - val_loss: 18.9213\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4759 - val_loss: 18.9038\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4363 - val_loss: 18.8857\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4412 - val_loss: 18.8672\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4303 - val_loss: 18.8491\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4058 - val_loss: 18.8323\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3951 - val_loss: 18.8158\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3221 - val_loss: 18.7998\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3278 - val_loss: 18.7839\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2720 - val_loss: 18.7678\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3129 - val_loss: 18.7521\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3321 - val_loss: 18.7368\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3179 - val_loss: 18.7211\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3061 - val_loss: 18.7057\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2733 - val_loss: 18.6909\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2575 - val_loss: 18.6768\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1809 - val_loss: 18.6626\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2541 - val_loss: 18.6480\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2124 - val_loss: 18.6336\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1866 - val_loss: 18.6192\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1059 - val_loss: 18.6053\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1634 - val_loss: 18.5917\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1919 - val_loss: 18.5770\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1586 - val_loss: 18.5630\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.1677 - val_loss: 18.5497\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.1259 - val_loss: 18.5361\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.1179 - val_loss: 18.5220\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1158 - val_loss: 18.5077\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0931 - val_loss: 18.4943\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.1097 - val_loss: 18.4798\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0653 - val_loss: 18.4657\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0627 - val_loss: 18.4511\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0473 - val_loss: 18.4372\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0367 - val_loss: 18.4228\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0436 - val_loss: 18.4088\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9887 - val_loss: 18.3950\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0145 - val_loss: 18.3810\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9987 - val_loss: 18.3669\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9607 - val_loss: 18.3531\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9241 - val_loss: 18.3388\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9468 - val_loss: 18.3253\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9408 - val_loss: 18.3108\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9368 - val_loss: 18.2964\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9026 - val_loss: 18.2820\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8977 - val_loss: 18.2684\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8950 - val_loss: 18.2537\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8806 - val_loss: 18.2391\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8429 - val_loss: 18.2250\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8469 - val_loss: 18.2105\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8191 - val_loss: 18.1961\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8205 - val_loss: 18.1812\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7667 - val_loss: 18.1678\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7947 - val_loss: 18.1528\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7858 - val_loss: 18.1379\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7690 - val_loss: 18.1233\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7237 - val_loss: 18.1085\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7368 - val_loss: 18.0934\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7164 - val_loss: 18.0795\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6783 - val_loss: 18.0653\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6967 - val_loss: 18.0500\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6659 - val_loss: 18.0350\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6199 - val_loss: 18.0201\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6372 - val_loss: 18.0054\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6421 - val_loss: 17.9902\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5646 - val_loss: 17.9756\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5504 - val_loss: 17.9606\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5809 - val_loss: 17.9454\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5708 - val_loss: 17.9303\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5645 - val_loss: 17.9143\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5172 - val_loss: 17.8996\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5331 - val_loss: 17.8842\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5057 - val_loss: 17.8684\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4703 - val_loss: 17.8531\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4561 - val_loss: 17.8380\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_64 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_66 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_67 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_68 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 7, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1340\n",
      "Model:                       QuantReg   Bandwidth:                    0.005540\n",
      "Method:                 Least Squares   Sparsity:                       0.2108\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:34:25   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0212      0.008      2.774      0.006       0.006       0.036\n",
      "three_month_yield_change     -0.3037      0.207     -1.465      0.143      -0.710       0.103\n",
      "term_spread_change           -0.5314      0.184     -2.884      0.004      -0.893      -0.170\n",
      "TED_spread                   -0.6756      0.805     -0.839      0.401      -2.254       0.903\n",
      "credit_spread_change          0.0483      0.274      0.176      0.860      -0.488       0.585\n",
      "market_return                -0.0594      0.115     -0.516      0.606      -0.285       0.166\n",
      "real_estate_excess_return     0.1107      0.128      0.864      0.388      -0.141       0.362\n",
      "equity_volatility             2.2125      0.211     10.496      0.000       1.799       2.626\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2228\n",
      "Model:                       QuantReg   Bandwidth:                    0.009170\n",
      "Method:                 Least Squares   Sparsity:                        1.025\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:34:26   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0765      0.018      4.187      0.000       0.041       0.112\n",
      "three_month_yield_change     -1.4413      0.552     -2.609      0.009      -2.525      -0.358\n",
      "term_spread_change           -1.6142      0.498     -3.241      0.001      -2.591      -0.638\n",
      "TED_spread                   -1.9493      1.981     -0.984      0.325      -5.835       1.936\n",
      "credit_spread_change         -0.2374      0.619     -0.383      0.702      -1.452       0.977\n",
      "market_return                 0.1765      0.280      0.629      0.529      -0.373       0.726\n",
      "real_estate_excess_return     0.1125      0.412      0.273      0.785      -0.694       0.919\n",
      "equity_volatility             2.7146      0.492      5.513      0.000       1.749       3.680\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3852\n",
      "Model:                       QuantReg   Bandwidth:                    0.002190\n",
      "Method:                 Least Squares   Sparsity:                      0.07399\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:34:26   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.002      3.809      0.000       0.005       0.014\n",
      "three_month_yield_change     -0.0401      0.074     -0.541      0.588      -0.185       0.105\n",
      "term_spread_change           -0.1662      0.069     -2.394      0.017      -0.302      -0.030\n",
      "TED_spread                   -0.6474      0.271     -2.390      0.017      -1.178      -0.116\n",
      "credit_spread_change         -0.0154      0.085     -0.181      0.856      -0.182       0.151\n",
      "market_return                -0.0833      0.037     -2.239      0.025      -0.156      -0.010\n",
      "real_estate_excess_return    -0.0127      0.045     -0.284      0.777      -0.100       0.075\n",
      "equity_volatility             0.8036      0.069     11.684      0.000       0.669       0.939\n",
      "institution                   0.3530      0.026     13.663      0.000       0.302       0.404\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4782\n",
      "Model:                       QuantReg   Bandwidth:                    0.004156\n",
      "Method:                 Least Squares   Sparsity:                       0.3351\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:34:26   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0330      0.005      6.485      0.000       0.023       0.043\n",
      "three_month_yield_change     -0.4524      0.151     -2.997      0.003      -0.748      -0.156\n",
      "term_spread_change           -0.3872      0.163     -2.380      0.017      -0.706      -0.068\n",
      "TED_spread                   -1.2260      0.687     -1.784      0.074      -2.573       0.121\n",
      "credit_spread_change         -0.6285      0.167     -3.759      0.000      -0.956      -0.301\n",
      "market_return                -0.0642      0.130     -0.492      0.623      -0.320       0.191\n",
      "real_estate_excess_return    -0.2479      0.103     -2.403      0.016      -0.450      -0.046\n",
      "equity_volatility             1.7867      0.200      8.914      0.000       1.394       2.180\n",
      "institution                   0.3612      0.087      4.162      0.000       0.191       0.531\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 19ms/step - loss: 36.0448 - val_loss: 32.8467\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.4059 - val_loss: 32.2304\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 34.6202 - val_loss: 31.6163\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.7504 - val_loss: 31.0052\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.2272 - val_loss: 30.4034\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.3332 - val_loss: 29.7867\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.7762 - val_loss: 29.1317\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.8822 - val_loss: 28.4861\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 30.2202 - val_loss: 27.8418\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.3983 - val_loss: 27.1938\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.5869 - val_loss: 26.5296\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.6342 - val_loss: 25.8922\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.8793 - val_loss: 25.2440\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.1127 - val_loss: 24.6163\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.5034 - val_loss: 24.0255\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.9451 - val_loss: 23.4847\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.4463 - val_loss: 23.0277\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.9437 - val_loss: 22.6855\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5842 - val_loss: 22.4418\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2238 - val_loss: 22.2668\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9258 - val_loss: 22.1630\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7071 - val_loss: 22.0713\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4359 - val_loss: 21.9934\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3699 - val_loss: 21.9330\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2251 - val_loss: 21.8816\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0082 - val_loss: 21.8460\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9616 - val_loss: 21.8139\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7718 - val_loss: 21.7830\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7832 - val_loss: 21.7536\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7864 - val_loss: 21.7267\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.6379 - val_loss: 21.7087\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4310 - val_loss: 21.6951\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.6122 - val_loss: 21.6823\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5708 - val_loss: 21.6697\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5147 - val_loss: 21.6572\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5283 - val_loss: 21.6446\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5092 - val_loss: 21.6323\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4616 - val_loss: 21.6199\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4041 - val_loss: 21.6075\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3082 - val_loss: 21.5950\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3673 - val_loss: 21.5826\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3660 - val_loss: 21.5700\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3566 - val_loss: 21.5576\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3151 - val_loss: 21.5451\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2950 - val_loss: 21.5326\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2956 - val_loss: 21.5201\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2420 - val_loss: 21.5076\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2465 - val_loss: 21.4960\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2122 - val_loss: 21.4855\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2173 - val_loss: 21.4752\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2192 - val_loss: 21.4650\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2050 - val_loss: 21.4549\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0897 - val_loss: 21.4451\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1757 - val_loss: 21.4353\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1701 - val_loss: 21.4246\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1539 - val_loss: 21.4139\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1313 - val_loss: 21.4034\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1186 - val_loss: 21.3926\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0882 - val_loss: 21.3817\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0914 - val_loss: 21.3707\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0586 - val_loss: 21.3592\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0066 - val_loss: 21.3477\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0667 - val_loss: 21.3361\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0386 - val_loss: 21.3244\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9412 - val_loss: 21.3126\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0122 - val_loss: 21.3005\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9988 - val_loss: 21.2884\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9821 - val_loss: 21.2763\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9717 - val_loss: 21.2640\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9471 - val_loss: 21.2513\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9417 - val_loss: 21.2384\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9321 - val_loss: 21.2257\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8144 - val_loss: 21.2126\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8199 - val_loss: 21.1996\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8989 - val_loss: 21.1864\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8319 - val_loss: 21.1731\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8218 - val_loss: 21.1600\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8625 - val_loss: 21.1469\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8020 - val_loss: 21.1335\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8021 - val_loss: 21.1198\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7354 - val_loss: 21.1065\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7981 - val_loss: 21.0929\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7189 - val_loss: 21.0792\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6654 - val_loss: 21.0655\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7554 - val_loss: 21.0518\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7393 - val_loss: 21.0382\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7378 - val_loss: 21.0245\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7227 - val_loss: 21.0103\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6624 - val_loss: 20.9963\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6881 - val_loss: 20.9825\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6503 - val_loss: 20.9680\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6052 - val_loss: 20.9539\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6305 - val_loss: 20.9398\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5300 - val_loss: 20.9255\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6113 - val_loss: 20.9109\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6010 - val_loss: 20.8967\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5385 - val_loss: 20.8822\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5819 - val_loss: 20.8678\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5610 - val_loss: 20.8536\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5191 - val_loss: 20.8391\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_70 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_74 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_76 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 26.2415 - val_loss: 24.9421\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.3675 - val_loss: 24.4458\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.0516 - val_loss: 24.0269\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5855 - val_loss: 23.6283\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0267 - val_loss: 23.2631\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6408 - val_loss: 22.9156\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2931 - val_loss: 22.5807\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7953 - val_loss: 22.2557\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4711 - val_loss: 21.9568\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1499 - val_loss: 21.6563\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8063 - val_loss: 21.3538\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4210 - val_loss: 21.0588\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0836 - val_loss: 20.7991\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8146 - val_loss: 20.5421\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4505 - val_loss: 20.3374\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2424 - val_loss: 20.1660\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9191 - val_loss: 20.0212\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7750 - val_loss: 19.8824\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5887 - val_loss: 19.7721\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4529 - val_loss: 19.6835\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2277 - val_loss: 19.5984\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1190 - val_loss: 19.5167\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0851 - val_loss: 19.4369\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9826 - val_loss: 19.3589\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8851 - val_loss: 19.2872\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8294 - val_loss: 19.2278\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7543 - val_loss: 19.1732\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7028 - val_loss: 19.1236\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5339 - val_loss: 19.0761\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5619 - val_loss: 19.0313\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5731 - val_loss: 18.9958\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4140 - val_loss: 18.9685\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5057 - val_loss: 18.9415\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4789 - val_loss: 18.9158\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4391 - val_loss: 18.8922\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3060 - val_loss: 18.8692\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4055 - val_loss: 18.8467\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3508 - val_loss: 18.8254\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3599 - val_loss: 18.8040\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3427 - val_loss: 18.7840\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3244 - val_loss: 18.7642\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3123 - val_loss: 18.7452\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2850 - val_loss: 18.7275\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2711 - val_loss: 18.7097\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2381 - val_loss: 18.6924\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2473 - val_loss: 18.6748\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2357 - val_loss: 18.6571\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2008 - val_loss: 18.6406\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2008 - val_loss: 18.6233\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1843 - val_loss: 18.6068\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1441 - val_loss: 18.5905\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1426 - val_loss: 18.5740\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1451 - val_loss: 18.5579\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1197 - val_loss: 18.5418\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1041 - val_loss: 18.5256\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1199 - val_loss: 18.5095\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0987 - val_loss: 18.4941\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0932 - val_loss: 18.4788\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0650 - val_loss: 18.4634\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9703 - val_loss: 18.4481\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0510 - val_loss: 18.4327\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0348 - val_loss: 18.4178\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9953 - val_loss: 18.4029\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9847 - val_loss: 18.3880\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9947 - val_loss: 18.3733\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9864 - val_loss: 18.3582\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9227 - val_loss: 18.3432\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9552 - val_loss: 18.3282\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9360 - val_loss: 18.3130\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9263 - val_loss: 18.2980\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9154 - val_loss: 18.2832\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7344 - val_loss: 18.2687\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8741 - val_loss: 18.2540\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8724 - val_loss: 18.2386\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8560 - val_loss: 18.2237\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7948 - val_loss: 18.2092\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8287 - val_loss: 18.1940\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7784 - val_loss: 18.1793\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7625 - val_loss: 18.1656\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7790 - val_loss: 18.1505\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7726 - val_loss: 18.1356\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7517 - val_loss: 18.1201\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7344 - val_loss: 18.1047\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7306 - val_loss: 18.0903\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7147 - val_loss: 18.0749\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6960 - val_loss: 18.0594\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6601 - val_loss: 18.0440\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6629 - val_loss: 18.0285\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6415 - val_loss: 18.0135\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6441 - val_loss: 17.9979\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6298 - val_loss: 17.9825\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6003 - val_loss: 17.9678\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5914 - val_loss: 17.9529\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5824 - val_loss: 17.9375\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5061 - val_loss: 17.9224\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4469 - val_loss: 17.9080\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5388 - val_loss: 17.8922\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4695 - val_loss: 17.8767\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5057 - val_loss: 17.8612\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4921 - val_loss: 17.8457\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_78 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_80 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_82 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1483\n",
      "Model:                       QuantReg   Bandwidth:                    0.004712\n",
      "Method:                 Least Squares   Sparsity:                       0.1475\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:35:31   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0047      0.005      0.935      0.350      -0.005       0.015\n",
      "three_month_yield_change     -0.0094      0.130     -0.072      0.942      -0.264       0.245\n",
      "term_spread_change           -0.0585      0.129     -0.453      0.651      -0.312       0.195\n",
      "TED_spread                   -0.8395      0.473     -1.774      0.076      -1.767       0.088\n",
      "credit_spread_change          0.2283      0.182      1.257      0.209      -0.128       0.585\n",
      "market_return                -0.1059      0.084     -1.267      0.205      -0.270       0.058\n",
      "real_estate_excess_return     0.1415      0.090      1.567      0.117      -0.036       0.319\n",
      "equity_volatility             1.9982      0.149     13.396      0.000       1.706       2.291\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2353\n",
      "Model:                       QuantReg   Bandwidth:                    0.007158\n",
      "Method:                 Least Squares   Sparsity:                       0.6955\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:35:31   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0219      0.011      2.007      0.045       0.001       0.043\n",
      "three_month_yield_change     -0.0976      0.280     -0.348      0.728      -0.648       0.452\n",
      "term_spread_change           -0.0365      0.277     -0.132      0.895      -0.580       0.507\n",
      "TED_spread                    1.7271      1.119      1.543      0.123      -0.468       3.922\n",
      "credit_spread_change         -0.5311      0.421     -1.262      0.207      -1.357       0.294\n",
      "market_return                 0.0712      0.250      0.284      0.776      -0.420       0.562\n",
      "real_estate_excess_return    -0.0796      0.247     -0.323      0.747      -0.564       0.404\n",
      "equity_volatility             3.4454      0.383      9.004      0.000       2.695       4.196\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4368\n",
      "Model:                       QuantReg   Bandwidth:                    0.001960\n",
      "Method:                 Least Squares   Sparsity:                      0.07546\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:35:31   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0119      0.003      4.316      0.000       0.006       0.017\n",
      "three_month_yield_change     -0.0148      0.079     -0.188      0.851      -0.169       0.139\n",
      "term_spread_change           -0.1622      0.068     -2.373      0.018      -0.296      -0.028\n",
      "TED_spread                   -0.7806      0.261     -2.986      0.003      -1.293      -0.268\n",
      "credit_spread_change         -0.0729      0.094     -0.776      0.438      -0.257       0.111\n",
      "market_return                -0.0452      0.038     -1.191      0.234      -0.120       0.029\n",
      "real_estate_excess_return    -0.0716      0.048     -1.489      0.137      -0.166       0.023\n",
      "equity_volatility             0.7299      0.070     10.356      0.000       0.592       0.868\n",
      "institution                   0.4434      0.035     12.744      0.000       0.375       0.512\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5548\n",
      "Model:                       QuantReg   Bandwidth:                    0.003439\n",
      "Method:                 Least Squares   Sparsity:                       0.2381\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:35:31   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0157      0.003      4.534      0.000       0.009       0.023\n",
      "three_month_yield_change      0.0366      0.115      0.318      0.751      -0.189       0.262\n",
      "term_spread_change           -0.3158      0.105     -3.001      0.003      -0.522      -0.109\n",
      "TED_spread                   -1.4837      0.421     -3.528      0.000      -2.308      -0.659\n",
      "credit_spread_change          0.0033      0.121      0.027      0.978      -0.233       0.240\n",
      "market_return                -0.0555      0.091     -0.609      0.543      -0.234       0.123\n",
      "real_estate_excess_return    -0.1704      0.070     -2.428      0.015      -0.308      -0.033\n",
      "equity_volatility             1.2774      0.139      9.201      0.000       1.005       1.550\n",
      "institution                   0.4328      0.080      5.406      0.000       0.276       0.590\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 37.0433 - val_loss: 34.1899\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.3750 - val_loss: 33.4703\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 35.4567 - val_loss: 32.6900\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 34.5765 - val_loss: 31.9186\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.5768 - val_loss: 31.0342\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.4599 - val_loss: 29.8393\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.0707 - val_loss: 28.6092\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.6929 - val_loss: 27.3379\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.4172 - val_loss: 26.1184\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.2850 - val_loss: 25.0624\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1303 - val_loss: 24.1712\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5855 - val_loss: 23.3708\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.9520 - val_loss: 22.6716\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4052 - val_loss: 22.1289\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9428 - val_loss: 21.6531\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5573 - val_loss: 21.2647\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2222 - val_loss: 21.0168\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9569 - val_loss: 20.8563\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7522 - val_loss: 20.7248\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6023 - val_loss: 20.6425\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4053 - val_loss: 20.5915\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3861 - val_loss: 20.5450\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3155 - val_loss: 20.5039\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2052 - val_loss: 20.4670\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1951 - val_loss: 20.4345\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0959 - val_loss: 20.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1493 - val_loss: 20.3754\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1190 - val_loss: 20.3489\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0941 - val_loss: 20.3231\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0628 - val_loss: 20.3038\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9918 - val_loss: 20.2866\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0139 - val_loss: 20.2711\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0229 - val_loss: 20.2555\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9775 - val_loss: 20.2406\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8792 - val_loss: 20.2260\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8729 - val_loss: 20.2116\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7740 - val_loss: 20.1981\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9420 - val_loss: 20.1840\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9092 - val_loss: 20.1705\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9191 - val_loss: 20.1566\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8973 - val_loss: 20.1428\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8873 - val_loss: 20.1289\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8815 - val_loss: 20.1157\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8640 - val_loss: 20.1031\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8276 - val_loss: 20.0910\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5997 - val_loss: 20.0792\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8498 - val_loss: 20.0672\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7851 - val_loss: 20.0554\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7586 - val_loss: 20.0435\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7640 - val_loss: 20.0315\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7556 - val_loss: 20.0194\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7618 - val_loss: 20.0073\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7516 - val_loss: 19.9951\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7433 - val_loss: 19.9828\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6960 - val_loss: 19.9705\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7145 - val_loss: 19.9580\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6952 - val_loss: 19.9455\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6670 - val_loss: 19.9329\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6617 - val_loss: 19.9202\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5695 - val_loss: 19.9075\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6546 - val_loss: 19.8947\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6239 - val_loss: 19.8819\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6317 - val_loss: 19.8689\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4542 - val_loss: 19.8559\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5952 - val_loss: 19.8428\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5813 - val_loss: 19.8297\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4880 - val_loss: 19.8165\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5662 - val_loss: 19.8032\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5512 - val_loss: 19.7899\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5353 - val_loss: 19.7764\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5159 - val_loss: 19.7630\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4885 - val_loss: 19.7494\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4187 - val_loss: 19.7358\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4690 - val_loss: 19.7221\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4363 - val_loss: 19.7083\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4461 - val_loss: 19.6945\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3313 - val_loss: 19.6807\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4171 - val_loss: 19.6668\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4100 - val_loss: 19.6528\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3607 - val_loss: 19.6388\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3553 - val_loss: 19.6247\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3478 - val_loss: 19.6106\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3461 - val_loss: 19.5964\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2994 - val_loss: 19.5821\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2506 - val_loss: 19.5678\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2532 - val_loss: 19.5533\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2920 - val_loss: 19.5390\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2472 - val_loss: 19.5245\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2656 - val_loss: 19.5101\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2446 - val_loss: 19.4955\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2358 - val_loss: 19.4810\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2062 - val_loss: 19.4663\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2163 - val_loss: 19.4516\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1520 - val_loss: 19.4368\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1852 - val_loss: 19.4220\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1726 - val_loss: 19.4072\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1415 - val_loss: 19.3923\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1339 - val_loss: 19.3774\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1258 - val_loss: 19.3624\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0928 - val_loss: 19.3473\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_89 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_90 (Conv1D)          (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 3s 17ms/step - loss: 25.3641 - val_loss: 24.1493\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.3689 - val_loss: 23.3058\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4774 - val_loss: 22.6255\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.7732 - val_loss: 22.0404\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9417 - val_loss: 21.4912\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4806 - val_loss: 21.0106\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9599 - val_loss: 20.6125\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.4974 - val_loss: 20.3133\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.0680 - val_loss: 20.0952\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.7952 - val_loss: 19.9191\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.5684 - val_loss: 19.7929\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.3666 - val_loss: 19.6761\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.2381 - val_loss: 19.5709\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 19.1059 - val_loss: 19.4705\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8166 - val_loss: 19.3855\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8520 - val_loss: 19.3127\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8263 - val_loss: 19.2512\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7790 - val_loss: 19.1950\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7340 - val_loss: 19.1536\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6872 - val_loss: 19.1207\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6406 - val_loss: 19.0911\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5827 - val_loss: 19.0633\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5998 - val_loss: 19.0375\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5584 - val_loss: 19.0123\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5134 - val_loss: 18.9884\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5248 - val_loss: 18.9652\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4901 - val_loss: 18.9438\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4942 - val_loss: 18.9242\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4450 - val_loss: 18.9057\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4600 - val_loss: 18.8889\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4541 - val_loss: 18.8718\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4317 - val_loss: 18.8555\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4456 - val_loss: 18.8399\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4107 - val_loss: 18.8251\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3496 - val_loss: 18.8109\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3553 - val_loss: 18.7969\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3666 - val_loss: 18.7830\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3883 - val_loss: 18.7687\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3607 - val_loss: 18.7546\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3343 - val_loss: 18.7424\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3512 - val_loss: 18.7286\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3110 - val_loss: 18.7157\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3279 - val_loss: 18.7018\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3004 - val_loss: 18.6892\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3098 - val_loss: 18.6748\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2919 - val_loss: 18.6614\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2885 - val_loss: 18.6486\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1954 - val_loss: 18.6351\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2604 - val_loss: 18.6219\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2431 - val_loss: 18.6088\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2374 - val_loss: 18.5963\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2100 - val_loss: 18.5844\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2150 - val_loss: 18.5713\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2026 - val_loss: 18.5591\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1847 - val_loss: 18.5460\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1719 - val_loss: 18.5327\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1658 - val_loss: 18.5201\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1374 - val_loss: 18.5076\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1150 - val_loss: 18.4957\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1038 - val_loss: 18.4828\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1029 - val_loss: 18.4701\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0150 - val_loss: 18.4582\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0882 - val_loss: 18.4447\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0802 - val_loss: 18.4313\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0715 - val_loss: 18.4178\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0492 - val_loss: 18.4043\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0420 - val_loss: 18.3908\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0108 - val_loss: 18.3781\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0134 - val_loss: 18.3665\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9974 - val_loss: 18.3533\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9808 - val_loss: 18.3403\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7787 - val_loss: 18.3283\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9643 - val_loss: 18.3154\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9496 - val_loss: 18.3017\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9367 - val_loss: 18.2880\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9090 - val_loss: 18.2747\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8776 - val_loss: 18.2617\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8910 - val_loss: 18.2481\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8865 - val_loss: 18.2338\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8396 - val_loss: 18.2200\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8482 - val_loss: 18.2065\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8422 - val_loss: 18.1923\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8258 - val_loss: 18.1784\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8057 - val_loss: 18.1649\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5965 - val_loss: 18.1520\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7750 - val_loss: 18.1389\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7666 - val_loss: 18.1245\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7188 - val_loss: 18.1113\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7452 - val_loss: 18.0980\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7172 - val_loss: 18.0834\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6940 - val_loss: 18.0694\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6872 - val_loss: 18.0551\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5590 - val_loss: 18.0422\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6781 - val_loss: 18.0278\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6379 - val_loss: 18.0139\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6460 - val_loss: 17.9992\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6293 - val_loss: 17.9841\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6002 - val_loss: 17.9696\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5712 - val_loss: 17.9562\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5902 - val_loss: 17.9417\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_93 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_96 (Conv1D)          (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1664\n",
      "Model:                       QuantReg   Bandwidth:                    0.005062\n",
      "Method:                 Least Squares   Sparsity:                       0.1533\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:36:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0324      0.006      5.662      0.000       0.021       0.044\n",
      "three_month_yield_change     -0.5062      0.147     -3.445      0.001      -0.794      -0.218\n",
      "term_spread_change           -0.7396      0.125     -5.929      0.000      -0.984      -0.495\n",
      "TED_spread                   -1.3243      0.579     -2.289      0.022      -2.459      -0.190\n",
      "credit_spread_change         -0.3372      0.204     -1.654      0.098      -0.737       0.063\n",
      "market_return                 0.0290      0.088      0.331      0.740      -0.143       0.201\n",
      "real_estate_excess_return     0.1825      0.097      1.877      0.061      -0.008       0.373\n",
      "equity_volatility             2.3000      0.149     15.471      0.000       2.008       2.591\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2782\n",
      "Model:                       QuantReg   Bandwidth:                    0.007723\n",
      "Method:                 Least Squares   Sparsity:                       0.7639\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:36:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0760      0.013      5.990      0.000       0.051       0.101\n",
      "three_month_yield_change     -0.8022      0.354     -2.269      0.023      -1.495      -0.109\n",
      "term_spread_change           -1.3077      0.328     -3.989      0.000      -1.951      -0.665\n",
      "TED_spread                   -1.0716      1.450     -0.739      0.460      -3.916       1.773\n",
      "credit_spread_change         -1.1509      0.450     -2.556      0.011      -2.034      -0.268\n",
      "market_return                -0.1958      0.297     -0.660      0.510      -0.778       0.386\n",
      "real_estate_excess_return     0.0618      0.308      0.201      0.841      -0.542       0.666\n",
      "equity_volatility             2.8164      0.458      6.147      0.000       1.918       3.715\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3776\n",
      "Model:                       QuantReg   Bandwidth:                    0.002258\n",
      "Method:                 Least Squares   Sparsity:                      0.06806\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:36:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0151      0.002      6.199      0.000       0.010       0.020\n",
      "three_month_yield_change     -0.0944      0.070     -1.348      0.178      -0.232       0.043\n",
      "term_spread_change           -0.1958      0.066     -2.988      0.003      -0.324      -0.067\n",
      "TED_spread                   -1.1827      0.258     -4.577      0.000      -1.689      -0.676\n",
      "credit_spread_change         -0.1682      0.083     -2.025      0.043      -0.331      -0.005\n",
      "market_return                -0.0270      0.034     -0.786      0.432      -0.094       0.040\n",
      "real_estate_excess_return    -0.0484      0.040     -1.205      0.228      -0.127       0.030\n",
      "equity_volatility             0.9052      0.071     12.745      0.000       0.766       1.045\n",
      "institution                   0.4183      0.031     13.407      0.000       0.357       0.479\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4528\n",
      "Model:                       QuantReg   Bandwidth:                    0.004183\n",
      "Method:                 Least Squares   Sparsity:                       0.3510\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:36:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.005      7.612      0.000       0.029       0.049\n",
      "three_month_yield_change     -0.4681      0.155     -3.011      0.003      -0.773      -0.163\n",
      "term_spread_change           -0.6276      0.168     -3.736      0.000      -0.957      -0.298\n",
      "TED_spread                   -2.2947      0.650     -3.531      0.000      -3.569      -1.020\n",
      "credit_spread_change         -0.3985      0.169     -2.358      0.018      -0.730      -0.067\n",
      "market_return                -0.0612      0.135     -0.452      0.652      -0.327       0.204\n",
      "real_estate_excess_return    -0.2818      0.107     -2.625      0.009      -0.492      -0.071\n",
      "equity_volatility             1.3550      0.211      6.434      0.000       0.942       1.768\n",
      "institution                   0.4309      0.126      3.419      0.001       0.184       0.678\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 19ms/step - loss: 35.0776 - val_loss: 31.7763\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 34.1372 - val_loss: 30.8304\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 33.1486 - val_loss: 29.9210\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 31.9803 - val_loss: 29.0639\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 31.0537 - val_loss: 28.2302\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 30.0482 - val_loss: 27.4859\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.0960 - val_loss: 26.7592\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 28.1622 - val_loss: 26.0853\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 27.3902 - val_loss: 25.4980\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 26.5623 - val_loss: 24.9626\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 25.9495 - val_loss: 24.4539\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.2520 - val_loss: 23.9591\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.8075 - val_loss: 23.4898\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.4033 - val_loss: 23.0626\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7916 - val_loss: 22.7072\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.6731 - val_loss: 22.4234\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3286 - val_loss: 22.2084\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.1258 - val_loss: 22.0656\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.9012 - val_loss: 21.9534\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.7243 - val_loss: 21.8598\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.6262 - val_loss: 21.7891\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.4567 - val_loss: 21.7260\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.3479 - val_loss: 21.6683\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.2857 - val_loss: 21.6118\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.1926 - val_loss: 21.5647\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.0399 - val_loss: 21.5336\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.0079 - val_loss: 21.5149\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.9620 - val_loss: 21.5027\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.7016 - val_loss: 21.4926\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.7682 - val_loss: 21.4825\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.8524 - val_loss: 21.4723\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.8167 - val_loss: 21.4621\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.7073 - val_loss: 21.4519\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5271 - val_loss: 21.4415\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.7232 - val_loss: 21.4311\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4509 - val_loss: 21.4206\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6572 - val_loss: 21.4100\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6470 - val_loss: 21.3993\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6228 - val_loss: 21.3886\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6317 - val_loss: 21.3777\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6143 - val_loss: 21.3667\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5743 - val_loss: 21.3557\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5641 - val_loss: 21.3446\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5130 - val_loss: 21.3334\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5433 - val_loss: 21.3222\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4989 - val_loss: 21.3109\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4498 - val_loss: 21.2995\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4839 - val_loss: 21.2882\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3881 - val_loss: 21.2767\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4379 - val_loss: 21.2652\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4466 - val_loss: 21.2536\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3920 - val_loss: 21.2420\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3991 - val_loss: 21.2303\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4095 - val_loss: 21.2186\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4002 - val_loss: 21.2069\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1460 - val_loss: 21.1950\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3484 - val_loss: 21.1832\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3162 - val_loss: 21.1712\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.3417 - val_loss: 21.1592\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2767 - val_loss: 21.1472\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2200 - val_loss: 21.1350\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2579 - val_loss: 21.1229\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1073 - val_loss: 21.1106\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2819 - val_loss: 21.0982\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2435 - val_loss: 21.0859\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2284 - val_loss: 21.0734\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2422 - val_loss: 21.0609\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1121 - val_loss: 21.0483\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0073 - val_loss: 21.0357\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1995 - val_loss: 21.0231\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1970 - val_loss: 21.0104\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1684 - val_loss: 20.9976\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1353 - val_loss: 20.9848\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1487 - val_loss: 20.9720\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1212 - val_loss: 20.9591\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1068 - val_loss: 20.9461\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9427 - val_loss: 20.9332\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0244 - val_loss: 20.9202\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0655 - val_loss: 20.9071\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0550 - val_loss: 20.8940\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0497 - val_loss: 20.8808\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0321 - val_loss: 20.8676\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0148 - val_loss: 20.8543\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9709 - val_loss: 20.8411\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9449 - val_loss: 20.8277\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9793 - val_loss: 20.8143\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9368 - val_loss: 20.8008\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8780 - val_loss: 20.7874\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9015 - val_loss: 20.7738\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9161 - val_loss: 20.7603\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8160 - val_loss: 20.7466\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8377 - val_loss: 20.7329\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8874 - val_loss: 20.7192\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.7995 - val_loss: 20.7055\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.7859 - val_loss: 20.6917\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8522 - val_loss: 20.6778\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8412 - val_loss: 20.6639\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.7162 - val_loss: 20.6500\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8096 - val_loss: 20.6360\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.7476 - val_loss: 20.6220\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_99 (Conv1D)          (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_102 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 25.6174 - val_loss: 24.3498\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.7823 - val_loss: 23.6814\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0886 - val_loss: 23.1001\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4447 - val_loss: 22.6143\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8412 - val_loss: 22.1988\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3589 - val_loss: 21.7701\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8405 - val_loss: 21.3518\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4341 - val_loss: 20.9839\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9888 - val_loss: 20.6742\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6358 - val_loss: 20.4104\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3233 - val_loss: 20.2074\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0846 - val_loss: 20.0461\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8164 - val_loss: 19.8994\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6114 - val_loss: 19.7822\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3464 - val_loss: 19.6899\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3005 - val_loss: 19.6014\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2000 - val_loss: 19.5172\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0976 - val_loss: 19.4352\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9081 - val_loss: 19.3581\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8954 - val_loss: 19.2892\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8380 - val_loss: 19.2297\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7723 - val_loss: 19.1761\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6321 - val_loss: 19.1251\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6512 - val_loss: 19.0788\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6129 - val_loss: 19.0383\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5801 - val_loss: 19.0036\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5449 - val_loss: 18.9733\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4664 - val_loss: 18.9471\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4870 - val_loss: 18.9214\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4156 - val_loss: 18.8973\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4046 - val_loss: 18.8731\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3515 - val_loss: 18.8494\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3900 - val_loss: 18.8267\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3301 - val_loss: 18.8055\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3440 - val_loss: 18.7850\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3505 - val_loss: 18.7650\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3239 - val_loss: 18.7461\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2647 - val_loss: 18.7285\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2724 - val_loss: 18.7118\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2712 - val_loss: 18.6941\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2494 - val_loss: 18.6779\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2528 - val_loss: 18.6616\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2493 - val_loss: 18.6459\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2091 - val_loss: 18.6301\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2260 - val_loss: 18.6148\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2067 - val_loss: 18.5993\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1668 - val_loss: 18.5839\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1422 - val_loss: 18.5688\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1759 - val_loss: 18.5539\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1473 - val_loss: 18.5399\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1175 - val_loss: 18.5256\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1327 - val_loss: 18.5111\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1100 - val_loss: 18.4970\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1081 - val_loss: 18.4822\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1025 - val_loss: 18.4675\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0698 - val_loss: 18.4549\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0456 - val_loss: 18.4417\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0684 - val_loss: 18.4283\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0372 - val_loss: 18.4159\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9924 - val_loss: 18.4030\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0273 - val_loss: 18.3893\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9914 - val_loss: 18.3753\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0014 - val_loss: 18.3614\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9130 - val_loss: 18.3479\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9761 - val_loss: 18.3335\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9275 - val_loss: 18.3209\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9205 - val_loss: 18.3076\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9109 - val_loss: 18.2942\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9246 - val_loss: 18.2800\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9111 - val_loss: 18.2658\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8999 - val_loss: 18.2517\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7181 - val_loss: 18.2382\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8497 - val_loss: 18.2251\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8406 - val_loss: 18.2118\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7594 - val_loss: 18.1989\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8349 - val_loss: 18.1846\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7938 - val_loss: 18.1711\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8049 - val_loss: 18.1575\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7090 - val_loss: 18.1438\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7722 - val_loss: 18.1298\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7128 - val_loss: 18.1163\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7445 - val_loss: 18.1027\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7137 - val_loss: 18.0893\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7118 - val_loss: 18.0763\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6881 - val_loss: 18.0622\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6472 - val_loss: 18.0480\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6633 - val_loss: 18.0336\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6724 - val_loss: 18.0190\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6150 - val_loss: 18.0059\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6229 - val_loss: 17.9917\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6224 - val_loss: 17.9774\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5940 - val_loss: 17.9636\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5963 - val_loss: 17.9491\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5848 - val_loss: 17.9347\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5714 - val_loss: 17.9204\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5413 - val_loss: 17.9059\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5403 - val_loss: 17.8918\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4345 - val_loss: 17.8776\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4641 - val_loss: 17.8629\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5007 - val_loss: 17.8486\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_105 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_108 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_111 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1369\n",
      "Model:                       QuantReg   Bandwidth:                    0.004515\n",
      "Method:                 Least Squares   Sparsity:                       0.1624\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:37:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0172      0.006      3.017      0.003       0.006       0.028\n",
      "three_month_yield_change      0.0567      0.148      0.382      0.703      -0.234       0.348\n",
      "term_spread_change           -0.2085      0.141     -1.476      0.140      -0.486       0.069\n",
      "TED_spread                   -1.2834      0.600     -2.138      0.033      -2.460      -0.107\n",
      "credit_spread_change         -0.1336      0.210     -0.635      0.525      -0.546       0.279\n",
      "market_return                -0.0748      0.096     -0.778      0.436      -0.263       0.114\n",
      "real_estate_excess_return     0.1639      0.100      1.647      0.100      -0.031       0.359\n",
      "equity_volatility             1.9198      0.157     12.203      0.000       1.611       2.228\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2608\n",
      "Model:                       QuantReg   Bandwidth:                    0.007085\n",
      "Method:                 Least Squares   Sparsity:                       0.8324\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:37:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0556      0.011      5.138      0.000       0.034       0.077\n",
      "three_month_yield_change     -0.5564      0.301     -1.847      0.065      -1.147       0.034\n",
      "term_spread_change           -0.5500      0.319     -1.727      0.084      -1.175       0.075\n",
      "TED_spread                    0.8534      1.450      0.588      0.556      -1.990       3.697\n",
      "credit_spread_change         -1.1968      0.457     -2.620      0.009      -2.093      -0.301\n",
      "market_return                 0.0816      0.287      0.284      0.776      -0.482       0.645\n",
      "real_estate_excess_return    -0.0843      0.271     -0.311      0.756      -0.615       0.447\n",
      "equity_volatility             3.2269      0.480      6.723      0.000       2.286       4.168\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4477\n",
      "Model:                       QuantReg   Bandwidth:                    0.002064\n",
      "Method:                 Least Squares   Sparsity:                      0.06189\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:37:52   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0191      0.002      8.778      0.000       0.015       0.023\n",
      "three_month_yield_change     -0.1645      0.065     -2.528      0.012      -0.292      -0.037\n",
      "term_spread_change           -0.1998      0.058     -3.431      0.001      -0.314      -0.086\n",
      "TED_spread                   -0.3999      0.240     -1.664      0.096      -0.871       0.071\n",
      "credit_spread_change         -0.3389      0.073     -4.656      0.000      -0.482      -0.196\n",
      "market_return                -0.0526      0.029     -1.816      0.070      -0.109       0.004\n",
      "real_estate_excess_return    -0.0410      0.039     -1.051      0.293      -0.118       0.036\n",
      "equity_volatility             0.6421      0.059     10.885      0.000       0.526       0.758\n",
      "institution                   0.4759      0.027     17.445      0.000       0.422       0.529\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5516\n",
      "Model:                       QuantReg   Bandwidth:                    0.003375\n",
      "Method:                 Least Squares   Sparsity:                       0.2652\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:37:52   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0223      0.004      6.110      0.000       0.015       0.029\n",
      "three_month_yield_change     -0.2728      0.124     -2.206      0.027      -0.515      -0.030\n",
      "term_spread_change           -0.2988      0.111     -2.704      0.007      -0.516      -0.082\n",
      "TED_spread                   -0.8866      0.487     -1.819      0.069      -1.842       0.069\n",
      "credit_spread_change         -0.2052      0.129     -1.589      0.112      -0.458       0.048\n",
      "market_return                -0.2037      0.101     -2.015      0.044      -0.402      -0.005\n",
      "real_estate_excess_return    -0.2821      0.087     -3.242      0.001      -0.453      -0.111\n",
      "equity_volatility             1.1585      0.154      7.523      0.000       0.857       1.460\n",
      "institution                   0.4977      0.083      5.976      0.000       0.334       0.661\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 39.7021 - val_loss: 40.2947\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.1032 - val_loss: 39.8114\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 38.5067 - val_loss: 39.2150\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 37.7480 - val_loss: 38.4704\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.8897 - val_loss: 37.7078\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 35.9104 - val_loss: 36.8588\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 34.7790 - val_loss: 35.9624\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.5515 - val_loss: 34.9726\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.3699 - val_loss: 33.8724\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.0237 - val_loss: 32.6647\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.7183 - val_loss: 31.4689\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.5688 - val_loss: 30.2618\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.5260 - val_loss: 29.1141\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4327 - val_loss: 28.1240\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6720 - val_loss: 27.2925\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8597 - val_loss: 26.6220\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5963 - val_loss: 26.0803\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1428 - val_loss: 25.6173\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9558 - val_loss: 25.2504\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6887 - val_loss: 24.9340\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4692 - val_loss: 24.6727\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3244 - val_loss: 24.4480\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3765 - val_loss: 24.2623\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1840 - val_loss: 24.1308\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2189 - val_loss: 24.0177\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1882 - val_loss: 23.9367\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0657 - val_loss: 23.8791\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9650 - val_loss: 23.8413\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9398 - val_loss: 23.8136\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9345 - val_loss: 23.7871\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0080 - val_loss: 23.7615\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9834 - val_loss: 23.7371\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8480 - val_loss: 23.7146\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9554 - val_loss: 23.6934\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9007 - val_loss: 23.6726\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9202 - val_loss: 23.6522\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8917 - val_loss: 23.6328\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8885 - val_loss: 23.6137\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7327 - val_loss: 23.5953\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8194 - val_loss: 23.5766\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8579 - val_loss: 23.5578\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8438 - val_loss: 23.5392\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7742 - val_loss: 23.5225\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6380 - val_loss: 23.5060\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7684 - val_loss: 23.4894\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7642 - val_loss: 23.4734\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7501 - val_loss: 23.4581\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7433 - val_loss: 23.4430\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7334 - val_loss: 23.4285\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6974 - val_loss: 23.4146\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7129 - val_loss: 23.4007\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6980 - val_loss: 23.3866\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6919 - val_loss: 23.3724\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6793 - val_loss: 23.3582\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6548 - val_loss: 23.3442\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6369 - val_loss: 23.3307\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6203 - val_loss: 23.3169\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5852 - val_loss: 23.3033\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6030 - val_loss: 23.2893\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5558 - val_loss: 23.2752\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4554 - val_loss: 23.2613\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5789 - val_loss: 23.2471\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5434 - val_loss: 23.2329\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4737 - val_loss: 23.2193\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4715 - val_loss: 23.2052\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4340 - val_loss: 23.1914\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4928 - val_loss: 23.1774\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4578 - val_loss: 23.1635\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4693 - val_loss: 23.1493\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4446 - val_loss: 23.1353\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4015 - val_loss: 23.1219\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3830 - val_loss: 23.1079\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4284 - val_loss: 23.0938\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3580 - val_loss: 23.0794\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3689 - val_loss: 23.0651\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3787 - val_loss: 23.0510\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3363 - val_loss: 23.0368\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3408 - val_loss: 23.0223\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3120 - val_loss: 23.0082\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3183 - val_loss: 22.9938\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2813 - val_loss: 22.9793\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2856 - val_loss: 22.9647\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2593 - val_loss: 22.9502\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2388 - val_loss: 22.9358\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2058 - val_loss: 22.9211\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2296 - val_loss: 22.9062\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1615 - val_loss: 22.8914\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1868 - val_loss: 22.8763\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1182 - val_loss: 22.8620\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1539 - val_loss: 22.8472\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1649 - val_loss: 22.8322\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0760 - val_loss: 22.8172\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0846 - val_loss: 22.8022\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1009 - val_loss: 22.7872\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0576 - val_loss: 22.7723\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9868 - val_loss: 22.7572\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0695 - val_loss: 22.7418\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9374 - val_loss: 22.7266\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9166 - val_loss: 22.7115\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0061 - val_loss: 22.6959\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_114 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_117 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 26.1098 - val_loss: 24.9403\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5341 - val_loss: 24.5246\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.1179 - val_loss: 24.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.8264 - val_loss: 23.8442\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2978 - val_loss: 23.5421\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9281 - val_loss: 23.2513\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5768 - val_loss: 22.9746\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3528 - val_loss: 22.7069\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9756 - val_loss: 22.4461\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7583 - val_loss: 22.1988\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2546 - val_loss: 21.9675\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1739 - val_loss: 21.7329\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9100 - val_loss: 21.4966\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5576 - val_loss: 21.2595\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3625 - val_loss: 21.0342\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9846 - val_loss: 20.8263\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7954 - val_loss: 20.6208\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3828 - val_loss: 20.4398\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3897 - val_loss: 20.2816\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1748 - val_loss: 20.1428\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9640 - val_loss: 20.0186\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8023 - val_loss: 19.8979\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6191 - val_loss: 19.7972\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4124 - val_loss: 19.7148\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3183 - val_loss: 19.6370\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2621 - val_loss: 19.5611\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0726 - val_loss: 19.4880\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0386 - val_loss: 19.4193\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8949 - val_loss: 19.3506\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8106 - val_loss: 19.2877\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7855 - val_loss: 19.2333\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7386 - val_loss: 19.1825\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6563 - val_loss: 19.1362\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6691 - val_loss: 19.0917\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5807 - val_loss: 19.0507\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5391 - val_loss: 19.0135\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5468 - val_loss: 18.9816\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4995 - val_loss: 18.9538\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4757 - val_loss: 18.9287\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4606 - val_loss: 18.9057\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4069 - val_loss: 18.8837\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3274 - val_loss: 18.8613\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3729 - val_loss: 18.8401\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3704 - val_loss: 18.8197\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3045 - val_loss: 18.7998\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3198 - val_loss: 18.7802\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2686 - val_loss: 18.7608\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3018 - val_loss: 18.7420\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2613 - val_loss: 18.7243\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2758 - val_loss: 18.7068\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2350 - val_loss: 18.6893\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2338 - val_loss: 18.6729\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2223 - val_loss: 18.6554\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2181 - val_loss: 18.6386\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1941 - val_loss: 18.6218\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1716 - val_loss: 18.6048\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1143 - val_loss: 18.5881\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1500 - val_loss: 18.5718\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1108 - val_loss: 18.5558\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0969 - val_loss: 18.5394\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1176 - val_loss: 18.5229\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0970 - val_loss: 18.5074\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0464 - val_loss: 18.4922\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0755 - val_loss: 18.4763\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0530 - val_loss: 18.4608\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9690 - val_loss: 18.4459\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0312 - val_loss: 18.4303\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0170 - val_loss: 18.4156\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0013 - val_loss: 18.4006\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9952 - val_loss: 18.3854\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9714 - val_loss: 18.3706\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9682 - val_loss: 18.3554\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9415 - val_loss: 18.3411\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8243 - val_loss: 18.3267\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9271 - val_loss: 18.3120\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8486 - val_loss: 18.2973\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9026 - val_loss: 18.2821\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8806 - val_loss: 18.2677\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8718 - val_loss: 18.2528\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7702 - val_loss: 18.2381\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8211 - val_loss: 18.2231\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7866 - val_loss: 18.2088\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7499 - val_loss: 18.1944\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7990 - val_loss: 18.1802\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6623 - val_loss: 18.1657\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7720 - val_loss: 18.1504\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7163 - val_loss: 18.1357\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7015 - val_loss: 18.1208\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7316 - val_loss: 18.1057\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7138 - val_loss: 18.0909\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6695 - val_loss: 18.0765\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6523 - val_loss: 18.0616\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5536 - val_loss: 18.0469\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6274 - val_loss: 18.0326\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6463 - val_loss: 18.0181\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6068 - val_loss: 18.0029\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6058 - val_loss: 17.9880\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5867 - val_loss: 17.9731\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5738 - val_loss: 17.9582\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5543 - val_loss: 17.9430\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_120 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_121 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_122 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_123 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_124 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_125 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08823\n",
      "Model:                       QuantReg   Bandwidth:                    0.005171\n",
      "Method:                 Least Squares   Sparsity:                       0.1939\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:38:50   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0293      0.007      4.150      0.000       0.015       0.043\n",
      "three_month_yield_change     -0.1056      0.192     -0.549      0.583      -0.483       0.272\n",
      "term_spread_change           -0.3577      0.180     -1.983      0.047      -0.711      -0.004\n",
      "TED_spread                   -1.9526      0.727     -2.685      0.007      -3.379      -0.527\n",
      "credit_spread_change         -0.1451      0.259     -0.560      0.575      -0.653       0.363\n",
      "market_return                 0.0059      0.108      0.055      0.956      -0.205       0.217\n",
      "real_estate_excess_return     0.1206      0.124      0.969      0.332      -0.123       0.365\n",
      "equity_volatility             1.7453      0.201      8.667      0.000       1.350       2.140\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1924\n",
      "Model:                       QuantReg   Bandwidth:                    0.008777\n",
      "Method:                 Least Squares   Sparsity:                        1.313\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:38:50   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0516      0.021      2.429      0.015       0.010       0.093\n",
      "three_month_yield_change     -0.0038      0.586     -0.006      0.995      -1.153       1.146\n",
      "term_spread_change           -0.7500      0.534     -1.403      0.161      -1.798       0.298\n",
      "TED_spread                   -0.6744      2.390     -0.282      0.778      -5.360       4.012\n",
      "credit_spread_change         -0.7226      0.736     -0.982      0.326      -2.165       0.720\n",
      "market_return                 0.0485      0.465      0.104      0.917      -0.863       0.960\n",
      "real_estate_excess_return     0.4981      0.394      1.264      0.206      -0.274       1.271\n",
      "equity_volatility             4.4774      0.740      6.047      0.000       3.025       5.929\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4244\n",
      "Model:                       QuantReg   Bandwidth:                    0.002046\n",
      "Method:                 Least Squares   Sparsity:                      0.07147\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:38:50   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0144      0.003      5.736      0.000       0.009       0.019\n",
      "three_month_yield_change     -0.0772      0.070     -1.100      0.271      -0.215       0.060\n",
      "term_spread_change           -0.2170      0.062     -3.479      0.001      -0.339      -0.095\n",
      "TED_spread                   -0.6170      0.250     -2.471      0.014      -1.107      -0.127\n",
      "credit_spread_change         -0.1773      0.090     -1.980      0.048      -0.353      -0.002\n",
      "market_return                -0.0707      0.037     -1.902      0.057      -0.144       0.002\n",
      "real_estate_excess_return    -0.0136      0.044     -0.311      0.756      -0.100       0.072\n",
      "equity_volatility             0.7729      0.073     10.653      0.000       0.631       0.915\n",
      "institution                   0.3978      0.032     12.537      0.000       0.336       0.460\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5448\n",
      "Model:                       QuantReg   Bandwidth:                    0.003615\n",
      "Method:                 Least Squares   Sparsity:                       0.3341\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:38:50   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0214      0.004      5.130      0.000       0.013       0.030\n",
      "three_month_yield_change     -0.0580      0.142     -0.409      0.683      -0.336       0.220\n",
      "term_spread_change           -0.4918      0.158     -3.116      0.002      -0.801      -0.182\n",
      "TED_spread                   -1.3972      0.660     -2.117      0.034      -2.691      -0.103\n",
      "credit_spread_change          0.0060      0.157      0.038      0.970      -0.301       0.313\n",
      "market_return                -0.1084      0.119     -0.908      0.364      -0.343       0.126\n",
      "real_estate_excess_return    -0.1569      0.102     -1.542      0.123      -0.356       0.043\n",
      "equity_volatility             1.0415      0.202      5.163      0.000       0.646       1.437\n",
      "institution                   0.3809      0.113      3.375      0.001       0.160       0.602\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 3s 19ms/step - loss: 45.3966 - val_loss: 45.6491\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 44.6541 - val_loss: 44.8928\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 43.5901 - val_loss: 43.4698\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 41.6652 - val_loss: 41.6589\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 39.3935 - val_loss: 39.8447\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 37.2530 - val_loss: 37.9957\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 35.5849 - val_loss: 36.3128\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 33.8100 - val_loss: 34.9220\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 32.3460 - val_loss: 33.6654\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 31.1158 - val_loss: 32.6141\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 29.7897 - val_loss: 31.7745\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 29.2700 - val_loss: 31.0792\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 28.6846 - val_loss: 30.5056\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 28.0532 - val_loss: 30.1556\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.7094 - val_loss: 29.8837\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.2968 - val_loss: 29.6460\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.1266 - val_loss: 29.4700\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.8468 - val_loss: 29.3573\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.6767 - val_loss: 29.2566\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.5917 - val_loss: 29.1597\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.4417 - val_loss: 29.0736\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.3038 - val_loss: 28.9952\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.2668 - val_loss: 28.9245\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.0093 - val_loss: 28.8625\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.1407 - val_loss: 28.8068\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.0445 - val_loss: 28.7563\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.0098 - val_loss: 28.7093\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.9851 - val_loss: 28.6651\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.9338 - val_loss: 28.6229\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.9202 - val_loss: 28.5839\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.8969 - val_loss: 28.5466\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7771 - val_loss: 28.5107\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.8701 - val_loss: 28.4755\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.8289 - val_loss: 28.4419\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7781 - val_loss: 28.4128\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7672 - val_loss: 28.3869\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7439 - val_loss: 28.3642\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7678 - val_loss: 28.3431\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6707 - val_loss: 28.3236\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.7171 - val_loss: 28.3063\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6804 - val_loss: 28.2916\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4272 - val_loss: 28.2779\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4456 - val_loss: 28.2648\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6491 - val_loss: 28.2520\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.5719 - val_loss: 28.2395\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6260 - val_loss: 28.2272\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6055 - val_loss: 28.2153\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4820 - val_loss: 28.2037\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.5512 - val_loss: 28.1920\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.5658 - val_loss: 28.1802\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.5588 - val_loss: 28.1684\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.5444 - val_loss: 28.1567\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1361 - val_loss: 28.1450\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4519 - val_loss: 28.1333\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1941 - val_loss: 28.1216\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4773 - val_loss: 28.1099\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3756 - val_loss: 28.0982\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4155 - val_loss: 28.0865\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4379 - val_loss: 28.0749\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4218 - val_loss: 28.0631\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3659 - val_loss: 28.0515\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 25.2809 - val_loss: 28.0396\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3304 - val_loss: 28.0278\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3161 - val_loss: 28.0159\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3336 - val_loss: 28.0040\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3603 - val_loss: 27.9921\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3392 - val_loss: 27.9802\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.3208 - val_loss: 27.9680\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.2717 - val_loss: 27.9559\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.2873 - val_loss: 27.9439\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 25.1791 - val_loss: 27.9315\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.2713 - val_loss: 27.9192\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0749 - val_loss: 27.9069\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1785 - val_loss: 27.8945\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 25.2249 - val_loss: 27.8820\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0983 - val_loss: 27.8694\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1427 - val_loss: 27.8567\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1543 - val_loss: 27.8441\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1087 - val_loss: 27.8314\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0718 - val_loss: 27.8186\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0613 - val_loss: 27.8057\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1425 - val_loss: 27.7929\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1136 - val_loss: 27.7801\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.1046 - val_loss: 27.7672\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0882 - val_loss: 27.7541\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0645 - val_loss: 27.7409\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0802 - val_loss: 27.7280\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0656 - val_loss: 27.7149\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0241 - val_loss: 27.7016\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9913 - val_loss: 27.6884\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.8869 - val_loss: 27.6748\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9782 - val_loss: 27.6613\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9754 - val_loss: 27.6475\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9666 - val_loss: 27.6339\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9338 - val_loss: 27.6201\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9335 - val_loss: 27.6064\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9244 - val_loss: 27.5927\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9057 - val_loss: 27.5791\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.8646 - val_loss: 27.5651\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.6976 - val_loss: 27.5512\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_126 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_127 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_128 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_129 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_132 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 26.0346 - val_loss: 24.6726\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 25.2602 - val_loss: 24.1212\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 24.6350 - val_loss: 23.5942\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9549 - val_loss: 23.0851\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 23.4189 - val_loss: 22.6178\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.8644 - val_loss: 22.1861\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 22.3462 - val_loss: 21.8033\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6973 - val_loss: 21.4282\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4377 - val_loss: 21.0671\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0021 - val_loss: 20.7604\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 20.7174 - val_loss: 20.4743\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.2444 - val_loss: 20.2530\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.1256 - val_loss: 20.0750\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.8913 - val_loss: 19.9214\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.6707 - val_loss: 19.7891\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.4489 - val_loss: 19.6896\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 19.3319 - val_loss: 19.5998\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.2060 - val_loss: 19.5139\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.0716 - val_loss: 19.4317\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9498 - val_loss: 19.3523\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9053 - val_loss: 19.2750\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7010 - val_loss: 19.2113\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7386 - val_loss: 19.1556\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5962 - val_loss: 19.1048\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6118 - val_loss: 19.0570\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.5972 - val_loss: 19.0132\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.5575 - val_loss: 18.9781\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4701 - val_loss: 18.9495\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4542 - val_loss: 18.9243\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4064 - val_loss: 18.8994\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4381 - val_loss: 18.8752\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3322 - val_loss: 18.8525\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3769 - val_loss: 18.8299\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3693 - val_loss: 18.8075\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3381 - val_loss: 18.7867\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2978 - val_loss: 18.7669\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2688 - val_loss: 18.7485\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2959 - val_loss: 18.7298\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2047 - val_loss: 18.7117\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2587 - val_loss: 18.6935\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2524 - val_loss: 18.6753\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2354 - val_loss: 18.6581\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2260 - val_loss: 18.6403\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2069 - val_loss: 18.6231\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2024 - val_loss: 18.6063\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1560 - val_loss: 18.5901\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1131 - val_loss: 18.5742\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1405 - val_loss: 18.5584\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1496 - val_loss: 18.5423\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0755 - val_loss: 18.5268\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0910 - val_loss: 18.5116\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0723 - val_loss: 18.4968\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0749 - val_loss: 18.4816\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.0713 - val_loss: 18.4666\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.0639 - val_loss: 18.4517\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9766 - val_loss: 18.4378\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0340 - val_loss: 18.4231\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0263 - val_loss: 18.4083\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9378 - val_loss: 18.3952\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9985 - val_loss: 18.3810\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9861 - val_loss: 18.3671\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.9723 - val_loss: 18.3528\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7926 - val_loss: 18.3389\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9028 - val_loss: 18.3246\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9372 - val_loss: 18.3100\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9105 - val_loss: 18.2956\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8790 - val_loss: 18.2814\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8569 - val_loss: 18.2670\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.8338 - val_loss: 18.2527\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8660 - val_loss: 18.2380\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8136 - val_loss: 18.2234\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.8474 - val_loss: 18.2084\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.8245 - val_loss: 18.1937\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8176 - val_loss: 18.1787\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.7924 - val_loss: 18.1643\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.7768 - val_loss: 18.1499\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7587 - val_loss: 18.1351\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6865 - val_loss: 18.1211\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.7498 - val_loss: 18.1056\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7319 - val_loss: 18.0905\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.7158 - val_loss: 18.0756\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.6643 - val_loss: 18.0606\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.6871 - val_loss: 18.0455\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.6433 - val_loss: 18.0315\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.6604 - val_loss: 18.0162\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6104 - val_loss: 18.0014\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5887 - val_loss: 17.9866\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.5989 - val_loss: 17.9722\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5985 - val_loss: 17.9566\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.5819 - val_loss: 17.9412\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.5739 - val_loss: 17.9261\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5237 - val_loss: 17.9106\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.5100 - val_loss: 17.8959\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4721 - val_loss: 17.8811\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4657 - val_loss: 17.8661\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.2806 - val_loss: 17.8517\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4052 - val_loss: 17.8367\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4594 - val_loss: 17.8214\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4098 - val_loss: 17.8060\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 12ms/step - loss: 17.4361 - val_loss: 17.7905\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_133 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_134 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_135 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_136 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_137 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_138 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_139 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1605\n",
      "Model:                       QuantReg   Bandwidth:                    0.006746\n",
      "Method:                 Least Squares   Sparsity:                       0.2203\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:40:15   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0139      0.008      1.797      0.072      -0.001       0.029\n",
      "three_month_yield_change     -0.2869      0.215     -1.336      0.182      -0.708       0.134\n",
      "term_spread_change           -0.4933      0.195     -2.527      0.012      -0.876      -0.110\n",
      "TED_spread                   -2.1461      0.794     -2.703      0.007      -3.703      -0.589\n",
      "credit_spread_change          0.3675      0.274      1.341      0.180      -0.170       0.905\n",
      "market_return                -0.1205      0.127     -0.948      0.343      -0.370       0.129\n",
      "real_estate_excess_return     0.1015      0.118      0.857      0.392      -0.131       0.334\n",
      "equity_volatility             3.0585      0.228     13.427      0.000       2.612       3.505\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2974\n",
      "Model:                       QuantReg   Bandwidth:                     0.01135\n",
      "Method:                 Least Squares   Sparsity:                       0.9595\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:40:15   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0146      0.016      0.938      0.348      -0.016       0.045\n",
      "three_month_yield_change      0.4241      0.411      1.032      0.302      -0.382       1.230\n",
      "term_spread_change           -0.7679      0.405     -1.898      0.058      -1.561       0.026\n",
      "TED_spread                   -3.7956      1.696     -2.237      0.025      -7.122      -0.469\n",
      "credit_spread_change          0.9885      0.593      1.668      0.095      -0.173       2.150\n",
      "market_return                 0.0793      0.395      0.201      0.841      -0.694       0.853\n",
      "real_estate_excess_return    -0.6180      0.282     -2.195      0.028      -1.170      -0.066\n",
      "equity_volatility             4.8451      0.745      6.502      0.000       3.384       6.306\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3921\n",
      "Model:                       QuantReg   Bandwidth:                    0.002384\n",
      "Method:                 Least Squares   Sparsity:                      0.06701\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:40:15   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0067      0.002      3.018      0.003       0.002       0.011\n",
      "three_month_yield_change     -0.1090      0.063     -1.737      0.083      -0.232       0.014\n",
      "term_spread_change           -0.1414      0.060     -2.375      0.018      -0.258      -0.025\n",
      "TED_spread                   -0.6599      0.217     -3.036      0.002      -1.086      -0.234\n",
      "credit_spread_change          0.0613      0.077      0.792      0.428      -0.090       0.213\n",
      "market_return                -0.0234      0.036     -0.653      0.514      -0.094       0.047\n",
      "real_estate_excess_return    -0.0183      0.045     -0.403      0.687      -0.107       0.071\n",
      "equity_volatility             0.9549      0.067     14.189      0.000       0.823       1.087\n",
      "institution                   0.3125      0.021     14.765      0.000       0.271       0.354\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5215\n",
      "Model:                       QuantReg   Bandwidth:                    0.003622\n",
      "Method:                 Least Squares   Sparsity:                       0.2977\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:40:16   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0140      0.004      3.228      0.001       0.005       0.022\n",
      "three_month_yield_change     -0.0580      0.126     -0.459      0.646      -0.305       0.189\n",
      "term_spread_change           -0.2870      0.132     -2.176      0.030      -0.546      -0.028\n",
      "TED_spread                   -1.3604      0.543     -2.505      0.012      -2.425      -0.296\n",
      "credit_spread_change          0.1462      0.177      0.826      0.409      -0.201       0.493\n",
      "market_return                -0.1172      0.110     -1.070      0.285      -0.332       0.098\n",
      "real_estate_excess_return    -0.0586      0.120     -0.487      0.626      -0.294       0.177\n",
      "equity_volatility             1.1834      0.183      6.451      0.000       0.824       1.543\n",
      "institution                   0.3088      0.063      4.880      0.000       0.185       0.433\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 37.0242 - val_loss: 31.2559\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 35.8725 - val_loss: 30.0585\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 34.1759 - val_loss: 28.8120\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 32.8214 - val_loss: 27.6880\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 31.4356 - val_loss: 26.6179\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 30.1206 - val_loss: 25.6266\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 28.9269 - val_loss: 24.6536\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.8092 - val_loss: 23.8522\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.8550 - val_loss: 23.1858\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.1346 - val_loss: 22.5703\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.4802 - val_loss: 22.0447\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9051 - val_loss: 21.5870\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.3557 - val_loss: 21.2166\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9809 - val_loss: 20.9318\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6971 - val_loss: 20.7121\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4003 - val_loss: 20.5248\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3170 - val_loss: 20.3772\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1218 - val_loss: 20.2363\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.9163 - val_loss: 20.1166\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.8572 - val_loss: 20.0326\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.7597 - val_loss: 19.9604\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.7234 - val_loss: 19.9088\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.7207 - val_loss: 19.8755\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.6619 - val_loss: 19.8436\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.5058 - val_loss: 19.8142\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.5556 - val_loss: 19.7851\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.5366 - val_loss: 19.7592\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.4597 - val_loss: 19.7347\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.4475 - val_loss: 19.7115\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2946 - val_loss: 19.6893\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.4155 - val_loss: 19.6674\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3911 - val_loss: 19.6461\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3321 - val_loss: 19.6250\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2479 - val_loss: 19.6049\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3391 - val_loss: 19.5856\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2445 - val_loss: 19.5669\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2596 - val_loss: 19.5482\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2843 - val_loss: 19.5292\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2635 - val_loss: 19.5104\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1606 - val_loss: 19.4929\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1379 - val_loss: 19.4757\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2239 - val_loss: 19.4590\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2049 - val_loss: 19.4421\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.2027 - val_loss: 19.4254\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1812 - val_loss: 19.4090\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1603 - val_loss: 19.3924\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0595 - val_loss: 19.3759\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1440 - val_loss: 19.3596\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1119 - val_loss: 19.3440\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1049 - val_loss: 19.3282\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0910 - val_loss: 19.3123\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0823 - val_loss: 19.2969\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0599 - val_loss: 19.2820\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0567 - val_loss: 19.2676\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0212 - val_loss: 19.2541\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0327 - val_loss: 19.2411\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.0226 - val_loss: 19.2283\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9953 - val_loss: 19.2159\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9898 - val_loss: 19.2037\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8580 - val_loss: 19.1916\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9726 - val_loss: 19.1797\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8683 - val_loss: 19.1675\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9346 - val_loss: 19.1555\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9010 - val_loss: 19.1435\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9210 - val_loss: 19.1316\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8600 - val_loss: 19.1195\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8845 - val_loss: 19.1075\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8751 - val_loss: 19.0956\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8044 - val_loss: 19.0831\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8549 - val_loss: 19.0708\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8374 - val_loss: 19.0585\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7942 - val_loss: 19.0463\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8068 - val_loss: 19.0337\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7854 - val_loss: 19.0212\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7637 - val_loss: 19.0082\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7703 - val_loss: 18.9953\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6720 - val_loss: 18.9822\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7427 - val_loss: 18.9692\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7369 - val_loss: 18.9562\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7145 - val_loss: 18.9431\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6743 - val_loss: 18.9298\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6740 - val_loss: 18.9165\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6615 - val_loss: 18.9031\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6269 - val_loss: 18.8898\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5236 - val_loss: 18.8761\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6273 - val_loss: 18.8626\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6001 - val_loss: 18.8488\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5942 - val_loss: 18.8351\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5943 - val_loss: 18.8214\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4753 - val_loss: 18.8073\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5615 - val_loss: 18.7935\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5460 - val_loss: 18.7795\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5240 - val_loss: 18.7654\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5193 - val_loss: 18.7511\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4394 - val_loss: 18.7370\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4689 - val_loss: 18.7228\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4333 - val_loss: 18.7086\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3256 - val_loss: 18.6944\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4497 - val_loss: 18.6801\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4362 - val_loss: 18.6658\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_140 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_141 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_142 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_143 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_144 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_145 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_146 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 25.9495 - val_loss: 24.4819\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.6741 - val_loss: 23.4909\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6429 - val_loss: 22.7324\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.8226 - val_loss: 22.1237\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.0937 - val_loss: 21.6078\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5712 - val_loss: 21.1442\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1624 - val_loss: 20.7589\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6438 - val_loss: 20.4388\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.1444 - val_loss: 20.2054\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.9195 - val_loss: 20.0141\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7273 - val_loss: 19.8619\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4773 - val_loss: 19.7452\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3201 - val_loss: 19.6371\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.1888 - val_loss: 19.5331\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9942 - val_loss: 19.4323\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9389 - val_loss: 19.3458\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8493 - val_loss: 19.2729\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7469 - val_loss: 19.2083\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6805 - val_loss: 19.1540\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6520 - val_loss: 19.1131\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6280 - val_loss: 19.0815\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6185 - val_loss: 19.0521\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5848 - val_loss: 19.0254\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5637 - val_loss: 19.0001\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5309 - val_loss: 18.9775\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5100 - val_loss: 18.9550\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5012 - val_loss: 18.9334\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4666 - val_loss: 18.9132\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4723 - val_loss: 18.8937\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4522 - val_loss: 18.8754\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3775 - val_loss: 18.8582\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4235 - val_loss: 18.8405\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4114 - val_loss: 18.8232\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3773 - val_loss: 18.8073\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3935 - val_loss: 18.7904\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3293 - val_loss: 18.7756\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3503 - val_loss: 18.7605\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3548 - val_loss: 18.7447\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3253 - val_loss: 18.7303\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3315 - val_loss: 18.7155\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2531 - val_loss: 18.7029\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3068 - val_loss: 18.6886\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2969 - val_loss: 18.6757\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2435 - val_loss: 18.6622\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2536 - val_loss: 18.6488\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2313 - val_loss: 18.6357\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2465 - val_loss: 18.6223\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1897 - val_loss: 18.6093\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1960 - val_loss: 18.5956\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1996 - val_loss: 18.5819\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1876 - val_loss: 18.5681\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1321 - val_loss: 18.5559\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1332 - val_loss: 18.5427\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1610 - val_loss: 18.5291\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0917 - val_loss: 18.5168\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0711 - val_loss: 18.5041\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1208 - val_loss: 18.4909\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0380 - val_loss: 18.4779\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1080 - val_loss: 18.4647\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0374 - val_loss: 18.4523\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0764 - val_loss: 18.4394\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0689 - val_loss: 18.4261\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.0539 - val_loss: 18.4133\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9806 - val_loss: 18.4008\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0278 - val_loss: 18.3867\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9889 - val_loss: 18.3738\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0040 - val_loss: 18.3597\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9954 - val_loss: 18.3458\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9784 - val_loss: 18.3328\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9485 - val_loss: 18.3201\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9461 - val_loss: 18.3068\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8160 - val_loss: 18.2942\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8966 - val_loss: 18.2809\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9062 - val_loss: 18.2670\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8598 - val_loss: 18.2544\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8709 - val_loss: 18.2413\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8554 - val_loss: 18.2279\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8314 - val_loss: 18.2134\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7909 - val_loss: 18.2008\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7762 - val_loss: 18.1875\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8086 - val_loss: 18.1724\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8028 - val_loss: 18.1585\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7912 - val_loss: 18.1447\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7735 - val_loss: 18.1307\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7611 - val_loss: 18.1158\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7018 - val_loss: 18.1013\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7375 - val_loss: 18.0869\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7285 - val_loss: 18.0734\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7000 - val_loss: 18.0591\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6570 - val_loss: 18.0458\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6829 - val_loss: 18.0313\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6293 - val_loss: 18.0170\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6439 - val_loss: 18.0020\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6176 - val_loss: 17.9877\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6208 - val_loss: 17.9732\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6083 - val_loss: 17.9584\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5922 - val_loss: 17.9436\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5804 - val_loss: 17.9289\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5640 - val_loss: 17.9139\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4932 - val_loss: 17.8998\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_147 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_148 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_149 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_150 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_151 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_152 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_153 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1365\n",
      "Model:                       QuantReg   Bandwidth:                    0.004679\n",
      "Method:                 Least Squares   Sparsity:                       0.1659\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:41:35   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0346      0.006      5.749      0.000       0.023       0.046\n",
      "three_month_yield_change     -0.5278      0.160     -3.301      0.001      -0.841      -0.214\n",
      "term_spread_change           -0.6201      0.153     -4.051      0.000      -0.920      -0.320\n",
      "TED_spread                    0.3476      0.580      0.599      0.549      -0.790       1.486\n",
      "credit_spread_change         -0.5683      0.210     -2.708      0.007      -0.980      -0.157\n",
      "market_return                 0.0458      0.091      0.504      0.615      -0.132       0.224\n",
      "real_estate_excess_return     0.1184      0.105      1.124      0.261      -0.088       0.325\n",
      "equity_volatility             1.8630      0.153     12.197      0.000       1.563       2.162\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2696\n",
      "Model:                       QuantReg   Bandwidth:                    0.008261\n",
      "Method:                 Least Squares   Sparsity:                       0.9705\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:41:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0734      0.017      4.217      0.000       0.039       0.107\n",
      "three_month_yield_change     -1.3926      0.479     -2.908      0.004      -2.332      -0.453\n",
      "term_spread_change           -1.5084      0.484     -3.117      0.002      -2.457      -0.559\n",
      "TED_spread                    0.0145      1.778      0.008      0.993      -3.471       3.500\n",
      "credit_spread_change         -1.1263      0.568     -1.984      0.047      -2.240      -0.013\n",
      "market_return                -0.4408      0.364     -1.211      0.226      -1.155       0.273\n",
      "real_estate_excess_return     0.1112      0.315      0.353      0.724      -0.507       0.730\n",
      "equity_volatility             4.0400      0.615      6.574      0.000       2.835       5.245\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4138\n",
      "Model:                       QuantReg   Bandwidth:                    0.002127\n",
      "Method:                 Least Squares   Sparsity:                      0.09005\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:41:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0175      0.003      5.326      0.000       0.011       0.024\n",
      "three_month_yield_change     -0.0774      0.093     -0.835      0.404      -0.259       0.104\n",
      "term_spread_change           -0.1799      0.082     -2.207      0.027      -0.340      -0.020\n",
      "TED_spread                   -1.1159      0.352     -3.174      0.002      -1.805      -0.427\n",
      "credit_spread_change         -0.2464      0.116     -2.119      0.034      -0.474      -0.018\n",
      "market_return                -0.0098      0.042     -0.234      0.815      -0.091       0.072\n",
      "real_estate_excess_return     0.0097      0.054      0.180      0.858      -0.096       0.116\n",
      "equity_volatility             0.7635      0.083      9.213      0.000       0.601       0.926\n",
      "institution                   0.4192      0.039     10.761      0.000       0.343       0.496\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5415\n",
      "Model:                       QuantReg   Bandwidth:                    0.003280\n",
      "Method:                 Least Squares   Sparsity:                       0.2588\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:41:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0274      0.004      6.590      0.000       0.019       0.036\n",
      "three_month_yield_change     -0.0812      0.133     -0.612      0.540      -0.341       0.179\n",
      "term_spread_change           -0.3264      0.125     -2.616      0.009      -0.571      -0.082\n",
      "TED_spread                   -1.9873      0.497     -3.999      0.000      -2.962      -1.013\n",
      "credit_spread_change         -0.1886      0.121     -1.564      0.118      -0.425       0.048\n",
      "market_return                 0.0709      0.089      0.794      0.427      -0.104       0.246\n",
      "real_estate_excess_return    -0.1538      0.089     -1.725      0.085      -0.329       0.021\n",
      "equity_volatility             0.8082      0.149      5.431      0.000       0.516       1.100\n",
      "institution                   0.4350      0.080      5.438      0.000       0.278       0.592\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 42.7412 - val_loss: 39.7240\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 41.4041 - val_loss: 38.5479\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 40.3283 - val_loss: 37.1416\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 38.9136 - val_loss: 35.6151\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 37.1719 - val_loss: 34.0085\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.6888 - val_loss: 32.3564\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.8713 - val_loss: 30.5749\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.1925 - val_loss: 28.7909\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.3707 - val_loss: 27.1982\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.8918 - val_loss: 25.6801\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.4597 - val_loss: 24.3979\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.5054 - val_loss: 23.2763\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.6588 - val_loss: 22.4501\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.2585 - val_loss: 21.8776\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.7879 - val_loss: 21.5308\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.4911 - val_loss: 21.2860\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.1540 - val_loss: 21.0951\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.9545 - val_loss: 20.9553\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8290 - val_loss: 20.8375\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8096 - val_loss: 20.7320\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7141 - val_loss: 20.6361\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5422 - val_loss: 20.5577\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5912 - val_loss: 20.4934\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3913 - val_loss: 20.4467\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5096 - val_loss: 20.4105\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5128 - val_loss: 20.3820\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4918 - val_loss: 20.3591\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4687 - val_loss: 20.3398\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4174 - val_loss: 20.3227\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3914 - val_loss: 20.3068\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4180 - val_loss: 20.2922\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3811 - val_loss: 20.2788\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2578 - val_loss: 20.2653\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3775 - val_loss: 20.2518\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3645 - val_loss: 20.2389\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2977 - val_loss: 20.2266\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3296 - val_loss: 20.2140\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2883 - val_loss: 20.2017\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3161 - val_loss: 20.1895\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2896 - val_loss: 20.1777\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2579 - val_loss: 20.1662\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2833 - val_loss: 20.1545\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2597 - val_loss: 20.1428\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2574 - val_loss: 20.1313\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2281 - val_loss: 20.1198\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1621 - val_loss: 20.1083\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2251 - val_loss: 20.0969\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1150 - val_loss: 20.0854\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1509 - val_loss: 20.0738\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0238 - val_loss: 20.0622\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1187 - val_loss: 20.0506\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1758 - val_loss: 20.0388\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0222 - val_loss: 20.0271\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0957 - val_loss: 20.0151\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0209 - val_loss: 20.0032\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9968 - val_loss: 19.9911\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0778 - val_loss: 19.9790\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8904 - val_loss: 19.9667\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0606 - val_loss: 19.9544\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0164 - val_loss: 19.9420\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9677 - val_loss: 19.9296\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0437 - val_loss: 19.9171\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9938 - val_loss: 19.9045\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0135 - val_loss: 19.8919\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9957 - val_loss: 19.8792\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9963 - val_loss: 19.8665\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9925 - val_loss: 19.8537\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9603 - val_loss: 19.8408\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9088 - val_loss: 19.8277\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9156 - val_loss: 19.8147\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9168 - val_loss: 19.8017\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9104 - val_loss: 19.7886\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8441 - val_loss: 19.7754\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8928 - val_loss: 19.7621\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7608 - val_loss: 19.7486\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8458 - val_loss: 19.7352\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8113 - val_loss: 19.7218\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7837 - val_loss: 19.7082\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7941 - val_loss: 19.6947\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7853 - val_loss: 19.6811\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6932 - val_loss: 19.6675\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7265 - val_loss: 19.6538\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6902 - val_loss: 19.6400\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7009 - val_loss: 19.6261\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5940 - val_loss: 19.6122\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7255 - val_loss: 19.5983\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7114 - val_loss: 19.5844\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6623 - val_loss: 19.5703\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4741 - val_loss: 19.5562\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6257 - val_loss: 19.5420\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6456 - val_loss: 19.5278\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5797 - val_loss: 19.5134\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6141 - val_loss: 19.4991\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6119 - val_loss: 19.4848\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5701 - val_loss: 19.4704\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5738 - val_loss: 19.4560\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5347 - val_loss: 19.4415\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5572 - val_loss: 19.4270\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5464 - val_loss: 19.4125\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4973 - val_loss: 19.3979\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_154 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_155 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_156 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_157 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_158 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_159 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_160 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 26.2411 - val_loss: 24.9532\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.5843 - val_loss: 24.4978\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.1558 - val_loss: 24.0998\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.6834 - val_loss: 23.7251\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.2382 - val_loss: 23.3687\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7519 - val_loss: 23.0189\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3668 - val_loss: 22.6725\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9484 - val_loss: 22.3363\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5576 - val_loss: 22.0184\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1416 - val_loss: 21.7124\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8383 - val_loss: 21.3994\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5015 - val_loss: 21.0911\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1011 - val_loss: 20.8114\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7808 - val_loss: 20.5435\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3795 - val_loss: 20.3227\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2113 - val_loss: 20.1429\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.9919 - val_loss: 19.9882\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7673 - val_loss: 19.8389\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5535 - val_loss: 19.7276\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3693 - val_loss: 19.6293\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2232 - val_loss: 19.5359\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0518 - val_loss: 19.4487\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9938 - val_loss: 19.3625\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8886 - val_loss: 19.2801\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8125 - val_loss: 19.2109\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6984 - val_loss: 19.1536\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6589 - val_loss: 19.1002\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6350 - val_loss: 19.0482\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5827 - val_loss: 19.0053\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5185 - val_loss: 18.9740\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4148 - val_loss: 18.9454\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4772 - val_loss: 18.9191\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4566 - val_loss: 18.8941\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4244 - val_loss: 18.8704\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3651 - val_loss: 18.8473\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3707 - val_loss: 18.8260\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3630 - val_loss: 18.8058\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3572 - val_loss: 18.7865\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3352 - val_loss: 18.7679\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3171 - val_loss: 18.7505\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2007 - val_loss: 18.7334\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2343 - val_loss: 18.7165\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2708 - val_loss: 18.6990\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2589 - val_loss: 18.6818\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2122 - val_loss: 18.6650\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2267 - val_loss: 18.6477\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2153 - val_loss: 18.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1362 - val_loss: 18.6154\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1862 - val_loss: 18.5992\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1548 - val_loss: 18.5836\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1645 - val_loss: 18.5674\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1206 - val_loss: 18.5523\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1310 - val_loss: 18.5370\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1208 - val_loss: 18.5215\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1029 - val_loss: 18.5065\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0923 - val_loss: 18.4918\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9826 - val_loss: 18.4773\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0740 - val_loss: 18.4622\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0473 - val_loss: 18.4475\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0490 - val_loss: 18.4322\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0109 - val_loss: 18.4179\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0129 - val_loss: 18.4027\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9668 - val_loss: 18.3886\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9992 - val_loss: 18.3734\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9801 - val_loss: 18.3585\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9697 - val_loss: 18.3441\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9247 - val_loss: 18.3301\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9395 - val_loss: 18.3152\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9293 - val_loss: 18.3000\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8811 - val_loss: 18.2862\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8950 - val_loss: 18.2711\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8830 - val_loss: 18.2563\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8255 - val_loss: 18.2420\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8305 - val_loss: 18.2274\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8253 - val_loss: 18.2125\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8329 - val_loss: 18.1975\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7779 - val_loss: 18.1826\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7259 - val_loss: 18.1686\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7865 - val_loss: 18.1539\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7747 - val_loss: 18.1390\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7248 - val_loss: 18.1242\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7449 - val_loss: 18.1090\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7230 - val_loss: 18.0932\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7182 - val_loss: 18.0781\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6042 - val_loss: 18.0638\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6862 - val_loss: 18.0495\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6770 - val_loss: 18.0342\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6497 - val_loss: 18.0197\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6430 - val_loss: 18.0044\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6308 - val_loss: 17.9890\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6190 - val_loss: 17.9738\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5974 - val_loss: 17.9584\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5433 - val_loss: 17.9428\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5726 - val_loss: 17.9280\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5592 - val_loss: 17.9126\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5447 - val_loss: 17.8968\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5014 - val_loss: 17.8814\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4704 - val_loss: 17.8661\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4684 - val_loss: 17.8515\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4797 - val_loss: 17.8359\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 1s 10ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_161 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_162 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_163 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_164 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_165 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_166 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_167 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09577\n",
      "Model:                       QuantReg   Bandwidth:                    0.005822\n",
      "Method:                 Least Squares   Sparsity:                       0.1992\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:42:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0182      0.007      2.531      0.011       0.004       0.032\n",
      "three_month_yield_change     -0.1846      0.185     -0.997      0.319      -0.548       0.179\n",
      "term_spread_change           -0.2068      0.174     -1.190      0.234      -0.548       0.134\n",
      "TED_spread                   -2.2392      0.720     -3.110      0.002      -3.651      -0.827\n",
      "credit_spread_change          0.3393      0.251      1.353      0.176      -0.152       0.831\n",
      "market_return                 0.1321      0.099      1.329      0.184      -0.063       0.327\n",
      "real_estate_excess_return     0.2325      0.130      1.787      0.074      -0.023       0.488\n",
      "equity_volatility             1.7677      0.176     10.031      0.000       1.422       2.113\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1259\n",
      "Model:                       QuantReg   Bandwidth:                    0.008623\n",
      "Method:                 Least Squares   Sparsity:                        1.141\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:42:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0833      0.018      4.614      0.000       0.048       0.119\n",
      "three_month_yield_change     -1.1166      0.555     -2.012      0.044      -2.205      -0.029\n",
      "term_spread_change           -1.0448      0.534     -1.957      0.050      -2.092       0.002\n",
      "TED_spread                   -1.8270      2.351     -0.777      0.437      -6.437       2.782\n",
      "credit_spread_change         -0.8095      0.648     -1.250      0.211      -2.079       0.460\n",
      "market_return                 0.3533      0.295      1.196      0.232      -0.226       0.932\n",
      "real_estate_excess_return     0.2945      0.457      0.645      0.519      -0.601       1.190\n",
      "equity_volatility             2.2704      0.569      3.992      0.000       1.155       3.386\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3687\n",
      "Model:                       QuantReg   Bandwidth:                    0.002147\n",
      "Method:                 Least Squares   Sparsity:                      0.07460\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:42:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0177      0.002      7.142      0.000       0.013       0.023\n",
      "three_month_yield_change     -0.1450      0.073     -1.986      0.047      -0.288      -0.002\n",
      "term_spread_change           -0.2245      0.068     -3.284      0.001      -0.359      -0.090\n",
      "TED_spread                   -0.7161      0.266     -2.696      0.007      -1.237      -0.195\n",
      "credit_spread_change         -0.2501      0.086     -2.915      0.004      -0.418      -0.082\n",
      "market_return                -0.0400      0.039     -1.020      0.308      -0.117       0.037\n",
      "real_estate_excess_return    -0.0220      0.046     -0.483      0.629      -0.111       0.067\n",
      "equity_volatility             0.7385      0.074      9.988      0.000       0.594       0.883\n",
      "institution                   0.3293      0.029     11.484      0.000       0.273       0.386\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4370\n",
      "Model:                       QuantReg   Bandwidth:                    0.004769\n",
      "Method:                 Least Squares   Sparsity:                       0.2927\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:42:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0273      0.004      6.864      0.000       0.019       0.035\n",
      "three_month_yield_change     -0.5459      0.121     -4.496      0.000      -0.784      -0.308\n",
      "term_spread_change           -0.4914      0.125     -3.916      0.000      -0.737      -0.245\n",
      "TED_spread                   -1.3650      0.549     -2.486      0.013      -2.442      -0.288\n",
      "credit_spread_change         -0.4082      0.142     -2.867      0.004      -0.687      -0.129\n",
      "market_return                -0.0131      0.114     -0.115      0.908      -0.236       0.210\n",
      "real_estate_excess_return    -0.1458      0.100     -1.465      0.143      -0.341       0.049\n",
      "equity_volatility             2.1663      0.176     12.317      0.000       1.821       2.511\n",
      "institution                   0.2969      0.084      3.529      0.000       0.132       0.462\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 22ms/step - loss: 37.7384 - val_loss: 37.9638\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 36.9365 - val_loss: 37.1540\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 36.1956 - val_loss: 36.3529\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 35.3007 - val_loss: 35.5928\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 34.4348 - val_loss: 34.8349\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 33.5557 - val_loss: 34.0310\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 32.5162 - val_loss: 33.1707\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 31.6998 - val_loss: 32.3042\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 30.8431 - val_loss: 31.4046\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 29.8475 - val_loss: 30.5074\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 29.0336 - val_loss: 29.6380\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 28.1309 - val_loss: 28.7937\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 27.3322 - val_loss: 27.9966\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 26.6734 - val_loss: 27.2667\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 25.9442 - val_loss: 26.5733\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 25.3308 - val_loss: 25.9394\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 24.7410 - val_loss: 25.3902\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 24.2859 - val_loss: 24.9735\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 23.8920 - val_loss: 24.6791\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 23.5291 - val_loss: 24.4390\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 23.2944 - val_loss: 24.2105\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.9667 - val_loss: 24.0050\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.6702 - val_loss: 23.8426\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.6217 - val_loss: 23.6983\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.4990 - val_loss: 23.5804\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 13ms/step - loss: 22.4059 - val_loss: 23.4887\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.2150 - val_loss: 23.4067\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.2033 - val_loss: 23.3376\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.0571 - val_loss: 23.2769\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.0555 - val_loss: 23.2204\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.9429 - val_loss: 23.1689\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.9260 - val_loss: 23.1204\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.7554 - val_loss: 23.0758\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.8327 - val_loss: 23.0332\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6622 - val_loss: 22.9934\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.7221 - val_loss: 22.9566\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.7593 - val_loss: 22.9256\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6206 - val_loss: 22.9014\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.7245 - val_loss: 22.8807\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6907 - val_loss: 22.8615\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6798 - val_loss: 22.8438\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.5174 - val_loss: 22.8265\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6209 - val_loss: 22.8100\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.6090 - val_loss: 22.7935\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.5947 - val_loss: 22.7778\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.5481 - val_loss: 22.7625\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.5618 - val_loss: 22.7469\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4856 - val_loss: 22.7317\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.5448 - val_loss: 22.7166\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4915 - val_loss: 22.7027\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4284 - val_loss: 22.6890\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3514 - val_loss: 22.6758\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4560 - val_loss: 22.6631\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4412 - val_loss: 22.6506\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4637 - val_loss: 22.6379\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4305 - val_loss: 22.6252\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4071 - val_loss: 22.6128\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4073 - val_loss: 22.6004\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4107 - val_loss: 22.5880\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3586 - val_loss: 22.5757\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3200 - val_loss: 22.5634\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3678 - val_loss: 22.5509\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3667 - val_loss: 22.5385\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3481 - val_loss: 22.5260\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.3097 - val_loss: 22.5133\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2518 - val_loss: 22.5007\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2969 - val_loss: 22.4880\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.1809 - val_loss: 22.4753\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2860 - val_loss: 22.4625\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2306 - val_loss: 22.4496\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2690 - val_loss: 22.4367\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2148 - val_loss: 22.4237\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2365 - val_loss: 22.4107\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.2135 - val_loss: 22.3976\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0805 - val_loss: 22.3844\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.1730 - val_loss: 22.3712\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.1627 - val_loss: 22.3579\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0974 - val_loss: 22.3446\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0792 - val_loss: 22.3312\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.1421 - val_loss: 22.3178\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.1182 - val_loss: 22.3043\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0757 - val_loss: 22.2908\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0616 - val_loss: 22.2772\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0742 - val_loss: 22.2636\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0515 - val_loss: 22.2499\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0309 - val_loss: 22.2361\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0341 - val_loss: 22.2223\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0162 - val_loss: 22.2085\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0171 - val_loss: 22.1946\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9712 - val_loss: 22.1807\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.7895 - val_loss: 22.1667\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9768 - val_loss: 22.1527\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9593 - val_loss: 22.1386\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9219 - val_loss: 22.1244\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.7394 - val_loss: 22.1103\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9082 - val_loss: 22.0961\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.9053 - val_loss: 22.0818\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.8944 - val_loss: 22.0676\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.8684 - val_loss: 22.0533\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.8517 - val_loss: 22.0389\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_168 (Conv1D)         (None, 7, 32)             96        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_169 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_170 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_171 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_172 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_173 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_174 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 25.5610 - val_loss: 24.4492\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 24.9173 - val_loss: 23.9367\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 24.4135 - val_loss: 23.4558\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 23.8440 - val_loss: 23.0058\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 23.2862 - val_loss: 22.5727\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.7414 - val_loss: 22.1616\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 22.2404 - val_loss: 21.7879\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.8283 - val_loss: 21.4342\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.4764 - val_loss: 21.1101\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 21.0713 - val_loss: 20.8389\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.8053 - val_loss: 20.5935\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.5808 - val_loss: 20.3964\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.3112 - val_loss: 20.2346\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 20.0907 - val_loss: 20.1007\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.8850 - val_loss: 19.9747\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.6900 - val_loss: 19.8736\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.5565 - val_loss: 19.7923\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.3955 - val_loss: 19.7146\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.3001 - val_loss: 19.6394\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.1037 - val_loss: 19.5698\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.1303 - val_loss: 19.5000\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 19.0410 - val_loss: 19.4322\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.8340 - val_loss: 19.3695\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.8742 - val_loss: 19.3153\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.8305 - val_loss: 19.2655\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.7802 - val_loss: 19.2191\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.7372 - val_loss: 19.1750\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.7039 - val_loss: 19.1339\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.6458 - val_loss: 19.0951\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.6434 - val_loss: 19.0623\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.5879 - val_loss: 19.0352\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.5670 - val_loss: 19.0107\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.5454 - val_loss: 18.9865\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.4346 - val_loss: 18.9638\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.4984 - val_loss: 18.9427\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.4751 - val_loss: 18.9222\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.4649 - val_loss: 18.9015\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.4255 - val_loss: 18.8816\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3129 - val_loss: 18.8630\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.4119 - val_loss: 18.8443\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3263 - val_loss: 18.8257\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3589 - val_loss: 18.8077\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3283 - val_loss: 18.7907\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3517 - val_loss: 18.7732\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2662 - val_loss: 18.7570\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3125 - val_loss: 18.7406\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.3020 - val_loss: 18.7240\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2821 - val_loss: 18.7078\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2343 - val_loss: 18.6916\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1562 - val_loss: 18.6757\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2437 - val_loss: 18.6596\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2190 - val_loss: 18.6442\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.2311 - val_loss: 18.6279\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1600 - val_loss: 18.6124\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1907 - val_loss: 18.5971\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1531 - val_loss: 18.5818\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1251 - val_loss: 18.5671\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1534 - val_loss: 18.5519\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1222 - val_loss: 18.5381\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1382 - val_loss: 18.5237\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1339 - val_loss: 18.5089\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.1071 - val_loss: 18.4954\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.0843 - val_loss: 18.4819\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 13ms/step - loss: 18.0517 - val_loss: 18.4679\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.0835 - val_loss: 18.4537\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.0415 - val_loss: 18.4396\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9766 - val_loss: 18.4261\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 18.0334 - val_loss: 18.4116\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 17.9874 - val_loss: 18.3973\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.0190 - val_loss: 18.3831\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9954 - val_loss: 18.3687\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9670 - val_loss: 18.3545\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9356 - val_loss: 18.3405\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9449 - val_loss: 18.3265\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9481 - val_loss: 18.3118\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9087 - val_loss: 18.2978\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8893 - val_loss: 18.2844\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8863 - val_loss: 18.2703\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.9016 - val_loss: 18.2566\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8721 - val_loss: 18.2425\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8667 - val_loss: 18.2281\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8068 - val_loss: 18.2147\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8337 - val_loss: 18.2009\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8301 - val_loss: 18.1872\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8134 - val_loss: 18.1728\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.8000 - val_loss: 18.1585\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.7708 - val_loss: 18.1441\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.7672 - val_loss: 18.1297\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.7526 - val_loss: 18.1148\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.7447 - val_loss: 18.1009\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6526 - val_loss: 18.0871\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6933 - val_loss: 18.0730\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.7066 - val_loss: 18.0589\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6816 - val_loss: 18.0444\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6700 - val_loss: 18.0298\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6533 - val_loss: 18.0156\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6482 - val_loss: 18.0007\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6221 - val_loss: 17.9861\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.6201 - val_loss: 17.9711\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 17.5549 - val_loss: 17.9562\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_175 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_176 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_177 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_178 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_179 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_180 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_181 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1016\n",
      "Model:                       QuantReg   Bandwidth:                    0.004987\n",
      "Method:                 Least Squares   Sparsity:                       0.1876\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:44:21   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0032      0.007      0.435      0.663      -0.011       0.018\n",
      "three_month_yield_change      0.0992      0.181      0.549      0.583      -0.255       0.453\n",
      "term_spread_change           -0.0735      0.149     -0.495      0.621      -0.365       0.218\n",
      "TED_spread                   -0.4284      0.616     -0.695      0.487      -1.637       0.780\n",
      "credit_spread_change          0.3456      0.259      1.334      0.182      -0.162       0.854\n",
      "market_return                 0.0480      0.101      0.477      0.634      -0.149       0.245\n",
      "real_estate_excess_return     0.1006      0.108      0.934      0.350      -0.111       0.312\n",
      "equity_volatility             1.9026      0.193      9.884      0.000       1.525       2.280\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2274\n",
      "Model:                       QuantReg   Bandwidth:                    0.007818\n",
      "Method:                 Least Squares   Sparsity:                       0.5971\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:44:21   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0078      0.010      0.802      0.423      -0.011       0.027\n",
      "three_month_yield_change      0.4940      0.256      1.932      0.053      -0.007       0.995\n",
      "term_spread_change            0.1579      0.240      0.658      0.511      -0.313       0.628\n",
      "TED_spread                    3.0374      0.931      3.263      0.001       1.212       4.863\n",
      "credit_spread_change         -0.2371      0.335     -0.708      0.479      -0.894       0.420\n",
      "market_return                -0.2520      0.244     -1.032      0.302      -0.731       0.227\n",
      "real_estate_excess_return    -0.0215      0.233     -0.092      0.927      -0.479       0.436\n",
      "equity_volatility             3.4253      0.396      8.656      0.000       2.649       4.201\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4358\n",
      "Model:                       QuantReg   Bandwidth:                    0.001977\n",
      "Method:                 Least Squares   Sparsity:                      0.07744\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:44:21   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0147      0.003      4.949      0.000       0.009       0.021\n",
      "three_month_yield_change     -0.1053      0.084     -1.247      0.213      -0.271       0.060\n",
      "term_spread_change           -0.1105      0.073     -1.522      0.128      -0.253       0.032\n",
      "TED_spread                   -0.5692      0.279     -2.039      0.042      -1.117      -0.022\n",
      "credit_spread_change         -0.2187      0.096     -2.281      0.023      -0.407      -0.031\n",
      "market_return                -0.0596      0.040     -1.471      0.142      -0.139       0.020\n",
      "real_estate_excess_return    -0.0384      0.044     -0.873      0.383      -0.125       0.048\n",
      "equity_volatility             0.6341      0.076      8.399      0.000       0.486       0.782\n",
      "institution                   0.4256      0.036     11.970      0.000       0.356       0.495\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5349\n",
      "Model:                       QuantReg   Bandwidth:                    0.003057\n",
      "Method:                 Least Squares   Sparsity:                       0.3316\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:44:21   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0086      0.006      1.400      0.162      -0.003       0.021\n",
      "three_month_yield_change      0.0482      0.197      0.244      0.807      -0.339       0.435\n",
      "term_spread_change           -0.1324      0.177     -0.749      0.454      -0.479       0.214\n",
      "TED_spread                    0.3830      0.600      0.638      0.523      -0.794       1.560\n",
      "credit_spread_change          0.1124      0.176      0.639      0.523      -0.233       0.458\n",
      "market_return                 0.0472      0.117      0.404      0.686      -0.182       0.276\n",
      "real_estate_excess_return    -0.1621      0.109     -1.483      0.138      -0.376       0.052\n",
      "equity_volatility             0.9488      0.188      5.034      0.000       0.579       1.318\n",
      "institution                   0.4474      0.091      4.928      0.000       0.269       0.625\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 20ms/step - loss: 43.0819 - val_loss: 41.4089\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 42.5004 - val_loss: 40.7663\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 41.6935 - val_loss: 39.9750\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 40.4830 - val_loss: 39.1390\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 39.6132 - val_loss: 38.1943\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 38.5305 - val_loss: 37.0700\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 37.2914 - val_loss: 35.8211\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 35.5304 - val_loss: 34.3973\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 33.8090 - val_loss: 32.8924\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 32.2671 - val_loss: 31.4577\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 30.6814 - val_loss: 30.0761\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 29.3007 - val_loss: 28.9480\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 28.0360 - val_loss: 27.9777\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.0892 - val_loss: 27.1828\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 26.3590 - val_loss: 26.6263\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.6499 - val_loss: 26.2009\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.2603 - val_loss: 25.9146\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.5588 - val_loss: 25.6720\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.6645 - val_loss: 25.5022\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.4732 - val_loss: 25.3685\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.3925 - val_loss: 25.2617\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.3024 - val_loss: 25.1672\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.2110 - val_loss: 25.0933\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.2060 - val_loss: 25.0349\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.1188 - val_loss: 24.9838\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.0997 - val_loss: 24.9461\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.0865 - val_loss: 24.9112\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.0460 - val_loss: 24.8780\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.0058 - val_loss: 24.8478\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9762 - val_loss: 24.8204\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9575 - val_loss: 24.7927\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8659 - val_loss: 24.7675\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9529 - val_loss: 24.7432\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9408 - val_loss: 24.7190\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.9038 - val_loss: 24.6957\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8800 - val_loss: 24.6730\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8517 - val_loss: 24.6514\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7543 - val_loss: 24.6320\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8504 - val_loss: 24.6121\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8052 - val_loss: 24.5935\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.8032 - val_loss: 24.5744\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5622 - val_loss: 24.5566\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7685 - val_loss: 24.5380\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7581 - val_loss: 24.5193\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7638 - val_loss: 24.5015\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5223 - val_loss: 24.4836\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6811 - val_loss: 24.4661\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7240 - val_loss: 24.4490\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6775 - val_loss: 24.4328\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6974 - val_loss: 24.4164\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6848 - val_loss: 24.4002\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6718 - val_loss: 24.3839\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6648 - val_loss: 24.3671\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6157 - val_loss: 24.3506\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6337 - val_loss: 24.3348\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5246 - val_loss: 24.3195\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5813 - val_loss: 24.3038\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4042 - val_loss: 24.2876\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5750 - val_loss: 24.2716\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5599 - val_loss: 24.2561\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5204 - val_loss: 24.2400\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3590 - val_loss: 24.2245\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4937 - val_loss: 24.2091\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.5060 - val_loss: 24.1952\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4914 - val_loss: 24.1796\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4678 - val_loss: 24.1654\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4695 - val_loss: 24.1503\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4469 - val_loss: 24.1360\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4484 - val_loss: 24.1210\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4339 - val_loss: 24.1062\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.4188 - val_loss: 24.0918\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3585 - val_loss: 24.0773\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3979 - val_loss: 24.0630\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3754 - val_loss: 24.0482\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3202 - val_loss: 24.0336\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3475 - val_loss: 24.0188\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3132 - val_loss: 24.0044\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2415 - val_loss: 23.9901\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2563 - val_loss: 23.9761\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2807 - val_loss: 23.9614\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2768 - val_loss: 23.9468\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2578 - val_loss: 23.9323\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2153 - val_loss: 23.9176\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1879 - val_loss: 23.9035\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.2140 - val_loss: 23.8880\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1493 - val_loss: 23.8732\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1746 - val_loss: 23.8574\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1730 - val_loss: 23.8418\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1418 - val_loss: 23.8270\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1465 - val_loss: 23.8117\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0579 - val_loss: 23.7970\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.1090 - val_loss: 23.7817\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0062 - val_loss: 23.7668\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0148 - val_loss: 23.7517\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0728 - val_loss: 23.7360\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.8006 - val_loss: 23.7208\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0091 - val_loss: 23.7055\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.9684 - val_loss: 23.6905\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.9365 - val_loss: 23.6750\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.9654 - val_loss: 23.6598\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_182 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_183 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_184 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_185 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_186 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_187 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_188 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 25.7104 - val_loss: 24.5624\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.0378 - val_loss: 23.9272\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.2323 - val_loss: 23.3451\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6274 - val_loss: 22.8161\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0255 - val_loss: 22.3278\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.4837 - val_loss: 21.9021\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.9740 - val_loss: 21.5030\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5631 - val_loss: 21.1045\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8670 - val_loss: 20.7580\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.6408 - val_loss: 20.4612\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.3349 - val_loss: 20.2276\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.0643 - val_loss: 20.0456\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7947 - val_loss: 19.8854\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.4432 - val_loss: 19.7708\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.3897 - val_loss: 19.6634\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.2360 - val_loss: 19.5652\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.1022 - val_loss: 19.4719\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9880 - val_loss: 19.3820\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8939 - val_loss: 19.3107\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8227 - val_loss: 19.2489\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7361 - val_loss: 19.1912\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7224 - val_loss: 19.1362\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6411 - val_loss: 19.0910\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6204 - val_loss: 19.0595\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5885 - val_loss: 19.0300\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5459 - val_loss: 19.0040\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5324 - val_loss: 18.9796\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4043 - val_loss: 18.9571\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4793 - val_loss: 18.9351\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4422 - val_loss: 18.9140\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4151 - val_loss: 18.8949\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4436 - val_loss: 18.8768\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2927 - val_loss: 18.8589\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3885 - val_loss: 18.8416\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3988 - val_loss: 18.8238\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3453 - val_loss: 18.8062\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3553 - val_loss: 18.7889\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3597 - val_loss: 18.7722\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3232 - val_loss: 18.7557\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3303 - val_loss: 18.7397\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2807 - val_loss: 18.7243\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2324 - val_loss: 18.7098\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2802 - val_loss: 18.6952\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2868 - val_loss: 18.6807\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2669 - val_loss: 18.6661\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2648 - val_loss: 18.6519\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2556 - val_loss: 18.6373\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2244 - val_loss: 18.6235\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1618 - val_loss: 18.6101\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2047 - val_loss: 18.5961\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1856 - val_loss: 18.5829\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1779 - val_loss: 18.5691\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1725 - val_loss: 18.5558\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1267 - val_loss: 18.5421\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1532 - val_loss: 18.5279\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0968 - val_loss: 18.5139\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1271 - val_loss: 18.5001\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1030 - val_loss: 18.4864\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0905 - val_loss: 18.4731\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0944 - val_loss: 18.4592\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0837 - val_loss: 18.4453\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0586 - val_loss: 18.4313\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0348 - val_loss: 18.4176\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0376 - val_loss: 18.4047\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0190 - val_loss: 18.3907\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9780 - val_loss: 18.3767\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9404 - val_loss: 18.3641\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9763 - val_loss: 18.3504\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9514 - val_loss: 18.3363\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9659 - val_loss: 18.3224\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8620 - val_loss: 18.3083\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9305 - val_loss: 18.2947\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9201 - val_loss: 18.2806\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8963 - val_loss: 18.2668\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8766 - val_loss: 18.2538\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8897 - val_loss: 18.2401\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8303 - val_loss: 18.2259\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8484 - val_loss: 18.2118\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8448 - val_loss: 18.1979\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8207 - val_loss: 18.1845\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8178 - val_loss: 18.1708\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7799 - val_loss: 18.1573\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7819 - val_loss: 18.1431\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7537 - val_loss: 18.1300\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7666 - val_loss: 18.1156\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7333 - val_loss: 18.1013\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7162 - val_loss: 18.0871\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6311 - val_loss: 18.0734\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6773 - val_loss: 18.0599\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6916 - val_loss: 18.0457\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6595 - val_loss: 18.0314\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6125 - val_loss: 18.0169\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6308 - val_loss: 18.0028\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5865 - val_loss: 17.9887\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6239 - val_loss: 17.9737\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5799 - val_loss: 17.9595\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5658 - val_loss: 17.9462\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5748 - val_loss: 17.9311\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5596 - val_loss: 17.9164\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5266 - val_loss: 17.9016\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_189 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_190 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_191 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_192 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_193 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_194 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_195 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1109\n",
      "Model:                       QuantReg   Bandwidth:                    0.005876\n",
      "Method:                 Least Squares   Sparsity:                       0.2370\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:45:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    -0.0100      0.009     -1.092      0.275      -0.028       0.008\n",
      "three_month_yield_change      0.2366      0.212      1.118      0.264      -0.178       0.651\n",
      "term_spread_change            0.2006      0.195      1.028      0.304      -0.182       0.583\n",
      "TED_spread                    0.1931      0.785      0.246      0.806      -1.346       1.732\n",
      "credit_spread_change          0.8097      0.317      2.552      0.011       0.188       1.432\n",
      "market_return                 0.0842      0.123      0.685      0.494      -0.157       0.325\n",
      "real_estate_excess_return     0.1871      0.145      1.291      0.197      -0.097       0.471\n",
      "equity_volatility             2.0206      0.210      9.605      0.000       1.608       2.433\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2369\n",
      "Model:                       QuantReg   Bandwidth:                    0.009637\n",
      "Method:                 Least Squares   Sparsity:                        1.070\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:45:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0019      0.018      0.102      0.919      -0.034       0.038\n",
      "three_month_yield_change      0.1956      0.467      0.419      0.676      -0.721       1.112\n",
      "term_spread_change           -0.0649      0.468     -0.139      0.890      -0.983       0.853\n",
      "TED_spread                    1.3527      2.084      0.649      0.516      -2.733       5.439\n",
      "credit_spread_change          0.6648      0.609      1.092      0.275      -0.529       1.859\n",
      "market_return                -0.2147      0.437     -0.492      0.623      -1.071       0.642\n",
      "real_estate_excess_return    -0.0417      0.446     -0.093      0.926      -0.917       0.833\n",
      "equity_volatility             3.8201      0.713      5.360      0.000       2.423       5.218\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4425\n",
      "Model:                       QuantReg   Bandwidth:                    0.002080\n",
      "Method:                 Least Squares   Sparsity:                      0.07276\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:45:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0100      0.003      3.913      0.000       0.005       0.015\n",
      "three_month_yield_change     -0.1317      0.072     -1.821      0.069      -0.273       0.010\n",
      "term_spread_change           -0.1467      0.065     -2.247      0.025      -0.275      -0.019\n",
      "TED_spread                   -0.5361      0.252     -2.129      0.033      -1.030      -0.042\n",
      "credit_spread_change         -0.0081      0.088     -0.091      0.927      -0.181       0.165\n",
      "market_return                -0.0300      0.037     -0.815      0.415      -0.102       0.042\n",
      "real_estate_excess_return    -0.0653      0.041     -1.594      0.111      -0.146       0.015\n",
      "equity_volatility             0.6687      0.073      9.211      0.000       0.526       0.811\n",
      "institution                   0.3602      0.027     13.337      0.000       0.307       0.413\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5549\n",
      "Model:                       QuantReg   Bandwidth:                    0.003365\n",
      "Method:                 Least Squares   Sparsity:                       0.2715\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:45:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0185      0.004      4.550      0.000       0.011       0.026\n",
      "three_month_yield_change     -0.0912      0.146     -0.624      0.532      -0.377       0.195\n",
      "term_spread_change           -0.3617      0.142     -2.556      0.011      -0.639      -0.084\n",
      "TED_spread                   -1.2739      0.523     -2.437      0.015      -2.299      -0.249\n",
      "credit_spread_change         -0.0118      0.114     -0.104      0.917      -0.235       0.211\n",
      "market_return                 0.0544      0.089      0.615      0.539      -0.119       0.228\n",
      "real_estate_excess_return    -0.1285      0.075     -1.702      0.089      -0.277       0.020\n",
      "equity_volatility             1.1200      0.159      7.043      0.000       0.808       1.432\n",
      "institution                   0.3818      0.064      5.997      0.000       0.257       0.507\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 19ms/step - loss: 41.9589 - val_loss: 36.7137\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 41.2311 - val_loss: 36.0900\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 40.4014 - val_loss: 35.3974\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.6047 - val_loss: 34.6614\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 38.7548 - val_loss: 33.8632\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 37.8781 - val_loss: 32.9665\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.5914 - val_loss: 32.0187\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.5480 - val_loss: 31.0392\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 34.4726 - val_loss: 29.9938\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.1260 - val_loss: 28.8190\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.6049 - val_loss: 27.4990\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.2514 - val_loss: 26.0431\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.9658 - val_loss: 24.6888\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.7885 - val_loss: 23.4825\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.7970 - val_loss: 22.4736\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.0015 - val_loss: 21.6581\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.1897 - val_loss: 21.0168\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.7497 - val_loss: 20.5811\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.3998 - val_loss: 20.3607\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0689 - val_loss: 20.1949\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8703 - val_loss: 20.0709\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5565 - val_loss: 19.9695\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5359 - val_loss: 19.8776\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5134 - val_loss: 19.7943\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4145 - val_loss: 19.7238\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3304 - val_loss: 19.6630\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3262 - val_loss: 19.6052\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2385 - val_loss: 19.5572\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0862 - val_loss: 19.5213\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2244 - val_loss: 19.4954\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1563 - val_loss: 19.4823\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1571 - val_loss: 19.4740\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1040 - val_loss: 19.4691\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1273 - val_loss: 19.4655\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0979 - val_loss: 19.4611\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0555 - val_loss: 19.4566\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0783 - val_loss: 19.4519\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0451 - val_loss: 19.4463\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0342 - val_loss: 19.4401\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0085 - val_loss: 19.4331\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9299 - val_loss: 19.4264\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8253 - val_loss: 19.4191\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9456 - val_loss: 19.4130\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9706 - val_loss: 19.4073\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9409 - val_loss: 19.4015\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9632 - val_loss: 19.3962\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9493 - val_loss: 19.3889\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7312 - val_loss: 19.3810\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8985 - val_loss: 19.3724\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9158 - val_loss: 19.3657\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8749 - val_loss: 19.3571\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8978 - val_loss: 19.3487\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8846 - val_loss: 19.3397\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8061 - val_loss: 19.3308\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8301 - val_loss: 19.3223\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7680 - val_loss: 19.3113\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8393 - val_loss: 19.3023\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8101 - val_loss: 19.2923\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8317 - val_loss: 19.2833\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7868 - val_loss: 19.2734\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7965 - val_loss: 19.2645\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6814 - val_loss: 19.2527\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7583 - val_loss: 19.2432\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7488 - val_loss: 19.2315\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7330 - val_loss: 19.2207\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6561 - val_loss: 19.2094\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7167 - val_loss: 19.1989\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7072 - val_loss: 19.1874\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6426 - val_loss: 19.1753\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6271 - val_loss: 19.1626\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6466 - val_loss: 19.1507\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6330 - val_loss: 19.1394\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6188 - val_loss: 19.1270\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6214 - val_loss: 19.1165\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5980 - val_loss: 19.1041\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6050 - val_loss: 19.0918\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4350 - val_loss: 19.0781\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5743 - val_loss: 19.0662\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5523 - val_loss: 19.0556\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5245 - val_loss: 19.0424\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5533 - val_loss: 19.0300\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5324 - val_loss: 19.0172\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5065 - val_loss: 19.0036\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4705 - val_loss: 18.9902\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4629 - val_loss: 18.9773\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4687 - val_loss: 18.9637\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4464 - val_loss: 18.9496\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1960 - val_loss: 18.9354\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4063 - val_loss: 18.9226\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3844 - val_loss: 18.9072\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3867 - val_loss: 18.8935\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3924 - val_loss: 18.8817\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3762 - val_loss: 18.8682\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3748 - val_loss: 18.8549\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3565 - val_loss: 18.8414\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3361 - val_loss: 18.8266\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2887 - val_loss: 18.8113\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2474 - val_loss: 18.7985\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2839 - val_loss: 18.7848\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1478 - val_loss: 18.7709\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_196 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_197 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_198 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_199 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_200 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_201 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_202 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  117\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 3s 19ms/step - loss: 25.6636 - val_loss: 24.4798\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.9860 - val_loss: 23.9152\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.3472 - val_loss: 23.3958\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.6311 - val_loss: 22.8290\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0229 - val_loss: 22.2669\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3955 - val_loss: 21.7858\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7809 - val_loss: 21.3259\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3245 - val_loss: 20.9127\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 20.8915 - val_loss: 20.5540\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 20.3737 - val_loss: 20.2590\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.0794 - val_loss: 20.0304\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.7942 - val_loss: 19.8282\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.4877 - val_loss: 19.6838\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 19.2752 - val_loss: 19.5540\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.9979 - val_loss: 19.4396\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8970 - val_loss: 19.3282\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.8531 - val_loss: 19.2372\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.7038 - val_loss: 19.1558\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.6850 - val_loss: 19.0846\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5958 - val_loss: 19.0317\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5668 - val_loss: 18.9917\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.5028 - val_loss: 18.9578\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4929 - val_loss: 18.9256\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.4624 - val_loss: 18.8977\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3749 - val_loss: 18.8730\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3852 - val_loss: 18.8517\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3255 - val_loss: 18.8301\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3792 - val_loss: 18.8098\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3230 - val_loss: 18.7909\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3462 - val_loss: 18.7737\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3397 - val_loss: 18.7562\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3358 - val_loss: 18.7393\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.3292 - val_loss: 18.7242\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2876 - val_loss: 18.7105\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2813 - val_loss: 18.6964\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2459 - val_loss: 18.6820\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2376 - val_loss: 18.6681\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2659 - val_loss: 18.6550\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2426 - val_loss: 18.6415\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 18.1638 - val_loss: 18.6280\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2089 - val_loss: 18.6145\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1852 - val_loss: 18.6016\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.2093 - val_loss: 18.5875\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1890 - val_loss: 18.5745\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1738 - val_loss: 18.5621\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1641 - val_loss: 18.5498\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1650 - val_loss: 18.5363\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1254 - val_loss: 18.5231\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0928 - val_loss: 18.5097\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0878 - val_loss: 18.4961\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0922 - val_loss: 18.4835\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0909 - val_loss: 18.4697\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0629 - val_loss: 18.4565\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0807 - val_loss: 18.4433\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0459 - val_loss: 18.4298\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9921 - val_loss: 18.4172\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0152 - val_loss: 18.4046\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0275 - val_loss: 18.3912\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9920 - val_loss: 18.3785\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.0024 - val_loss: 18.3651\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9385 - val_loss: 18.3516\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9794 - val_loss: 18.3382\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9481 - val_loss: 18.3248\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9243 - val_loss: 18.3117\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9348 - val_loss: 18.2981\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.9127 - val_loss: 18.2844\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8964 - val_loss: 18.2712\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8856 - val_loss: 18.2570\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8592 - val_loss: 18.2434\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8686 - val_loss: 18.2289\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8192 - val_loss: 18.2148\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8288 - val_loss: 18.2005\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.8201 - val_loss: 18.1861\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6613 - val_loss: 18.1721\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7615 - val_loss: 18.1577\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7709 - val_loss: 18.1435\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7681 - val_loss: 18.1309\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7661 - val_loss: 18.1166\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7505 - val_loss: 18.1018\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.7350 - val_loss: 18.0872\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6995 - val_loss: 18.0725\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6624 - val_loss: 18.0595\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6596 - val_loss: 18.0458\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6782 - val_loss: 18.0314\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6644 - val_loss: 18.0169\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6188 - val_loss: 18.0027\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6325 - val_loss: 17.9872\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.6168 - val_loss: 17.9722\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5528 - val_loss: 17.9582\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5527 - val_loss: 17.9436\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5304 - val_loss: 17.9289\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5529 - val_loss: 17.9141\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5378 - val_loss: 17.8990\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5344 - val_loss: 17.8844\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4759 - val_loss: 17.8694\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.5053 - val_loss: 17.8539\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4809 - val_loss: 17.8386\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4447 - val_loss: 17.8239\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4546 - val_loss: 17.8091\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 17.4273 - val_loss: 17.7946\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_203 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_204 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_205 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_206 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_207 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_208 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_209 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.06039\n",
      "Model:                       QuantReg   Bandwidth:                    0.005858\n",
      "Method:                 Least Squares   Sparsity:                       0.2265\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:46:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0188      0.008      2.214      0.027       0.002       0.035\n",
      "three_month_yield_change      0.1649      0.211      0.784      0.433      -0.248       0.578\n",
      "term_spread_change           -0.1876      0.197     -0.951      0.342      -0.575       0.199\n",
      "TED_spread                   -1.9347      0.829     -2.333      0.020      -3.561      -0.309\n",
      "credit_spread_change          0.2439      0.303      0.805      0.421      -0.350       0.838\n",
      "market_return                -0.1575      0.115     -1.374      0.169      -0.382       0.067\n",
      "real_estate_excess_return     0.1438      0.125      1.147      0.252      -0.102       0.390\n",
      "equity_volatility             1.6774      0.198      8.489      0.000       1.290       2.065\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1030\n",
      "Model:                       QuantReg   Bandwidth:                    0.008279\n",
      "Method:                 Least Squares   Sparsity:                       0.9801\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:46:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0618      0.015      4.013      0.000       0.032       0.092\n",
      "three_month_yield_change     -0.1327      0.443     -0.300      0.764      -1.001       0.735\n",
      "term_spread_change           -0.2755      0.447     -0.616      0.538      -1.152       0.601\n",
      "TED_spread                    2.9713      1.649      1.802      0.072      -0.262       6.205\n",
      "credit_spread_change         -1.2972      0.534     -2.429      0.015      -2.344      -0.250\n",
      "market_return                -0.3694      0.276     -1.341      0.180      -0.910       0.171\n",
      "real_estate_excess_return    -0.2728      0.291     -0.936      0.349      -0.844       0.299\n",
      "equity_volatility             2.4809      0.463      5.364      0.000       1.574       3.388\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3872\n",
      "Model:                       QuantReg   Bandwidth:                    0.002116\n",
      "Method:                 Least Squares   Sparsity:                      0.08346\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:46:59   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0163      0.003      5.839      0.000       0.011       0.022\n",
      "three_month_yield_change     -0.1352      0.085     -1.591      0.112      -0.302       0.031\n",
      "term_spread_change           -0.2189      0.078     -2.798      0.005      -0.372      -0.066\n",
      "TED_spread                   -0.7354      0.311     -2.364      0.018      -1.345      -0.125\n",
      "credit_spread_change         -0.1866      0.097     -1.917      0.055      -0.377       0.004\n",
      "market_return                 0.0326      0.045      0.721      0.471      -0.056       0.121\n",
      "real_estate_excess_return    -0.0289      0.054     -0.537      0.591      -0.134       0.077\n",
      "equity_volatility             0.7273      0.083      8.717      0.000       0.564       0.891\n",
      "institution                   0.3485      0.031     11.073      0.000       0.287       0.410\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4642\n",
      "Model:                       QuantReg   Bandwidth:                    0.003871\n",
      "Method:                 Least Squares   Sparsity:                       0.4151\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:46:59   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0358      0.006      5.720      0.000       0.024       0.048\n",
      "three_month_yield_change     -0.4656      0.178     -2.613      0.009      -0.815      -0.116\n",
      "term_spread_change           -0.5501      0.184     -2.983      0.003      -0.912      -0.188\n",
      "TED_spread                   -1.9573      0.856     -2.286      0.022      -3.636      -0.279\n",
      "credit_spread_change         -0.3982      0.244     -1.631      0.103      -0.877       0.080\n",
      "market_return                 0.0417      0.178      0.235      0.815      -0.307       0.391\n",
      "real_estate_excess_return    -0.1566      0.174     -0.899      0.369      -0.498       0.185\n",
      "equity_volatility             1.2643      0.274      4.611      0.000       0.727       1.802\n",
      "institution                   0.3599      0.113      3.198      0.001       0.139       0.581\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 35.1039 - val_loss: 28.9039\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 34.2693 - val_loss: 28.4310\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 33.6720 - val_loss: 28.0035\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 32.8397 - val_loss: 27.5977\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 32.3193 - val_loss: 27.1770\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 31.8178 - val_loss: 26.6942\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 31.0355 - val_loss: 26.2079\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 30.2201 - val_loss: 25.6908\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 29.3523 - val_loss: 25.1056\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 28.1847 - val_loss: 24.5302\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 27.3846 - val_loss: 23.9623\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 26.6194 - val_loss: 23.4515\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 25.8688 - val_loss: 22.9894\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 25.0889 - val_loss: 22.5616\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.6391 - val_loss: 22.1357\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 24.1558 - val_loss: 21.7610\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.7205 - val_loss: 21.4695\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.3438 - val_loss: 21.2400\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 23.0167 - val_loss: 21.0453\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.7814 - val_loss: 20.8833\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3873 - val_loss: 20.7600\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.3746 - val_loss: 20.6660\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 22.1559 - val_loss: 20.5888\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.0127 - val_loss: 20.5148\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.9420 - val_loss: 20.4467\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.8437 - val_loss: 20.3856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6730 - val_loss: 20.3276\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.7414 - val_loss: 20.2739\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.6745 - val_loss: 20.2247\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5689 - val_loss: 20.1795\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5312 - val_loss: 20.1383\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4853 - val_loss: 20.1007\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5196 - val_loss: 20.0649\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.5120 - val_loss: 20.0313\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4317 - val_loss: 20.0038\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4593 - val_loss: 19.9824\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2657 - val_loss: 19.9678\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.4021 - val_loss: 19.9555\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3979 - val_loss: 19.9446\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3270 - val_loss: 19.9336\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3372 - val_loss: 19.9226\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.3199 - val_loss: 19.9115\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2627 - val_loss: 19.9003\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2798 - val_loss: 19.8891\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2944 - val_loss: 19.8778\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2766 - val_loss: 19.8664\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2575 - val_loss: 19.8549\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1989 - val_loss: 19.8434\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1310 - val_loss: 19.8318\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.2189 - val_loss: 19.8201\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1773 - val_loss: 19.8083\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1889 - val_loss: 19.7965\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0938 - val_loss: 19.7846\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0776 - val_loss: 19.7726\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1610 - val_loss: 19.7606\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9196 - val_loss: 19.7485\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.1177 - val_loss: 19.7363\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0234 - val_loss: 19.7241\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0930 - val_loss: 19.7118\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 21.0812 - val_loss: 19.6994\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0338 - val_loss: 19.6870\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0233 - val_loss: 19.6745\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0455 - val_loss: 19.6619\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0440 - val_loss: 19.6493\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0101 - val_loss: 19.6367\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9979 - val_loss: 19.6240\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9972 - val_loss: 19.6111\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9836 - val_loss: 19.5983\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9758 - val_loss: 19.5853\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9648 - val_loss: 19.5724\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9421 - val_loss: 19.5594\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8855 - val_loss: 19.5463\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.9186 - val_loss: 19.5332\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8627 - val_loss: 19.5200\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8284 - val_loss: 19.5068\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8768 - val_loss: 19.4934\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8780 - val_loss: 19.4801\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8071 - val_loss: 19.4667\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8299 - val_loss: 19.4532\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7933 - val_loss: 19.4397\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.8047 - val_loss: 19.4261\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7893 - val_loss: 19.4125\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7884 - val_loss: 19.3988\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7858 - val_loss: 19.3851\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7516 - val_loss: 19.3713\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7450 - val_loss: 19.3575\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6716 - val_loss: 19.3436\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.7122 - val_loss: 19.3296\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6906 - val_loss: 19.3157\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6702 - val_loss: 19.3016\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6792 - val_loss: 19.2876\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6185 - val_loss: 19.2735\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5571 - val_loss: 19.2593\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6240 - val_loss: 19.2451\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.6254 - val_loss: 19.2309\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5652 - val_loss: 19.2166\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5814 - val_loss: 19.2022\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5716 - val_loss: 19.1878\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.5579 - val_loss: 19.1733\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 20.5247 - val_loss: 19.1588\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_210 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_211 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_212 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_213 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_214 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_215 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_216 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 25.1085 - val_loss: 24.0122\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.4249 - val_loss: 23.3769\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.7075 - val_loss: 22.8301\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.1201 - val_loss: 22.3596\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.5978 - val_loss: 21.9220\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.0699 - val_loss: 21.5466\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6514 - val_loss: 21.1924\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.2462 - val_loss: 20.8697\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8996 - val_loss: 20.5903\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.5581 - val_loss: 20.3391\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2386 - val_loss: 20.1411\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.0303 - val_loss: 19.9849\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8084 - val_loss: 19.8403\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6057 - val_loss: 19.7180\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3829 - val_loss: 19.6263\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2345 - val_loss: 19.5397\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1034 - val_loss: 19.4575\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0181 - val_loss: 19.3811\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8952 - val_loss: 19.3029\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7729 - val_loss: 19.2284\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7588 - val_loss: 19.1642\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6743 - val_loss: 19.1077\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4811 - val_loss: 19.0560\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4540 - val_loss: 19.0074\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5278 - val_loss: 18.9606\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4929 - val_loss: 18.9228\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4647 - val_loss: 18.8932\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3300 - val_loss: 18.8657\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2061 - val_loss: 18.8397\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3228 - val_loss: 18.8145\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3400 - val_loss: 18.7900\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3231 - val_loss: 18.7683\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3013 - val_loss: 18.7469\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2737 - val_loss: 18.7271\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2026 - val_loss: 18.7095\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2458 - val_loss: 18.6926\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2472 - val_loss: 18.6757\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2361 - val_loss: 18.6586\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1818 - val_loss: 18.6420\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2118 - val_loss: 18.6254\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1483 - val_loss: 18.6102\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1621 - val_loss: 18.5947\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1316 - val_loss: 18.5789\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 18.1621 - val_loss: 18.5643\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0906 - val_loss: 18.5497\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0756 - val_loss: 18.5350\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0846 - val_loss: 18.5208\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1050 - val_loss: 18.5062\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0871 - val_loss: 18.4923\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0901 - val_loss: 18.4789\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0472 - val_loss: 18.4655\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0637 - val_loss: 18.4508\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0298 - val_loss: 18.4374\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0450 - val_loss: 18.4225\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0238 - val_loss: 18.4094\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9928 - val_loss: 18.3965\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8880 - val_loss: 18.3831\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9718 - val_loss: 18.3697\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9695 - val_loss: 18.3562\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9751 - val_loss: 18.3425\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9125 - val_loss: 18.3299\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9135 - val_loss: 18.3165\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9255 - val_loss: 18.3029\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9128 - val_loss: 18.2896\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9106 - val_loss: 18.2775\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9000 - val_loss: 18.2646\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7107 - val_loss: 18.2519\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8729 - val_loss: 18.2383\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8547 - val_loss: 18.2251\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8495 - val_loss: 18.2118\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8347 - val_loss: 18.1983\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8157 - val_loss: 18.1854\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8091 - val_loss: 18.1718\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7544 - val_loss: 18.1587\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7840 - val_loss: 18.1456\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7663 - val_loss: 18.1317\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7429 - val_loss: 18.1192\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7350 - val_loss: 18.1061\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7348 - val_loss: 18.0924\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7118 - val_loss: 18.0794\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7113 - val_loss: 18.0656\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6884 - val_loss: 18.0534\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6807 - val_loss: 18.0394\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6701 - val_loss: 18.0254\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6275 - val_loss: 18.0122\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6477 - val_loss: 17.9979\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6247 - val_loss: 17.9844\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6190 - val_loss: 17.9711\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6080 - val_loss: 17.9568\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5693 - val_loss: 17.9434\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5654 - val_loss: 17.9298\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5542 - val_loss: 17.9167\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5423 - val_loss: 17.9034\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4778 - val_loss: 17.8899\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.4217 - val_loss: 17.8765\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5112 - val_loss: 17.8627\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.4887 - val_loss: 17.8482\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4843 - val_loss: 17.8337\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.4608 - val_loss: 17.8199\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.4439 - val_loss: 17.8056\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_217 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_218 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_219 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_220 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_221 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_222 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_223 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09500\n",
      "Model:                       QuantReg   Bandwidth:                    0.004714\n",
      "Method:                 Least Squares   Sparsity:                       0.1961\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:48:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0246      0.007      3.525      0.000       0.011       0.038\n",
      "three_month_yield_change     -0.1514      0.188     -0.807      0.420      -0.519       0.217\n",
      "term_spread_change           -0.0647      0.166     -0.391      0.696      -0.390       0.260\n",
      "TED_spread                   -0.1585      0.710     -0.223      0.823      -1.551       1.234\n",
      "credit_spread_change         -0.6789      0.248     -2.733      0.006      -1.166      -0.192\n",
      "market_return                -0.1224      0.099     -1.234      0.217      -0.317       0.072\n",
      "real_estate_excess_return     0.0457      0.110      0.416      0.677      -0.170       0.261\n",
      "equity_volatility             2.4728      0.201     12.326      0.000       2.079       2.866\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2143\n",
      "Model:                       QuantReg   Bandwidth:                    0.007588\n",
      "Method:                 Least Squares   Sparsity:                       0.7042\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:48:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0144      0.013      1.114      0.265      -0.011       0.040\n",
      "three_month_yield_change      0.7641      0.356      2.147      0.032       0.066       1.462\n",
      "term_spread_change            0.2101      0.339      0.620      0.535      -0.455       0.875\n",
      "TED_spread                    0.5648      1.429      0.395      0.693      -2.237       3.366\n",
      "credit_spread_change         -0.2798      0.438     -0.638      0.523      -1.140       0.580\n",
      "market_return                -0.1240      0.196     -0.632      0.527      -0.508       0.260\n",
      "real_estate_excess_return    -0.7174      0.267     -2.690      0.007      -1.240      -0.194\n",
      "equity_volatility             3.5829      0.379      9.450      0.000       2.839       4.326\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5051\n",
      "Model:                       QuantReg   Bandwidth:                    0.001681\n",
      "Method:                 Least Squares   Sparsity:                      0.06286\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:48:15   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.002      4.322      0.000       0.005       0.014\n",
      "three_month_yield_change     -0.0183      0.058     -0.314      0.753      -0.133       0.096\n",
      "term_spread_change           -0.1378      0.053     -2.623      0.009      -0.241      -0.035\n",
      "TED_spread                   -0.1450      0.220     -0.660      0.509      -0.576       0.286\n",
      "credit_spread_change         -0.1023      0.077     -1.330      0.184      -0.253       0.049\n",
      "market_return                 0.0116      0.034      0.341      0.733      -0.055       0.078\n",
      "real_estate_excess_return    -0.0291      0.038     -0.761      0.446      -0.104       0.046\n",
      "equity_volatility             0.5488      0.063      8.778      0.000       0.426       0.671\n",
      "institution                   0.5182      0.032     16.077      0.000       0.455       0.581\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5778\n",
      "Model:                       QuantReg   Bandwidth:                    0.003109\n",
      "Method:                 Least Squares   Sparsity:                       0.2758\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:48:15   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0254      0.004      5.689      0.000       0.017       0.034\n",
      "three_month_yield_change     -0.2806      0.122     -2.300      0.022      -0.520      -0.041\n",
      "term_spread_change           -0.0355      0.114     -0.311      0.756      -0.259       0.188\n",
      "TED_spread                   -0.4435      0.529     -0.839      0.402      -1.480       0.593\n",
      "credit_spread_change         -0.6986      0.159     -4.394      0.000      -1.010      -0.387\n",
      "market_return                 0.0484      0.095      0.511      0.609      -0.137       0.234\n",
      "real_estate_excess_return     0.0284      0.096      0.294      0.769      -0.161       0.217\n",
      "equity_volatility             1.3978      0.150      9.300      0.000       1.103       1.693\n",
      "institution                   0.4977      0.085      5.874      0.000       0.332       0.664\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 33.3837 - val_loss: 40.3512\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.8762 - val_loss: 39.8480\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.3756 - val_loss: 39.3369\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.8651 - val_loss: 38.8173\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.4362 - val_loss: 38.2620\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.9581 - val_loss: 37.6620\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.3636 - val_loss: 37.0290\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.7817 - val_loss: 36.3136\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.1807 - val_loss: 35.5675\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.5738 - val_loss: 34.8193\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.9339 - val_loss: 34.0308\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.1503 - val_loss: 33.2576\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.5629 - val_loss: 32.4726\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.8187 - val_loss: 31.6679\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.1872 - val_loss: 30.8618\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.6930 - val_loss: 30.0584\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.1287 - val_loss: 29.3419\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8134 - val_loss: 28.7122\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3985 - val_loss: 28.1793\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0581 - val_loss: 27.7423\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8420 - val_loss: 27.3738\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5783 - val_loss: 27.0668\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3872 - val_loss: 26.7898\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1390 - val_loss: 26.5378\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0628 - val_loss: 26.3200\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8442 - val_loss: 26.1341\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8363 - val_loss: 25.9666\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7273 - val_loss: 25.8173\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.6679 - val_loss: 25.6888\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5571 - val_loss: 25.5785\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4896 - val_loss: 25.4782\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4513 - val_loss: 25.3855\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3964 - val_loss: 25.3068\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2540 - val_loss: 25.2398\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0997 - val_loss: 25.1734\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2995 - val_loss: 25.1107\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2474 - val_loss: 25.0586\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1726 - val_loss: 25.0090\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2008 - val_loss: 24.9637\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1320 - val_loss: 24.9214\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1535 - val_loss: 24.8838\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0926 - val_loss: 24.8509\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0844 - val_loss: 24.8221\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8708 - val_loss: 24.7956\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9743 - val_loss: 24.7700\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0250 - val_loss: 24.7451\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0205 - val_loss: 24.7206\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0295 - val_loss: 24.6959\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9523 - val_loss: 24.6729\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9370 - val_loss: 24.6496\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8392 - val_loss: 24.6282\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9480 - val_loss: 24.6056\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9176 - val_loss: 24.5865\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.8952 - val_loss: 24.5666\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8731 - val_loss: 24.5468\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9015 - val_loss: 24.5272\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8685 - val_loss: 24.5085\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8454 - val_loss: 24.4897\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8392 - val_loss: 24.4710\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8411 - val_loss: 24.4521\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7556 - val_loss: 24.4326\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7966 - val_loss: 24.4134\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7590 - val_loss: 24.3950\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7752 - val_loss: 24.3773\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7615 - val_loss: 24.3595\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7566 - val_loss: 24.3417\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6734 - val_loss: 24.3243\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6469 - val_loss: 24.3076\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6970 - val_loss: 24.2909\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6839 - val_loss: 24.2745\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6903 - val_loss: 24.2579\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5762 - val_loss: 24.2417\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6531 - val_loss: 24.2253\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5559 - val_loss: 24.2091\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6388 - val_loss: 24.1927\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5104 - val_loss: 24.1773\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6036 - val_loss: 24.1612\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5703 - val_loss: 24.1450\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5813 - val_loss: 24.1296\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5638 - val_loss: 24.1145\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5468 - val_loss: 24.0987\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5360 - val_loss: 24.0833\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4703 - val_loss: 24.0681\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4841 - val_loss: 24.0529\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4725 - val_loss: 24.0377\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4551 - val_loss: 24.0223\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3120 - val_loss: 24.0074\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4211 - val_loss: 23.9923\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4032 - val_loss: 23.9769\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4170 - val_loss: 23.9614\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3791 - val_loss: 23.9459\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3728 - val_loss: 23.9306\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3742 - val_loss: 23.9151\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3570 - val_loss: 23.9001\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3325 - val_loss: 23.8842\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2709 - val_loss: 23.8691\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2832 - val_loss: 23.8544\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2928 - val_loss: 23.8385\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2744 - val_loss: 23.8229\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.1524 - val_loss: 23.8076\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_224 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_225 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_226 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_227 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_228 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_229 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_230 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  128\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 18ms/step - loss: 24.8209 - val_loss: 23.5483\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6063 - val_loss: 22.6334\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5706 - val_loss: 21.9076\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7650 - val_loss: 21.2992\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0787 - val_loss: 20.8402\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6917 - val_loss: 20.4913\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3559 - val_loss: 20.2547\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.9730 - val_loss: 20.0684\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7525 - val_loss: 19.9304\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5592 - val_loss: 19.8212\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4219 - val_loss: 19.7174\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2619 - val_loss: 19.6202\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9577 - val_loss: 19.5291\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0469 - val_loss: 19.4539\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9791 - val_loss: 19.3895\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8512 - val_loss: 19.3327\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8564 - val_loss: 19.2800\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7440 - val_loss: 19.2363\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7598 - val_loss: 19.1993\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7163 - val_loss: 19.1702\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6751 - val_loss: 19.1427\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6683 - val_loss: 19.1163\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6030 - val_loss: 19.0911\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6392 - val_loss: 19.0685\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6114 - val_loss: 19.0465\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5912 - val_loss: 19.0256\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5811 - val_loss: 19.0053\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5634 - val_loss: 18.9856\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5313 - val_loss: 18.9672\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5341 - val_loss: 18.9495\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4718 - val_loss: 18.9316\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4603 - val_loss: 18.9164\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4871 - val_loss: 18.9019\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4930 - val_loss: 18.8872\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4373 - val_loss: 18.8729\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4510 - val_loss: 18.8582\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4211 - val_loss: 18.8443\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4504 - val_loss: 18.8305\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4339 - val_loss: 18.8170\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4193 - val_loss: 18.8035\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4100 - val_loss: 18.7900\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3913 - val_loss: 18.7766\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3508 - val_loss: 18.7639\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3399 - val_loss: 18.7502\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3549 - val_loss: 18.7382\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3515 - val_loss: 18.7243\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3343 - val_loss: 18.7108\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2967 - val_loss: 18.6982\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3215 - val_loss: 18.6857\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3009 - val_loss: 18.6727\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2955 - val_loss: 18.6595\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2860 - val_loss: 18.6471\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2558 - val_loss: 18.6352\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2478 - val_loss: 18.6230\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2315 - val_loss: 18.6102\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2419 - val_loss: 18.5967\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1826 - val_loss: 18.5850\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1959 - val_loss: 18.5722\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1709 - val_loss: 18.5591\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1889 - val_loss: 18.5468\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1677 - val_loss: 18.5347\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1641 - val_loss: 18.5218\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1529 - val_loss: 18.5090\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1223 - val_loss: 18.4958\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0605 - val_loss: 18.4835\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0622 - val_loss: 18.4715\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0776 - val_loss: 18.4585\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0885 - val_loss: 18.4453\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0396 - val_loss: 18.4315\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0410 - val_loss: 18.4191\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0470 - val_loss: 18.4059\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0396 - val_loss: 18.3921\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9775 - val_loss: 18.3794\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9894 - val_loss: 18.3669\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9905 - val_loss: 18.3550\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9400 - val_loss: 18.3429\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9760 - val_loss: 18.3291\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9481 - val_loss: 18.3158\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9320 - val_loss: 18.3027\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9332 - val_loss: 18.2885\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8947 - val_loss: 18.2761\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8113 - val_loss: 18.2635\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8919 - val_loss: 18.2491\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6699 - val_loss: 18.2359\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8673 - val_loss: 18.2221\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8416 - val_loss: 18.2079\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7721 - val_loss: 18.1935\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6730 - val_loss: 18.1802\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8138 - val_loss: 18.1661\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7933 - val_loss: 18.1519\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7654 - val_loss: 18.1375\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7633 - val_loss: 18.1230\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7395 - val_loss: 18.1097\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7398 - val_loss: 18.0957\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6613 - val_loss: 18.0822\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6478 - val_loss: 18.0684\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6739 - val_loss: 18.0538\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6726 - val_loss: 18.0391\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6478 - val_loss: 18.0256\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6599 - val_loss: 18.0104\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_231 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_232 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_233 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_234 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_235 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_236 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_237 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1404\n",
      "Model:                       QuantReg   Bandwidth:                    0.004565\n",
      "Method:                 Least Squares   Sparsity:                       0.1699\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:49:23   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0132      0.006      2.254      0.024       0.002       0.025\n",
      "three_month_yield_change     -0.4009      0.153     -2.626      0.009      -0.700      -0.102\n",
      "term_spread_change           -0.3192      0.155     -2.058      0.040      -0.623      -0.015\n",
      "TED_spread                   -1.2311      0.590     -2.086      0.037      -2.388      -0.074\n",
      "credit_spread_change          0.1099      0.212      0.520      0.603      -0.305       0.525\n",
      "market_return                -0.0276      0.098     -0.283      0.778      -0.219       0.164\n",
      "real_estate_excess_return     0.0176      0.104      0.169      0.866      -0.186       0.221\n",
      "equity_volatility             2.0613      0.171     12.040      0.000       1.726       2.397\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3195\n",
      "Model:                       QuantReg   Bandwidth:                    0.007509\n",
      "Method:                 Least Squares   Sparsity:                       0.6251\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:49:23   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0077      0.011      0.715      0.475      -0.013       0.029\n",
      "three_month_yield_change     -0.0567      0.302     -0.188      0.851      -0.649       0.536\n",
      "term_spread_change           -0.0818      0.297     -0.276      0.783      -0.664       0.500\n",
      "TED_spread                   -3.3262      1.383     -2.405      0.016      -6.039      -0.614\n",
      "credit_spread_change          0.2418      0.366      0.662      0.508      -0.475       0.959\n",
      "market_return                -0.1991      0.266     -0.750      0.453      -0.720       0.322\n",
      "real_estate_excess_return    -0.3730      0.265     -1.409      0.159      -0.892       0.146\n",
      "equity_volatility             4.6435      0.429     10.812      0.000       3.801       5.486\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4173\n",
      "Model:                       QuantReg   Bandwidth:                    0.001998\n",
      "Method:                 Least Squares   Sparsity:                      0.09581\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:49:23   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0078      0.004      2.217      0.027       0.001       0.015\n",
      "three_month_yield_change      0.0133      0.097      0.137      0.891      -0.177       0.203\n",
      "term_spread_change           -0.1596      0.083     -1.919      0.055      -0.323       0.003\n",
      "TED_spread                   -0.6759      0.338     -2.001      0.045      -1.338      -0.014\n",
      "credit_spread_change          0.0284      0.120      0.236      0.813      -0.207       0.264\n",
      "market_return                 0.0019      0.053      0.036      0.972      -0.102       0.106\n",
      "real_estate_excess_return    -0.0377      0.058     -0.653      0.514      -0.151       0.076\n",
      "equity_volatility             0.7249      0.094      7.719      0.000       0.541       0.909\n",
      "institution                   0.5024      0.052      9.587      0.000       0.400       0.605\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5211\n",
      "Model:                       QuantReg   Bandwidth:                    0.003253\n",
      "Method:                 Least Squares   Sparsity:                       0.2799\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:49:23   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0115      0.005      2.476      0.013       0.002       0.021\n",
      "three_month_yield_change      0.0808      0.131      0.619      0.536      -0.175       0.337\n",
      "term_spread_change           -0.1706      0.134     -1.277      0.202      -0.433       0.091\n",
      "TED_spread                    2.2662      0.499      4.541      0.000       1.288       3.245\n",
      "credit_spread_change         -0.2076      0.158     -1.311      0.190      -0.518       0.103\n",
      "market_return                -0.0938      0.129     -0.730      0.465      -0.346       0.158\n",
      "real_estate_excess_return    -0.1010      0.082     -1.239      0.216      -0.261       0.059\n",
      "equity_volatility             1.1275      0.193      5.842      0.000       0.749       1.506\n",
      "institution                   0.4167      0.134      3.105      0.002       0.153       0.680\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 3s 33ms/step - loss: 30.4960 - val_loss: 31.2019\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.8971 - val_loss: 30.7558\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.3755 - val_loss: 30.3022\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 28.8616 - val_loss: 29.8387\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 28.3258 - val_loss: 29.3473\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 27.7211 - val_loss: 28.8497\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 27.2340 - val_loss: 28.3268\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 26.7321 - val_loss: 27.7773\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 26.1382 - val_loss: 27.2200\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 25.5325 - val_loss: 26.6550\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.9702 - val_loss: 26.0756\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.3849 - val_loss: 25.5384\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.8216 - val_loss: 25.0201\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.3014 - val_loss: 24.5224\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.7858 - val_loss: 24.0892\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.3196 - val_loss: 23.7263\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.7787 - val_loss: 23.4244\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.4934 - val_loss: 23.1588\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1895 - val_loss: 22.9239\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.9068 - val_loss: 22.7363\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.6590 - val_loss: 22.6136\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.3190 - val_loss: 22.5065\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.3596 - val_loss: 22.4073\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.2425 - val_loss: 22.3200\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.9679 - val_loss: 22.2412\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.0719 - val_loss: 22.1730\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.0273 - val_loss: 22.1207\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.9086 - val_loss: 22.0794\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.8878 - val_loss: 22.0462\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.8662 - val_loss: 22.0199\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.8050 - val_loss: 22.0005\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7954 - val_loss: 21.9857\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7410 - val_loss: 21.9734\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7412 - val_loss: 21.9615\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7295 - val_loss: 21.9495\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6176 - val_loss: 21.9376\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6696 - val_loss: 21.9256\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6609 - val_loss: 21.9135\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6524 - val_loss: 21.9014\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6327 - val_loss: 21.8893\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5910 - val_loss: 21.8771\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5726 - val_loss: 21.8649\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5857 - val_loss: 21.8528\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5559 - val_loss: 21.8407\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5556 - val_loss: 21.8285\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5420 - val_loss: 21.8162\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5143 - val_loss: 21.8039\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4822 - val_loss: 21.7916\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4751 - val_loss: 21.7792\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4798 - val_loss: 21.7667\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4714 - val_loss: 21.7542\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4465 - val_loss: 21.7416\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4481 - val_loss: 21.7289\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3948 - val_loss: 21.7163\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.4213 - val_loss: 21.7035\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3966 - val_loss: 21.6908\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3598 - val_loss: 21.6780\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3246 - val_loss: 21.6652\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3633 - val_loss: 21.6522\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3416 - val_loss: 21.6393\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3301 - val_loss: 21.6264\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3293 - val_loss: 21.6134\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3170 - val_loss: 21.6004\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.2993 - val_loss: 21.5872\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.2655 - val_loss: 21.5740\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.2705 - val_loss: 21.5608\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.2524 - val_loss: 21.5476\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0812 - val_loss: 21.5344\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1701 - val_loss: 21.5210\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1933 - val_loss: 21.5076\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1747 - val_loss: 21.4941\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1883 - val_loss: 21.4807\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1432 - val_loss: 21.4672\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0927 - val_loss: 21.4537\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1488 - val_loss: 21.4401\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1284 - val_loss: 21.4264\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1209 - val_loss: 21.4126\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1135 - val_loss: 21.3988\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0970 - val_loss: 21.3850\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0802 - val_loss: 21.3711\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0476 - val_loss: 21.3572\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0513 - val_loss: 21.3431\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0408 - val_loss: 21.3290\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9686 - val_loss: 21.3150\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9687 - val_loss: 21.3008\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9955 - val_loss: 21.2866\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8561 - val_loss: 21.2725\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9622 - val_loss: 21.2582\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8644 - val_loss: 21.2438\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9337 - val_loss: 21.2294\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9109 - val_loss: 21.2150\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8936 - val_loss: 21.2005\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8980 - val_loss: 21.1860\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8847 - val_loss: 21.1714\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8689 - val_loss: 21.1567\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8145 - val_loss: 21.1421\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8086 - val_loss: 21.1273\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7928 - val_loss: 21.1126\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8067 - val_loss: 21.0977\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7629 - val_loss: 21.0829\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_238 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_239 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_240 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_241 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_242 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_243 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_244 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 25.9379 - val_loss: 24.6110\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.9632 - val_loss: 23.7797\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 24.0238 - val_loss: 23.1240\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.3574 - val_loss: 22.5589\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.6711 - val_loss: 22.0589\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.1058 - val_loss: 21.5969\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.6291 - val_loss: 21.1625\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.1359 - val_loss: 20.8037\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.7376 - val_loss: 20.5098\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.3948 - val_loss: 20.2900\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.1092 - val_loss: 20.1158\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.8500 - val_loss: 19.9665\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.6873 - val_loss: 19.8583\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5121 - val_loss: 19.7636\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.3360 - val_loss: 19.6741\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.1269 - val_loss: 19.5917\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0464 - val_loss: 19.5101\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.0400 - val_loss: 19.4347\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.9658 - val_loss: 19.3711\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8633 - val_loss: 19.3152\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8383 - val_loss: 19.2638\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7884 - val_loss: 19.2146\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7402 - val_loss: 19.1715\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 18.7143 - val_loss: 19.1380\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6818 - val_loss: 19.1109\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6328 - val_loss: 19.0864\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6274 - val_loss: 19.0629\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6003 - val_loss: 19.0409\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5759 - val_loss: 19.0192\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5424 - val_loss: 18.9984\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5436 - val_loss: 18.9783\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.5129 - val_loss: 18.9590\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4918 - val_loss: 18.9408\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4648 - val_loss: 18.9230\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4478 - val_loss: 18.9051\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4564 - val_loss: 18.8868\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4200 - val_loss: 18.8690\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4007 - val_loss: 18.8520\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4079 - val_loss: 18.8353\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3605 - val_loss: 18.8187\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3777 - val_loss: 18.8029\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3735 - val_loss: 18.7871\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3551 - val_loss: 18.7719\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3232 - val_loss: 18.7566\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3126 - val_loss: 18.7425\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3168 - val_loss: 18.7284\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2166 - val_loss: 18.7141\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2756 - val_loss: 18.6994\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2516 - val_loss: 18.6853\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2730 - val_loss: 18.6706\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2684 - val_loss: 18.6566\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2456 - val_loss: 18.6424\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2326 - val_loss: 18.6280\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2266 - val_loss: 18.6136\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2097 - val_loss: 18.5991\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1595 - val_loss: 18.5849\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1835 - val_loss: 18.5711\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1684 - val_loss: 18.5572\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1501 - val_loss: 18.5440\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1353 - val_loss: 18.5302\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1334 - val_loss: 18.5157\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0968 - val_loss: 18.5017\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0204 - val_loss: 18.4875\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0648 - val_loss: 18.4730\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0683 - val_loss: 18.4589\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0231 - val_loss: 18.4453\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0552 - val_loss: 18.4309\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0448 - val_loss: 18.4172\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9810 - val_loss: 18.4036\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9825 - val_loss: 18.3896\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9975 - val_loss: 18.3752\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9795 - val_loss: 18.3609\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9543 - val_loss: 18.3470\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9509 - val_loss: 18.3324\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9455 - val_loss: 18.3177\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8457 - val_loss: 18.3040\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8679 - val_loss: 18.2900\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8913 - val_loss: 18.2754\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8775 - val_loss: 18.2610\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8632 - val_loss: 18.2463\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8770 - val_loss: 18.2322\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8211 - val_loss: 18.2175\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8242 - val_loss: 18.2045\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8215 - val_loss: 18.1898\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8165 - val_loss: 18.1745\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7920 - val_loss: 18.1600\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7870 - val_loss: 18.1454\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6925 - val_loss: 18.1310\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7562 - val_loss: 18.1163\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6447 - val_loss: 18.1027\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.7267 - val_loss: 18.0875\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6689 - val_loss: 18.0736\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6497 - val_loss: 18.0591\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6882 - val_loss: 18.0443\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6739 - val_loss: 18.0290\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6552 - val_loss: 18.0142\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6230 - val_loss: 17.9989\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6223 - val_loss: 17.9834\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5545 - val_loss: 17.9686\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5629 - val_loss: 17.9542\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_36 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_245 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_246 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_247 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_248 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_249 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_250 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_251 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1148\n",
      "Model:                       QuantReg   Bandwidth:                    0.004023\n",
      "Method:                 Least Squares   Sparsity:                       0.1492\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:50:38   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0093      0.005      1.786      0.074      -0.001       0.019\n",
      "three_month_yield_change      0.1550      0.146      1.062      0.288      -0.131       0.441\n",
      "term_spread_change           -0.0753      0.137     -0.552      0.581      -0.343       0.192\n",
      "TED_spread                   -1.6156      0.574     -2.815      0.005      -2.741      -0.490\n",
      "credit_spread_change         -0.0344      0.184     -0.186      0.852      -0.396       0.327\n",
      "market_return                -0.0036      0.085     -0.042      0.966      -0.171       0.163\n",
      "real_estate_excess_return     0.0543      0.089      0.611      0.541      -0.120       0.229\n",
      "equity_volatility             1.9287      0.161     11.949      0.000       1.612       2.245\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2766\n",
      "Model:                       QuantReg   Bandwidth:                    0.005886\n",
      "Method:                 Least Squares   Sparsity:                       0.7090\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:50:38   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0326      0.011      2.872      0.004       0.010       0.055\n",
      "three_month_yield_change      0.0573      0.299      0.192      0.848      -0.529       0.644\n",
      "term_spread_change            0.1622      0.286      0.568      0.570      -0.398       0.723\n",
      "TED_spread                   -0.8800      1.280     -0.687      0.492      -3.390       1.630\n",
      "credit_spread_change         -0.8957      0.459     -1.953      0.051      -1.795       0.003\n",
      "market_return                -0.0357      0.227     -0.157      0.875      -0.482       0.410\n",
      "real_estate_excess_return    -0.1856      0.225     -0.825      0.410      -0.627       0.256\n",
      "equity_volatility             3.0425      0.494      6.155      0.000       2.073       4.012\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3725\n",
      "Model:                       QuantReg   Bandwidth:                    0.002013\n",
      "Method:                 Least Squares   Sparsity:                      0.07725\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:50:38   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0107      0.003      3.793      0.000       0.005       0.016\n",
      "three_month_yield_change     -0.0325      0.075     -0.435      0.664      -0.179       0.114\n",
      "term_spread_change           -0.1235      0.062     -2.002      0.045      -0.244      -0.003\n",
      "TED_spread                   -0.2916      0.270     -1.078      0.281      -0.822       0.239\n",
      "credit_spread_change         -0.0858      0.105     -0.815      0.415      -0.292       0.120\n",
      "market_return                -0.0714      0.038     -1.877      0.061      -0.146       0.003\n",
      "real_estate_excess_return     0.0065      0.044      0.148      0.882      -0.079       0.092\n",
      "equity_volatility             0.6331      0.074      8.596      0.000       0.489       0.778\n",
      "institution                   0.5618      0.042     13.530      0.000       0.480       0.643\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4573\n",
      "Model:                       QuantReg   Bandwidth:                    0.003788\n",
      "Method:                 Least Squares   Sparsity:                       0.3814\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:50:38   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0331      0.007      4.957      0.000       0.020       0.046\n",
      "three_month_yield_change     -0.4114      0.155     -2.659      0.008      -0.715      -0.108\n",
      "term_spread_change           -0.6709      0.148     -4.533      0.000      -0.961      -0.381\n",
      "TED_spread                   -0.6654      0.616     -1.080      0.280      -1.873       0.543\n",
      "credit_spread_change         -0.2758      0.245     -1.125      0.260      -0.756       0.205\n",
      "market_return                 0.1282      0.151      0.850      0.395      -0.168       0.424\n",
      "real_estate_excess_return     0.1501      0.140      1.072      0.284      -0.124       0.425\n",
      "equity_volatility             1.1631      0.232      5.008      0.000       0.708       1.619\n",
      "institution                   0.5386      0.154      3.507      0.000       0.237       0.840\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 38.4668 - val_loss: 43.6605\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.9240 - val_loss: 42.2752\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 35.3552 - val_loss: 40.9175\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 34.0946 - val_loss: 39.4252\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.6429 - val_loss: 37.9554\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.3093 - val_loss: 36.5070\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.0536 - val_loss: 35.1913\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.7151 - val_loss: 34.1218\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.0690 - val_loss: 33.2000\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.2715 - val_loss: 32.3462\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.6703 - val_loss: 31.5667\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.9053 - val_loss: 30.8461\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.6666 - val_loss: 30.2551\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.3038 - val_loss: 29.7423\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.0368 - val_loss: 29.2955\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.7525 - val_loss: 28.9521\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.5594 - val_loss: 28.6603\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.3922 - val_loss: 28.4257\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.2274 - val_loss: 28.2272\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.1585 - val_loss: 28.0435\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0780 - val_loss: 27.8970\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0324 - val_loss: 27.7637\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.9811 - val_loss: 27.6305\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7012 - val_loss: 27.5141\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8054 - val_loss: 27.4037\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8136 - val_loss: 27.3149\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7103 - val_loss: 27.2350\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7741 - val_loss: 27.1651\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4616 - val_loss: 27.1051\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6032 - val_loss: 27.0409\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7001 - val_loss: 26.9744\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6743 - val_loss: 26.9060\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6395 - val_loss: 26.8429\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6070 - val_loss: 26.7827\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.6038 - val_loss: 26.7303\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5772 - val_loss: 26.6846\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5564 - val_loss: 26.6384\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5061 - val_loss: 26.5980\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.5199 - val_loss: 26.5568\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4763 - val_loss: 26.5181\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4944 - val_loss: 26.4802\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4722 - val_loss: 26.4422\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4766 - val_loss: 26.4038\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4624 - val_loss: 26.3710\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4272 - val_loss: 26.3390\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4020 - val_loss: 26.3066\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3805 - val_loss: 26.2748\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4125 - val_loss: 26.2489\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3558 - val_loss: 26.2219\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3829 - val_loss: 26.1970\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1933 - val_loss: 26.1718\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3324 - val_loss: 26.1472\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2418 - val_loss: 26.1247\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3322 - val_loss: 26.1024\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3198 - val_loss: 26.0780\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1798 - val_loss: 26.0579\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2904 - val_loss: 26.0377\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2689 - val_loss: 26.0162\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2789 - val_loss: 25.9955\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2241 - val_loss: 25.9781\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2383 - val_loss: 25.9613\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2010 - val_loss: 25.9437\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.2119 - val_loss: 25.9262\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1688 - val_loss: 25.9100\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1735 - val_loss: 25.8931\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1413 - val_loss: 25.8796\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1100 - val_loss: 25.8651\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0967 - val_loss: 25.8484\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0677 - val_loss: 25.8330\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1157 - val_loss: 25.8198\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0836 - val_loss: 25.8056\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9302 - val_loss: 25.7920\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9204 - val_loss: 25.7779\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0754 - val_loss: 25.7630\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0699 - val_loss: 25.7465\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0334 - val_loss: 25.7328\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9819 - val_loss: 25.7191\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.7347 - val_loss: 25.7049\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9746 - val_loss: 25.6941\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9281 - val_loss: 25.6795\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8955 - val_loss: 25.6645\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9338 - val_loss: 25.6510\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9390 - val_loss: 25.6372\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9345 - val_loss: 25.6226\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9333 - val_loss: 25.6077\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9299 - val_loss: 25.5923\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8993 - val_loss: 25.5773\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8939 - val_loss: 25.5611\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8418 - val_loss: 25.5464\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8289 - val_loss: 25.5318\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7381 - val_loss: 25.5183\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8264 - val_loss: 25.5032\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6556 - val_loss: 25.4892\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7854 - val_loss: 25.4738\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7508 - val_loss: 25.4598\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7661 - val_loss: 25.4461\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7495 - val_loss: 25.4316\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.7283 - val_loss: 25.4164\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6674 - val_loss: 25.4027\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5670 - val_loss: 25.3875\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_252 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_253 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_254 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_255 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_256 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_257 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_258 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 25.7532 - val_loss: 24.4856\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8720 - val_loss: 23.6457\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7309 - val_loss: 22.7338\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7470 - val_loss: 21.9740\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9483 - val_loss: 21.3477\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2839 - val_loss: 20.8373\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7583 - val_loss: 20.4319\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2867 - val_loss: 20.1547\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8933 - val_loss: 19.9398\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5509 - val_loss: 19.7838\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3259 - val_loss: 19.6652\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1685 - val_loss: 19.5567\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0206 - val_loss: 19.4560\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9777 - val_loss: 19.3622\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8712 - val_loss: 19.2843\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8197 - val_loss: 19.2197\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7164 - val_loss: 19.1608\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6768 - val_loss: 19.1071\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5776 - val_loss: 19.0661\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4951 - val_loss: 19.0352\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5780 - val_loss: 19.0064\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5089 - val_loss: 18.9798\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4828 - val_loss: 18.9557\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4847 - val_loss: 18.9321\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4016 - val_loss: 18.9105\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3847 - val_loss: 18.8893\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3822 - val_loss: 18.8693\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3923 - val_loss: 18.8500\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3810 - val_loss: 18.8315\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3941 - val_loss: 18.8137\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3739 - val_loss: 18.7963\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3593 - val_loss: 18.7790\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3383 - val_loss: 18.7628\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3369 - val_loss: 18.7467\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2776 - val_loss: 18.7318\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3029 - val_loss: 18.7164\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2889 - val_loss: 18.7008\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2817 - val_loss: 18.6857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2687 - val_loss: 18.6716\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2492 - val_loss: 18.6570\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2562 - val_loss: 18.6434\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2076 - val_loss: 18.6299\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1901 - val_loss: 18.6160\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1911 - val_loss: 18.6020\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1719 - val_loss: 18.5881\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1483 - val_loss: 18.5749\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1795 - val_loss: 18.5610\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1631 - val_loss: 18.5473\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1234 - val_loss: 18.5333\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0614 - val_loss: 18.5204\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0340 - val_loss: 18.5069\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1198 - val_loss: 18.4933\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1043 - val_loss: 18.4798\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0903 - val_loss: 18.4653\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9568 - val_loss: 18.4518\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0208 - val_loss: 18.4378\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0469 - val_loss: 18.4237\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0497 - val_loss: 18.4092\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0359 - val_loss: 18.3953\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0040 - val_loss: 18.3815\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9898 - val_loss: 18.3670\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9592 - val_loss: 18.3533\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8375 - val_loss: 18.3392\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8611 - val_loss: 18.3260\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9364 - val_loss: 18.3115\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9382 - val_loss: 18.2973\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9227 - val_loss: 18.2829\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8815 - val_loss: 18.2693\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8966 - val_loss: 18.2556\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8409 - val_loss: 18.2415\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8717 - val_loss: 18.2272\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8595 - val_loss: 18.2130\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7827 - val_loss: 18.1992\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7947 - val_loss: 18.1856\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8161 - val_loss: 18.1708\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7411 - val_loss: 18.1569\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7528 - val_loss: 18.1430\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7353 - val_loss: 18.1288\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7645 - val_loss: 18.1145\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7418 - val_loss: 18.1002\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7378 - val_loss: 18.0856\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7023 - val_loss: 18.0715\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6818 - val_loss: 18.0575\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6807 - val_loss: 18.0429\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6642 - val_loss: 18.0282\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6488 - val_loss: 18.0136\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6331 - val_loss: 17.9992\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6106 - val_loss: 17.9848\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6077 - val_loss: 17.9700\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5040 - val_loss: 17.9557\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5780 - val_loss: 17.9403\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5663 - val_loss: 17.9249\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5592 - val_loss: 17.9099\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5261 - val_loss: 17.8955\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4956 - val_loss: 17.8802\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5039 - val_loss: 17.8658\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4960 - val_loss: 17.8501\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4743 - val_loss: 17.8352\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4728 - val_loss: 17.8208\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4430 - val_loss: 17.8056\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_259 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_260 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_261 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_263 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_264 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1701\n",
      "Model:                       QuantReg   Bandwidth:                    0.005783\n",
      "Method:                 Least Squares   Sparsity:                       0.1719\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:51:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0139      0.006      2.396      0.017       0.003       0.025\n",
      "three_month_yield_change     -0.1727      0.163     -1.058      0.290      -0.493       0.147\n",
      "term_spread_change           -0.2301      0.158     -1.454      0.146      -0.541       0.080\n",
      "TED_spread                   -2.2352      0.638     -3.501      0.000      -3.487      -0.983\n",
      "credit_spread_change          0.0502      0.208      0.241      0.810      -0.359       0.459\n",
      "market_return                -0.1499      0.095     -1.578      0.115      -0.336       0.036\n",
      "real_estate_excess_return     0.0493      0.106      0.467      0.641      -0.158       0.256\n",
      "equity_volatility             2.7913      0.192     14.570      0.000       2.416       3.167\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2823\n",
      "Model:                       QuantReg   Bandwidth:                    0.009315\n",
      "Method:                 Least Squares   Sparsity:                       0.8138\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:51:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0275      0.014      1.984      0.047       0.000       0.055\n",
      "three_month_yield_change     -0.8274      0.358     -2.313      0.021      -1.529      -0.126\n",
      "term_spread_change           -1.2341      0.349     -3.538      0.000      -1.918      -0.550\n",
      "TED_spread                   -2.1536      1.574     -1.368      0.171      -5.240       0.933\n",
      "credit_spread_change          0.5139      0.491      1.047      0.295      -0.449       1.477\n",
      "market_return                -0.5021      0.326     -1.541      0.123      -1.141       0.137\n",
      "real_estate_excess_return    -0.6275      0.319     -1.970      0.049      -1.252      -0.003\n",
      "equity_volatility             5.2440      0.543      9.651      0.000       4.179       6.310\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4038\n",
      "Model:                       QuantReg   Bandwidth:                    0.002006\n",
      "Method:                 Least Squares   Sparsity:                      0.08708\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:51:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0135      0.003      4.178      0.000       0.007       0.020\n",
      "three_month_yield_change     -0.0143      0.088     -0.162      0.872      -0.188       0.159\n",
      "term_spread_change           -0.1408      0.080     -1.770      0.077      -0.297       0.015\n",
      "TED_spread                   -0.8488      0.330     -2.576      0.010      -1.495      -0.203\n",
      "credit_spread_change         -0.1183      0.117     -1.014      0.311      -0.347       0.110\n",
      "market_return                -0.0197      0.049     -0.400      0.689      -0.116       0.077\n",
      "real_estate_excess_return    -0.0367      0.051     -0.714      0.475      -0.137       0.064\n",
      "equity_volatility             0.6236      0.084      7.406      0.000       0.459       0.789\n",
      "institution                   0.3741      0.034     10.983      0.000       0.307       0.441\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5071\n",
      "Model:                       QuantReg   Bandwidth:                    0.003388\n",
      "Method:                 Least Squares   Sparsity:                       0.3316\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:51:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0069      0.006      1.180      0.238      -0.005       0.018\n",
      "three_month_yield_change      0.3266      0.162      2.011      0.044       0.008       0.645\n",
      "term_spread_change           -0.0114      0.171     -0.067      0.947      -0.346       0.324\n",
      "TED_spread                   -2.1876      0.632     -3.462      0.001      -3.427      -0.948\n",
      "credit_spread_change          0.2871      0.199      1.445      0.148      -0.102       0.677\n",
      "market_return                -0.0666      0.109     -0.614      0.540      -0.279       0.146\n",
      "real_estate_excess_return    -0.1299      0.098     -1.329      0.184      -0.322       0.062\n",
      "equity_volatility             1.1968      0.193      6.187      0.000       0.817       1.576\n",
      "institution                   0.3671      0.092      3.976      0.000       0.186       0.548\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 30.6942 - val_loss: 30.3938\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.9419 - val_loss: 29.7932\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.1771 - val_loss: 29.1740\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.5491 - val_loss: 28.5677\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9197 - val_loss: 27.9035\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.1988 - val_loss: 27.1864\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4835 - val_loss: 26.4193\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6203 - val_loss: 25.5963\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.7737 - val_loss: 24.6977\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0137 - val_loss: 23.8044\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2052 - val_loss: 23.0210\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4918 - val_loss: 22.3152\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0226 - val_loss: 21.7475\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5005 - val_loss: 21.2342\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0270 - val_loss: 20.8535\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7173 - val_loss: 20.5663\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.4331 - val_loss: 20.3314\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3280 - val_loss: 20.1336\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1162 - val_loss: 19.9821\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0332 - val_loss: 19.8560\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9275 - val_loss: 19.7593\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8696 - val_loss: 19.6931\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7991 - val_loss: 19.6347\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7412 - val_loss: 19.5874\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7476 - val_loss: 19.5468\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7166 - val_loss: 19.5086\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6528 - val_loss: 19.4726\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6657 - val_loss: 19.4396\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5915 - val_loss: 19.4138\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5764 - val_loss: 19.3921\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6052 - val_loss: 19.3702\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5840 - val_loss: 19.3500\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5585 - val_loss: 19.3304\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5477 - val_loss: 19.3126\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5449 - val_loss: 19.2956\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5292 - val_loss: 19.2793\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4848 - val_loss: 19.2648\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4417 - val_loss: 19.2505\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4733 - val_loss: 19.2363\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4717 - val_loss: 19.2226\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4261 - val_loss: 19.2091\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4473 - val_loss: 19.1954\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3858 - val_loss: 19.1822\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4099 - val_loss: 19.1690\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4003 - val_loss: 19.1560\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3886 - val_loss: 19.1425\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3843 - val_loss: 19.1292\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3785 - val_loss: 19.1158\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3681 - val_loss: 19.1023\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3377 - val_loss: 19.0891\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 19.3396 - val_loss: 19.0758\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3239 - val_loss: 19.0625\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2836 - val_loss: 19.0494\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2927 - val_loss: 19.0362\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2893 - val_loss: 19.0228\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2326 - val_loss: 19.0095\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2617 - val_loss: 18.9961\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2510 - val_loss: 18.9828\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 19.1456 - val_loss: 18.9693\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2280 - val_loss: 18.9558\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2059 - val_loss: 18.9422\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1908 - val_loss: 18.9285\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1750 - val_loss: 18.9147\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1644 - val_loss: 18.9009\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1510 - val_loss: 18.8869\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0829 - val_loss: 18.8732\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0232 - val_loss: 18.8593\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1105 - val_loss: 18.8452\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0947 - val_loss: 18.8311\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0840 - val_loss: 18.8171\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0575 - val_loss: 18.8029\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0198 - val_loss: 18.7887\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0368 - val_loss: 18.7745\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9611 - val_loss: 18.7601\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9811 - val_loss: 18.7457\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9180 - val_loss: 18.7313\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9850 - val_loss: 18.7166\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9539 - val_loss: 18.7020\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9530 - val_loss: 18.6873\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8951 - val_loss: 18.6726\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9232 - val_loss: 18.6577\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7892 - val_loss: 18.6429\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8588 - val_loss: 18.6280\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8162 - val_loss: 18.6131\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8635 - val_loss: 18.5981\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8457 - val_loss: 18.5830\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7873 - val_loss: 18.5680\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7493 - val_loss: 18.5530\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7645 - val_loss: 18.5378\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7894 - val_loss: 18.5226\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7360 - val_loss: 18.5073\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7571 - val_loss: 18.4918\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6162 - val_loss: 18.4765\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7361 - val_loss: 18.4611\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7171 - val_loss: 18.4456\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7030 - val_loss: 18.4301\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6193 - val_loss: 18.4145\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6538 - val_loss: 18.3988\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6210 - val_loss: 18.3831\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6235 - val_loss: 18.3673\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_266 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_267 (Conv1D)         (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_269 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_270 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_271 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_272 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.2462 - val_loss: 24.3747\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.8289 - val_loss: 23.7955\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2430 - val_loss: 23.3184\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6573 - val_loss: 22.8755\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0063 - val_loss: 22.4633\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6668 - val_loss: 22.0716\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1862 - val_loss: 21.6954\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7492 - val_loss: 21.3422\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2655 - val_loss: 21.0206\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9831 - val_loss: 20.7330\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7255 - val_loss: 20.4819\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.4014 - val_loss: 20.2816\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1226 - val_loss: 20.1236\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8797 - val_loss: 19.9792\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7329 - val_loss: 19.8658\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5464 - val_loss: 19.7736\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3727 - val_loss: 19.6840\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.2777 - val_loss: 19.5993\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1461 - val_loss: 19.5186\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0701 - val_loss: 19.4375\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9515 - val_loss: 19.3643\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8983 - val_loss: 19.3022\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7989 - val_loss: 19.2449\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7454 - val_loss: 19.1914\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7019 - val_loss: 19.1430\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6885 - val_loss: 19.1043\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6490 - val_loss: 19.0750\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5550 - val_loss: 19.0489\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5875 - val_loss: 19.0243\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4974 - val_loss: 19.0014\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5321 - val_loss: 18.9783\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5133 - val_loss: 18.9565\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4794 - val_loss: 18.9347\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4728 - val_loss: 18.9143\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3997 - val_loss: 18.8943\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4440 - val_loss: 18.8740\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4079 - val_loss: 18.8550\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4133 - val_loss: 18.8356\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3774 - val_loss: 18.8174\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3672 - val_loss: 18.8007\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3690 - val_loss: 18.7838\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3632 - val_loss: 18.7673\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2977 - val_loss: 18.7513\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3174 - val_loss: 18.7360\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2606 - val_loss: 18.7212\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3083 - val_loss: 18.7063\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3002 - val_loss: 18.6911\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2580 - val_loss: 18.6768\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2345 - val_loss: 18.6635\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2612 - val_loss: 18.6486\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2222 - val_loss: 18.6346\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2359 - val_loss: 18.6201\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2114 - val_loss: 18.6062\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1765 - val_loss: 18.5932\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1810 - val_loss: 18.5791\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1920 - val_loss: 18.5652\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1752 - val_loss: 18.5519\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1463 - val_loss: 18.5383\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1331 - val_loss: 18.5242\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0733 - val_loss: 18.5111\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0731 - val_loss: 18.4980\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0941 - val_loss: 18.4842\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0923 - val_loss: 18.4708\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0925 - val_loss: 18.4572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0866 - val_loss: 18.4430\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0558 - val_loss: 18.4294\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0129 - val_loss: 18.4156\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9499 - val_loss: 18.4023\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0335 - val_loss: 18.3894\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9810 - val_loss: 18.3761\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0015 - val_loss: 18.3623\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9279 - val_loss: 18.3493\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9674 - val_loss: 18.3359\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9646 - val_loss: 18.3215\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9293 - val_loss: 18.3084\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9356 - val_loss: 18.2944\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8693 - val_loss: 18.2811\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9050 - val_loss: 18.2672\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8779 - val_loss: 18.2536\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8746 - val_loss: 18.2391\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8245 - val_loss: 18.2253\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8619 - val_loss: 18.2121\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7993 - val_loss: 18.1986\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7951 - val_loss: 18.1852\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7530 - val_loss: 18.1719\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7838 - val_loss: 18.1580\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7599 - val_loss: 18.1445\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7721 - val_loss: 18.1302\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5239 - val_loss: 18.1177\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7015 - val_loss: 18.1035\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6932 - val_loss: 18.0885\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7205 - val_loss: 18.0735\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7050 - val_loss: 18.0592\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6398 - val_loss: 18.0452\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6725 - val_loss: 18.0304\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6596 - val_loss: 18.0171\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6476 - val_loss: 18.0028\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6263 - val_loss: 17.9884\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5433 - val_loss: 17.9751\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4912 - val_loss: 17.9607\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_273 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_274 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_275 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_276 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_277 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_278 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_279 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08061\n",
      "Model:                       QuantReg   Bandwidth:                    0.003346\n",
      "Method:                 Least Squares   Sparsity:                       0.1324\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:52:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0181      0.004      4.125      0.000       0.009       0.027\n",
      "three_month_yield_change     -0.1292      0.121     -1.066      0.286      -0.367       0.108\n",
      "term_spread_change           -0.0461      0.118     -0.390      0.696      -0.278       0.185\n",
      "TED_spread                   -0.2280      0.512     -0.445      0.656      -1.232       0.776\n",
      "credit_spread_change         -0.2372      0.158     -1.499      0.134      -0.547       0.073\n",
      "market_return                -0.1128      0.067     -1.688      0.091      -0.244       0.018\n",
      "real_estate_excess_return     0.2071      0.078      2.661      0.008       0.055       0.360\n",
      "equity_volatility             1.0263      0.143      7.164      0.000       0.745       1.307\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1021\n",
      "Model:                       QuantReg   Bandwidth:                    0.004840\n",
      "Method:                 Least Squares   Sparsity:                       0.6519\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:52:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0257      0.010      2.521      0.012       0.006       0.046\n",
      "three_month_yield_change      0.2828      0.282      1.004      0.316      -0.270       0.835\n",
      "term_spread_change            0.0760      0.270      0.282      0.778      -0.453       0.605\n",
      "TED_spread                   -2.8616      1.462     -1.958      0.050      -5.728       0.005\n",
      "credit_spread_change          0.2347      0.406      0.577      0.564      -0.562       1.032\n",
      "market_return                -0.0081      0.191     -0.042      0.966      -0.383       0.367\n",
      "real_estate_excess_return    -0.2048      0.272     -0.752      0.452      -0.738       0.329\n",
      "equity_volatility             1.2199      0.411      2.968      0.003       0.414       2.026\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3357\n",
      "Model:                       QuantReg   Bandwidth:                    0.002160\n",
      "Method:                 Least Squares   Sparsity:                      0.09053\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:52:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0091      0.003      2.653      0.008       0.002       0.016\n",
      "three_month_yield_change      0.0359      0.093      0.386      0.699      -0.146       0.218\n",
      "term_spread_change           -0.1324      0.078     -1.702      0.089      -0.285       0.020\n",
      "TED_spread                   -1.1176      0.339     -3.302      0.001      -1.781      -0.454\n",
      "credit_spread_change          0.0116      0.116      0.101      0.920      -0.215       0.238\n",
      "market_return                -0.0202      0.045     -0.449      0.654      -0.109       0.068\n",
      "real_estate_excess_return    -0.0046      0.055     -0.084      0.933      -0.113       0.103\n",
      "equity_volatility             0.8734      0.082     10.665      0.000       0.713       1.034\n",
      "institution                   0.5057      0.052      9.758      0.000       0.404       0.607\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4206\n",
      "Model:                       QuantReg   Bandwidth:                    0.004505\n",
      "Method:                 Least Squares   Sparsity:                       0.5490\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:52:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0235      0.010      2.465      0.014       0.005       0.042\n",
      "three_month_yield_change     -0.1361      0.273     -0.499      0.618      -0.671       0.398\n",
      "term_spread_change           -0.2989      0.227     -1.318      0.188      -0.744       0.146\n",
      "TED_spread                   -1.7067      0.977     -1.747      0.081      -3.623       0.209\n",
      "credit_spread_change         -0.3600      0.320     -1.123      0.261      -0.988       0.268\n",
      "market_return                 0.1261      0.211      0.597      0.551      -0.288       0.540\n",
      "real_estate_excess_return    -0.0994      0.174     -0.573      0.567      -0.440       0.241\n",
      "equity_volatility             2.2550      0.338      6.664      0.000       1.591       2.919\n",
      "institution                   0.4359      0.218      1.996      0.046       0.008       0.864\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 27\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 29.7471 - val_loss: 29.0946\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.7006 - val_loss: 27.7999\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.1678 - val_loss: 26.3877\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.9584 - val_loss: 24.9521\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.5404 - val_loss: 23.5467\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3335 - val_loss: 22.4934\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 22.4533 - val_loss: 21.6882\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7645 - val_loss: 21.1187\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2381 - val_loss: 20.6493\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7908 - val_loss: 20.2828\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.3991 - val_loss: 20.0289\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2917 - val_loss: 19.8406\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 20.1541 - val_loss: 19.6771\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.0252 - val_loss: 19.5589\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.9554 - val_loss: 19.4567\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.9289 - val_loss: 19.3678\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.7910 - val_loss: 19.2877\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8287 - val_loss: 19.2184\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7926 - val_loss: 19.1576\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7775 - val_loss: 19.1061\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7478 - val_loss: 19.0617\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7400 - val_loss: 19.0215\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7099 - val_loss: 18.9880\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7080 - val_loss: 18.9594\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6959 - val_loss: 18.9368\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6622 - val_loss: 18.9168\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6558 - val_loss: 18.9004\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6548 - val_loss: 18.8836\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6238 - val_loss: 18.8685\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6182 - val_loss: 18.8545\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6249 - val_loss: 18.8407\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6108 - val_loss: 18.8275\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5630 - val_loss: 18.8152\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5909 - val_loss: 18.8027\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5721 - val_loss: 18.7910\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5289 - val_loss: 18.7794\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5240 - val_loss: 18.7683\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 19.5348 - val_loss: 18.7566\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4414 - val_loss: 18.7453\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5235 - val_loss: 18.7336\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5074 - val_loss: 18.7218\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3906 - val_loss: 18.7102\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4890 - val_loss: 18.6985\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4673 - val_loss: 18.6867\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3825 - val_loss: 18.6750\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4488 - val_loss: 18.6632\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4269 - val_loss: 18.6513\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3986 - val_loss: 18.6393\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4185 - val_loss: 18.6272\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4012 - val_loss: 18.6151\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3944 - val_loss: 18.6029\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3823 - val_loss: 18.5907\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3722 - val_loss: 18.5785\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3125 - val_loss: 18.5662\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3427 - val_loss: 18.5538\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2910 - val_loss: 18.5413\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2937 - val_loss: 18.5288\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2985 - val_loss: 18.5161\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2612 - val_loss: 18.5033\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2832 - val_loss: 18.4905\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2705 - val_loss: 18.4776\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2542 - val_loss: 18.4647\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2264 - val_loss: 18.4518\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2254 - val_loss: 18.4387\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1757 - val_loss: 18.4256\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2055 - val_loss: 18.4123\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1942 - val_loss: 18.3990\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1748 - val_loss: 18.3857\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1125 - val_loss: 18.3725\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1445 - val_loss: 18.3590\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1340 - val_loss: 18.3454\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1136 - val_loss: 18.3318\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0577 - val_loss: 18.3181\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0557 - val_loss: 18.3044\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0840 - val_loss: 18.2905\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0693 - val_loss: 18.2767\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9139 - val_loss: 18.2629\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0033 - val_loss: 18.2489\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0268 - val_loss: 18.2349\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9748 - val_loss: 18.2208\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9738 - val_loss: 18.2067\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9878 - val_loss: 18.1925\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9455 - val_loss: 18.1783\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9606 - val_loss: 18.1640\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9406 - val_loss: 18.1496\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9064 - val_loss: 18.1351\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8220 - val_loss: 18.1207\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8933 - val_loss: 18.1061\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8760 - val_loss: 18.0916\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8558 - val_loss: 18.0769\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7853 - val_loss: 18.0622\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8373 - val_loss: 18.0474\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5970 - val_loss: 18.0326\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7871 - val_loss: 18.0178\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7697 - val_loss: 18.0030\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6980 - val_loss: 17.9881\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7462 - val_loss: 17.9731\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5315 - val_loss: 17.9581\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7209 - val_loss: 17.9430\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7175 - val_loss: 17.9279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_280 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_281 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_282 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_283 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_284 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_285 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_286 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  119\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 25.9477 - val_loss: 24.6759\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 25.2330 - val_loss: 24.1032\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.5842 - val_loss: 23.5189\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8114 - val_loss: 22.9706\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0869 - val_loss: 22.4299\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5715 - val_loss: 21.9204\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.9457 - val_loss: 21.4439\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4177 - val_loss: 21.0173\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9581 - val_loss: 20.6606\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6033 - val_loss: 20.3647\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.1845 - val_loss: 20.1428\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8585 - val_loss: 19.9503\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4987 - val_loss: 19.8045\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4098 - val_loss: 19.6889\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2029 - val_loss: 19.5776\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1242 - val_loss: 19.4724\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9730 - val_loss: 19.3744\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.8834 - val_loss: 19.2967\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7334 - val_loss: 19.2287\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7252 - val_loss: 19.1659\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.6477 - val_loss: 19.1107\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6552 - val_loss: 19.0716\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6141 - val_loss: 19.0399\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5493 - val_loss: 19.0114\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4964 - val_loss: 18.9839\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3903 - val_loss: 18.9592\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4724 - val_loss: 18.9358\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3086 - val_loss: 18.9129\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4547 - val_loss: 18.8920\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.4387 - val_loss: 18.8718\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4160 - val_loss: 18.8544\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3924 - val_loss: 18.8361\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4029 - val_loss: 18.8179\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.3698 - val_loss: 18.8014\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3343 - val_loss: 18.7845\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3608 - val_loss: 18.7679\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3394 - val_loss: 18.7527\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3330 - val_loss: 18.7373\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3193 - val_loss: 18.7223\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3111 - val_loss: 18.7072\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2853 - val_loss: 18.6924\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2349 - val_loss: 18.6789\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2583 - val_loss: 18.6649\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2214 - val_loss: 18.6507\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2477 - val_loss: 18.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.2238 - val_loss: 18.6231\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2277 - val_loss: 18.6094\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1661 - val_loss: 18.5959\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2053 - val_loss: 18.5828\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.1845 - val_loss: 18.5692\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1825 - val_loss: 18.5562\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1764 - val_loss: 18.5426\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1213 - val_loss: 18.5300\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1447 - val_loss: 18.5163\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1307 - val_loss: 18.5028\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1133 - val_loss: 18.4892\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0604 - val_loss: 18.4773\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0843 - val_loss: 18.4639\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0399 - val_loss: 18.4516\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0017 - val_loss: 18.4380\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0575 - val_loss: 18.4246\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0415 - val_loss: 18.4108\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0327 - val_loss: 18.3975\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0186 - val_loss: 18.3844\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 18.0110 - val_loss: 18.3702\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9964 - val_loss: 18.3573\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.9856 - val_loss: 18.3445\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9571 - val_loss: 18.3310\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8893 - val_loss: 18.3181\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9534 - val_loss: 18.3043\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8841 - val_loss: 18.2920\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9256 - val_loss: 18.2784\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8050 - val_loss: 18.2658\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8375 - val_loss: 18.2517\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8790 - val_loss: 18.2375\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8421 - val_loss: 18.2242\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8450 - val_loss: 18.2104\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8306 - val_loss: 18.1975\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.8120 - val_loss: 18.1833\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8140 - val_loss: 18.1691\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7296 - val_loss: 18.1552\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6978 - val_loss: 18.1405\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7248 - val_loss: 18.1269\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7327 - val_loss: 18.1127\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7489 - val_loss: 18.0982\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7321 - val_loss: 18.0837\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6950 - val_loss: 18.0702\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6954 - val_loss: 18.0559\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6723 - val_loss: 18.0421\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6559 - val_loss: 18.0286\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.6345 - val_loss: 18.0151\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6489 - val_loss: 18.0005\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6186 - val_loss: 17.9862\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6163 - val_loss: 17.9717\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6095 - val_loss: 17.9569\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 17.5707 - val_loss: 17.9427\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5750 - val_loss: 17.9281\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5312 - val_loss: 17.9138\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4983 - val_loss: 17.8996\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5337 - val_loss: 17.8843\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_287 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_288 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_289 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_290 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_291 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_292 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_293 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1327\n",
      "Model:                       QuantReg   Bandwidth:                    0.003505\n",
      "Method:                 Least Squares   Sparsity:                       0.1179\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:53:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0281      0.004      6.977      0.000       0.020       0.036\n",
      "three_month_yield_change     -0.5368      0.106     -5.078      0.000      -0.744      -0.330\n",
      "term_spread_change           -0.4707      0.108     -4.353      0.000      -0.683      -0.259\n",
      "TED_spread                   -0.1677      0.420     -0.399      0.690      -0.991       0.656\n",
      "credit_spread_change         -0.4237      0.137     -3.083      0.002      -0.693      -0.154\n",
      "market_return                -0.1211      0.069     -1.749      0.080      -0.257       0.015\n",
      "real_estate_excess_return    -0.1084      0.069     -1.578      0.115      -0.243       0.026\n",
      "equity_volatility             1.4284      0.115     12.395      0.000       1.202       1.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3121\n",
      "Model:                       QuantReg   Bandwidth:                    0.006166\n",
      "Method:                 Least Squares   Sparsity:                       0.6029\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:53:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0439      0.009      4.652      0.000       0.025       0.062\n",
      "three_month_yield_change     -0.7922      0.286     -2.774      0.006      -1.352      -0.232\n",
      "term_spread_change           -0.7126      0.278     -2.565      0.010      -1.257      -0.168\n",
      "TED_spread                    0.1140      1.118      0.102      0.919      -2.078       2.306\n",
      "credit_spread_change         -0.9496      0.300     -3.160      0.002      -1.539      -0.360\n",
      "market_return                -0.0637      0.234     -0.272      0.786      -0.523       0.396\n",
      "real_estate_excess_return    -0.2715      0.196     -1.387      0.166      -0.655       0.112\n",
      "equity_volatility             3.4067      0.379      8.993      0.000       2.664       4.149\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3617\n",
      "Model:                       QuantReg   Bandwidth:                    0.002225\n",
      "Method:                 Least Squares   Sparsity:                      0.08026\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:53:46   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0088      0.003      3.208      0.001       0.003       0.014\n",
      "three_month_yield_change      0.0424      0.075      0.568      0.570      -0.104       0.189\n",
      "term_spread_change           -0.0918      0.071     -1.286      0.199      -0.232       0.048\n",
      "TED_spread                   -0.8489      0.305     -2.787      0.005      -1.446      -0.252\n",
      "credit_spread_change          0.0036      0.098      0.037      0.970      -0.189       0.196\n",
      "market_return                -0.0370      0.042     -0.886      0.376      -0.119       0.045\n",
      "real_estate_excess_return    -0.0278      0.045     -0.621      0.535      -0.116       0.060\n",
      "equity_volatility             0.8520      0.082     10.336      0.000       0.690       1.014\n",
      "institution                   0.5375      0.054     10.034      0.000       0.432       0.643\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4798\n",
      "Model:                       QuantReg   Bandwidth:                    0.003574\n",
      "Method:                 Least Squares   Sparsity:                       0.3359\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:53:46   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0121      0.005      2.382      0.017       0.002       0.022\n",
      "three_month_yield_change      0.1294      0.160      0.807      0.420      -0.185       0.444\n",
      "term_spread_change           -0.2529      0.165     -1.531      0.126      -0.577       0.071\n",
      "TED_spread                   -1.8013      0.689     -2.616      0.009      -3.151      -0.451\n",
      "credit_spread_change          0.3412      0.179      1.903      0.057      -0.010       0.693\n",
      "market_return                -0.0584      0.082     -0.712      0.477      -0.219       0.102\n",
      "real_estate_excess_return    -0.1498      0.136     -1.105      0.269      -0.416       0.116\n",
      "equity_volatility             0.9379      0.200      4.679      0.000       0.545       1.331\n",
      "institution                   0.4730      0.138      3.416      0.001       0.201       0.745\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 16ms/step - loss: 36.7333 - val_loss: 40.3582\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.8460 - val_loss: 39.2303\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 34.6889 - val_loss: 37.9903\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.3854 - val_loss: 36.6114\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.9887 - val_loss: 35.2251\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 30.6743 - val_loss: 33.8396\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.2178 - val_loss: 32.4551\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.8218 - val_loss: 31.0920\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.6237 - val_loss: 29.8153\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.4278 - val_loss: 28.7143\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.6009 - val_loss: 27.8860\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.8338 - val_loss: 27.2055\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.3311 - val_loss: 26.6449\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0687 - val_loss: 26.2347\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.8023 - val_loss: 25.9269\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.6148 - val_loss: 25.6905\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5019 - val_loss: 25.4884\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3273 - val_loss: 25.3283\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3596 - val_loss: 25.2027\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3098 - val_loss: 25.0992\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2454 - val_loss: 25.0140\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.2302 - val_loss: 24.9279\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1884 - val_loss: 24.8498\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0291 - val_loss: 24.7694\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1030 - val_loss: 24.6982\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0255 - val_loss: 24.6359\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0650 - val_loss: 24.5786\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.0416 - val_loss: 24.5255\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8358 - val_loss: 24.4800\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9913 - val_loss: 24.4377\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9646 - val_loss: 24.3976\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9501 - val_loss: 24.3612\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9429 - val_loss: 24.3272\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8527 - val_loss: 24.2986\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.9224 - val_loss: 24.2694\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8928 - val_loss: 24.2426\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8381 - val_loss: 24.2204\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8500 - val_loss: 24.1985\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8484 - val_loss: 24.1781\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8411 - val_loss: 24.1576\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7909 - val_loss: 24.1375\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8123 - val_loss: 24.1167\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8167 - val_loss: 24.0950\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8031 - val_loss: 24.0748\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7713 - val_loss: 24.0553\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7718 - val_loss: 24.0353\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.6468 - val_loss: 24.0175\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5500 - val_loss: 24.0007\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6622 - val_loss: 23.9831\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6780 - val_loss: 23.9653\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6911 - val_loss: 23.9488\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5688 - val_loss: 23.9327\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6741 - val_loss: 23.9173\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6659 - val_loss: 23.9024\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6565 - val_loss: 23.8880\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6475 - val_loss: 23.8739\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5711 - val_loss: 23.8601\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5749 - val_loss: 23.8459\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5983 - val_loss: 23.8312\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5358 - val_loss: 23.8179\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5712 - val_loss: 23.8045\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5620 - val_loss: 23.7906\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5320 - val_loss: 23.7769\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4954 - val_loss: 23.7635\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.5347 - val_loss: 23.7505\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3655 - val_loss: 23.7376\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4345 - val_loss: 23.7241\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4543 - val_loss: 23.7103\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4705 - val_loss: 23.6972\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4578 - val_loss: 23.6838\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3367 - val_loss: 23.6705\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4054 - val_loss: 23.6572\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4330 - val_loss: 23.6433\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3885 - val_loss: 23.6291\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3083 - val_loss: 23.6157\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3845 - val_loss: 23.6017\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3640 - val_loss: 23.5879\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3231 - val_loss: 23.5744\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3063 - val_loss: 23.5605\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2057 - val_loss: 23.5464\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3136 - val_loss: 23.5320\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.3045 - val_loss: 23.5180\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2457 - val_loss: 23.5042\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2258 - val_loss: 23.4907\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2443 - val_loss: 23.4763\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2222 - val_loss: 23.4622\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2299 - val_loss: 23.4479\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2153 - val_loss: 23.4338\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1374 - val_loss: 23.4200\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1933 - val_loss: 23.4052\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1710 - val_loss: 23.3910\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0131 - val_loss: 23.3766\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1295 - val_loss: 23.3618\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0810 - val_loss: 23.3481\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1180 - val_loss: 23.3335\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9472 - val_loss: 23.3193\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0906 - val_loss: 23.3042\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 21.0629 - val_loss: 23.2902\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9362 - val_loss: 23.2753\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.9125 - val_loss: 23.2607\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_294 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_295 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_296 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_297 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_298 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_299 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_300 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 25.7973 - val_loss: 24.7187\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.2791 - val_loss: 24.2900\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.8906 - val_loss: 23.9043\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.4043 - val_loss: 23.5518\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0044 - val_loss: 23.2306\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.7003 - val_loss: 22.9230\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.0386 - val_loss: 22.6285\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.9681 - val_loss: 22.3486\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.5507 - val_loss: 22.0890\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.3095 - val_loss: 21.8487\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0482 - val_loss: 21.6090\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7185 - val_loss: 21.3773\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5218 - val_loss: 21.1509\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.2129 - val_loss: 20.9430\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0043 - val_loss: 20.7516\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.7263 - val_loss: 20.5680\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6017 - val_loss: 20.4055\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3637 - val_loss: 20.2644\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.2120 - val_loss: 20.1405\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0065 - val_loss: 20.0332\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8522 - val_loss: 19.9338\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7075 - val_loss: 19.8394\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5992 - val_loss: 19.7568\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4952 - val_loss: 19.6868\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3102 - val_loss: 19.6242\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0871 - val_loss: 19.5647\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1542 - val_loss: 19.5065\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0826 - val_loss: 19.4520\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0120 - val_loss: 19.3972\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9629 - val_loss: 19.3431\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8988 - val_loss: 19.2895\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8593 - val_loss: 19.2369\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8008 - val_loss: 19.1869\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6892 - val_loss: 19.1418\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6640 - val_loss: 19.0993\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6211 - val_loss: 19.0592\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5590 - val_loss: 19.0217\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5109 - val_loss: 18.9858\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5302 - val_loss: 18.9505\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4534 - val_loss: 18.9180\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4623 - val_loss: 18.8876\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3799 - val_loss: 18.8598\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4056 - val_loss: 18.8341\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3837 - val_loss: 18.8102\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2372 - val_loss: 18.7887\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3079 - val_loss: 18.7678\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2686 - val_loss: 18.7467\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2650 - val_loss: 18.7256\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2682 - val_loss: 18.7047\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2459 - val_loss: 18.6849\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2246 - val_loss: 18.6651\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2111 - val_loss: 18.6457\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1787 - val_loss: 18.6265\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1680 - val_loss: 18.6078\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1569 - val_loss: 18.5890\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1431 - val_loss: 18.5706\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1255 - val_loss: 18.5526\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0895 - val_loss: 18.5353\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9418 - val_loss: 18.5182\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0623 - val_loss: 18.5011\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0317 - val_loss: 18.4840\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0066 - val_loss: 18.4677\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0198 - val_loss: 18.4512\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9915 - val_loss: 18.4347\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0032 - val_loss: 18.4180\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9653 - val_loss: 18.4011\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9439 - val_loss: 18.3846\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8908 - val_loss: 18.3685\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8907 - val_loss: 18.3524\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9042 - val_loss: 18.3361\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9054 - val_loss: 18.3206\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8808 - val_loss: 18.3045\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8870 - val_loss: 18.2882\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8279 - val_loss: 18.2726\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8666 - val_loss: 18.2569\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8458 - val_loss: 18.2412\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8388 - val_loss: 18.2255\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8165 - val_loss: 18.2096\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6696 - val_loss: 18.1943\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7663 - val_loss: 18.1790\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7826 - val_loss: 18.1631\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7495 - val_loss: 18.1478\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7345 - val_loss: 18.1325\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7241 - val_loss: 18.1171\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7128 - val_loss: 18.1019\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6864 - val_loss: 18.0864\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6446 - val_loss: 18.0710\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6781 - val_loss: 18.0559\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5900 - val_loss: 18.0409\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5604 - val_loss: 18.0258\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6225 - val_loss: 18.0099\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6021 - val_loss: 17.9946\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6047 - val_loss: 17.9785\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5965 - val_loss: 17.9626\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5756 - val_loss: 17.9471\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4711 - val_loss: 17.9322\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5257 - val_loss: 17.9169\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5315 - val_loss: 17.9018\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4902 - val_loss: 17.8868\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4567 - val_loss: 17.8717\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_301 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_302 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_303 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_304 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_305 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_306 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_307 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    128\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08973\n",
      "Model:                       QuantReg   Bandwidth:                    0.004931\n",
      "Method:                 Least Squares   Sparsity:                       0.1713\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:54:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0133      0.006      2.124      0.034       0.001       0.026\n",
      "three_month_yield_change      0.1650      0.176      0.937      0.349      -0.180       0.510\n",
      "term_spread_change           -0.3006      0.160     -1.882      0.060      -0.614       0.013\n",
      "TED_spread                   -1.4645      0.699     -2.094      0.036      -2.836      -0.093\n",
      "credit_spread_change          0.3153      0.213      1.481      0.139      -0.102       0.733\n",
      "market_return                -0.1079      0.087     -1.238      0.216      -0.279       0.063\n",
      "real_estate_excess_return     0.1204      0.105      1.146      0.252      -0.086       0.326\n",
      "equity_volatility             1.5513      0.166      9.326      0.000       1.225       1.877\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1843\n",
      "Model:                       QuantReg   Bandwidth:                    0.008162\n",
      "Method:                 Least Squares   Sparsity:                       0.9629\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:54:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0345      0.017      2.001      0.045       0.001       0.068\n",
      "three_month_yield_change     -0.1019      0.455     -0.224      0.823      -0.994       0.790\n",
      "term_spread_change           -0.3844      0.374     -1.028      0.304      -1.117       0.349\n",
      "TED_spread                   -3.3143      1.885     -1.758      0.079      -7.010       0.382\n",
      "credit_spread_change         -0.0794      0.603     -0.132      0.895      -1.262       1.104\n",
      "market_return                 0.0512      0.361      0.142      0.887      -0.656       0.759\n",
      "real_estate_excess_return    -0.0215      0.305     -0.070      0.944      -0.620       0.577\n",
      "equity_volatility             3.7473      0.598      6.266      0.000       2.575       4.920\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3340\n",
      "Model:                       QuantReg   Bandwidth:                    0.002438\n",
      "Method:                 Least Squares   Sparsity:                      0.08385\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:54:51   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0079      0.003      2.818      0.005       0.002       0.013\n",
      "three_month_yield_change      0.0661      0.081      0.815      0.415      -0.093       0.225\n",
      "term_spread_change           -0.0692      0.074     -0.940      0.347      -0.214       0.075\n",
      "TED_spread                   -0.6224      0.311     -2.001      0.046      -1.232      -0.012\n",
      "credit_spread_change          0.0012      0.100      0.011      0.991      -0.195       0.198\n",
      "market_return                -0.0358      0.043     -0.829      0.407      -0.121       0.049\n",
      "real_estate_excess_return    -0.0284      0.048     -0.591      0.554      -0.123       0.066\n",
      "equity_volatility             0.8845      0.081     10.910      0.000       0.726       1.043\n",
      "institution                   0.3752      0.039      9.708      0.000       0.299       0.451\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4436\n",
      "Model:                       QuantReg   Bandwidth:                    0.003664\n",
      "Method:                 Least Squares   Sparsity:                       0.3934\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:54:51   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0129      0.006      2.102      0.036       0.001       0.025\n",
      "three_month_yield_change      0.1129      0.195      0.580      0.562      -0.269       0.495\n",
      "term_spread_change           -0.1382      0.196     -0.706      0.480      -0.522       0.246\n",
      "TED_spread                   -1.0673      0.809     -1.319      0.187      -2.654       0.519\n",
      "credit_spread_change          0.1520      0.233      0.652      0.515      -0.305       0.609\n",
      "market_return                 0.0016      0.159      0.010      0.992      -0.310       0.313\n",
      "real_estate_excess_return    -0.1698      0.109     -1.560      0.119      -0.383       0.044\n",
      "equity_volatility             1.1212      0.249      4.502      0.000       0.633       1.610\n",
      "institution                   0.3771      0.144      2.614      0.009       0.094       0.660\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 15ms/step - loss: 32.8323 - val_loss: 31.1927\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.1793 - val_loss: 30.6491\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.6886 - val_loss: 30.1632\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.2430 - val_loss: 29.6931\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.7232 - val_loss: 29.2085\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.1288 - val_loss: 28.6960\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.6089 - val_loss: 28.1553\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.1196 - val_loss: 27.5841\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.4853 - val_loss: 26.9919\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.8310 - val_loss: 26.4040\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.2038 - val_loss: 25.8285\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.5351 - val_loss: 25.2073\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.8609 - val_loss: 24.5665\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0989 - val_loss: 23.9258\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8493 - val_loss: 23.3166\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2629 - val_loss: 22.7411\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7480 - val_loss: 22.2430\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2986 - val_loss: 21.8243\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9039 - val_loss: 21.4302\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5452 - val_loss: 21.0614\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1967 - val_loss: 20.7503\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9650 - val_loss: 20.4841\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7024 - val_loss: 20.2643\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5778 - val_loss: 20.0869\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3984 - val_loss: 19.9495\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1846 - val_loss: 19.8349\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9909 - val_loss: 19.7274\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9308 - val_loss: 19.6238\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9820 - val_loss: 19.5310\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9232 - val_loss: 19.4577\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7826 - val_loss: 19.3991\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7256 - val_loss: 19.3465\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7406 - val_loss: 19.2959\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7143 - val_loss: 19.2502\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7032 - val_loss: 19.2060\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5624 - val_loss: 19.1646\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6434 - val_loss: 19.1247\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6174 - val_loss: 19.0875\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5733 - val_loss: 19.0506\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5298 - val_loss: 19.0172\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5585 - val_loss: 18.9839\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5339 - val_loss: 18.9535\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4698 - val_loss: 18.9244\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4987 - val_loss: 18.8944\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3490 - val_loss: 18.8656\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4627 - val_loss: 18.8370\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4555 - val_loss: 18.8087\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4050 - val_loss: 18.7843\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4048 - val_loss: 18.7597\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3798 - val_loss: 18.7396\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3641 - val_loss: 18.7180\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3842 - val_loss: 18.6976\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3663 - val_loss: 18.6765\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3611 - val_loss: 18.6559\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3204 - val_loss: 18.6383\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3276 - val_loss: 18.6189\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3195 - val_loss: 18.6000\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3003 - val_loss: 18.5820\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2497 - val_loss: 18.5649\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2814 - val_loss: 18.5472\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2382 - val_loss: 18.5303\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2437 - val_loss: 18.5129\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1681 - val_loss: 18.4965\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2357 - val_loss: 18.4787\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2072 - val_loss: 18.4633\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1812 - val_loss: 18.4476\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1907 - val_loss: 18.4314\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0889 - val_loss: 18.4167\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1708 - val_loss: 18.3999\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1497 - val_loss: 18.3838\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1391 - val_loss: 18.3670\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1008 - val_loss: 18.3528\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1161 - val_loss: 18.3383\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0958 - val_loss: 18.3228\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0738 - val_loss: 18.3088\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0472 - val_loss: 18.2943\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0220 - val_loss: 18.2794\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0336 - val_loss: 18.2641\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0267 - val_loss: 18.2487\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0176 - val_loss: 18.2333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0067 - val_loss: 18.2168\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9759 - val_loss: 18.2013\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9464 - val_loss: 18.1855\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8188 - val_loss: 18.1706\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8754 - val_loss: 18.1545\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9328 - val_loss: 18.1391\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8855 - val_loss: 18.1246\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8678 - val_loss: 18.1094\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8781 - val_loss: 18.0933\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8718 - val_loss: 18.0781\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7889 - val_loss: 18.0640\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8542 - val_loss: 18.0487\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7691 - val_loss: 18.0328\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8023 - val_loss: 18.0178\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7565 - val_loss: 18.0019\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7729 - val_loss: 17.9867\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7836 - val_loss: 17.9701\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7139 - val_loss: 17.9535\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7648 - val_loss: 17.9375\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7164 - val_loss: 17.9221\n",
      "4/4 [==============================] - 0s 526us/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_308 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_309 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_310 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_311 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_312 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_313 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_314 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 26.2326 - val_loss: 24.8263\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2355 - val_loss: 23.9255\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2386 - val_loss: 23.2146\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4490 - val_loss: 22.5927\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7948 - val_loss: 22.0713\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1546 - val_loss: 21.6164\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6276 - val_loss: 21.1888\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2080 - val_loss: 20.8288\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8013 - val_loss: 20.5198\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.4151 - val_loss: 20.2843\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1336 - val_loss: 20.1041\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8487 - val_loss: 19.9464\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6631 - val_loss: 19.8210\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4296 - val_loss: 19.7245\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3052 - val_loss: 19.6338\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1857 - val_loss: 19.5496\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1065 - val_loss: 19.4681\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0051 - val_loss: 19.3894\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8546 - val_loss: 19.3196\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8648 - val_loss: 19.2587\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7934 - val_loss: 19.2038\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7402 - val_loss: 19.1533\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6581 - val_loss: 19.1064\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6571 - val_loss: 19.0678\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6138 - val_loss: 19.0350\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5653 - val_loss: 19.0095\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5253 - val_loss: 18.9862\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5316 - val_loss: 18.9632\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5024 - val_loss: 18.9410\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4687 - val_loss: 18.9193\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4380 - val_loss: 18.8986\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4381 - val_loss: 18.8780\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4016 - val_loss: 18.8581\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3976 - val_loss: 18.8387\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3899 - val_loss: 18.8200\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3682 - val_loss: 18.8021\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3595 - val_loss: 18.7842\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3386 - val_loss: 18.7670\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2967 - val_loss: 18.7504\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2984 - val_loss: 18.7351\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3107 - val_loss: 18.7189\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2672 - val_loss: 18.7029\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2840 - val_loss: 18.6867\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2688 - val_loss: 18.6712\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2472 - val_loss: 18.6558\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2357 - val_loss: 18.6408\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1834 - val_loss: 18.6261\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2197 - val_loss: 18.6119\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2097 - val_loss: 18.5973\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1925 - val_loss: 18.5832\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1628 - val_loss: 18.5690\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1716 - val_loss: 18.5546\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1568 - val_loss: 18.5409\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1424 - val_loss: 18.5265\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1392 - val_loss: 18.5132\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0887 - val_loss: 18.4998\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 17.9905 - val_loss: 18.4857\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0987 - val_loss: 18.4716\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0676 - val_loss: 18.4578\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0422 - val_loss: 18.4435\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0431 - val_loss: 18.4296\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9936 - val_loss: 18.4156\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9640 - val_loss: 18.4015\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.0219 - val_loss: 18.3871\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9973 - val_loss: 18.3733\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8621 - val_loss: 18.3599\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9883 - val_loss: 18.3460\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9585 - val_loss: 18.3315\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9313 - val_loss: 18.3174\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9217 - val_loss: 18.3034\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9140 - val_loss: 18.2897\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9076 - val_loss: 18.2760\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8729 - val_loss: 18.2627\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8879 - val_loss: 18.2486\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7381 - val_loss: 18.2345\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8623 - val_loss: 18.2199\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8447 - val_loss: 18.2051\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8194 - val_loss: 18.1911\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8183 - val_loss: 18.1767\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8048 - val_loss: 18.1623\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7743 - val_loss: 18.1486\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7575 - val_loss: 18.1343\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7641 - val_loss: 18.1205\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7304 - val_loss: 18.1062\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7362 - val_loss: 18.0913\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7345 - val_loss: 18.0767\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6483 - val_loss: 18.0623\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6959 - val_loss: 18.0474\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6889 - val_loss: 18.0336\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5647 - val_loss: 18.0192\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6613 - val_loss: 18.0046\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6157 - val_loss: 17.9908\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6256 - val_loss: 17.9759\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5355 - val_loss: 17.9618\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5836 - val_loss: 17.9465\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5798 - val_loss: 17.9318\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5743 - val_loss: 17.9170\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5511 - val_loss: 17.9025\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5089 - val_loss: 17.8885\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5078 - val_loss: 17.8739\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_315 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_316 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_317 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_318 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_319 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_320 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_321 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1332\n",
      "Model:                       QuantReg   Bandwidth:                    0.003865\n",
      "Method:                 Least Squares   Sparsity:                       0.1370\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:55:48   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0229      0.005      4.883      0.000       0.014       0.032\n",
      "three_month_yield_change     -0.2562      0.128     -2.002      0.045      -0.507      -0.005\n",
      "term_spread_change           -0.3075      0.122     -2.525      0.012      -0.546      -0.069\n",
      "TED_spread                   -0.7192      0.472     -1.524      0.128      -1.645       0.206\n",
      "credit_spread_change         -0.2939      0.171     -1.720      0.086      -0.629       0.041\n",
      "market_return                 0.0082      0.076      0.108      0.914      -0.140       0.157\n",
      "real_estate_excess_return    -0.0417      0.079     -0.529      0.597      -0.196       0.113\n",
      "equity_volatility             1.5943      0.135     11.832      0.000       1.330       1.859\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2858\n",
      "Model:                       QuantReg   Bandwidth:                    0.006856\n",
      "Method:                 Least Squares   Sparsity:                       0.7720\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:55:48   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.013      3.041      0.002       0.014       0.063\n",
      "three_month_yield_change     -0.4325      0.387     -1.119      0.263      -1.191       0.326\n",
      "term_spread_change           -0.1096      0.348     -0.315      0.753      -0.792       0.573\n",
      "TED_spread                    2.4083      1.281      1.879      0.060      -0.104       4.921\n",
      "credit_spread_change         -1.3634      0.474     -2.875      0.004      -2.293      -0.434\n",
      "market_return                -0.2442      0.255     -0.959      0.338      -0.744       0.255\n",
      "real_estate_excess_return    -0.4523      0.209     -2.160      0.031      -0.863      -0.042\n",
      "equity_volatility             4.1796      0.438      9.534      0.000       3.320       5.039\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3819\n",
      "Model:                       QuantReg   Bandwidth:                    0.002247\n",
      "Method:                 Least Squares   Sparsity:                      0.07619\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:55:49   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0124      0.003      4.591      0.000       0.007       0.018\n",
      "three_month_yield_change     -0.0161      0.078     -0.206      0.837      -0.170       0.137\n",
      "term_spread_change           -0.1908      0.066     -2.891      0.004      -0.320      -0.061\n",
      "TED_spread                   -0.4716      0.274     -1.724      0.085      -1.008       0.065\n",
      "credit_spread_change         -0.1301      0.092     -1.409      0.159      -0.311       0.051\n",
      "market_return                -0.0495      0.035     -1.406      0.160      -0.118       0.019\n",
      "real_estate_excess_return    -0.0214      0.044     -0.484      0.629      -0.108       0.065\n",
      "equity_volatility             0.8564      0.076     11.290      0.000       0.708       1.005\n",
      "institution                   0.5049      0.042     12.112      0.000       0.423       0.587\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4925\n",
      "Model:                       QuantReg   Bandwidth:                    0.003719\n",
      "Method:                 Least Squares   Sparsity:                       0.3233\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:55:49   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0179      0.005      3.895      0.000       0.009       0.027\n",
      "three_month_yield_change     -0.0175      0.151     -0.116      0.908      -0.313       0.278\n",
      "term_spread_change           -0.4355      0.163     -2.672      0.008      -0.755      -0.116\n",
      "TED_spread                   -1.1285      0.599     -1.885      0.060      -2.302       0.046\n",
      "credit_spread_change          0.0547      0.152      0.360      0.719      -0.243       0.353\n",
      "market_return                -0.0442      0.105     -0.422      0.673      -0.249       0.161\n",
      "real_estate_excess_return    -0.0277      0.101     -0.275      0.784      -0.225       0.170\n",
      "equity_volatility             1.2085      0.185      6.545      0.000       0.846       1.571\n",
      "institution                   0.4326      0.143      3.026      0.003       0.152       0.713\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 15ms/step - loss: 31.0276 - val_loss: 32.8444\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.3321 - val_loss: 31.9200\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.4835 - val_loss: 30.9759\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.5233 - val_loss: 29.9279\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.6321 - val_loss: 28.9024\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.6017 - val_loss: 27.8740\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6913 - val_loss: 26.8877\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.9670 - val_loss: 26.0181\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1868 - val_loss: 25.1851\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4907 - val_loss: 24.4813\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9419 - val_loss: 23.8435\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4583 - val_loss: 23.3028\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9354 - val_loss: 22.8320\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.6053 - val_loss: 22.3867\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3204 - val_loss: 22.0280\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0354 - val_loss: 21.7402\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8459 - val_loss: 21.5240\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6643 - val_loss: 21.3495\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5308 - val_loss: 21.1987\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4227 - val_loss: 21.0817\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2733 - val_loss: 20.9988\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2782 - val_loss: 20.9292\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2182 - val_loss: 20.8702\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1848 - val_loss: 20.8118\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1137 - val_loss: 20.7655\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0806 - val_loss: 20.7244\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0337 - val_loss: 20.6849\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0173 - val_loss: 20.6465\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9560 - val_loss: 20.6098\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8879 - val_loss: 20.5746\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9251 - val_loss: 20.5420\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8341 - val_loss: 20.5133\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8852 - val_loss: 20.4863\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8391 - val_loss: 20.4606\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8498 - val_loss: 20.4365\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8098 - val_loss: 20.4133\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6706 - val_loss: 20.3924\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8101 - val_loss: 20.3705\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7933 - val_loss: 20.3493\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7535 - val_loss: 20.3308\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7614 - val_loss: 20.3134\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7557 - val_loss: 20.2961\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7273 - val_loss: 20.2790\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7101 - val_loss: 20.2634\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6217 - val_loss: 20.2478\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6292 - val_loss: 20.2320\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5916 - val_loss: 20.2171\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6780 - val_loss: 20.2020\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4956 - val_loss: 20.1877\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6301 - val_loss: 20.1727\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6036 - val_loss: 20.1583\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5466 - val_loss: 20.1443\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6104 - val_loss: 20.1293\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5299 - val_loss: 20.1149\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5838 - val_loss: 20.1010\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5459 - val_loss: 20.0869\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5492 - val_loss: 20.0729\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5486 - val_loss: 20.0592\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5309 - val_loss: 20.0453\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5187 - val_loss: 20.0312\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4718 - val_loss: 20.0175\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4902 - val_loss: 20.0041\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4522 - val_loss: 19.9906\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4639 - val_loss: 19.9776\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3656 - val_loss: 19.9639\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3697 - val_loss: 19.9499\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3900 - val_loss: 19.9368\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3873 - val_loss: 19.9229\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2541 - val_loss: 19.9089\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3754 - val_loss: 19.8951\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3634 - val_loss: 19.8807\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3642 - val_loss: 19.8663\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3344 - val_loss: 19.8523\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2651 - val_loss: 19.8379\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2434 - val_loss: 19.8236\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3026 - val_loss: 19.8094\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2699 - val_loss: 19.7952\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2139 - val_loss: 19.7811\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2482 - val_loss: 19.7664\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2383 - val_loss: 19.7517\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1977 - val_loss: 19.7372\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2187 - val_loss: 19.7225\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1835 - val_loss: 19.7079\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1673 - val_loss: 19.6931\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1534 - val_loss: 19.6786\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0689 - val_loss: 19.6637\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1229 - val_loss: 19.6489\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0430 - val_loss: 19.6345\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1094 - val_loss: 19.6188\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0703 - val_loss: 19.6044\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0871 - val_loss: 19.5887\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0538 - val_loss: 19.5737\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9883 - val_loss: 19.5583\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0381 - val_loss: 19.5429\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0245 - val_loss: 19.5276\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8352 - val_loss: 19.5130\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9964 - val_loss: 19.4974\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9694 - val_loss: 19.4820\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9317 - val_loss: 19.4668\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8530 - val_loss: 19.4517\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_322 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_323 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_324 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_325 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_326 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_327 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_328 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.9286 - val_loss: 24.6327\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0869 - val_loss: 23.9881\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3402 - val_loss: 23.4309\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7136 - val_loss: 22.8850\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0309 - val_loss: 22.3605\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4824 - val_loss: 21.8869\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6679 - val_loss: 21.4261\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3680 - val_loss: 21.0232\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9772 - val_loss: 20.6688\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6026 - val_loss: 20.3976\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1743 - val_loss: 20.1965\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8508 - val_loss: 20.0209\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6997 - val_loss: 19.8931\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5038 - val_loss: 19.7831\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3699 - val_loss: 19.6829\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2478 - val_loss: 19.5913\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1313 - val_loss: 19.5014\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9844 - val_loss: 19.4258\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9423 - val_loss: 19.3608\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8832 - val_loss: 19.3024\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8339 - val_loss: 19.2514\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7901 - val_loss: 19.2061\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7151 - val_loss: 19.1737\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6410 - val_loss: 19.1451\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6358 - val_loss: 19.1176\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6478 - val_loss: 19.0909\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6201 - val_loss: 19.0656\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5855 - val_loss: 19.0416\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5491 - val_loss: 19.0188\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5589 - val_loss: 18.9967\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5354 - val_loss: 18.9750\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5287 - val_loss: 18.9567\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5138 - val_loss: 18.9377\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4945 - val_loss: 18.9195\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4434 - val_loss: 18.9027\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4590 - val_loss: 18.8856\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4558 - val_loss: 18.8690\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4470 - val_loss: 18.8528\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4086 - val_loss: 18.8367\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3879 - val_loss: 18.8208\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3800 - val_loss: 18.8070\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3818 - val_loss: 18.7919\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2467 - val_loss: 18.7779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3503 - val_loss: 18.7631\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3175 - val_loss: 18.7486\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3136 - val_loss: 18.7337\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2425 - val_loss: 18.7193\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3074 - val_loss: 18.7047\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2652 - val_loss: 18.6903\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2784 - val_loss: 18.6758\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2520 - val_loss: 18.6615\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2032 - val_loss: 18.6478\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2019 - val_loss: 18.6331\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2295 - val_loss: 18.6192\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2306 - val_loss: 18.6045\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2006 - val_loss: 18.5905\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1958 - val_loss: 18.5761\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1911 - val_loss: 18.5618\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1702 - val_loss: 18.5473\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1460 - val_loss: 18.5332\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1490 - val_loss: 18.5185\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1350 - val_loss: 18.5037\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1054 - val_loss: 18.4891\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1111 - val_loss: 18.4748\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0511 - val_loss: 18.4608\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0869 - val_loss: 18.4463\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0677 - val_loss: 18.4315\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0401 - val_loss: 18.4170\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0145 - val_loss: 18.4024\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9716 - val_loss: 18.3877\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0121 - val_loss: 18.3733\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9890 - val_loss: 18.3592\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9835 - val_loss: 18.3443\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9530 - val_loss: 18.3303\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9300 - val_loss: 18.3162\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9446 - val_loss: 18.3011\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9290 - val_loss: 18.2860\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8214 - val_loss: 18.2715\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9044 - val_loss: 18.2567\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8729 - val_loss: 18.2416\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8630 - val_loss: 18.2270\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8591 - val_loss: 18.2114\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7762 - val_loss: 18.1975\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8336 - val_loss: 18.1822\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8140 - val_loss: 18.1669\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7763 - val_loss: 18.1518\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7616 - val_loss: 18.1367\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7691 - val_loss: 18.1217\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7484 - val_loss: 18.1069\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7246 - val_loss: 18.0918\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7004 - val_loss: 18.0771\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7082 - val_loss: 18.0621\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6459 - val_loss: 18.0471\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6619 - val_loss: 18.0321\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6030 - val_loss: 18.0167\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5907 - val_loss: 18.0015\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5172 - val_loss: 17.9860\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6079 - val_loss: 17.9704\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5152 - val_loss: 17.9547\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5746 - val_loss: 17.9393\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_48 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_329 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_330 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_331 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_332 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_333 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_334 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_335 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1314\n",
      "Model:                       QuantReg   Bandwidth:                    0.003718\n",
      "Method:                 Least Squares   Sparsity:                       0.1353\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:56:48   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0284      0.005      5.938      0.000       0.019       0.038\n",
      "three_month_yield_change     -0.4026      0.126     -3.184      0.001      -0.651      -0.155\n",
      "term_spread_change           -0.4193      0.116     -3.622      0.000      -0.646      -0.192\n",
      "TED_spread                    0.0590      0.435      0.136      0.892      -0.793       0.912\n",
      "credit_spread_change         -0.5183      0.168     -3.081      0.002      -0.848      -0.188\n",
      "market_return                -0.0152      0.075     -0.202      0.840      -0.162       0.132\n",
      "real_estate_excess_return     0.0369      0.078      0.472      0.637      -0.116       0.190\n",
      "equity_volatility             1.5164      0.147     10.293      0.000       1.227       1.805\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3156\n",
      "Model:                       QuantReg   Bandwidth:                    0.006434\n",
      "Method:                 Least Squares   Sparsity:                       0.5902\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:56:48   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.010      3.772      0.000       0.019       0.059\n",
      "three_month_yield_change     -0.3992      0.281     -1.422      0.155      -0.950       0.151\n",
      "term_spread_change           -0.6014      0.248     -2.429      0.015      -1.087      -0.116\n",
      "TED_spread                   -0.1392      0.994     -0.140      0.889      -2.089       1.811\n",
      "credit_spread_change         -0.8141      0.359     -2.269      0.023      -1.518      -0.110\n",
      "market_return                -0.1387      0.228     -0.608      0.543      -0.586       0.309\n",
      "real_estate_excess_return    -0.3365      0.236     -1.426      0.154      -0.799       0.126\n",
      "equity_volatility             3.5938      0.359     10.005      0.000       2.889       4.298\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3687\n",
      "Model:                       QuantReg   Bandwidth:                    0.002165\n",
      "Method:                 Least Squares   Sparsity:                      0.07518\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:56:48   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0072      0.003      2.741      0.006       0.002       0.012\n",
      "three_month_yield_change      0.1032      0.073      1.422      0.155      -0.039       0.246\n",
      "term_spread_change           -0.0562      0.067     -0.840      0.401      -0.188       0.075\n",
      "TED_spread                   -0.8738      0.278     -3.139      0.002      -1.420      -0.328\n",
      "credit_spread_change         -0.0195      0.093     -0.210      0.834      -0.201       0.162\n",
      "market_return                -0.0817      0.038     -2.176      0.030      -0.155      -0.008\n",
      "real_estate_excess_return    -0.0169      0.044     -0.381      0.703      -0.104       0.070\n",
      "equity_volatility             0.9226      0.071     13.057      0.000       0.784       1.061\n",
      "institution                   0.5078      0.049     10.460      0.000       0.413       0.603\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4662\n",
      "Model:                       QuantReg   Bandwidth:                    0.003876\n",
      "Method:                 Least Squares   Sparsity:                       0.3546\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:56:48   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    -0.0061      0.005     -1.181      0.238      -0.016       0.004\n",
      "three_month_yield_change      0.5008      0.178      2.817      0.005       0.152       0.849\n",
      "term_spread_change           -0.0919      0.199     -0.461      0.645      -0.483       0.299\n",
      "TED_spread                   -2.3643      0.796     -2.972      0.003      -3.924      -0.804\n",
      "credit_spread_change          0.9539      0.184      5.180      0.000       0.593       1.315\n",
      "market_return                -0.0921      0.116     -0.793      0.428      -0.320       0.136\n",
      "real_estate_excess_return    -0.1332      0.124     -1.072      0.284      -0.377       0.111\n",
      "equity_volatility             1.0309      0.244      4.227      0.000       0.553       1.509\n",
      "institution                   0.4148      0.171      2.421      0.016       0.079       0.751\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 32.5130 - val_loss: 29.3469\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.7937 - val_loss: 28.6980\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.1071 - val_loss: 28.0497\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.4070 - val_loss: 27.3605\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.3829 - val_loss: 26.6570\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.7958 - val_loss: 25.9800\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9403 - val_loss: 25.3098\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.4083 - val_loss: 24.6218\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.5983 - val_loss: 23.9331\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7119 - val_loss: 23.2347\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.0015 - val_loss: 22.5242\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.2998 - val_loss: 21.8446\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6655 - val_loss: 21.2200\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0704 - val_loss: 20.7374\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7528 - val_loss: 20.3406\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4121 - val_loss: 20.0589\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0985 - val_loss: 19.8336\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9120 - val_loss: 19.6525\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7838 - val_loss: 19.4927\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6163 - val_loss: 19.3462\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5753 - val_loss: 19.2268\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3220 - val_loss: 19.1292\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4298 - val_loss: 19.0403\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3246 - val_loss: 18.9670\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2998 - val_loss: 18.9020\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2398 - val_loss: 18.8447\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2233 - val_loss: 18.8017\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1031 - val_loss: 18.7673\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2230 - val_loss: 18.7359\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1931 - val_loss: 18.7057\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1837 - val_loss: 18.6787\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1162 - val_loss: 18.6543\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1558 - val_loss: 18.6320\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1359 - val_loss: 18.6095\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1400 - val_loss: 18.5875\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1167 - val_loss: 18.5664\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0926 - val_loss: 18.5454\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0793 - val_loss: 18.5252\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9647 - val_loss: 18.5055\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0641 - val_loss: 18.4873\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0548 - val_loss: 18.4690\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0204 - val_loss: 18.4510\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0156 - val_loss: 18.4341\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0203 - val_loss: 18.4173\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6896 - val_loss: 18.4023\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9907 - val_loss: 18.3871\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9734 - val_loss: 18.3718\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9784 - val_loss: 18.3569\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9732 - val_loss: 18.3417\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9534 - val_loss: 18.3273\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9381 - val_loss: 18.3133\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8736 - val_loss: 18.2991\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8527 - val_loss: 18.2856\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9019 - val_loss: 18.2722\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8269 - val_loss: 18.2581\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8861 - val_loss: 18.2440\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8218 - val_loss: 18.2305\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8541 - val_loss: 18.2164\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8436 - val_loss: 18.2023\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8020 - val_loss: 18.1883\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6488 - val_loss: 18.1746\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7747 - val_loss: 18.1609\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7666 - val_loss: 18.1464\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7781 - val_loss: 18.1318\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7574 - val_loss: 18.1170\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7309 - val_loss: 18.1024\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5518 - val_loss: 18.0882\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7006 - val_loss: 18.0736\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7093 - val_loss: 18.0587\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6792 - val_loss: 18.0444\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5493 - val_loss: 18.0303\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6026 - val_loss: 18.0163\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.6364 - val_loss: 18.0023\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5429 - val_loss: 17.9878\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5394 - val_loss: 17.9738\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5800 - val_loss: 17.9596\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5879 - val_loss: 17.9452\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5578 - val_loss: 17.9315\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5720 - val_loss: 17.9170\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5586 - val_loss: 17.9026\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5235 - val_loss: 17.8885\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.4827 - val_loss: 17.8747\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4672 - val_loss: 17.8605\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5096 - val_loss: 17.8460\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4703 - val_loss: 17.8315\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4618 - val_loss: 17.8170\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3886 - val_loss: 17.8021\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4108 - val_loss: 17.7875\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3784 - val_loss: 17.7732\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4155 - val_loss: 17.7585\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3319 - val_loss: 17.7437\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3125 - val_loss: 17.7292\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3591 - val_loss: 17.7144\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3127 - val_loss: 17.6996\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3486 - val_loss: 17.6849\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1397 - val_loss: 17.6702\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3031 - val_loss: 17.6553\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2697 - val_loss: 17.6404\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2896 - val_loss: 17.6254\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2673 - val_loss: 17.6104\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_336 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_337 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_338 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_339 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_340 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_341 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_342 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.5553 - val_loss: 24.5038\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.8838 - val_loss: 23.7561\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.0436 - val_loss: 23.0568\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2657 - val_loss: 22.4352\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5009 - val_loss: 21.8757\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8180 - val_loss: 21.3346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1837 - val_loss: 20.8660\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8153 - val_loss: 20.4737\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3175 - val_loss: 20.1921\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9806 - val_loss: 19.9747\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6846 - val_loss: 19.8103\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4565 - val_loss: 19.6850\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1946 - val_loss: 19.5698\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0553 - val_loss: 19.4625\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9972 - val_loss: 19.3618\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8826 - val_loss: 19.2806\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8075 - val_loss: 19.2116\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7419 - val_loss: 19.1508\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6578 - val_loss: 19.1051\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6278 - val_loss: 19.0703\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6123 - val_loss: 19.0394\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5667 - val_loss: 19.0120\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5039 - val_loss: 18.9864\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5261 - val_loss: 18.9618\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5059 - val_loss: 18.9382\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4771 - val_loss: 18.9170\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4709 - val_loss: 18.8967\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4428 - val_loss: 18.8771\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4339 - val_loss: 18.8579\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4215 - val_loss: 18.8397\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4019 - val_loss: 18.8223\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.3609 - val_loss: 18.8060\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3868 - val_loss: 18.7908\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3731 - val_loss: 18.7752\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3590 - val_loss: 18.7601\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2784 - val_loss: 18.7461\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3394 - val_loss: 18.7317\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3102 - val_loss: 18.7178\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3040 - val_loss: 18.7043\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3013 - val_loss: 18.6909\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2132 - val_loss: 18.6773\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2603 - val_loss: 18.6634\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2424 - val_loss: 18.6503\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1845 - val_loss: 18.6379\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2133 - val_loss: 18.6247\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2314 - val_loss: 18.6115\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2262 - val_loss: 18.5980\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0508 - val_loss: 18.5847\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1891 - val_loss: 18.5716\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1037 - val_loss: 18.5586\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1747 - val_loss: 18.5450\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1556 - val_loss: 18.5319\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1371 - val_loss: 18.5186\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1084 - val_loss: 18.5058\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9584 - val_loss: 18.4924\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0944 - val_loss: 18.4797\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0995 - val_loss: 18.4657\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0771 - val_loss: 18.4522\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0677 - val_loss: 18.4384\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0442 - val_loss: 18.4253\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0464 - val_loss: 18.4113\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0318 - val_loss: 18.3973\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0076 - val_loss: 18.3837\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0026 - val_loss: 18.3704\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9890 - val_loss: 18.3574\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9743 - val_loss: 18.3442\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9731 - val_loss: 18.3307\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9518 - val_loss: 18.3174\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9326 - val_loss: 18.3041\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9322 - val_loss: 18.2902\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8753 - val_loss: 18.2765\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9057 - val_loss: 18.2628\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8982 - val_loss: 18.2485\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8637 - val_loss: 18.2353\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8699 - val_loss: 18.2212\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8554 - val_loss: 18.2076\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8343 - val_loss: 18.1940\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8249 - val_loss: 18.1807\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8157 - val_loss: 18.1666\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7809 - val_loss: 18.1533\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6276 - val_loss: 18.1393\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7780 - val_loss: 18.1248\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7423 - val_loss: 18.1106\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7437 - val_loss: 18.0962\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7019 - val_loss: 18.0826\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6595 - val_loss: 18.0694\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6720 - val_loss: 18.0549\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6715 - val_loss: 18.0419\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6115 - val_loss: 18.0269\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6534 - val_loss: 18.0127\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6355 - val_loss: 17.9980\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6177 - val_loss: 17.9833\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6085 - val_loss: 17.9693\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5991 - val_loss: 17.9557\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5939 - val_loss: 17.9407\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5652 - val_loss: 17.9268\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5439 - val_loss: 17.9125\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5450 - val_loss: 17.8977\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5288 - val_loss: 17.8839\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5165 - val_loss: 17.8696\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_343 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_344 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_345 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_346 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_347 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_348 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_349 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1486\n",
      "Model:                       QuantReg   Bandwidth:                    0.004225\n",
      "Method:                 Least Squares   Sparsity:                       0.1267\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:57:46   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0411      0.004      9.742      0.000       0.033       0.049\n",
      "three_month_yield_change     -0.8377      0.125     -6.687      0.000      -1.083      -0.592\n",
      "term_spread_change           -0.5977      0.124     -4.833      0.000      -0.840      -0.355\n",
      "TED_spread                    0.0707      0.489      0.145      0.885      -0.888       1.029\n",
      "credit_spread_change         -0.9449      0.145     -6.528      0.000      -1.229      -0.661\n",
      "market_return                -0.1254      0.066     -1.900      0.058      -0.255       0.004\n",
      "real_estate_excess_return    -0.0110      0.074     -0.150      0.881      -0.156       0.134\n",
      "equity_volatility             2.1684      0.119     18.204      0.000       1.935       2.402\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3221\n",
      "Model:                       QuantReg   Bandwidth:                    0.007339\n",
      "Method:                 Least Squares   Sparsity:                       0.5044\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:57:46   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0542      0.008      7.160      0.000       0.039       0.069\n",
      "three_month_yield_change     -1.1402      0.293     -3.885      0.000      -1.716      -0.565\n",
      "term_spread_change           -0.7875      0.269     -2.926      0.003      -1.315      -0.260\n",
      "TED_spread                    2.3095      1.036      2.230      0.026       0.279       4.340\n",
      "credit_spread_change         -1.5241      0.221     -6.888      0.000      -1.958      -1.090\n",
      "market_return                -0.2506      0.179     -1.398      0.162      -0.602       0.101\n",
      "real_estate_excess_return    -0.0845      0.161     -0.525      0.600      -0.400       0.231\n",
      "equity_volatility             3.7827      0.282     13.429      0.000       3.230       4.335\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3729\n",
      "Model:                       QuantReg   Bandwidth:                    0.002120\n",
      "Method:                 Least Squares   Sparsity:                      0.08669\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:57:46   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0093      0.003      2.848      0.004       0.003       0.016\n",
      "three_month_yield_change      0.0624      0.089      0.701      0.483      -0.112       0.237\n",
      "term_spread_change           -0.1799      0.074     -2.434      0.015      -0.325      -0.035\n",
      "TED_spread                   -1.0500      0.317     -3.313      0.001      -1.671      -0.429\n",
      "credit_spread_change          0.0508      0.114      0.443      0.657      -0.174       0.275\n",
      "market_return                 0.0259      0.047      0.551      0.582      -0.066       0.118\n",
      "real_estate_excess_return    -0.0057      0.051     -0.112      0.911      -0.106       0.094\n",
      "equity_volatility             0.7555      0.092      8.183      0.000       0.574       0.937\n",
      "institution                   0.5203      0.044     11.839      0.000       0.434       0.607\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4935\n",
      "Model:                       QuantReg   Bandwidth:                    0.004278\n",
      "Method:                 Least Squares   Sparsity:                       0.2896\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:57:47   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0276      0.005      6.064      0.000       0.019       0.037\n",
      "three_month_yield_change      0.1485      0.144      1.032      0.302      -0.134       0.431\n",
      "term_spread_change           -0.5649      0.133     -4.259      0.000      -0.825      -0.305\n",
      "TED_spread                   -3.5412      0.604     -5.863      0.000      -4.726      -2.357\n",
      "credit_spread_change          0.0941      0.174      0.542      0.588      -0.246       0.435\n",
      "market_return                 0.0311      0.118      0.264      0.792      -0.200       0.262\n",
      "real_estate_excess_return    -0.0334      0.091     -0.369      0.712      -0.211       0.144\n",
      "equity_volatility             1.0680      0.186      5.731      0.000       0.703       1.433\n",
      "institution                   0.4662      0.124      3.755      0.000       0.223       0.710\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 14ms/step - loss: 38.1699 - val_loss: 41.5547\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 37.1922 - val_loss: 40.6325\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 36.2358 - val_loss: 39.8130\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 35.2310 - val_loss: 38.9819\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 34.4902 - val_loss: 38.1006\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.7161 - val_loss: 37.2314\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.7618 - val_loss: 36.3578\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.6975 - val_loss: 35.4516\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.8857 - val_loss: 34.5336\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.7582 - val_loss: 33.6437\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.9078 - val_loss: 32.8091\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9585 - val_loss: 32.0141\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.1865 - val_loss: 31.3202\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4354 - val_loss: 30.6759\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7211 - val_loss: 30.0970\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2032 - val_loss: 29.5870\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.7549 - val_loss: 29.1907\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4344 - val_loss: 28.8633\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1921 - val_loss: 28.5838\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9439 - val_loss: 28.3370\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7373 - val_loss: 28.1143\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6032 - val_loss: 27.9275\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4521 - val_loss: 27.7543\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.3193 - val_loss: 27.6000\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1114 - val_loss: 27.4676\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1264 - val_loss: 27.3586\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9024 - val_loss: 27.2622\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0041 - val_loss: 27.1721\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8456 - val_loss: 27.0916\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8542 - val_loss: 27.0220\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6429 - val_loss: 26.9667\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8076 - val_loss: 26.9190\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7599 - val_loss: 26.8793\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6944 - val_loss: 26.8494\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5946 - val_loss: 26.8263\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6728 - val_loss: 26.8055\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5743 - val_loss: 26.7866\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5920 - val_loss: 26.7681\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5531 - val_loss: 26.7499\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5683 - val_loss: 26.7322\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5586 - val_loss: 26.7142\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5312 - val_loss: 26.6967\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5053 - val_loss: 26.6797\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4874 - val_loss: 26.6628\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4702 - val_loss: 26.6465\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4468 - val_loss: 26.6306\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3281 - val_loss: 26.6153\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3629 - val_loss: 26.5998\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3920 - val_loss: 26.5842\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3986 - val_loss: 26.5692\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3495 - val_loss: 26.5551\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3609 - val_loss: 26.5416\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3184 - val_loss: 26.5285\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3433 - val_loss: 26.5158\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3084 - val_loss: 26.5033\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3020 - val_loss: 26.4910\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2969 - val_loss: 26.4787\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2421 - val_loss: 26.4663\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2635 - val_loss: 26.4541\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1833 - val_loss: 26.4418\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2441 - val_loss: 26.4295\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2321 - val_loss: 26.4171\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2114 - val_loss: 26.4046\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2064 - val_loss: 26.3922\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1617 - val_loss: 26.3797\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1750 - val_loss: 26.3671\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1219 - val_loss: 26.3545\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1531 - val_loss: 26.3418\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1315 - val_loss: 26.3291\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0981 - val_loss: 26.3163\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0981 - val_loss: 26.3034\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0900 - val_loss: 26.2905\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0677 - val_loss: 26.2775\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0117 - val_loss: 26.2644\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0492 - val_loss: 26.2513\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0339 - val_loss: 26.2381\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0410 - val_loss: 26.2249\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9128 - val_loss: 26.2116\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0004 - val_loss: 26.1983\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9447 - val_loss: 26.1849\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9030 - val_loss: 26.1715\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9463 - val_loss: 26.1580\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9441 - val_loss: 26.1445\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8879 - val_loss: 26.1309\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5347 - val_loss: 26.1172\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9111 - val_loss: 26.1035\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8833 - val_loss: 26.0898\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8645 - val_loss: 26.0760\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8189 - val_loss: 26.0622\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8612 - val_loss: 26.0483\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8018 - val_loss: 26.0344\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8286 - val_loss: 26.0204\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7675 - val_loss: 26.0064\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8039 - val_loss: 25.9923\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7992 - val_loss: 25.9782\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6056 - val_loss: 25.9640\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7220 - val_loss: 25.9498\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6363 - val_loss: 25.9356\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7230 - val_loss: 25.9213\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7156 - val_loss: 25.9070\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_350 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_351 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_352 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_353 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_354 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_355 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_356 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 26.1325 - val_loss: 24.9825\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6720 - val_loss: 24.5547\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.1207 - val_loss: 24.0609\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5340 - val_loss: 23.6163\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0559 - val_loss: 23.2003\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5577 - val_loss: 22.7729\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9473 - val_loss: 22.3377\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5120 - val_loss: 21.9097\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9088 - val_loss: 21.4688\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4329 - val_loss: 21.0297\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9522 - val_loss: 20.6444\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5662 - val_loss: 20.3112\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1697 - val_loss: 20.0609\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8439 - val_loss: 19.8579\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5701 - val_loss: 19.7103\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3322 - val_loss: 19.5902\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9938 - val_loss: 19.4817\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0350 - val_loss: 19.3788\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8192 - val_loss: 19.2823\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8179 - val_loss: 19.2065\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6863 - val_loss: 19.1378\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6529 - val_loss: 19.0798\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3971 - val_loss: 19.0255\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5653 - val_loss: 18.9853\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5150 - val_loss: 18.9558\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4695 - val_loss: 18.9291\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4633 - val_loss: 18.9035\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4452 - val_loss: 18.8789\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4121 - val_loss: 18.8551\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3716 - val_loss: 18.8330\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3759 - val_loss: 18.8118\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3506 - val_loss: 18.7918\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2838 - val_loss: 18.7743\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2427 - val_loss: 18.7565\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3042 - val_loss: 18.7393\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2700 - val_loss: 18.7220\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2767 - val_loss: 18.7058\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2543 - val_loss: 18.6897\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2459 - val_loss: 18.6737\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2439 - val_loss: 18.6573\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2160 - val_loss: 18.6409\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1750 - val_loss: 18.6251\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0305 - val_loss: 18.6102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1918 - val_loss: 18.5953\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1762 - val_loss: 18.5804\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1531 - val_loss: 18.5654\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1387 - val_loss: 18.5507\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1389 - val_loss: 18.5358\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1216 - val_loss: 18.5214\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0496 - val_loss: 18.5075\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9847 - val_loss: 18.4934\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0607 - val_loss: 18.4794\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0760 - val_loss: 18.4649\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0598 - val_loss: 18.4511\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0039 - val_loss: 18.4369\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0277 - val_loss: 18.4232\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0208 - val_loss: 18.4091\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9624 - val_loss: 18.3954\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9714 - val_loss: 18.3815\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9376 - val_loss: 18.3674\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9350 - val_loss: 18.3530\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8779 - val_loss: 18.3386\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9217 - val_loss: 18.3245\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9164 - val_loss: 18.3111\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8705 - val_loss: 18.2974\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9018 - val_loss: 18.2829\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8851 - val_loss: 18.2690\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8705 - val_loss: 18.2546\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8562 - val_loss: 18.2400\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8543 - val_loss: 18.2257\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8387 - val_loss: 18.2111\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8223 - val_loss: 18.1966\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8167 - val_loss: 18.1816\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8051 - val_loss: 18.1668\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6960 - val_loss: 18.1522\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7507 - val_loss: 18.1375\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7523 - val_loss: 18.1224\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7404 - val_loss: 18.1072\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6755 - val_loss: 18.0925\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6976 - val_loss: 18.0779\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6916 - val_loss: 18.0632\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6828 - val_loss: 18.0477\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6371 - val_loss: 18.0335\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6520 - val_loss: 18.0182\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5892 - val_loss: 18.0035\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5404 - val_loss: 17.9890\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6073 - val_loss: 17.9744\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5886 - val_loss: 17.9594\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5285 - val_loss: 17.9447\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5166 - val_loss: 17.9301\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5505 - val_loss: 17.9149\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5490 - val_loss: 17.8993\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4948 - val_loss: 17.8842\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4675 - val_loss: 17.8690\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.2948 - val_loss: 17.8545\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4146 - val_loss: 17.8400\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4454 - val_loss: 17.8257\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4570 - val_loss: 17.8102\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4403 - val_loss: 17.7946\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4166 - val_loss: 17.7791\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_52 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_357 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_358 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_359 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_360 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_361 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_362 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_363 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1366\n",
      "Model:                       QuantReg   Bandwidth:                    0.005426\n",
      "Method:                 Least Squares   Sparsity:                       0.1997\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:58:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0003      0.007      0.048      0.962      -0.013       0.014\n",
      "three_month_yield_change     -0.3610      0.186     -1.936      0.053      -0.727       0.005\n",
      "term_spread_change           -0.2084      0.183     -1.136      0.256      -0.568       0.151\n",
      "TED_spread                    0.6317      0.673      0.939      0.348      -0.688       1.951\n",
      "credit_spread_change          0.4283      0.245      1.750      0.080      -0.052       0.908\n",
      "market_return                 0.0831      0.106      0.781      0.435      -0.126       0.292\n",
      "real_estate_excess_return     0.0568      0.126      0.450      0.653      -0.191       0.304\n",
      "equity_volatility             2.3357      0.208     11.225      0.000       1.928       2.744\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3279\n",
      "Model:                       QuantReg   Bandwidth:                    0.009052\n",
      "Method:                 Least Squares   Sparsity:                       0.9229\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:58:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0049      0.014      0.353      0.724      -0.022       0.032\n",
      "three_month_yield_change      0.2939      0.394      0.745      0.456      -0.479       1.067\n",
      "term_spread_change           -0.2017      0.387     -0.521      0.602      -0.960       0.557\n",
      "TED_spread                    0.2385      1.551      0.154      0.878      -2.802       3.279\n",
      "credit_spread_change          0.5309      0.507      1.048      0.295      -0.463       1.525\n",
      "market_return                 0.2808      0.355      0.792      0.429      -0.415       0.976\n",
      "real_estate_excess_return    -0.1696      0.366     -0.463      0.643      -0.888       0.548\n",
      "equity_volatility             3.9839      0.571      6.977      0.000       2.864       5.104\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 27\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3666\n",
      "Model:                       QuantReg   Bandwidth:                    0.002270\n",
      "Method:                 Least Squares   Sparsity:                      0.08539\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:58:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0110      0.003      3.781      0.000       0.005       0.017\n",
      "three_month_yield_change      0.0485      0.081      0.602      0.547      -0.110       0.206\n",
      "term_spread_change           -0.2840      0.074     -3.859      0.000      -0.428      -0.140\n",
      "TED_spread                   -0.5823      0.297     -1.958      0.050      -1.166       0.001\n",
      "credit_spread_change         -0.0049      0.108     -0.046      0.963      -0.217       0.207\n",
      "market_return                -0.1196      0.044     -2.721      0.007      -0.206      -0.033\n",
      "real_estate_excess_return    -0.0764      0.052     -1.456      0.145      -0.179       0.026\n",
      "equity_volatility             0.7838      0.084      9.277      0.000       0.618       0.950\n",
      "institution                   0.3607      0.039      9.168      0.000       0.284       0.438\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4797\n",
      "Model:                       QuantReg   Bandwidth:                    0.003644\n",
      "Method:                 Least Squares   Sparsity:                       0.3304\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:58:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0258      0.005      5.363      0.000       0.016       0.035\n",
      "three_month_yield_change     -0.2443      0.161     -1.521      0.128      -0.559       0.071\n",
      "term_spread_change           -0.5294      0.162     -3.274      0.001      -0.847      -0.212\n",
      "TED_spread                   -1.3775      0.553     -2.492      0.013      -2.461      -0.294\n",
      "credit_spread_change         -0.0689      0.183     -0.377      0.706      -0.427       0.289\n",
      "market_return                -0.2180      0.112     -1.950      0.051      -0.437       0.001\n",
      "real_estate_excess_return    -0.1805      0.117     -1.547      0.122      -0.409       0.048\n",
      "equity_volatility             1.0918      0.244      4.467      0.000       0.613       1.571\n",
      "institution                   0.3614      0.128      2.830      0.005       0.111       0.612\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 36.0645 - val_loss: 40.4314\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 35.4199 - val_loss: 39.7975\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.8898 - val_loss: 39.3507\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.4818 - val_loss: 38.9263\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.8777 - val_loss: 38.4898\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.4915 - val_loss: 38.0284\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.0970 - val_loss: 37.5359\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.5185 - val_loss: 37.0100\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 31.9649 - val_loss: 36.4341\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.3731 - val_loss: 35.8382\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.8688 - val_loss: 35.2078\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.1400 - val_loss: 34.5174\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.4359 - val_loss: 33.7891\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.6459 - val_loss: 33.0125\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.0066 - val_loss: 32.1593\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.2535 - val_loss: 31.2664\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.5581 - val_loss: 30.3673\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.7578 - val_loss: 29.4958\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0786 - val_loss: 28.7109\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3360 - val_loss: 27.9934\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.8681 - val_loss: 27.3476\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3614 - val_loss: 26.7980\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9569 - val_loss: 26.3620\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7007 - val_loss: 26.0194\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4025 - val_loss: 25.7672\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2867 - val_loss: 25.5366\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1335 - val_loss: 25.3330\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9896 - val_loss: 25.1633\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9365 - val_loss: 25.0194\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8630 - val_loss: 24.8852\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6853 - val_loss: 24.7725\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7462 - val_loss: 24.6766\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7034 - val_loss: 24.5956\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6274 - val_loss: 24.5336\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6219 - val_loss: 24.4763\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6083 - val_loss: 24.4202\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5799 - val_loss: 24.3673\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5282 - val_loss: 24.3166\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3517 - val_loss: 24.2707\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4944 - val_loss: 24.2310\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4952 - val_loss: 24.1933\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4749 - val_loss: 24.1642\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3174 - val_loss: 24.1359\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4579 - val_loss: 24.1103\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4356 - val_loss: 24.0856\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3359 - val_loss: 24.0648\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3601 - val_loss: 24.0459\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3833 - val_loss: 24.0253\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3818 - val_loss: 24.0066\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3777 - val_loss: 23.9846\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2890 - val_loss: 23.9638\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3423 - val_loss: 23.9421\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2740 - val_loss: 23.9210\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3298 - val_loss: 23.9016\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3103 - val_loss: 23.8813\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2395 - val_loss: 23.8622\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2812 - val_loss: 23.8420\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2543 - val_loss: 23.8231\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2686 - val_loss: 23.8048\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2544 - val_loss: 23.7871\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2142 - val_loss: 23.7696\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2291 - val_loss: 23.7505\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1981 - val_loss: 23.7341\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1823 - val_loss: 23.7192\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1721 - val_loss: 23.7036\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0612 - val_loss: 23.6887\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1575 - val_loss: 23.6734\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1498 - val_loss: 23.6577\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1076 - val_loss: 23.6426\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1237 - val_loss: 23.6259\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1042 - val_loss: 23.6108\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0549 - val_loss: 23.5971\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0156 - val_loss: 23.5832\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0649 - val_loss: 23.5685\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9875 - val_loss: 23.5554\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0340 - val_loss: 23.5427\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0052 - val_loss: 23.5284\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0131 - val_loss: 23.5143\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9613 - val_loss: 23.5013\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9476 - val_loss: 23.4884\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9681 - val_loss: 23.4745\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9628 - val_loss: 23.4601\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9063 - val_loss: 23.4452\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7088 - val_loss: 23.4318\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9106 - val_loss: 23.4179\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8340 - val_loss: 23.4039\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8502 - val_loss: 23.3899\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8798 - val_loss: 23.3746\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8641 - val_loss: 23.3597\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8526 - val_loss: 23.3463\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8368 - val_loss: 23.3308\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8126 - val_loss: 23.3167\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7960 - val_loss: 23.3030\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7778 - val_loss: 23.2883\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6951 - val_loss: 23.2742\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7634 - val_loss: 23.2569\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7444 - val_loss: 23.2417\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7296 - val_loss: 23.2268\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7284 - val_loss: 23.2112\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6532 - val_loss: 23.1966\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_364 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_365 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_366 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_367 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_368 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_369 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_370 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.5270 - val_loss: 24.3884\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5902 - val_loss: 23.3124\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3397 - val_loss: 22.4853\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3446 - val_loss: 21.7678\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6465 - val_loss: 21.1127\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0161 - val_loss: 20.6110\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4106 - val_loss: 20.2768\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0115 - val_loss: 20.0333\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7114 - val_loss: 19.8725\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4430 - val_loss: 19.7358\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2410 - val_loss: 19.6135\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0927 - val_loss: 19.5003\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0170 - val_loss: 19.4153\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8952 - val_loss: 19.3443\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8552 - val_loss: 19.2822\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8030 - val_loss: 19.2325\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7699 - val_loss: 19.1994\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7002 - val_loss: 19.1711\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7035 - val_loss: 19.1447\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6014 - val_loss: 19.1206\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6363 - val_loss: 19.0975\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6362 - val_loss: 19.0757\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5497 - val_loss: 19.0554\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5515 - val_loss: 19.0373\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5860 - val_loss: 19.0193\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5740 - val_loss: 19.0013\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5515 - val_loss: 18.9834\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5359 - val_loss: 18.9660\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5211 - val_loss: 18.9495\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5121 - val_loss: 18.9331\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5004 - val_loss: 18.9174\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4762 - val_loss: 18.9022\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4765 - val_loss: 18.8865\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4654 - val_loss: 18.8715\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4574 - val_loss: 18.8568\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4231 - val_loss: 18.8424\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4337 - val_loss: 18.8281\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3970 - val_loss: 18.8143\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4060 - val_loss: 18.7996\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3848 - val_loss: 18.7861\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3669 - val_loss: 18.7722\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3593 - val_loss: 18.7587\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2542 - val_loss: 18.7452\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3438 - val_loss: 18.7315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3318 - val_loss: 18.7177\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2949 - val_loss: 18.7039\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2983 - val_loss: 18.6907\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2923 - val_loss: 18.6776\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2760 - val_loss: 18.6648\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2781 - val_loss: 18.6510\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2625 - val_loss: 18.6369\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1119 - val_loss: 18.6235\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2382 - val_loss: 18.6097\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2210 - val_loss: 18.5961\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2062 - val_loss: 18.5822\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1766 - val_loss: 18.5686\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1875 - val_loss: 18.5542\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0736 - val_loss: 18.5404\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9948 - val_loss: 18.5264\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1462 - val_loss: 18.5122\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1355 - val_loss: 18.4978\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1223 - val_loss: 18.4838\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0915 - val_loss: 18.4702\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0880 - val_loss: 18.4558\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0766 - val_loss: 18.4416\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0519 - val_loss: 18.4285\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0450 - val_loss: 18.4138\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9402 - val_loss: 18.3992\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0185 - val_loss: 18.3847\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9652 - val_loss: 18.3707\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0007 - val_loss: 18.3557\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9812 - val_loss: 18.3412\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9697 - val_loss: 18.3263\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9533 - val_loss: 18.3123\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9332 - val_loss: 18.2976\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9255 - val_loss: 18.2831\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9148 - val_loss: 18.2681\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8967 - val_loss: 18.2536\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8787 - val_loss: 18.2390\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8657 - val_loss: 18.2243\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8440 - val_loss: 18.2104\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8426 - val_loss: 18.1959\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8020 - val_loss: 18.1814\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8166 - val_loss: 18.1659\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7705 - val_loss: 18.1510\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7885 - val_loss: 18.1362\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7715 - val_loss: 18.1210\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7509 - val_loss: 18.1061\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6885 - val_loss: 18.0910\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7050 - val_loss: 18.0767\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6814 - val_loss: 18.0616\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6998 - val_loss: 18.0462\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6419 - val_loss: 18.0310\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6473 - val_loss: 18.0160\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6087 - val_loss: 18.0012\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6360 - val_loss: 17.9856\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5946 - val_loss: 17.9705\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6057 - val_loss: 17.9547\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5782 - val_loss: 17.9392\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5760 - val_loss: 17.9234\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_371 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_372 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_373 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_374 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_375 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_376 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_377 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.05782\n",
      "Model:                       QuantReg   Bandwidth:                    0.004660\n",
      "Method:                 Least Squares   Sparsity:                       0.1696\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:59:43   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.006      1.650      0.099      -0.002       0.021\n",
      "three_month_yield_change      0.1882      0.164      1.148      0.251      -0.133       0.510\n",
      "term_spread_change           -0.1291      0.142     -0.909      0.363      -0.408       0.149\n",
      "TED_spread                   -0.5914      0.661     -0.895      0.371      -1.888       0.705\n",
      "credit_spread_change          0.1624      0.212      0.765      0.444      -0.254       0.579\n",
      "market_return                -0.0297      0.091     -0.326      0.745      -0.208       0.149\n",
      "real_estate_excess_return    -0.0148      0.091     -0.162      0.871      -0.193       0.164\n",
      "equity_volatility             1.7730      0.182      9.750      0.000       1.416       2.130\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1490\n",
      "Model:                       QuantReg   Bandwidth:                    0.007677\n",
      "Method:                 Least Squares   Sparsity:                        1.067\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:59:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0199      0.018      1.108      0.268      -0.015       0.055\n",
      "three_month_yield_change     -0.1563      0.492     -0.318      0.751      -1.121       0.809\n",
      "term_spread_change           -0.7914      0.400     -1.980      0.048      -1.575      -0.007\n",
      "TED_spread                   -1.0598      2.079     -0.510      0.610      -5.136       3.017\n",
      "credit_spread_change          0.9397      0.679      1.384      0.166      -0.392       2.271\n",
      "market_return                 0.0743      0.380      0.196      0.845      -0.671       0.819\n",
      "real_estate_excess_return    -0.1314      0.306     -0.429      0.668      -0.732       0.469\n",
      "equity_volatility             2.4383      0.635      3.837      0.000       1.192       3.684\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.2478\n",
      "Model:                       QuantReg   Bandwidth:                    0.002497\n",
      "Method:                 Least Squares   Sparsity:                       0.1035\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:59:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.004      1.814      0.070      -0.001       0.013\n",
      "three_month_yield_change      0.1027      0.095      1.078      0.281      -0.084       0.290\n",
      "term_spread_change            0.0166      0.089      0.188      0.851      -0.157       0.190\n",
      "TED_spread                   -0.9283      0.364     -2.550      0.011      -1.642      -0.214\n",
      "credit_spread_change          0.0257      0.131      0.196      0.845      -0.232       0.283\n",
      "market_return                 0.0004      0.056      0.008      0.994      -0.110       0.111\n",
      "real_estate_excess_return     0.0164      0.061      0.269      0.788      -0.103       0.136\n",
      "equity_volatility             0.9518      0.104      9.134      0.000       0.747       1.156\n",
      "institution                   0.3064      0.048      6.335      0.000       0.212       0.401\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3609\n",
      "Model:                       QuantReg   Bandwidth:                    0.004096\n",
      "Method:                 Least Squares   Sparsity:                       0.5971\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        09:59:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0108      0.009      1.247      0.213      -0.006       0.028\n",
      "three_month_yield_change      0.1849      0.237      0.779      0.436      -0.280       0.650\n",
      "term_spread_change           -0.0298      0.287     -0.104      0.917      -0.592       0.533\n",
      "TED_spread                   -0.6630      0.996     -0.666      0.506      -2.617       1.291\n",
      "credit_spread_change          0.1017      0.371      0.275      0.784      -0.625       0.828\n",
      "market_return                -0.0752      0.226     -0.332      0.740      -0.518       0.368\n",
      "real_estate_excess_return    -0.2751      0.232     -1.185      0.236      -0.730       0.180\n",
      "equity_volatility             1.6975      0.397      4.275      0.000       0.919       2.476\n",
      "institution                   0.3338      0.211      1.585      0.113      -0.079       0.747\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 47.3558 - val_loss: 43.7356\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 46.4994 - val_loss: 42.8733\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 45.3329 - val_loss: 41.9202\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 43.8707 - val_loss: 40.9264\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 42.7944 - val_loss: 39.9022\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 41.4567 - val_loss: 38.8879\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.2750 - val_loss: 37.8779\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 38.8478 - val_loss: 36.8493\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 37.5509 - val_loss: 35.8597\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.0212 - val_loss: 34.8927\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.8682 - val_loss: 33.9292\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.5617 - val_loss: 33.0194\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.7127 - val_loss: 32.1839\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.2955 - val_loss: 31.4008\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.9107 - val_loss: 30.7216\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.1403 - val_loss: 30.0865\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.4963 - val_loss: 29.5307\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.9947 - val_loss: 29.1027\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.6008 - val_loss: 28.6987\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.2127 - val_loss: 28.3191\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9324 - val_loss: 27.9850\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.4962 - val_loss: 27.6885\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.4406 - val_loss: 27.4084\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.3048 - val_loss: 27.1619\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.1091 - val_loss: 26.9595\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.9600 - val_loss: 26.7870\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.8322 - val_loss: 26.6464\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.8589 - val_loss: 26.5375\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.7568 - val_loss: 26.4353\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.7787 - val_loss: 26.3421\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.7485 - val_loss: 26.2554\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.6915 - val_loss: 26.1748\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.7169 - val_loss: 26.0938\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.6671 - val_loss: 26.0274\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.6436 - val_loss: 25.9678\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.6207 - val_loss: 25.9102\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.5974 - val_loss: 25.8626\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4368 - val_loss: 25.8232\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.5537 - val_loss: 25.7894\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.5014 - val_loss: 25.7576\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4892 - val_loss: 25.7291\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4397 - val_loss: 25.7039\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4680 - val_loss: 25.6822\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.4283 - val_loss: 25.6646\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3540 - val_loss: 25.6477\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3754 - val_loss: 25.6310\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.4001 - val_loss: 25.6156\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3417 - val_loss: 25.6008\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3523 - val_loss: 25.5869\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3494 - val_loss: 25.5737\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3274 - val_loss: 25.5611\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3325 - val_loss: 25.5487\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3023 - val_loss: 25.5366\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3017 - val_loss: 25.5244\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2430 - val_loss: 25.5123\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2708 - val_loss: 25.5001\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.9054 - val_loss: 25.4879\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1674 - val_loss: 25.4756\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.2116 - val_loss: 25.4632\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1863 - val_loss: 25.4508\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.9740 - val_loss: 25.4383\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2089 - val_loss: 25.4257\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.1101 - val_loss: 25.4131\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1788 - val_loss: 25.4004\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1447 - val_loss: 25.3876\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.1321 - val_loss: 25.3748\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1423 - val_loss: 25.3619\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1209 - val_loss: 25.3490\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9601 - val_loss: 25.3360\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0004 - val_loss: 25.3229\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9553 - val_loss: 25.3099\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8892 - val_loss: 25.2967\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8772 - val_loss: 25.2835\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0558 - val_loss: 25.2702\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.0235 - val_loss: 25.2569\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6216 - val_loss: 25.2436\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.9839 - val_loss: 25.2301\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9971 - val_loss: 25.2166\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9817 - val_loss: 25.2031\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9698 - val_loss: 25.1895\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8544 - val_loss: 25.1759\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7349 - val_loss: 25.1622\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7743 - val_loss: 25.1484\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.8650 - val_loss: 25.1346\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9025 - val_loss: 25.1207\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8296 - val_loss: 25.1068\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8609 - val_loss: 25.0929\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8043 - val_loss: 25.0789\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8035 - val_loss: 25.0648\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.5940 - val_loss: 25.0507\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.8023 - val_loss: 25.0366\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.7923 - val_loss: 25.0224\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.7735 - val_loss: 25.0081\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7623 - val_loss: 24.9938\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6547 - val_loss: 24.9795\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6208 - val_loss: 24.9651\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7234 - val_loss: 24.9506\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4823 - val_loss: 24.9362\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6371 - val_loss: 24.9217\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6389 - val_loss: 24.9072\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_378 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_379 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_380 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_381 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_382 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_383 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_384 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 26.0659 - val_loss: 24.8263\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.3502 - val_loss: 24.1583\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4499 - val_loss: 23.4096\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6812 - val_loss: 22.7771\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9696 - val_loss: 22.2334\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3212 - val_loss: 21.7822\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7694 - val_loss: 21.3555\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3215 - val_loss: 20.9872\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9366 - val_loss: 20.6682\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5321 - val_loss: 20.4151\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2720 - val_loss: 20.2211\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8734 - val_loss: 20.0660\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8219 - val_loss: 19.9235\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6363 - val_loss: 19.8197\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4283 - val_loss: 19.7277\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3184 - val_loss: 19.6412\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1671 - val_loss: 19.5604\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0941 - val_loss: 19.4808\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9299 - val_loss: 19.4053\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9432 - val_loss: 19.3402\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8595 - val_loss: 19.2826\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8121 - val_loss: 19.2310\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7694 - val_loss: 19.1828\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7051 - val_loss: 19.1381\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6405 - val_loss: 19.1009\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5587 - val_loss: 19.0744\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5867 - val_loss: 19.0502\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5732 - val_loss: 19.0263\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5514 - val_loss: 19.0037\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4071 - val_loss: 18.9817\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4708 - val_loss: 18.9602\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3941 - val_loss: 18.9407\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4856 - val_loss: 18.9204\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4432 - val_loss: 18.9001\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3689 - val_loss: 18.8812\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4262 - val_loss: 18.8627\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4093 - val_loss: 18.8445\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3867 - val_loss: 18.8271\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2052 - val_loss: 18.8100\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3657 - val_loss: 18.7923\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3476 - val_loss: 18.7749\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2883 - val_loss: 18.7589\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3160 - val_loss: 18.7427\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3125 - val_loss: 18.7263\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2947 - val_loss: 18.7105\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2603 - val_loss: 18.6950\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2664 - val_loss: 18.6789\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2567 - val_loss: 18.6624\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2481 - val_loss: 18.6462\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2158 - val_loss: 18.6309\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2211 - val_loss: 18.6155\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1952 - val_loss: 18.6003\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1753 - val_loss: 18.5855\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1738 - val_loss: 18.5703\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1715 - val_loss: 18.5553\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1525 - val_loss: 18.5413\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0981 - val_loss: 18.5272\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1040 - val_loss: 18.5138\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1206 - val_loss: 18.4995\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1044 - val_loss: 18.4846\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0702 - val_loss: 18.4704\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0345 - val_loss: 18.4563\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0641 - val_loss: 18.4418\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0275 - val_loss: 18.4277\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9959 - val_loss: 18.4128\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0259 - val_loss: 18.3980\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0053 - val_loss: 18.3837\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9987 - val_loss: 18.3688\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9767 - val_loss: 18.3544\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9340 - val_loss: 18.3401\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9348 - val_loss: 18.3254\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9374 - val_loss: 18.3109\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9256 - val_loss: 18.2963\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9187 - val_loss: 18.2811\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8737 - val_loss: 18.2662\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8484 - val_loss: 18.2513\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8604 - val_loss: 18.2361\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8567 - val_loss: 18.2207\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8375 - val_loss: 18.2061\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7788 - val_loss: 18.1918\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8119 - val_loss: 18.1765\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7890 - val_loss: 18.1626\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7867 - val_loss: 18.1473\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7262 - val_loss: 18.1323\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7460 - val_loss: 18.1176\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7462 - val_loss: 18.1024\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7299 - val_loss: 18.0867\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7061 - val_loss: 18.0713\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6609 - val_loss: 18.0567\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6576 - val_loss: 18.0423\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6213 - val_loss: 18.0274\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6528 - val_loss: 18.0115\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6358 - val_loss: 17.9961\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6283 - val_loss: 17.9802\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6171 - val_loss: 17.9650\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5727 - val_loss: 17.9496\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5535 - val_loss: 17.9344\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5509 - val_loss: 17.9193\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5488 - val_loss: 17.9034\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5298 - val_loss: 17.8875\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_385 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_386 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_387 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_388 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_389 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_390 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_391 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1400\n",
      "Model:                       QuantReg   Bandwidth:                    0.006988\n",
      "Method:                 Least Squares   Sparsity:                       0.2729\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:00:40   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0343      0.010      3.534      0.000       0.015       0.053\n",
      "three_month_yield_change     -0.3876      0.254     -1.528      0.127      -0.885       0.110\n",
      "term_spread_change           -0.7536      0.247     -3.056      0.002      -1.237      -0.270\n",
      "TED_spread                   -1.4252      0.940     -1.516      0.130      -3.269       0.418\n",
      "credit_spread_change         -0.1777      0.347     -0.513      0.608      -0.857       0.502\n",
      "market_return                 0.0131      0.155      0.085      0.933      -0.291       0.318\n",
      "real_estate_excess_return     0.2637      0.180      1.464      0.143      -0.090       0.617\n",
      "equity_volatility             2.9296      0.256     11.426      0.000       2.427       3.432\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2847\n",
      "Model:                       QuantReg   Bandwidth:                     0.01207\n",
      "Method:                 Least Squares   Sparsity:                        1.214\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:00:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.1113      0.016      7.068      0.000       0.080       0.142\n",
      "three_month_yield_change     -2.2245      0.531     -4.190      0.000      -3.266      -1.183\n",
      "term_spread_change           -2.3767      0.549     -4.329      0.000      -3.453      -1.300\n",
      "TED_spread                    1.0455      2.026      0.516      0.606      -2.928       5.019\n",
      "credit_spread_change         -1.9576      0.582     -3.366      0.001      -3.098      -0.817\n",
      "market_return                -0.1619      0.460     -0.352      0.725      -1.063       0.740\n",
      "real_estate_excess_return    -0.0095      0.370     -0.026      0.980      -0.736       0.717\n",
      "equity_volatility             6.4285      0.740      8.683      0.000       4.977       7.880\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4407\n",
      "Model:                       QuantReg   Bandwidth:                    0.001900\n",
      "Method:                 Least Squares   Sparsity:                      0.08209\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:00:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0131      0.003      4.547      0.000       0.007       0.019\n",
      "three_month_yield_change     -0.1471      0.086     -1.712      0.087      -0.316       0.021\n",
      "term_spread_change           -0.1750      0.076     -2.290      0.022      -0.325      -0.025\n",
      "TED_spread                   -0.3075      0.287     -1.073      0.283      -0.869       0.254\n",
      "credit_spread_change         -0.1622      0.099     -1.631      0.103      -0.357       0.033\n",
      "market_return                -0.0628      0.038     -1.648      0.100      -0.138       0.012\n",
      "real_estate_excess_return    -0.0373      0.053     -0.706      0.480      -0.141       0.066\n",
      "equity_volatility             0.7145      0.072      9.941      0.000       0.574       0.855\n",
      "institution                   0.3063      0.025     12.348      0.000       0.258       0.355\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5280\n",
      "Model:                       QuantReg   Bandwidth:                    0.002917\n",
      "Method:                 Least Squares   Sparsity:                       0.2923\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:00:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0206      0.004      4.843      0.000       0.012       0.029\n",
      "three_month_yield_change     -0.3820      0.156     -2.445      0.015      -0.688      -0.076\n",
      "term_spread_change           -0.4054      0.155     -2.623      0.009      -0.709      -0.102\n",
      "TED_spread                    0.0292      0.595      0.049      0.961      -1.137       1.195\n",
      "credit_spread_change         -0.0941      0.146     -0.645      0.519      -0.380       0.192\n",
      "market_return                -0.1843      0.100     -1.851      0.064      -0.380       0.011\n",
      "real_estate_excess_return    -0.0393      0.099     -0.398      0.691      -0.233       0.154\n",
      "equity_volatility             0.8847      0.167      5.286      0.000       0.557       1.213\n",
      "institution                   0.3232      0.064      5.047      0.000       0.198       0.449\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 26ms/step - loss: 32.0803 - val_loss: 29.8381\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.0042 - val_loss: 28.8032\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.7936 - val_loss: 27.9416\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.8303 - val_loss: 27.1766\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.7558 - val_loss: 26.4929\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.9681 - val_loss: 25.8452\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3469 - val_loss: 25.2495\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.5731 - val_loss: 24.6777\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7622 - val_loss: 24.1225\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1374 - val_loss: 23.5856\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7043 - val_loss: 23.0788\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2608 - val_loss: 22.5927\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8401 - val_loss: 22.1686\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5190 - val_loss: 21.7768\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2239 - val_loss: 21.4556\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8399 - val_loss: 21.1809\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7786 - val_loss: 20.9584\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6308 - val_loss: 20.7754\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4879 - val_loss: 20.6105\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4010 - val_loss: 20.4776\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2321 - val_loss: 20.3592\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2127 - val_loss: 20.2525\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1175 - val_loss: 20.1622\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0908 - val_loss: 20.0963\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0063 - val_loss: 20.0384\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9889 - val_loss: 19.9826\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9463 - val_loss: 19.9300\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8678 - val_loss: 19.8780\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8367 - val_loss: 19.8308\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8096 - val_loss: 19.7879\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7957 - val_loss: 19.7503\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7365 - val_loss: 19.7161\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7532 - val_loss: 19.6829\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6765 - val_loss: 19.6510\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7022 - val_loss: 19.6192\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6511 - val_loss: 19.5899\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6559 - val_loss: 19.5612\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6308 - val_loss: 19.5338\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5727 - val_loss: 19.5076\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5335 - val_loss: 19.4833\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5589 - val_loss: 19.4590\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5741 - val_loss: 19.4360\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5533 - val_loss: 19.4133\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4906 - val_loss: 19.3919\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5309 - val_loss: 19.3714\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4846 - val_loss: 19.3519\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4683 - val_loss: 19.3331\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4475 - val_loss: 19.3151\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4829 - val_loss: 19.2973\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4531 - val_loss: 19.2811\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4361 - val_loss: 19.2647\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4250 - val_loss: 19.2486\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2097 - val_loss: 19.2328\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3958 - val_loss: 19.2171\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3613 - val_loss: 19.2019\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3382 - val_loss: 19.1866\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3427 - val_loss: 19.1718\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3555 - val_loss: 19.1569\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1012 - val_loss: 19.1427\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3023 - val_loss: 19.1285\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2941 - val_loss: 19.1145\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2823 - val_loss: 19.1003\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2716 - val_loss: 19.0860\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2316 - val_loss: 19.0720\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1304 - val_loss: 19.0580\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2297 - val_loss: 19.0440\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2329 - val_loss: 19.0300\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9032 - val_loss: 19.0161\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1697 - val_loss: 19.0021\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1680 - val_loss: 18.9880\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1774 - val_loss: 18.9738\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1587 - val_loss: 18.9595\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1172 - val_loss: 18.9453\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1295 - val_loss: 18.9310\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0737 - val_loss: 18.9166\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0947 - val_loss: 18.9022\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0309 - val_loss: 18.8878\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0540 - val_loss: 18.8733\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9579 - val_loss: 18.8587\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0376 - val_loss: 18.8441\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0256 - val_loss: 18.8295\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9400 - val_loss: 18.8148\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0008 - val_loss: 18.8000\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9711 - val_loss: 18.7852\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9723 - val_loss: 18.7703\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9269 - val_loss: 18.7554\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9363 - val_loss: 18.7404\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9210 - val_loss: 18.7255\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8825 - val_loss: 18.7104\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8621 - val_loss: 18.6952\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8805 - val_loss: 18.6800\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8186 - val_loss: 18.6647\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8456 - val_loss: 18.6494\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8114 - val_loss: 18.6341\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7622 - val_loss: 18.6186\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7799 - val_loss: 18.6032\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7572 - val_loss: 18.5878\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7801 - val_loss: 18.5723\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7561 - val_loss: 18.5567\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7251 - val_loss: 18.5411\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_392 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_393 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_394 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_395 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_396 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_397 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_398 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 26.4617 - val_loss: 25.0666\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.5368 - val_loss: 24.3984\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8443 - val_loss: 23.8410\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2104 - val_loss: 23.2553\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5174 - val_loss: 22.6454\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7570 - val_loss: 22.0710\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0903 - val_loss: 21.5399\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4734 - val_loss: 21.0403\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9621 - val_loss: 20.6173\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.4910 - val_loss: 20.3058\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0716 - val_loss: 20.0752\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7692 - val_loss: 19.8884\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5573 - val_loss: 19.7592\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3537 - val_loss: 19.6438\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1987 - val_loss: 19.5391\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0800 - val_loss: 19.4416\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9740 - val_loss: 19.3569\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8458 - val_loss: 19.2876\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7909 - val_loss: 19.2259\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7363 - val_loss: 19.1697\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7000 - val_loss: 19.1246\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6657 - val_loss: 19.0929\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6031 - val_loss: 19.0654\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5278 - val_loss: 19.0401\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5342 - val_loss: 19.0154\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5016 - val_loss: 18.9937\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4882 - val_loss: 18.9728\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4819 - val_loss: 18.9520\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4930 - val_loss: 18.9323\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4099 - val_loss: 18.9142\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4605 - val_loss: 18.8965\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4440 - val_loss: 18.8789\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4332 - val_loss: 18.8626\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4214 - val_loss: 18.8458\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4058 - val_loss: 18.8300\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3923 - val_loss: 18.8142\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2857 - val_loss: 18.7983\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3563 - val_loss: 18.7837\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3603 - val_loss: 18.7687\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3407 - val_loss: 18.7541\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3407 - val_loss: 18.7388\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3093 - val_loss: 18.7244\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2945 - val_loss: 18.7099\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3005 - val_loss: 18.6954\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2715 - val_loss: 18.6813\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2722 - val_loss: 18.6668\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2261 - val_loss: 18.6530\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2271 - val_loss: 18.6391\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2357 - val_loss: 18.6247\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2212 - val_loss: 18.6105\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1953 - val_loss: 18.5968\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1768 - val_loss: 18.5835\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1842 - val_loss: 18.5700\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1395 - val_loss: 18.5567\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1646 - val_loss: 18.5428\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0816 - val_loss: 18.5295\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1063 - val_loss: 18.5156\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1309 - val_loss: 18.5016\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1027 - val_loss: 18.4882\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0980 - val_loss: 18.4745\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0459 - val_loss: 18.4609\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0626 - val_loss: 18.4470\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0595 - val_loss: 18.4327\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0518 - val_loss: 18.4185\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0188 - val_loss: 18.4055\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0149 - val_loss: 18.3915\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9967 - val_loss: 18.3773\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9716 - val_loss: 18.3635\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9808 - val_loss: 18.3493\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9741 - val_loss: 18.3348\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9180 - val_loss: 18.3205\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9264 - val_loss: 18.3060\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8883 - val_loss: 18.2913\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9147 - val_loss: 18.2767\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7996 - val_loss: 18.2629\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8420 - val_loss: 18.2495\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8474 - val_loss: 18.2351\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8622 - val_loss: 18.2205\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8135 - val_loss: 18.2067\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8398 - val_loss: 18.1919\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8091 - val_loss: 18.1773\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7418 - val_loss: 18.1633\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7972 - val_loss: 18.1483\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7203 - val_loss: 18.1341\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7366 - val_loss: 18.1202\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7408 - val_loss: 18.1055\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7282 - val_loss: 18.0908\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6842 - val_loss: 18.0767\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7010 - val_loss: 18.0619\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6903 - val_loss: 18.0478\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6738 - val_loss: 18.0325\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6069 - val_loss: 18.0182\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6417 - val_loss: 18.0033\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6237 - val_loss: 17.9884\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5912 - val_loss: 17.9741\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5543 - val_loss: 17.9595\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5637 - val_loss: 17.9445\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5814 - val_loss: 17.9293\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4917 - val_loss: 17.9145\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5286 - val_loss: 17.8989\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_399 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_400 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_401 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_402 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_403 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_404 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_405 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1536\n",
      "Model:                       QuantReg   Bandwidth:                    0.004041\n",
      "Method:                 Least Squares   Sparsity:                       0.1331\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:01:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0233      0.005      5.090      0.000       0.014       0.032\n",
      "three_month_yield_change     -0.4419      0.129     -3.432      0.001      -0.694      -0.189\n",
      "term_spread_change           -0.4177      0.122     -3.423      0.001      -0.657      -0.178\n",
      "TED_spread                   -0.1014      0.500     -0.203      0.839      -1.081       0.878\n",
      "credit_spread_change         -0.3980      0.160     -2.490      0.013      -0.711      -0.085\n",
      "market_return                -0.0658      0.072     -0.913      0.361      -0.207       0.075\n",
      "real_estate_excess_return     0.0303      0.081      0.373      0.709      -0.129       0.190\n",
      "equity_volatility             1.9872      0.134     14.815      0.000       1.724       2.250\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3591\n",
      "Model:                       QuantReg   Bandwidth:                    0.007033\n",
      "Method:                 Least Squares   Sparsity:                       0.6183\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:01:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0417      0.009      4.783      0.000       0.025       0.059\n",
      "three_month_yield_change     -0.6573      0.266     -2.475      0.013      -1.178      -0.136\n",
      "term_spread_change           -0.7721      0.305     -2.531      0.011      -1.370      -0.174\n",
      "TED_spread                   -0.4220      0.907     -0.465      0.642      -2.201       1.357\n",
      "credit_spread_change         -0.8009      0.349     -2.295      0.022      -1.485      -0.117\n",
      "market_return                -0.7998      0.182     -4.405      0.000      -1.156      -0.444\n",
      "real_estate_excess_return    -0.1368      0.230     -0.595      0.552      -0.588       0.314\n",
      "equity_volatility             4.1362      0.304     13.599      0.000       3.540       4.733\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4426\n",
      "Model:                       QuantReg   Bandwidth:                    0.001905\n",
      "Method:                 Least Squares   Sparsity:                      0.06687\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:01:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0124      0.002      5.049      0.000       0.008       0.017\n",
      "three_month_yield_change     -0.0422      0.071     -0.594      0.552      -0.181       0.097\n",
      "term_spread_change           -0.1555      0.060     -2.586      0.010      -0.273      -0.038\n",
      "TED_spread                   -1.1281      0.257     -4.396      0.000      -1.631      -0.625\n",
      "credit_spread_change         -0.0830      0.085     -0.977      0.329      -0.249       0.084\n",
      "market_return                -0.0176      0.030     -0.581      0.561      -0.077       0.042\n",
      "real_estate_excess_return    -0.0285      0.041     -0.698      0.485      -0.108       0.052\n",
      "equity_volatility             0.6781      0.069      9.817      0.000       0.543       0.814\n",
      "institution                   0.5674      0.029     19.270      0.000       0.510       0.625\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5047\n",
      "Model:                       QuantReg   Bandwidth:                    0.003483\n",
      "Method:                 Least Squares   Sparsity:                       0.2103\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:01:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0239      0.004      6.574      0.000       0.017       0.031\n",
      "three_month_yield_change     -0.0897      0.107     -0.835      0.404      -0.300       0.121\n",
      "term_spread_change           -0.4941      0.100     -4.931      0.000      -0.691      -0.298\n",
      "TED_spread                   -2.3592      0.410     -5.749      0.000      -3.164      -1.555\n",
      "credit_spread_change         -0.0180      0.135     -0.134      0.894      -0.282       0.246\n",
      "market_return                 0.2036      0.080      2.550      0.011       0.047       0.360\n",
      "real_estate_excess_return     0.1001      0.086      1.170      0.242      -0.068       0.268\n",
      "equity_volatility             1.0380      0.157      6.622      0.000       0.731       1.345\n",
      "institution                   0.5514      0.074      7.476      0.000       0.407       0.696\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 27.7648 - val_loss: 30.5575\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.8965 - val_loss: 29.8342\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3493 - val_loss: 29.1667\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6042 - val_loss: 28.4764\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0130 - val_loss: 27.7526\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3131 - val_loss: 27.0265\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5887 - val_loss: 26.3222\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0057 - val_loss: 25.6968\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4550 - val_loss: 25.0966\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8837 - val_loss: 24.5304\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4179 - val_loss: 24.0084\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9767 - val_loss: 23.5676\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4502 - val_loss: 23.2154\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2993 - val_loss: 22.9415\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9774 - val_loss: 22.6936\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7634 - val_loss: 22.5113\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5267 - val_loss: 22.3595\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3572 - val_loss: 22.2245\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2578 - val_loss: 22.1225\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1605 - val_loss: 22.0435\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1006 - val_loss: 21.9744\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9756 - val_loss: 21.9236\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9373 - val_loss: 21.8827\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8962 - val_loss: 21.8439\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8155 - val_loss: 21.8088\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8361 - val_loss: 21.7772\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7820 - val_loss: 21.7510\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7534 - val_loss: 21.7261\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7056 - val_loss: 21.7046\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6192 - val_loss: 21.6865\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6952 - val_loss: 21.6688\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5753 - val_loss: 21.6525\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6267 - val_loss: 21.6364\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6163 - val_loss: 21.6207\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6281 - val_loss: 21.6070\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6125 - val_loss: 21.5943\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5974 - val_loss: 21.5822\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5911 - val_loss: 21.5706\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5613 - val_loss: 21.5589\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4554 - val_loss: 21.5473\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5408 - val_loss: 21.5354\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4182 - val_loss: 21.5236\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4137 - val_loss: 21.5118\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4985 - val_loss: 21.4999\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4887 - val_loss: 21.4880\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4700 - val_loss: 21.4765\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3516 - val_loss: 21.4649\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4424 - val_loss: 21.4534\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4447 - val_loss: 21.4420\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3843 - val_loss: 21.4306\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4178 - val_loss: 21.4191\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4075 - val_loss: 21.4077\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2554 - val_loss: 21.3962\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3808 - val_loss: 21.3847\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3260 - val_loss: 21.3729\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3253 - val_loss: 21.3609\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3068 - val_loss: 21.3490\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3240 - val_loss: 21.3370\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3062 - val_loss: 21.3249\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2945 - val_loss: 21.3126\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2879 - val_loss: 21.3004\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2146 - val_loss: 21.2878\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2577 - val_loss: 21.2753\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2439 - val_loss: 21.2628\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1970 - val_loss: 21.2500\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1993 - val_loss: 21.2371\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2131 - val_loss: 21.2245\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1993 - val_loss: 21.2117\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1806 - val_loss: 21.1987\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1495 - val_loss: 21.1856\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1583 - val_loss: 21.1725\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1435 - val_loss: 21.1594\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1295 - val_loss: 21.1462\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1187 - val_loss: 21.1329\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0937 - val_loss: 21.1193\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0586 - val_loss: 21.1057\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0706 - val_loss: 21.0921\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0316 - val_loss: 21.0784\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0002 - val_loss: 21.0644\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0296 - val_loss: 21.0506\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9864 - val_loss: 21.0367\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9935 - val_loss: 21.0228\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9553 - val_loss: 21.0088\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9737 - val_loss: 20.9948\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9653 - val_loss: 20.9809\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9455 - val_loss: 20.9665\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9293 - val_loss: 20.9523\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8664 - val_loss: 20.9379\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8898 - val_loss: 20.9234\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8518 - val_loss: 20.9089\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8316 - val_loss: 20.8942\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8564 - val_loss: 20.8799\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8182 - val_loss: 20.8652\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7921 - val_loss: 20.8503\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7754 - val_loss: 20.8354\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7625 - val_loss: 20.8204\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7748 - val_loss: 20.8057\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7468 - val_loss: 20.7907\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7438 - val_loss: 20.7758\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7102 - val_loss: 20.7608\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_406 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_407 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_408 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_409 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_410 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_411 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_412 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.5445 - val_loss: 24.5279\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0874 - val_loss: 24.0224\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5004 - val_loss: 23.5150\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.8523 - val_loss: 23.0212\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3032 - val_loss: 22.5696\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7966 - val_loss: 22.1535\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.1648 - val_loss: 21.7640\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.7726 - val_loss: 21.3763\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4194 - val_loss: 21.0256\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9744 - val_loss: 20.7152\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6013 - val_loss: 20.4501\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3390 - val_loss: 20.2457\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0032 - val_loss: 20.0783\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8007 - val_loss: 19.9304\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5355 - val_loss: 19.8260\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4069 - val_loss: 19.7281\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2903 - val_loss: 19.6376\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1250 - val_loss: 19.5519\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0250 - val_loss: 19.4660\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9967 - val_loss: 19.3878\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8659 - val_loss: 19.3267\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8096 - val_loss: 19.2695\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8013 - val_loss: 19.2162\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7232 - val_loss: 19.1668\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6904 - val_loss: 19.1260\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6480 - val_loss: 19.0980\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6362 - val_loss: 19.0712\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6107 - val_loss: 19.0448\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5859 - val_loss: 19.0201\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5295 - val_loss: 18.9968\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5174 - val_loss: 18.9754\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4932 - val_loss: 18.9545\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4945 - val_loss: 18.9343\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4496 - val_loss: 18.9147\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4417 - val_loss: 18.8963\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4532 - val_loss: 18.8773\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4047 - val_loss: 18.8592\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3977 - val_loss: 18.8407\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3961 - val_loss: 18.8228\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3729 - val_loss: 18.8065\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3767 - val_loss: 18.7891\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3657 - val_loss: 18.7719\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3514 - val_loss: 18.7551\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3395 - val_loss: 18.7387\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3157 - val_loss: 18.7231\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2875 - val_loss: 18.7088\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2473 - val_loss: 18.6939\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2756 - val_loss: 18.6792\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1610 - val_loss: 18.6648\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2532 - val_loss: 18.6503\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2319 - val_loss: 18.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2363 - val_loss: 18.6220\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2102 - val_loss: 18.6081\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1902 - val_loss: 18.5947\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2047 - val_loss: 18.5798\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1450 - val_loss: 18.5665\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1626 - val_loss: 18.5525\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1556 - val_loss: 18.5384\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1354 - val_loss: 18.5242\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1412 - val_loss: 18.5098\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1077 - val_loss: 18.4950\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0615 - val_loss: 18.4805\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0746 - val_loss: 18.4661\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0870 - val_loss: 18.4514\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0725 - val_loss: 18.4363\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0586 - val_loss: 18.4213\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0454 - val_loss: 18.4067\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0205 - val_loss: 18.3926\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0033 - val_loss: 18.3786\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9547 - val_loss: 18.3648\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9849 - val_loss: 18.3508\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9729 - val_loss: 18.3367\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9294 - val_loss: 18.3229\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9516 - val_loss: 18.3086\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9185 - val_loss: 18.2943\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9241 - val_loss: 18.2798\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8677 - val_loss: 18.2656\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8951 - val_loss: 18.2510\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8935 - val_loss: 18.2369\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8024 - val_loss: 18.2227\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8584 - val_loss: 18.2083\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8445 - val_loss: 18.1936\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8081 - val_loss: 18.1798\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8144 - val_loss: 18.1654\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8006 - val_loss: 18.1510\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7132 - val_loss: 18.1368\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7765 - val_loss: 18.1224\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7560 - val_loss: 18.1080\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7455 - val_loss: 18.0932\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7298 - val_loss: 18.0785\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7015 - val_loss: 18.0645\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6895 - val_loss: 18.0502\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6607 - val_loss: 18.0360\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6761 - val_loss: 18.0211\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6281 - val_loss: 18.0065\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6478 - val_loss: 17.9920\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6269 - val_loss: 17.9772\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6103 - val_loss: 17.9628\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6014 - val_loss: 17.9478\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5465 - val_loss: 17.9335\n",
      "4/4 [==============================] - 0s 603us/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_413 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_414 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_415 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_416 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_417 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_418 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_419 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09198\n",
      "Model:                       QuantReg   Bandwidth:                    0.003351\n",
      "Method:                 Least Squares   Sparsity:                       0.1220\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:02:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0177      0.004      4.210      0.000       0.009       0.026\n",
      "three_month_yield_change     -0.0322      0.112     -0.288      0.773      -0.251       0.187\n",
      "term_spread_change            0.0041      0.105      0.039      0.969      -0.202       0.210\n",
      "TED_spread                   -0.9586      0.412     -2.327      0.020      -1.767      -0.151\n",
      "credit_spread_change         -0.3520      0.152     -2.319      0.020      -0.650      -0.054\n",
      "market_return                -0.0101      0.068     -0.148      0.883      -0.144       0.124\n",
      "real_estate_excess_return     0.1583      0.073      2.168      0.030       0.015       0.301\n",
      "equity_volatility             1.3707      0.126     10.873      0.000       1.123       1.618\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2239\n",
      "Model:                       QuantReg   Bandwidth:                    0.005442\n",
      "Method:                 Least Squares   Sparsity:                       0.5975\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:02:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0373      0.008      4.428      0.000       0.021       0.054\n",
      "three_month_yield_change     -0.0176      0.254     -0.069      0.945      -0.515       0.480\n",
      "term_spread_change           -0.4696      0.307     -1.528      0.127      -1.072       0.133\n",
      "TED_spread                   -1.2682      1.089     -1.165      0.244      -3.403       0.867\n",
      "credit_spread_change         -0.6035      0.270     -2.232      0.026      -1.134      -0.073\n",
      "market_return                 0.0513      0.236      0.217      0.828      -0.412       0.515\n",
      "real_estate_excess_return    -0.0706      0.166     -0.427      0.670      -0.395       0.254\n",
      "equity_volatility             2.3235      0.449      5.173      0.000       1.443       3.204\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4374\n",
      "Model:                       QuantReg   Bandwidth:                    0.001965\n",
      "Method:                 Least Squares   Sparsity:                      0.07305\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:02:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0080      0.003      2.998      0.003       0.003       0.013\n",
      "three_month_yield_change      0.0202      0.074      0.271      0.786      -0.126       0.166\n",
      "term_spread_change           -0.1333      0.062     -2.135      0.033      -0.256      -0.011\n",
      "TED_spread                   -0.6063      0.265     -2.288      0.022      -1.126      -0.087\n",
      "credit_spread_change         -0.0216      0.093     -0.231      0.817      -0.205       0.162\n",
      "market_return                -0.0683      0.037     -1.831      0.067      -0.141       0.005\n",
      "real_estate_excess_return    -0.0289      0.042     -0.685      0.494      -0.112       0.054\n",
      "equity_volatility             0.8285      0.071     11.658      0.000       0.689       0.968\n",
      "institution                   0.6505      0.044     14.821      0.000       0.564       0.737\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5391\n",
      "Model:                       QuantReg   Bandwidth:                    0.003295\n",
      "Method:                 Least Squares   Sparsity:                       0.3856\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:02:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0253      0.008      3.331      0.001       0.010       0.040\n",
      "three_month_yield_change     -0.1190      0.190     -0.627      0.531      -0.491       0.253\n",
      "term_spread_change           -0.3228      0.186     -1.739      0.082      -0.687       0.041\n",
      "TED_spread                   -0.4262      0.594     -0.717      0.473      -1.592       0.740\n",
      "credit_spread_change         -0.4097      0.267     -1.535      0.125      -0.933       0.114\n",
      "market_return                -0.1184      0.143     -0.829      0.407      -0.399       0.162\n",
      "real_estate_excess_return     0.0143      0.112      0.127      0.899      -0.206       0.235\n",
      "equity_volatility             1.3775      0.230      5.988      0.000       0.926       1.829\n",
      "institution                   0.6266      0.182      3.436      0.001       0.269       0.984\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 54.6973 - val_loss: 61.4556\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 53.5900 - val_loss: 60.1554\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 52.4593 - val_loss: 58.6749\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 50.9098 - val_loss: 56.9920\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 49.1907 - val_loss: 54.9389\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 47.1806 - val_loss: 52.6283\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 45.0002 - val_loss: 50.0485\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 42.5074 - val_loss: 47.3280\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.9210 - val_loss: 44.7290\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 37.2724 - val_loss: 42.0645\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.3943 - val_loss: 39.4857\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.6031 - val_loss: 37.2333\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.8313 - val_loss: 35.3785\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.3893 - val_loss: 34.0355\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.3198 - val_loss: 32.9234\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.5835 - val_loss: 32.1203\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.1276 - val_loss: 31.5169\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.8060 - val_loss: 31.0417\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.7118 - val_loss: 30.6435\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.4595 - val_loss: 30.3396\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.2802 - val_loss: 30.1139\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.4554 - val_loss: 29.9551\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.4193 - val_loss: 29.8456\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3744 - val_loss: 29.7651\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3551 - val_loss: 29.7077\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.3505 - val_loss: 29.6578\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 26.2838 - val_loss: 29.6181\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2523 - val_loss: 29.5837\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3014 - val_loss: 29.5529\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2374 - val_loss: 29.5223\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.0411 - val_loss: 29.5042\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1685 - val_loss: 29.4847\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2447 - val_loss: 29.4648\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1529 - val_loss: 29.4492\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2001 - val_loss: 29.4325\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2237 - val_loss: 29.4167\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1811 - val_loss: 29.4024\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1201 - val_loss: 29.3887\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.0394 - val_loss: 29.3760\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1485 - val_loss: 29.3625\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1389 - val_loss: 29.3502\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.1383 - val_loss: 29.3363\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0810 - val_loss: 29.3229\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.1215 - val_loss: 29.3101\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.0954 - val_loss: 29.2967\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0902 - val_loss: 29.2830\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0706 - val_loss: 29.2701\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0157 - val_loss: 29.2574\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0579 - val_loss: 29.2440\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0032 - val_loss: 29.2312\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8933 - val_loss: 29.2182\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8870 - val_loss: 29.2058\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0087 - val_loss: 29.1919\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8628 - val_loss: 29.1780\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8812 - val_loss: 29.1649\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9710 - val_loss: 29.1509\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8644 - val_loss: 29.1367\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9352 - val_loss: 29.1233\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.9118 - val_loss: 29.1093\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8488 - val_loss: 29.0955\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7550 - val_loss: 29.0824\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8959 - val_loss: 29.0687\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8419 - val_loss: 29.0549\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8375 - val_loss: 29.0422\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8026 - val_loss: 29.0285\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7997 - val_loss: 29.0152\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8304 - val_loss: 29.0019\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7901 - val_loss: 28.9886\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8109 - val_loss: 28.9745\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7826 - val_loss: 28.9606\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7365 - val_loss: 28.9473\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7778 - val_loss: 28.9337\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7593 - val_loss: 28.9194\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6232 - val_loss: 28.9055\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7134 - val_loss: 28.8917\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.7270 - val_loss: 28.8782\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6493 - val_loss: 28.8643\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6671 - val_loss: 28.8502\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6680 - val_loss: 28.8365\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6699 - val_loss: 28.8219\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6451 - val_loss: 28.8075\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6342 - val_loss: 28.7935\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6132 - val_loss: 28.7793\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.6044 - val_loss: 28.7651\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5899 - val_loss: 28.7507\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.4482 - val_loss: 28.7365\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4999 - val_loss: 28.7223\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5206 - val_loss: 28.7078\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.3638 - val_loss: 28.6937\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4899 - val_loss: 28.6801\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5047 - val_loss: 28.6657\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.4806 - val_loss: 28.6514\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.4748 - val_loss: 28.6365\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.4358 - val_loss: 28.6223\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4169 - val_loss: 28.6076\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.3833 - val_loss: 28.5930\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.4119 - val_loss: 28.5778\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4010 - val_loss: 28.5624\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2615 - val_loss: 28.5472\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.3729 - val_loss: 28.5321\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_420 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_421 (Conv1D)         (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_422 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_423 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_424 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_425 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_426 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.9364 - val_loss: 24.6629\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0860 - val_loss: 23.9580\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3132 - val_loss: 23.3570\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5606 - val_loss: 22.8221\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0296 - val_loss: 22.3726\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5701 - val_loss: 21.9679\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9293 - val_loss: 21.5757\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6449 - val_loss: 21.1954\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2430 - val_loss: 20.8634\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8210 - val_loss: 20.5609\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5013 - val_loss: 20.3269\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0905 - val_loss: 20.1139\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8231 - val_loss: 19.9226\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4842 - val_loss: 19.7923\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3875 - val_loss: 19.6781\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1827 - val_loss: 19.5724\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0675 - val_loss: 19.4702\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9736 - val_loss: 19.3794\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8889 - val_loss: 19.3047\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8034 - val_loss: 19.2385\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7177 - val_loss: 19.1809\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7103 - val_loss: 19.1299\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6672 - val_loss: 19.0943\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6313 - val_loss: 19.0648\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5178 - val_loss: 19.0383\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4920 - val_loss: 19.0131\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5295 - val_loss: 18.9891\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5294 - val_loss: 18.9668\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5016 - val_loss: 18.9464\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4674 - val_loss: 18.9261\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4655 - val_loss: 18.9073\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4611 - val_loss: 18.8889\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4272 - val_loss: 18.8705\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4184 - val_loss: 18.8523\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4174 - val_loss: 18.8341\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3573 - val_loss: 18.8170\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3640 - val_loss: 18.8000\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3026 - val_loss: 18.7842\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3657 - val_loss: 18.7685\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3486 - val_loss: 18.7529\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3298 - val_loss: 18.7378\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3272 - val_loss: 18.7227\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2423 - val_loss: 18.7087\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2864 - val_loss: 18.6936\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2642 - val_loss: 18.6800\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2711 - val_loss: 18.6658\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2641 - val_loss: 18.6514\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2364 - val_loss: 18.6371\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1077 - val_loss: 18.6234\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2323 - val_loss: 18.6091\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1789 - val_loss: 18.5950\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2019 - val_loss: 18.5812\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1811 - val_loss: 18.5672\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1623 - val_loss: 18.5532\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1564 - val_loss: 18.5392\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1447 - val_loss: 18.5252\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1288 - val_loss: 18.5110\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1076 - val_loss: 18.4975\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1069 - val_loss: 18.4833\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0751 - val_loss: 18.4695\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0693 - val_loss: 18.4555\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0718 - val_loss: 18.4417\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0640 - val_loss: 18.4276\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0333 - val_loss: 18.4132\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0343 - val_loss: 18.3988\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9992 - val_loss: 18.3848\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9976 - val_loss: 18.3705\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9430 - val_loss: 18.3559\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9395 - val_loss: 18.3415\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9611 - val_loss: 18.3264\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9237 - val_loss: 18.3125\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9381 - val_loss: 18.2973\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7645 - val_loss: 18.2834\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9122 - val_loss: 18.2690\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8980 - val_loss: 18.2545\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8808 - val_loss: 18.2399\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8535 - val_loss: 18.2256\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8386 - val_loss: 18.2110\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8286 - val_loss: 18.1974\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8278 - val_loss: 18.1823\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8098 - val_loss: 18.1678\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7397 - val_loss: 18.1536\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7822 - val_loss: 18.1388\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.7734 - val_loss: 18.1235\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7362 - val_loss: 18.1086\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7278 - val_loss: 18.0938\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7359 - val_loss: 18.0789\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7053 - val_loss: 18.0642\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6847 - val_loss: 18.0491\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6827 - val_loss: 18.0338\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6184 - val_loss: 18.0191\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6272 - val_loss: 18.0043\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6203 - val_loss: 17.9895\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5979 - val_loss: 17.9747\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6130 - val_loss: 17.9597\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5659 - val_loss: 17.9445\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5422 - val_loss: 17.9295\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5603 - val_loss: 17.9140\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5277 - val_loss: 17.8997\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5288 - val_loss: 17.8842\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_427 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_428 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_429 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_430 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_431 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_432 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_433 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.04343\n",
      "Model:                       QuantReg   Bandwidth:                    0.007674\n",
      "Method:                 Least Squares   Sparsity:                       0.3232\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:03:39   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0310      0.011      2.768      0.006       0.009       0.053\n",
      "three_month_yield_change     -0.2546      0.301     -0.846      0.397      -0.845       0.335\n",
      "term_spread_change            0.0621      0.262      0.237      0.813      -0.452       0.576\n",
      "TED_spread                   -0.6051      1.204     -0.503      0.615      -2.965       1.755\n",
      "credit_spread_change         -0.0831      0.407     -0.204      0.838      -0.881       0.715\n",
      "market_return                -0.1531      0.171     -0.893      0.372      -0.489       0.183\n",
      "real_estate_excess_return    -0.2115      0.178     -1.187      0.235      -0.561       0.138\n",
      "equity_volatility             2.1458      0.338      6.357      0.000       1.484       2.808\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1424\n",
      "Model:                       QuantReg   Bandwidth:                     0.01136\n",
      "Method:                 Least Squares   Sparsity:                        1.323\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:03:39   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.1061      0.025      4.240      0.000       0.057       0.155\n",
      "three_month_yield_change     -0.9975      0.615     -1.623      0.105      -2.203       0.208\n",
      "term_spread_change           -0.5729      0.523     -1.096      0.273      -1.598       0.452\n",
      "TED_spread                   -2.1422      2.193     -0.977      0.329      -6.443       2.159\n",
      "credit_spread_change         -1.3194      0.889     -1.484      0.138      -3.063       0.424\n",
      "market_return                 0.1767      0.333      0.530      0.596      -0.477       0.830\n",
      "real_estate_excess_return    -0.5025      0.420     -1.195      0.232      -1.327       0.322\n",
      "equity_volatility             2.5684      0.569      4.511      0.000       1.452       3.685\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.1944\n",
      "Model:                       QuantReg   Bandwidth:                    0.002634\n",
      "Method:                 Least Squares   Sparsity:                       0.1135\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:03:39   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.004      1.633      0.103      -0.001       0.014\n",
      "three_month_yield_change      0.1222      0.104      1.177      0.239      -0.081       0.326\n",
      "term_spread_change           -0.0376      0.099     -0.381      0.703      -0.231       0.156\n",
      "TED_spread                   -1.7742      0.412     -4.303      0.000      -2.583      -0.966\n",
      "credit_spread_change          0.0835      0.142      0.587      0.557      -0.195       0.362\n",
      "market_return                -0.0150      0.062     -0.239      0.811      -0.137       0.108\n",
      "real_estate_excess_return    -0.0200      0.068     -0.294      0.768      -0.153       0.113\n",
      "equity_volatility             1.2757      0.113     11.287      0.000       1.054       1.497\n",
      "institution                   0.1123      0.033      3.400      0.001       0.048       0.177\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3216\n",
      "Model:                       QuantReg   Bandwidth:                    0.004769\n",
      "Method:                 Least Squares   Sparsity:                       0.5293\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:03:39   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0168      0.008      2.034      0.042       0.001       0.033\n",
      "three_month_yield_change      0.1691      0.204      0.828      0.408      -0.232       0.570\n",
      "term_spread_change           -0.4176      0.243     -1.715      0.086      -0.895       0.060\n",
      "TED_spread                   -2.0796      0.802     -2.593      0.010      -3.652      -0.507\n",
      "credit_spread_change          0.0590      0.325      0.182      0.856      -0.579       0.697\n",
      "market_return                -0.0589      0.183     -0.321      0.748      -0.418       0.300\n",
      "real_estate_excess_return    -0.2181      0.155     -1.406      0.160      -0.522       0.086\n",
      "equity_volatility             2.4299      0.314      7.741      0.000       1.814       3.045\n",
      "institution                   0.1159      0.109      1.064      0.288      -0.098       0.330\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 30.6921 - val_loss: 26.8549\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.7768 - val_loss: 26.0684\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.8305 - val_loss: 25.2795\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.8907 - val_loss: 24.4577\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.7610 - val_loss: 23.6385\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.7459 - val_loss: 22.8431\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.7817 - val_loss: 22.0906\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.9764 - val_loss: 21.3935\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.1144 - val_loss: 20.8318\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 22.4180 - val_loss: 20.3925\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.8189 - val_loss: 20.0304\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.4403 - val_loss: 19.7543\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.0481 - val_loss: 19.5164\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.8090 - val_loss: 19.3492\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.5770 - val_loss: 19.2111\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.3830 - val_loss: 19.0962\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.1924 - val_loss: 19.0054\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.9551 - val_loss: 18.9503\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 20.0181 - val_loss: 18.9142\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.9012 - val_loss: 18.8883\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8777 - val_loss: 18.8722\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8300 - val_loss: 18.8626\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7220 - val_loss: 18.8555\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.7223 - val_loss: 18.8508\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5135 - val_loss: 18.8473\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6833 - val_loss: 18.8476\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6244 - val_loss: 18.8487\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.6059 - val_loss: 18.8497\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.5138 - val_loss: 18.8506\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5498 - val_loss: 18.8510\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5644 - val_loss: 18.8495\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5560 - val_loss: 18.8473\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4867 - val_loss: 18.8430\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5120 - val_loss: 18.8382\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4800 - val_loss: 18.8328\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4481 - val_loss: 18.8269\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4805 - val_loss: 18.8212\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4746 - val_loss: 18.8149\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4085 - val_loss: 18.8082\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4172 - val_loss: 18.8009\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4339 - val_loss: 18.7941\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3973 - val_loss: 18.7871\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.4076 - val_loss: 18.7800\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3854 - val_loss: 18.7721\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3268 - val_loss: 18.7645\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2604 - val_loss: 18.7560\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3512 - val_loss: 18.7478\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3394 - val_loss: 18.7395\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2800 - val_loss: 18.7307\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.3141 - val_loss: 18.7214\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2975 - val_loss: 18.7123\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2871 - val_loss: 18.7031\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2788 - val_loss: 18.6941\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1982 - val_loss: 18.6846\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1938 - val_loss: 18.6748\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2430 - val_loss: 18.6647\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.2318 - val_loss: 18.6546\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1864 - val_loss: 18.6435\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1438 - val_loss: 18.6326\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1892 - val_loss: 18.6223\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1410 - val_loss: 18.6119\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1471 - val_loss: 18.6018\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1071 - val_loss: 18.5909\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1394 - val_loss: 18.5804\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1207 - val_loss: 18.5691\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.1085 - val_loss: 18.5578\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0996 - val_loss: 18.5467\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0570 - val_loss: 18.5352\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0732 - val_loss: 18.5236\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0138 - val_loss: 18.5118\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0254 - val_loss: 18.4999\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0318 - val_loss: 18.4877\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.0132 - val_loss: 18.4758\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9911 - val_loss: 18.4638\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9622 - val_loss: 18.4511\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9499 - val_loss: 18.4380\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9688 - val_loss: 18.4249\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9182 - val_loss: 18.4111\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8415 - val_loss: 18.3972\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8988 - val_loss: 18.3839\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8909 - val_loss: 18.3709\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8957 - val_loss: 18.3583\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8528 - val_loss: 18.3448\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.8739 - val_loss: 18.3319\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7777 - val_loss: 18.3186\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7608 - val_loss: 18.3052\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8200 - val_loss: 18.2912\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7921 - val_loss: 18.2772\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7232 - val_loss: 18.2626\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7416 - val_loss: 18.2485\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7347 - val_loss: 18.2341\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7332 - val_loss: 18.2205\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7357 - val_loss: 18.2062\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6541 - val_loss: 18.1922\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7123 - val_loss: 18.1782\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6586 - val_loss: 18.1633\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6733 - val_loss: 18.1492\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6479 - val_loss: 18.1350\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6313 - val_loss: 18.1205\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6407 - val_loss: 18.1059\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_434 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_435 (Conv1D)         (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_436 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_437 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_438 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_439 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_440 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 25.4887 - val_loss: 24.3153\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8333 - val_loss: 23.7518\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 24.2680 - val_loss: 23.2874\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7133 - val_loss: 22.8737\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1319 - val_loss: 22.4961\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7087 - val_loss: 22.1469\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3866 - val_loss: 21.8125\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9679 - val_loss: 21.4786\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5750 - val_loss: 21.1606\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2174 - val_loss: 20.8768\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9366 - val_loss: 20.6227\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6104 - val_loss: 20.3971\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3769 - val_loss: 20.2185\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0772 - val_loss: 20.0744\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9412 - val_loss: 19.9472\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6835 - val_loss: 19.8296\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5402 - val_loss: 19.7299\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3803 - val_loss: 19.6436\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2491 - val_loss: 19.5554\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0798 - val_loss: 19.4734\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0310 - val_loss: 19.3908\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.9525 - val_loss: 19.3116\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8298 - val_loss: 19.2396\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.7822 - val_loss: 19.1791\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6911 - val_loss: 19.1228\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.6583 - val_loss: 19.0718\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5555 - val_loss: 19.0235\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5614 - val_loss: 18.9788\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.5234 - val_loss: 18.9441\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4884 - val_loss: 18.9145\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4087 - val_loss: 18.8878\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.4296 - val_loss: 18.8611\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3592 - val_loss: 18.8363\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3474 - val_loss: 18.8123\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3132 - val_loss: 18.7886\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2953 - val_loss: 18.7665\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3072 - val_loss: 18.7455\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3004 - val_loss: 18.7250\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2516 - val_loss: 18.7066\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2627 - val_loss: 18.6880\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2357 - val_loss: 18.6701\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.1471 - val_loss: 18.6531\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 18.2132 - val_loss: 18.6358\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1637 - val_loss: 18.6194\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1256 - val_loss: 18.6035\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1803 - val_loss: 18.5886\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1681 - val_loss: 18.5732\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9805 - val_loss: 18.5596\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1103 - val_loss: 18.5445\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1379 - val_loss: 18.5298\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1028 - val_loss: 18.5149\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0987 - val_loss: 18.5009\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1045 - val_loss: 18.4860\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0847 - val_loss: 18.4720\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9342 - val_loss: 18.4578\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0267 - val_loss: 18.4435\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0518 - val_loss: 18.4293\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0327 - val_loss: 18.4150\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0206 - val_loss: 18.4006\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9562 - val_loss: 18.3866\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9936 - val_loss: 18.3724\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9845 - val_loss: 18.3587\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9268 - val_loss: 18.3449\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9570 - val_loss: 18.3302\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9450 - val_loss: 18.3157\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8921 - val_loss: 18.3021\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9202 - val_loss: 18.2880\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9045 - val_loss: 18.2733\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8892 - val_loss: 18.2588\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8776 - val_loss: 18.2448\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8579 - val_loss: 18.2301\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8265 - val_loss: 18.2156\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.8404 - val_loss: 18.2012\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8315 - val_loss: 18.1867\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8144 - val_loss: 18.1720\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7691 - val_loss: 18.1574\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6904 - val_loss: 18.1432\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7727 - val_loss: 18.1288\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7524 - val_loss: 18.1140\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6939 - val_loss: 18.1003\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7313 - val_loss: 18.0860\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6699 - val_loss: 18.0717\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6879 - val_loss: 18.0569\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6904 - val_loss: 18.0422\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6694 - val_loss: 18.0277\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6610 - val_loss: 18.0128\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6413 - val_loss: 17.9979\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6302 - val_loss: 17.9830\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.6167 - val_loss: 17.9677\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6037 - val_loss: 17.9528\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5525 - val_loss: 17.9384\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5744 - val_loss: 17.9236\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5573 - val_loss: 17.9084\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4966 - val_loss: 17.8942\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5294 - val_loss: 17.8794\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.4833 - val_loss: 17.8648\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4816 - val_loss: 17.8499\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4814 - val_loss: 17.8352\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4211 - val_loss: 17.8205\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4518 - val_loss: 17.8054\n",
      "4/4 [==============================] - 0s 465us/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_64 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_441 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_442 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_443 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_444 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_445 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_446 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_63 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_447 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.07939\n",
      "Model:                       QuantReg   Bandwidth:                    0.003642\n",
      "Method:                 Least Squares   Sparsity:                       0.1537\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:04:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0185      0.006      3.358      0.001       0.008       0.029\n",
      "three_month_yield_change      0.0608      0.140      0.435      0.664      -0.213       0.335\n",
      "term_spread_change           -0.1937      0.146     -1.325      0.185      -0.480       0.093\n",
      "TED_spread                   -1.2675      0.542     -2.340      0.019      -2.330      -0.205\n",
      "credit_spread_change         -0.1403      0.198     -0.709      0.478      -0.528       0.248\n",
      "market_return                -0.0527      0.088     -0.602      0.547      -0.224       0.119\n",
      "real_estate_excess_return    -0.0867      0.097     -0.889      0.374      -0.278       0.104\n",
      "equity_volatility             1.2552      0.178      7.058      0.000       0.906       1.604\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1877\n",
      "Model:                       QuantReg   Bandwidth:                    0.006024\n",
      "Method:                 Least Squares   Sparsity:                       0.7645\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:04:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0434      0.014      3.125      0.002       0.016       0.071\n",
      "three_month_yield_change      0.2276      0.385      0.591      0.554      -0.527       0.982\n",
      "term_spread_change           -0.7849      0.376     -2.089      0.037      -1.522      -0.048\n",
      "TED_spread                   -5.2498      1.315     -3.992      0.000      -7.829      -2.671\n",
      "credit_spread_change          0.2374      0.484      0.490      0.624      -0.712       1.187\n",
      "market_return                -0.1217      0.184     -0.660      0.509      -0.483       0.240\n",
      "real_estate_excess_return     0.2074      0.322      0.644      0.520      -0.424       0.839\n",
      "equity_volatility             1.5683      0.391      4.008      0.000       0.801       2.336\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3453\n",
      "Model:                       QuantReg   Bandwidth:                    0.002321\n",
      "Method:                 Least Squares   Sparsity:                      0.08365\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:04:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0154      0.003      5.034      0.000       0.009       0.021\n",
      "three_month_yield_change     -0.1319      0.077     -1.709      0.088      -0.283       0.019\n",
      "term_spread_change           -0.1998      0.068     -2.927      0.003      -0.334      -0.066\n",
      "TED_spread                   -0.4950      0.299     -1.655      0.098      -1.082       0.092\n",
      "credit_spread_change         -0.1811      0.114     -1.591      0.112      -0.404       0.042\n",
      "market_return                -0.0804      0.044     -1.842      0.066      -0.166       0.005\n",
      "real_estate_excess_return    -0.1251      0.049     -2.540      0.011      -0.222      -0.029\n",
      "equity_volatility             0.8454      0.084     10.029      0.000       0.680       1.011\n",
      "institution                   0.5641      0.049     11.520      0.000       0.468       0.660\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4613\n",
      "Model:                       QuantReg   Bandwidth:                    0.004158\n",
      "Method:                 Least Squares   Sparsity:                       0.3398\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:04:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0192      0.005      4.136      0.000       0.010       0.028\n",
      "three_month_yield_change     -0.0340      0.123     -0.275      0.783      -0.276       0.208\n",
      "term_spread_change           -0.3195      0.137     -2.329      0.020      -0.589      -0.051\n",
      "TED_spread                   -0.7132      0.565     -1.263      0.207      -1.821       0.394\n",
      "credit_spread_change         -0.2015      0.179     -1.129      0.259      -0.552       0.149\n",
      "market_return                 0.1295      0.136      0.956      0.339      -0.136       0.395\n",
      "real_estate_excess_return     0.0105      0.104      0.100      0.920      -0.194       0.215\n",
      "equity_volatility             1.6955      0.206      8.232      0.000       1.292       2.099\n",
      "institution                   0.5586      0.143      3.902      0.000       0.278       0.839\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 41.8243 - val_loss: 40.4437\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.8244 - val_loss: 39.6543\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.1782 - val_loss: 38.9321\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4917 - val_loss: 38.2229\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 38.6111 - val_loss: 37.5003\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 37.6795 - val_loss: 36.7489\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.7189 - val_loss: 36.0261\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 35.8364 - val_loss: 35.3159\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.8429 - val_loss: 34.6507\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.0467 - val_loss: 33.9741\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.2367 - val_loss: 33.2722\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.2372 - val_loss: 32.6421\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.2127 - val_loss: 32.0282\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.4237 - val_loss: 31.4304\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.7317 - val_loss: 30.8753\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.9825 - val_loss: 30.3337\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.3830 - val_loss: 29.7934\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.7793 - val_loss: 29.2564\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.2757 - val_loss: 28.7266\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.8545 - val_loss: 28.2084\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.4854 - val_loss: 27.7705\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.1308 - val_loss: 27.4237\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.9289 - val_loss: 27.1096\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.7053 - val_loss: 26.8333\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4728 - val_loss: 26.6431\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4403 - val_loss: 26.5053\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.3184 - val_loss: 26.3862\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8643 - val_loss: 26.2787\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0401 - val_loss: 26.1773\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0646 - val_loss: 26.0835\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.0390 - val_loss: 26.0032\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.9751 - val_loss: 25.9294\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8799 - val_loss: 25.8609\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.9064 - val_loss: 25.7992\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8781 - val_loss: 25.7398\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8124 - val_loss: 25.6853\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5342 - val_loss: 25.6332\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7968 - val_loss: 25.5847\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5179 - val_loss: 25.5430\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7445 - val_loss: 25.5070\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7311 - val_loss: 25.4783\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6810 - val_loss: 25.4534\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6826 - val_loss: 25.4292\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5807 - val_loss: 25.4055\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6448 - val_loss: 25.3842\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6286 - val_loss: 25.3631\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6222 - val_loss: 25.3425\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5391 - val_loss: 25.3233\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3361 - val_loss: 25.3045\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5776 - val_loss: 25.2851\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5565 - val_loss: 25.2655\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5189 - val_loss: 25.2452\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4116 - val_loss: 25.2264\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.5003 - val_loss: 25.2076\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1686 - val_loss: 25.1893\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3973 - val_loss: 25.1709\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4742 - val_loss: 25.1531\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4517 - val_loss: 25.1361\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3878 - val_loss: 25.1196\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4177 - val_loss: 25.1028\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.4160 - val_loss: 25.0873\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3829 - val_loss: 25.0718\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3730 - val_loss: 25.0561\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3859 - val_loss: 25.0403\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2968 - val_loss: 25.0262\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3280 - val_loss: 25.0107\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3182 - val_loss: 24.9957\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3146 - val_loss: 24.9807\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2115 - val_loss: 24.9663\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2638 - val_loss: 24.9525\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2373 - val_loss: 24.9380\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2346 - val_loss: 24.9238\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2425 - val_loss: 24.9098\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2434 - val_loss: 24.8962\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2458 - val_loss: 24.8830\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.2301 - val_loss: 24.8689\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9962 - val_loss: 24.8558\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1491 - val_loss: 24.8420\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0876 - val_loss: 24.8282\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0523 - val_loss: 24.8145\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1520 - val_loss: 24.8002\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1592 - val_loss: 24.7867\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9411 - val_loss: 24.7740\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0863 - val_loss: 24.7604\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9930 - val_loss: 24.7470\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0936 - val_loss: 24.7328\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0796 - val_loss: 24.7193\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0497 - val_loss: 24.7060\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0586 - val_loss: 24.6921\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.0087 - val_loss: 24.6788\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7775 - val_loss: 24.6649\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9041 - val_loss: 24.6514\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.8688 - val_loss: 24.6377\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9180 - val_loss: 24.6240\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9130 - val_loss: 24.6100\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9728 - val_loss: 24.5960\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.8933 - val_loss: 24.5827\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 23.9468 - val_loss: 24.5683\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9273 - val_loss: 24.5537\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9110 - val_loss: 24.5390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_448 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_449 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_450 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_451 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_452 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_453 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_64 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_454 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 25.2095 - val_loss: 24.0823\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3953 - val_loss: 23.4411\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6999 - val_loss: 22.8375\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0062 - val_loss: 22.3279\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4335 - val_loss: 21.8952\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9653 - val_loss: 21.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.5543 - val_loss: 21.1260\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 21.1076 - val_loss: 20.8183\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7780 - val_loss: 20.5439\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4879 - val_loss: 20.3303\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1700 - val_loss: 20.1583\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 19.8890 - val_loss: 20.0128\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7845 - val_loss: 19.8827\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5226 - val_loss: 19.7851\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.4474 - val_loss: 19.7002\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2674 - val_loss: 19.6198\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2044 - val_loss: 19.5418\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0259 - val_loss: 19.4656\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9651 - val_loss: 19.3912\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9306 - val_loss: 19.3226\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8345 - val_loss: 19.2643\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7828 - val_loss: 19.2108\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6136 - val_loss: 19.1620\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6968 - val_loss: 19.1143\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6570 - val_loss: 19.0744\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6246 - val_loss: 19.0416\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5340 - val_loss: 19.0127\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5451 - val_loss: 18.9878\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5250 - val_loss: 18.9639\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5028 - val_loss: 18.9404\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4858 - val_loss: 18.9186\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4557 - val_loss: 18.8970\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4148 - val_loss: 18.8762\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4204 - val_loss: 18.8557\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3573 - val_loss: 18.8355\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3134 - val_loss: 18.8167\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3687 - val_loss: 18.7967\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3019 - val_loss: 18.7782\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3365 - val_loss: 18.7603\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3212 - val_loss: 18.7431\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3022 - val_loss: 18.7265\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2859 - val_loss: 18.7104\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2860 - val_loss: 18.6940\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2803 - val_loss: 18.6780\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2100 - val_loss: 18.6628\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2489 - val_loss: 18.6480\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2387 - val_loss: 18.6330\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1955 - val_loss: 18.6183\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2122 - val_loss: 18.6035\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0333 - val_loss: 18.5895\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1215 - val_loss: 18.5754\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1812 - val_loss: 18.5610\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1648 - val_loss: 18.5468\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1562 - val_loss: 18.5324\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1072 - val_loss: 18.5190\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1364 - val_loss: 18.5057\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1205 - val_loss: 18.4914\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1057 - val_loss: 18.4773\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0344 - val_loss: 18.4637\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0774 - val_loss: 18.4499\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0702 - val_loss: 18.4362\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0633 - val_loss: 18.4227\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9111 - val_loss: 18.4095\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0263 - val_loss: 18.3954\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0229 - val_loss: 18.3817\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9865 - val_loss: 18.3685\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9889 - val_loss: 18.3545\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9812 - val_loss: 18.3404\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9536 - val_loss: 18.3275\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9519 - val_loss: 18.3145\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9283 - val_loss: 18.3011\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.9134 - val_loss: 18.2881\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9067 - val_loss: 18.2748\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8746 - val_loss: 18.2616\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8936 - val_loss: 18.2484\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8778 - val_loss: 18.2350\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8669 - val_loss: 18.2211\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8385 - val_loss: 18.2077\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8238 - val_loss: 18.1945\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8301 - val_loss: 18.1810\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8054 - val_loss: 18.1676\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7847 - val_loss: 18.1546\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7900 - val_loss: 18.1408\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7451 - val_loss: 18.1271\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7592 - val_loss: 18.1130\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7416 - val_loss: 18.0993\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7060 - val_loss: 18.0856\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7095 - val_loss: 18.0721\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7059 - val_loss: 18.0580\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6831 - val_loss: 18.0438\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6720 - val_loss: 18.0299\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6634 - val_loss: 18.0154\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6413 - val_loss: 18.0015\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6169 - val_loss: 17.9877\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5987 - val_loss: 17.9741\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6094 - val_loss: 17.9601\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5685 - val_loss: 17.9468\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5789 - val_loss: 17.9318\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5604 - val_loss: 17.9172\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5502 - val_loss: 17.9032\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_66 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_455 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_456 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_457 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_458 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_459 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_460 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_65 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_461 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    121\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    121\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1282\n",
      "Model:                       QuantReg   Bandwidth:                    0.005735\n",
      "Method:                 Least Squares   Sparsity:                       0.2209\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:05:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0448      0.008      5.892      0.000       0.030       0.060\n",
      "three_month_yield_change     -0.4106      0.202     -2.034      0.042      -0.807      -0.015\n",
      "term_spread_change           -0.9291      0.195     -4.753      0.000      -1.312      -0.546\n",
      "TED_spread                   -2.2239      0.813     -2.734      0.006      -3.819      -0.629\n",
      "credit_spread_change         -0.4179      0.280     -1.491      0.136      -0.968       0.132\n",
      "market_return                -0.1710      0.122     -1.406      0.160      -0.409       0.067\n",
      "real_estate_excess_return    -0.0297      0.122     -0.243      0.808      -0.269       0.210\n",
      "equity_volatility             2.3425      0.234     10.005      0.000       1.883       2.802\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2857\n",
      "Model:                       QuantReg   Bandwidth:                     0.01013\n",
      "Method:                 Least Squares   Sparsity:                        1.091\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:05:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0890      0.016      5.502      0.000       0.057       0.121\n",
      "three_month_yield_change     -1.0173      0.452     -2.251      0.024      -1.904      -0.131\n",
      "term_spread_change           -1.4350      0.510     -2.811      0.005      -2.436      -0.434\n",
      "TED_spread                    0.0006      1.855      0.000      1.000      -3.636       3.638\n",
      "credit_spread_change         -2.1212      0.567     -3.739      0.000      -3.234      -1.009\n",
      "market_return                -0.6611      0.398     -1.662      0.097      -1.441       0.119\n",
      "real_estate_excess_return    -0.4739      0.346     -1.370      0.171      -1.152       0.204\n",
      "equity_volatility             6.3697      0.658      9.681      0.000       5.079       7.660\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4099\n",
      "Model:                       QuantReg   Bandwidth:                    0.001983\n",
      "Method:                 Least Squares   Sparsity:                      0.08423\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:05:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0152      0.003      5.281      0.000       0.010       0.021\n",
      "three_month_yield_change     -0.1638      0.085     -1.924      0.054      -0.331       0.003\n",
      "term_spread_change           -0.1481      0.077     -1.928      0.054      -0.299       0.003\n",
      "TED_spread                   -0.4963      0.309     -1.607      0.108      -1.102       0.109\n",
      "credit_spread_change         -0.2154      0.098     -2.199      0.028      -0.407      -0.023\n",
      "market_return                 0.0161      0.043      0.373      0.709      -0.068       0.100\n",
      "real_estate_excess_return    -0.0023      0.055     -0.042      0.967      -0.110       0.105\n",
      "equity_volatility             0.6946      0.078      8.949      0.000       0.542       0.847\n",
      "institution                   0.3566      0.028     12.905      0.000       0.302       0.411\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5178\n",
      "Model:                       QuantReg   Bandwidth:                    0.003390\n",
      "Method:                 Least Squares   Sparsity:                       0.3333\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:05:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0317      0.005      6.210      0.000       0.022       0.042\n",
      "three_month_yield_change     -0.3475      0.161     -2.159      0.031      -0.663      -0.032\n",
      "term_spread_change           -0.3382      0.156     -2.165      0.030      -0.644      -0.032\n",
      "TED_spread                   -0.7696      0.680     -1.131      0.258      -2.103       0.564\n",
      "credit_spread_change         -0.5903      0.173     -3.412      0.001      -0.930      -0.251\n",
      "market_return                -0.1636      0.128     -1.275      0.202      -0.415       0.088\n",
      "real_estate_excess_return    -0.0112      0.140     -0.080      0.936      -0.286       0.264\n",
      "equity_volatility             1.2687      0.200      6.344      0.000       0.877       1.661\n",
      "institution                   0.3502      0.082      4.264      0.000       0.189       0.511\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 35.1881 - val_loss: 36.8638\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 34.2761 - val_loss: 36.0853\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.5668 - val_loss: 35.2958\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.6009 - val_loss: 34.5620\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.8661 - val_loss: 33.8573\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.0979 - val_loss: 33.1737\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.3182 - val_loss: 32.4686\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.3988 - val_loss: 31.7736\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.6149 - val_loss: 31.1025\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.8358 - val_loss: 30.4568\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.1234 - val_loss: 29.8691\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.5095 - val_loss: 29.2996\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8092 - val_loss: 28.7570\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2165 - val_loss: 28.2439\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6603 - val_loss: 27.8121\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4012 - val_loss: 27.3916\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9719 - val_loss: 26.8907\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4604 - val_loss: 26.4833\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1109 - val_loss: 26.1621\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7728 - val_loss: 25.8871\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5490 - val_loss: 25.6334\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2786 - val_loss: 25.4019\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.0281 - val_loss: 25.2093\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0822 - val_loss: 25.0397\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0336 - val_loss: 24.8771\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7683 - val_loss: 24.7377\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8642 - val_loss: 24.6249\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7221 - val_loss: 24.5355\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7704 - val_loss: 24.4613\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7353 - val_loss: 24.3950\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6039 - val_loss: 24.3334\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6582 - val_loss: 24.2757\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6316 - val_loss: 24.2224\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5965 - val_loss: 24.1724\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5611 - val_loss: 24.1252\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3895 - val_loss: 24.0806\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5705 - val_loss: 24.0359\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5279 - val_loss: 23.9911\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3659 - val_loss: 23.9493\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4958 - val_loss: 23.9065\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4818 - val_loss: 23.8673\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3607 - val_loss: 23.8316\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4631 - val_loss: 23.7953\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3532 - val_loss: 23.7614\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4349 - val_loss: 23.7290\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2693 - val_loss: 23.7019\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4020 - val_loss: 23.6725\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3892 - val_loss: 23.6474\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3281 - val_loss: 23.6237\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3590 - val_loss: 23.6017\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3565 - val_loss: 23.5794\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3101 - val_loss: 23.5604\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2637 - val_loss: 23.5424\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3080 - val_loss: 23.5244\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2712 - val_loss: 23.5087\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2790 - val_loss: 23.4919\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2548 - val_loss: 23.4766\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2087 - val_loss: 23.4608\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2435 - val_loss: 23.4447\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2158 - val_loss: 23.4297\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2393 - val_loss: 23.4142\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9405 - val_loss: 23.4021\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1532 - val_loss: 23.3886\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1150 - val_loss: 23.3764\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1955 - val_loss: 23.3608\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1081 - val_loss: 23.3485\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1538 - val_loss: 23.3331\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1594 - val_loss: 23.3189\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.1337 - val_loss: 23.3040\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0670 - val_loss: 23.2927\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1049 - val_loss: 23.2778\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0680 - val_loss: 23.2642\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0483 - val_loss: 23.2494\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9491 - val_loss: 23.2369\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0707 - val_loss: 23.2217\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9147 - val_loss: 23.2091\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9938 - val_loss: 23.1959\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0126 - val_loss: 23.1824\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9686 - val_loss: 23.1694\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9402 - val_loss: 23.1571\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9635 - val_loss: 23.1433\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9288 - val_loss: 23.1274\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9362 - val_loss: 23.1129\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9446 - val_loss: 23.0982\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9223 - val_loss: 23.0845\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8727 - val_loss: 23.0707\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7986 - val_loss: 23.0572\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8815 - val_loss: 23.0432\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8198 - val_loss: 23.0297\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8375 - val_loss: 23.0171\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8313 - val_loss: 23.0029\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7814 - val_loss: 22.9888\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7898 - val_loss: 22.9759\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7837 - val_loss: 22.9611\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7902 - val_loss: 22.9449\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7772 - val_loss: 22.9300\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7047 - val_loss: 22.9165\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6503 - val_loss: 22.9021\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5387 - val_loss: 22.8890\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5616 - val_loss: 22.8762\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_462 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_463 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_464 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_465 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_466 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_467 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_66 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_468 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  127\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.8802 - val_loss: 24.7270\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2727 - val_loss: 24.1908\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.6587 - val_loss: 23.6811\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.1425 - val_loss: 23.2372\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.5083 - val_loss: 22.8377\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.0620 - val_loss: 22.4732\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5814 - val_loss: 22.1433\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1829 - val_loss: 21.8315\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8958 - val_loss: 21.5289\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5979 - val_loss: 21.2362\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3294 - val_loss: 20.9771\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9802 - val_loss: 20.7366\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6860 - val_loss: 20.5288\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.5149 - val_loss: 20.3540\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2210 - val_loss: 20.2112\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9860 - val_loss: 20.0851\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8182 - val_loss: 19.9678\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7045 - val_loss: 19.8724\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.5903 - val_loss: 19.7911\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3944 - val_loss: 19.7164\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3225 - val_loss: 19.6449\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1990 - val_loss: 19.5749\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1299 - val_loss: 19.5068\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0692 - val_loss: 19.4417\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9896 - val_loss: 19.3832\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9014 - val_loss: 19.3294\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8441 - val_loss: 19.2815\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8182 - val_loss: 19.2341\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7221 - val_loss: 19.1907\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7201 - val_loss: 19.1482\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6534 - val_loss: 19.1106\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6173 - val_loss: 19.0777\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6250 - val_loss: 19.0477\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5323 - val_loss: 19.0214\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5045 - val_loss: 18.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5373 - val_loss: 18.9727\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4622 - val_loss: 18.9512\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4776 - val_loss: 18.9297\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3847 - val_loss: 18.9084\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4229 - val_loss: 18.8875\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4117 - val_loss: 18.8676\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3762 - val_loss: 18.8485\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3961 - val_loss: 18.8291\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3546 - val_loss: 18.8099\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3647 - val_loss: 18.7907\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3471 - val_loss: 18.7723\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3403 - val_loss: 18.7539\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2759 - val_loss: 18.7371\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3133 - val_loss: 18.7195\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2818 - val_loss: 18.7029\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2515 - val_loss: 18.6859\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1305 - val_loss: 18.6701\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2565 - val_loss: 18.6544\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2098 - val_loss: 18.6394\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2271 - val_loss: 18.6236\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2114 - val_loss: 18.6084\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1854 - val_loss: 18.5932\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1880 - val_loss: 18.5787\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1686 - val_loss: 18.5638\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1627 - val_loss: 18.5491\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1537 - val_loss: 18.5345\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1351 - val_loss: 18.5197\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0916 - val_loss: 18.5052\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1125 - val_loss: 18.4907\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0959 - val_loss: 18.4760\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0860 - val_loss: 18.4608\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0385 - val_loss: 18.4472\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0603 - val_loss: 18.4323\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0251 - val_loss: 18.4188\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0237 - val_loss: 18.4042\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0224 - val_loss: 18.3899\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9529 - val_loss: 18.3763\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0016 - val_loss: 18.3620\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9301 - val_loss: 18.3477\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9704 - val_loss: 18.3331\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9543 - val_loss: 18.3185\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9348 - val_loss: 18.3047\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9147 - val_loss: 18.2904\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9116 - val_loss: 18.2762\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8830 - val_loss: 18.2622\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8644 - val_loss: 18.2487\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8723 - val_loss: 18.2340\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8518 - val_loss: 18.2195\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8505 - val_loss: 18.2049\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7973 - val_loss: 18.1914\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8145 - val_loss: 18.1770\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7923 - val_loss: 18.1631\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7740 - val_loss: 18.1488\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7764 - val_loss: 18.1343\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7233 - val_loss: 18.1213\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7516 - val_loss: 18.1066\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7305 - val_loss: 18.0922\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6923 - val_loss: 18.0782\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6950 - val_loss: 18.0643\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6937 - val_loss: 18.0499\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6756 - val_loss: 18.0350\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6424 - val_loss: 18.0213\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6444 - val_loss: 18.0068\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6308 - val_loss: 17.9925\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5667 - val_loss: 17.9784\n",
      "4/4 [==============================] - 1s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_469 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_470 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_471 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_472 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_473 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_474 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_67 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_475 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    125\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    121\n",
      "0             1                    125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1398\n",
      "Model:                       QuantReg   Bandwidth:                    0.004509\n",
      "Method:                 Least Squares   Sparsity:                       0.1819\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:06:40   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0264      0.006      4.363      0.000       0.015       0.038\n",
      "three_month_yield_change     -0.4618      0.168     -2.756      0.006      -0.790      -0.133\n",
      "term_spread_change           -0.5186      0.153     -3.398      0.001      -0.818      -0.219\n",
      "TED_spread                   -1.1136      0.591     -1.885      0.060      -2.272       0.045\n",
      "credit_spread_change         -0.1993      0.223     -0.895      0.371      -0.636       0.238\n",
      "market_return                -0.0098      0.101     -0.097      0.923      -0.209       0.189\n",
      "real_estate_excess_return     0.0424      0.112      0.380      0.704      -0.177       0.261\n",
      "equity_volatility             1.9124      0.187     10.251      0.000       1.547       2.278\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2997\n",
      "Model:                       QuantReg   Bandwidth:                    0.007610\n",
      "Method:                 Least Squares   Sparsity:                       0.6767\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:06:40   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0418      0.011      3.637      0.000       0.019       0.064\n",
      "three_month_yield_change     -0.5555      0.267     -2.078      0.038      -1.080      -0.031\n",
      "term_spread_change           -0.4382      0.289     -1.514      0.130      -1.005       0.129\n",
      "TED_spread                   -0.7870      1.076     -0.732      0.464      -2.896       1.322\n",
      "credit_spread_change         -0.8132      0.435     -1.868      0.062      -1.667       0.040\n",
      "market_return                -0.2050      0.256     -0.801      0.423      -0.707       0.297\n",
      "real_estate_excess_return    -0.2455      0.267     -0.919      0.358      -0.769       0.278\n",
      "equity_volatility             3.7577      0.419      8.965      0.000       2.936       4.580\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4160\n",
      "Model:                       QuantReg   Bandwidth:                    0.001968\n",
      "Method:                 Least Squares   Sparsity:                      0.07781\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:06:40   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0109      0.003      3.882      0.000       0.005       0.016\n",
      "three_month_yield_change     -0.1428      0.079     -1.817      0.069      -0.297       0.011\n",
      "term_spread_change           -0.2130      0.073     -2.910      0.004      -0.357      -0.069\n",
      "TED_spread                   -0.6224      0.284     -2.191      0.029      -1.179      -0.065\n",
      "credit_spread_change          0.0066      0.097      0.068      0.946      -0.184       0.198\n",
      "market_return                -0.0279      0.038     -0.743      0.458      -0.102       0.046\n",
      "real_estate_excess_return     0.0291      0.044      0.668      0.504      -0.056       0.115\n",
      "equity_volatility             0.6593      0.068      9.631      0.000       0.525       0.793\n",
      "institution                   0.5069      0.038     13.313      0.000       0.432       0.582\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4717\n",
      "Model:                       QuantReg   Bandwidth:                    0.003226\n",
      "Method:                 Least Squares   Sparsity:                       0.3167\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:06:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0218      0.005      4.401      0.000       0.012       0.032\n",
      "three_month_yield_change     -0.1440      0.133     -1.085      0.278      -0.404       0.116\n",
      "term_spread_change           -0.2887      0.131     -2.200      0.028      -0.546      -0.031\n",
      "TED_spread                    0.9430      0.593      1.590      0.112      -0.220       2.106\n",
      "credit_spread_change         -0.4513      0.185     -2.436      0.015      -0.815      -0.088\n",
      "market_return                 0.0031      0.106      0.029      0.977      -0.205       0.212\n",
      "real_estate_excess_return    -0.0966      0.099     -0.977      0.329      -0.290       0.097\n",
      "equity_volatility             1.3627      0.176      7.725      0.000       1.017       1.709\n",
      "institution                   0.4097      0.119      3.456      0.001       0.177       0.642\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 41.4903 - val_loss: 41.5868\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.6329 - val_loss: 40.8817\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.8122 - val_loss: 40.3332\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.1581 - val_loss: 39.7785\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 38.4531 - val_loss: 39.2342\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 37.9865 - val_loss: 38.6520\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.8605 - val_loss: 37.9182\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.1717 - val_loss: 36.9589\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.8900 - val_loss: 35.6638\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.0701 - val_loss: 34.1955\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.8535 - val_loss: 32.5230\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.8685 - val_loss: 30.7284\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.1263 - val_loss: 29.2751\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.9385 - val_loss: 28.2703\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.2737 - val_loss: 27.4789\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7240 - val_loss: 27.0036\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3652 - val_loss: 26.7266\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9737 - val_loss: 26.5338\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9727 - val_loss: 26.4089\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7502 - val_loss: 26.3392\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6973 - val_loss: 26.3094\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7306 - val_loss: 26.2854\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7421 - val_loss: 26.2634\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6759 - val_loss: 26.2446\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6785 - val_loss: 26.2266\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6089 - val_loss: 26.2109\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6707 - val_loss: 26.1955\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6159 - val_loss: 26.1806\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5561 - val_loss: 26.1669\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5609 - val_loss: 26.1536\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5835 - val_loss: 26.1400\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.6110 - val_loss: 26.1262\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5924 - val_loss: 26.1125\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4553 - val_loss: 26.1000\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5746 - val_loss: 26.0870\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5340 - val_loss: 26.0745\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5354 - val_loss: 26.0620\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2157 - val_loss: 26.0500\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2438 - val_loss: 26.0380\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.5053 - val_loss: 26.0258\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4804 - val_loss: 26.0136\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4911 - val_loss: 26.0012\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4671 - val_loss: 25.9889\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4562 - val_loss: 25.9768\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4552 - val_loss: 25.9645\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4443 - val_loss: 25.9525\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4320 - val_loss: 25.9402\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4222 - val_loss: 25.9277\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3958 - val_loss: 25.9157\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3835 - val_loss: 25.9037\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3813 - val_loss: 25.8916\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2422 - val_loss: 25.8800\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3051 - val_loss: 25.8677\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3143 - val_loss: 25.8554\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3369 - val_loss: 25.8433\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2550 - val_loss: 25.8310\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2930 - val_loss: 25.8186\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2932 - val_loss: 25.8058\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2893 - val_loss: 25.7931\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2695 - val_loss: 25.7802\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2554 - val_loss: 25.7674\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1834 - val_loss: 25.7548\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1771 - val_loss: 25.7419\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.2037 - val_loss: 25.7293\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1637 - val_loss: 25.7163\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0816 - val_loss: 25.7030\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0583 - val_loss: 25.6901\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0750 - val_loss: 25.6770\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1662 - val_loss: 25.6639\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1077 - val_loss: 25.6508\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1188 - val_loss: 25.6376\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0890 - val_loss: 25.6245\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0899 - val_loss: 25.6112\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0736 - val_loss: 25.5976\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8493 - val_loss: 25.5840\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9937 - val_loss: 25.5704\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9596 - val_loss: 25.5566\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9406 - val_loss: 25.5431\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0315 - val_loss: 25.5294\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8983 - val_loss: 25.5159\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 22.8847 - val_loss: 25.5023\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7716 - val_loss: 25.4885\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9433 - val_loss: 25.4746\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9582 - val_loss: 25.4604\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9232 - val_loss: 25.4463\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8908 - val_loss: 25.4324\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9126 - val_loss: 25.4179\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8954 - val_loss: 25.4035\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8880 - val_loss: 25.3890\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5640 - val_loss: 25.3746\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8594 - val_loss: 25.3601\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8395 - val_loss: 25.3455\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6577 - val_loss: 25.3313\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7877 - val_loss: 25.3168\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7832 - val_loss: 25.3023\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7766 - val_loss: 25.2878\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7102 - val_loss: 25.2731\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7516 - val_loss: 25.2582\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7357 - val_loss: 25.2433\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7303 - val_loss: 25.2285\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_476 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_477 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_478 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_479 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_480 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_481 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_482 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.9148 - val_loss: 24.7207\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.3356 - val_loss: 24.0026\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.1288 - val_loss: 22.8524\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8970 - val_loss: 21.9501\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8366 - val_loss: 21.2356\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1202 - val_loss: 20.6448\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4407 - val_loss: 20.2050\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9492 - val_loss: 19.9230\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5103 - val_loss: 19.7223\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3307 - val_loss: 19.5798\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0983 - val_loss: 19.4516\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9061 - val_loss: 19.3320\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8595 - val_loss: 19.2320\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7392 - val_loss: 19.1488\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5903 - val_loss: 19.0806\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5941 - val_loss: 19.0243\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5539 - val_loss: 18.9879\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5196 - val_loss: 18.9565\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4704 - val_loss: 18.9272\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4428 - val_loss: 18.9012\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4296 - val_loss: 18.8766\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4060 - val_loss: 18.8535\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3950 - val_loss: 18.8320\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3479 - val_loss: 18.8124\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2007 - val_loss: 18.7944\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3514 - val_loss: 18.7762\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3335 - val_loss: 18.7588\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3242 - val_loss: 18.7423\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3130 - val_loss: 18.7257\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2882 - val_loss: 18.7098\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2871 - val_loss: 18.6935\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2729 - val_loss: 18.6782\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2406 - val_loss: 18.6632\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1301 - val_loss: 18.6490\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2390 - val_loss: 18.6343\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2108 - val_loss: 18.6205\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2214 - val_loss: 18.6068\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2050 - val_loss: 18.5930\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1896 - val_loss: 18.5798\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1307 - val_loss: 18.5665\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1699 - val_loss: 18.5527\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1180 - val_loss: 18.5401\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1380 - val_loss: 18.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1393 - val_loss: 18.5124\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0726 - val_loss: 18.4990\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0946 - val_loss: 18.4853\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0934 - val_loss: 18.4721\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0124 - val_loss: 18.4585\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0586 - val_loss: 18.4453\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0513 - val_loss: 18.4322\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0372 - val_loss: 18.4184\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9903 - val_loss: 18.4048\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0182 - val_loss: 18.3908\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9850 - val_loss: 18.3771\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8120 - val_loss: 18.3634\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9813 - val_loss: 18.3495\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9471 - val_loss: 18.3358\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9508 - val_loss: 18.3217\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7957 - val_loss: 18.3081\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8964 - val_loss: 18.2939\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9044 - val_loss: 18.2793\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8826 - val_loss: 18.2650\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8659 - val_loss: 18.2506\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8452 - val_loss: 18.2363\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8584 - val_loss: 18.2218\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8370 - val_loss: 18.2069\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7911 - val_loss: 18.1931\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8132 - val_loss: 18.1781\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8018 - val_loss: 18.1629\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7812 - val_loss: 18.1482\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6960 - val_loss: 18.1334\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7508 - val_loss: 18.1181\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7419 - val_loss: 18.1036\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7079 - val_loss: 18.0895\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7153 - val_loss: 18.0746\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6994 - val_loss: 18.0590\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6376 - val_loss: 18.0444\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6602 - val_loss: 18.0294\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6320 - val_loss: 18.0143\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5864 - val_loss: 17.9991\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5849 - val_loss: 17.9840\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5678 - val_loss: 17.9690\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5317 - val_loss: 17.9537\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 17.5864 - val_loss: 17.9383\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5445 - val_loss: 17.9235\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5544 - val_loss: 17.9080\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5239 - val_loss: 17.8923\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5154 - val_loss: 17.8765\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4960 - val_loss: 17.8609\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4909 - val_loss: 17.8454\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4090 - val_loss: 17.8298\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4590 - val_loss: 17.8144\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4449 - val_loss: 17.7982\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4195 - val_loss: 17.7824\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.3501 - val_loss: 17.7670\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4039 - val_loss: 17.7507\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.3813 - val_loss: 17.7348\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.3678 - val_loss: 17.7190\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.2994 - val_loss: 17.7033\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.2256 - val_loss: 17.6877\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_70 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_483 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_484 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_485 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_486 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_487 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_488 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_489 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1424\n",
      "Model:                       QuantReg   Bandwidth:                    0.005485\n",
      "Method:                 Least Squares   Sparsity:                       0.2023\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:07:39   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0172      0.007      2.450      0.014       0.003       0.031\n",
      "three_month_yield_change     -0.1409      0.189     -0.744      0.457      -0.512       0.230\n",
      "term_spread_change           -0.3455      0.177     -1.949      0.051      -0.693       0.002\n",
      "TED_spread                    0.3725      0.721      0.517      0.605      -1.041       1.786\n",
      "credit_spread_change         -0.1258      0.249     -0.504      0.614      -0.615       0.363\n",
      "market_return                 0.0376      0.115      0.328      0.743      -0.187       0.262\n",
      "real_estate_excess_return     0.2231      0.120      1.862      0.063      -0.012       0.458\n",
      "equity_volatility             2.3729      0.210     11.311      0.000       1.961       2.784\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2288\n",
      "Model:                       QuantReg   Bandwidth:                    0.009608\n",
      "Method:                 Least Squares   Sparsity:                        1.327\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:07:39   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0630      0.022      2.913      0.004       0.021       0.105\n",
      "three_month_yield_change     -0.3791      0.567     -0.669      0.504      -1.491       0.733\n",
      "term_spread_change           -0.7181      0.542     -1.324      0.185      -1.781       0.345\n",
      "TED_spread                    3.2081      2.277      1.409      0.159      -1.257       7.673\n",
      "credit_spread_change         -1.6988      0.764     -2.224      0.026      -3.197      -0.201\n",
      "market_return                 0.2570      0.521      0.494      0.622      -0.764       1.278\n",
      "real_estate_excess_return    -0.4016      0.513     -0.783      0.434      -1.407       0.604\n",
      "equity_volatility             4.8855      0.798      6.124      0.000       3.321       6.450\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4201\n",
      "Model:                       QuantReg   Bandwidth:                    0.002164\n",
      "Method:                 Least Squares   Sparsity:                      0.07728\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:07:39   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.003      3.562      0.000       0.004       0.015\n",
      "three_month_yield_change      0.0413      0.079      0.522      0.602      -0.114       0.196\n",
      "term_spread_change           -0.0861      0.071     -1.221      0.222      -0.224       0.052\n",
      "TED_spread                   -0.4064      0.287     -1.416      0.157      -0.969       0.157\n",
      "credit_spread_change         -0.0874      0.091     -0.957      0.339      -0.266       0.092\n",
      "market_return                -0.0925      0.037     -2.534      0.011      -0.164      -0.021\n",
      "real_estate_excess_return    -0.0049      0.047     -0.104      0.917      -0.098       0.088\n",
      "equity_volatility             0.7562      0.074     10.232      0.000       0.611       0.901\n",
      "institution                   0.3637      0.028     13.111      0.000       0.309       0.418\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5353\n",
      "Model:                       QuantReg   Bandwidth:                    0.003424\n",
      "Method:                 Least Squares   Sparsity:                       0.3361\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:07:39   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0318      0.005      6.009      0.000       0.021       0.042\n",
      "three_month_yield_change     -0.3696      0.155     -2.387      0.017      -0.673      -0.066\n",
      "term_spread_change           -0.4610      0.172     -2.680      0.007      -0.798      -0.124\n",
      "TED_spread                   -0.1074      0.620     -0.173      0.862      -1.322       1.108\n",
      "credit_spread_change         -0.4914      0.191     -2.567      0.010      -0.867      -0.116\n",
      "market_return                -0.2213      0.122     -1.810      0.070      -0.461       0.018\n",
      "real_estate_excess_return    -0.0805      0.104     -0.772      0.440      -0.285       0.124\n",
      "equity_volatility             1.0512      0.197      5.329      0.000       0.664       1.438\n",
      "institution                   0.3709      0.097      3.810      0.000       0.180       0.562\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 40.4308 - val_loss: 33.8964\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.0174 - val_loss: 32.9198\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 38.2788 - val_loss: 31.9085\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.7250 - val_loss: 30.8957\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 35.8855 - val_loss: 29.8733\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.6274 - val_loss: 28.7743\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.3485 - val_loss: 27.6518\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.8810 - val_loss: 26.5802\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.5089 - val_loss: 25.4703\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.0399 - val_loss: 24.4663\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.1483 - val_loss: 23.5749\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.0876 - val_loss: 22.7490\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.2113 - val_loss: 22.0639\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.2605 - val_loss: 21.4475\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8829 - val_loss: 20.9992\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3383 - val_loss: 20.6746\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9755 - val_loss: 20.5318\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.7795 - val_loss: 20.4240\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4058 - val_loss: 20.3396\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.4149 - val_loss: 20.2919\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2038 - val_loss: 20.2851\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1891 - val_loss: 20.2924\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.1266 - val_loss: 20.2979\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0514 - val_loss: 20.3018\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9851 - val_loss: 20.3037\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8754 - val_loss: 20.3041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.9167 - val_loss: 20.3041\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8513 - val_loss: 20.3024\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.8416 - val_loss: 20.3001\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7922 - val_loss: 20.2969\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7625 - val_loss: 20.2933\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7396 - val_loss: 20.2894\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7314 - val_loss: 20.2850\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7061 - val_loss: 20.2800\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5858 - val_loss: 20.2744\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6517 - val_loss: 20.2685\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6600 - val_loss: 20.2623\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6543 - val_loss: 20.2557\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5696 - val_loss: 20.2500\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6250 - val_loss: 20.2453\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5865 - val_loss: 20.2405\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4744 - val_loss: 20.2358\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5226 - val_loss: 20.2308\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5237 - val_loss: 20.2262\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5071 - val_loss: 20.2215\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.5269 - val_loss: 20.2171\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5222 - val_loss: 20.2112\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4020 - val_loss: 20.2053\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4978 - val_loss: 20.1989\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4789 - val_loss: 20.1918\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4384 - val_loss: 20.1848\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4293 - val_loss: 20.1764\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4268 - val_loss: 20.1688\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3551 - val_loss: 20.1607\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3149 - val_loss: 20.1527\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3897 - val_loss: 20.1448\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3666 - val_loss: 20.1366\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3611 - val_loss: 20.1276\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3547 - val_loss: 20.1186\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3599 - val_loss: 20.1097\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3119 - val_loss: 20.0997\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3260 - val_loss: 20.0903\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2115 - val_loss: 20.0803\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2857 - val_loss: 20.0706\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2109 - val_loss: 20.0610\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2718 - val_loss: 20.0514\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1717 - val_loss: 20.0396\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2083 - val_loss: 20.0291\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2403 - val_loss: 20.0191\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2094 - val_loss: 20.0086\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1427 - val_loss: 19.9982\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1553 - val_loss: 19.9865\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1432 - val_loss: 19.9756\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1379 - val_loss: 19.9643\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1287 - val_loss: 19.9534\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0447 - val_loss: 19.9415\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1349 - val_loss: 19.9306\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0807 - val_loss: 19.9189\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0303 - val_loss: 19.9068\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0609 - val_loss: 19.8950\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0738 - val_loss: 19.8820\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0623 - val_loss: 19.8691\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0033 - val_loss: 19.8568\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0211 - val_loss: 19.8441\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9866 - val_loss: 19.8306\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9849 - val_loss: 19.8177\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8425 - val_loss: 19.8044\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9726 - val_loss: 19.7908\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9603 - val_loss: 19.7782\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9308 - val_loss: 19.7649\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8904 - val_loss: 19.7509\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.7752 - val_loss: 19.7372\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9064 - val_loss: 19.7238\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8857 - val_loss: 19.7101\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8767 - val_loss: 19.6963\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8517 - val_loss: 19.6827\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8445 - val_loss: 19.6693\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8380 - val_loss: 19.6556\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7555 - val_loss: 19.6417\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7412 - val_loss: 19.6277\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_71 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_490 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_491 (Conv1D)         (None, 7, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_492 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_493 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_494 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_495 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_70 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_496 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.9335 - val_loss: 24.6552\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.9286 - val_loss: 23.7605\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0170 - val_loss: 23.0723\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2864 - val_loss: 22.4712\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.5532 - val_loss: 21.9760\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9873 - val_loss: 21.5135\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5232 - val_loss: 21.0976\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.0700 - val_loss: 20.7549\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.6814 - val_loss: 20.4674\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3663 - val_loss: 20.2494\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0868 - val_loss: 20.0798\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8318 - val_loss: 19.9296\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6347 - val_loss: 19.8228\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.4471 - val_loss: 19.7287\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3351 - val_loss: 19.6404\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1960 - val_loss: 19.5568\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0630 - val_loss: 19.4763\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9803 - val_loss: 19.4006\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.9358 - val_loss: 19.3389\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8755 - val_loss: 19.2830\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7729 - val_loss: 19.2332\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7691 - val_loss: 19.1871\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7142 - val_loss: 19.1439\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6867 - val_loss: 19.1065\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6546 - val_loss: 19.0797\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6029 - val_loss: 19.0544\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5538 - val_loss: 19.0304\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5598 - val_loss: 19.0069\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5225 - val_loss: 18.9844\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4896 - val_loss: 18.9626\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4830 - val_loss: 18.9415\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4671 - val_loss: 18.9206\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4529 - val_loss: 18.9001\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3762 - val_loss: 18.8810\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4266 - val_loss: 18.8620\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3991 - val_loss: 18.8438\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2753 - val_loss: 18.8256\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3647 - val_loss: 18.8073\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3692 - val_loss: 18.7886\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3502 - val_loss: 18.7709\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3213 - val_loss: 18.7537\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3002 - val_loss: 18.7365\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2459 - val_loss: 18.7204\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2877 - val_loss: 18.7044\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2683 - val_loss: 18.6883\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1909 - val_loss: 18.6731\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0572 - val_loss: 18.6574\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2237 - val_loss: 18.6417\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2264 - val_loss: 18.6260\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.2133 - val_loss: 18.6102\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1789 - val_loss: 18.5949\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1895 - val_loss: 18.5796\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1552 - val_loss: 18.5650\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1481 - val_loss: 18.5498\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1396 - val_loss: 18.5354\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1228 - val_loss: 18.5214\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0729 - val_loss: 18.5067\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1028 - val_loss: 18.4917\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0707 - val_loss: 18.4773\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0810 - val_loss: 18.4626\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0394 - val_loss: 18.4477\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0413 - val_loss: 18.4334\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0453 - val_loss: 18.4188\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9933 - val_loss: 18.4037\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0105 - val_loss: 18.3888\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9943 - val_loss: 18.3741\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9914 - val_loss: 18.3591\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9715 - val_loss: 18.3436\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7994 - val_loss: 18.3288\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9442 - val_loss: 18.3138\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8969 - val_loss: 18.2990\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9229 - val_loss: 18.2843\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8982 - val_loss: 18.2694\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8792 - val_loss: 18.2546\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8539 - val_loss: 18.2399\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8458 - val_loss: 18.2248\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8501 - val_loss: 18.2090\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8313 - val_loss: 18.1940\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7987 - val_loss: 18.1789\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7742 - val_loss: 18.1641\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7832 - val_loss: 18.1487\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7636 - val_loss: 18.1334\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7582 - val_loss: 18.1185\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7535 - val_loss: 18.1026\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7301 - val_loss: 18.0874\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6483 - val_loss: 18.0725\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7074 - val_loss: 18.0565\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6881 - val_loss: 18.0410\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6717 - val_loss: 18.0253\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6167 - val_loss: 18.0105\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6407 - val_loss: 17.9947\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5395 - val_loss: 17.9791\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5563 - val_loss: 17.9646\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5783 - val_loss: 17.9497\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5807 - val_loss: 17.9336\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5247 - val_loss: 17.9179\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5531 - val_loss: 17.9021\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5203 - val_loss: 17.8871\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5065 - val_loss: 17.8719\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4997 - val_loss: 17.8569\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_72 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_497 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_498 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_499 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_500 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_501 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_502 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_71 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_503 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    121\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08561\n",
      "Model:                       QuantReg   Bandwidth:                    0.005317\n",
      "Method:                 Least Squares   Sparsity:                       0.2246\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:08:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0290      0.008      3.578      0.000       0.013       0.045\n",
      "three_month_yield_change     -0.0970      0.211     -0.460      0.645      -0.510       0.316\n",
      "term_spread_change           -0.2672      0.189     -1.414      0.157      -0.638       0.103\n",
      "TED_spread                   -0.4905      0.795     -0.617      0.537      -2.049       1.068\n",
      "credit_spread_change         -0.3865      0.291     -1.330      0.184      -0.956       0.183\n",
      "market_return                -0.1203      0.106     -1.136      0.256      -0.328       0.087\n",
      "real_estate_excess_return     0.0195      0.137      0.143      0.887      -0.249       0.288\n",
      "equity_volatility             1.9552      0.197      9.929      0.000       1.569       2.341\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1904\n",
      "Model:                       QuantReg   Bandwidth:                    0.008418\n",
      "Method:                 Least Squares   Sparsity:                       0.8439\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:08:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0408      0.017      2.472      0.014       0.008       0.073\n",
      "three_month_yield_change     -0.1545      0.409     -0.378      0.705      -0.956       0.647\n",
      "term_spread_change           -0.3317      0.386     -0.859      0.391      -1.089       0.426\n",
      "TED_spread                   -0.4864      1.438     -0.338      0.735      -3.306       2.333\n",
      "credit_spread_change         -0.3864      0.585     -0.660      0.509      -1.534       0.762\n",
      "market_return                -0.5615      0.167     -3.370      0.001      -0.888      -0.235\n",
      "real_estate_excess_return    -0.2557      0.268     -0.954      0.340      -0.782       0.270\n",
      "equity_volatility             3.1790      0.291     10.932      0.000       2.609       3.749\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4070\n",
      "Model:                       QuantReg   Bandwidth:                    0.001949\n",
      "Method:                 Least Squares   Sparsity:                      0.07278\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:08:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0118      0.003      4.575      0.000       0.007       0.017\n",
      "three_month_yield_change     -0.0091      0.075     -0.122      0.903      -0.156       0.138\n",
      "term_spread_change           -0.1913      0.068     -2.818      0.005      -0.324      -0.058\n",
      "TED_spread                   -0.4743      0.287     -1.653      0.098      -1.037       0.088\n",
      "credit_spread_change         -0.1356      0.086     -1.576      0.115      -0.304       0.033\n",
      "market_return                 0.0641      0.040      1.590      0.112      -0.015       0.143\n",
      "real_estate_excess_return     0.0315      0.048      0.660      0.509      -0.062       0.125\n",
      "equity_volatility             0.6791      0.081      8.417      0.000       0.521       0.837\n",
      "institution                   0.4247      0.030     14.166      0.000       0.366       0.483\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4464\n",
      "Model:                       QuantReg   Bandwidth:                    0.004012\n",
      "Method:                 Least Squares   Sparsity:                       0.3426\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:08:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0231      0.005      4.574      0.000       0.013       0.033\n",
      "three_month_yield_change     -0.2040      0.140     -1.455      0.146      -0.479       0.071\n",
      "term_spread_change           -0.4859      0.151     -3.210      0.001      -0.783      -0.189\n",
      "TED_spread                   -0.9207      0.645     -1.427      0.154      -2.186       0.345\n",
      "credit_spread_change         -0.3302      0.181     -1.822      0.069      -0.685       0.025\n",
      "market_return                 0.0569      0.133      0.428      0.669      -0.204       0.318\n",
      "real_estate_excess_return     0.0275      0.111      0.247      0.805      -0.191       0.246\n",
      "equity_volatility             1.8046      0.215      8.389      0.000       1.383       2.226\n",
      "institution                   0.3532      0.110      3.220      0.001       0.138       0.568\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 35.5899 - val_loss: 34.3825\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 34.7132 - val_loss: 33.6854\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.9505 - val_loss: 32.9995\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.0012 - val_loss: 32.1203\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 32.1945 - val_loss: 31.2677\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 31.1729 - val_loss: 30.4263\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.3229 - val_loss: 29.6064\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.4768 - val_loss: 28.8311\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 28.6877 - val_loss: 28.0651\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 27.5507 - val_loss: 27.3520\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 27.3172 - val_loss: 26.7525\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 26.5050 - val_loss: 26.2044\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 26.0303 - val_loss: 25.7102\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.5145 - val_loss: 25.2792\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.1344 - val_loss: 24.9118\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 24.7104 - val_loss: 24.5874\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.3293 - val_loss: 24.2916\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 24.0896 - val_loss: 24.0242\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.7484 - val_loss: 23.7674\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.4125 - val_loss: 23.5201\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.2507 - val_loss: 23.3047\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 23.1496 - val_loss: 23.1210\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.9277 - val_loss: 22.9692\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.9185 - val_loss: 22.8323\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.8097 - val_loss: 22.7060\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.7175 - val_loss: 22.5966\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.6388 - val_loss: 22.4969\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3512 - val_loss: 22.4091\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.4460 - val_loss: 22.3293\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.4445 - val_loss: 22.2511\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.3148 - val_loss: 22.1810\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.3654 - val_loss: 22.1230\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.2444 - val_loss: 22.0741\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2728 - val_loss: 22.0336\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.2085 - val_loss: 22.0009\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.2350 - val_loss: 21.9720\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.2217 - val_loss: 21.9463\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.1099 - val_loss: 21.9243\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.0132 - val_loss: 21.9051\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 22.1342 - val_loss: 21.8873\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.0770 - val_loss: 21.8701\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.1045 - val_loss: 21.8539\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9080 - val_loss: 21.8388\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 6ms/step - loss: 22.0621 - val_loss: 21.8239\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9671 - val_loss: 21.8092\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9662 - val_loss: 21.7953\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9932 - val_loss: 21.7825\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9629 - val_loss: 21.7704\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9684 - val_loss: 21.7587\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7968 - val_loss: 21.7473\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 21.9318 - val_loss: 21.7361\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9149 - val_loss: 21.7250\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9226 - val_loss: 21.7142\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9139 - val_loss: 21.7037\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8724 - val_loss: 21.6935\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8862 - val_loss: 21.6834\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8660 - val_loss: 21.6739\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8610 - val_loss: 21.6647\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.8272 - val_loss: 21.6553\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7893 - val_loss: 21.6458\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6687 - val_loss: 21.6362\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7993 - val_loss: 21.6268\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7280 - val_loss: 21.6169\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7311 - val_loss: 21.6071\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7617 - val_loss: 21.5975\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7432 - val_loss: 21.5880\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7277 - val_loss: 21.5786\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.7218 - val_loss: 21.5690\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6735 - val_loss: 21.5588\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6931 - val_loss: 21.5485\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6591 - val_loss: 21.5380\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6262 - val_loss: 21.5274\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6612 - val_loss: 21.5168\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6043 - val_loss: 21.5062\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5975 - val_loss: 21.4953\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5826 - val_loss: 21.4845\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.6055 - val_loss: 21.4732\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4924 - val_loss: 21.4615\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5114 - val_loss: 21.4502\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5582 - val_loss: 21.4387\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4975 - val_loss: 21.4271\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4974 - val_loss: 21.4153\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4823 - val_loss: 21.4036\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5171 - val_loss: 21.3915\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5012 - val_loss: 21.3794\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4075 - val_loss: 21.3672\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4795 - val_loss: 21.3553\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4207 - val_loss: 21.3428\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4476 - val_loss: 21.3303\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.4267 - val_loss: 21.3174\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2961 - val_loss: 21.3049\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3632 - val_loss: 21.2922\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2506 - val_loss: 21.2798\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3726 - val_loss: 21.2671\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3659 - val_loss: 21.2545\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2218 - val_loss: 21.2415\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3502 - val_loss: 21.2289\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3427 - val_loss: 21.2161\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3212 - val_loss: 21.2032\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.2385 - val_loss: 21.1904\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_73 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_504 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_505 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_506 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_507 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_508 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_509 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_72 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_510 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 26.1846 - val_loss: 24.9880\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6586 - val_loss: 24.5874\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.2034 - val_loss: 24.2277\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7838 - val_loss: 23.8802\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.3698 - val_loss: 23.5389\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.0051 - val_loss: 23.2041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.3736 - val_loss: 22.8697\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1804 - val_loss: 22.5265\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7618 - val_loss: 22.1972\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.3291 - val_loss: 21.8735\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.9550 - val_loss: 21.5373\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5560 - val_loss: 21.1959\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0885 - val_loss: 20.8846\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8598 - val_loss: 20.5913\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5222 - val_loss: 20.3477\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2081 - val_loss: 20.1497\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9021 - val_loss: 19.9789\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.6947 - val_loss: 19.8488\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3663 - val_loss: 19.7410\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.3442 - val_loss: 19.6409\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.1838 - val_loss: 19.5426\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.0588 - val_loss: 19.4493\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.9872 - val_loss: 19.3680\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8835 - val_loss: 19.2968\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7880 - val_loss: 19.2347\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.7195 - val_loss: 19.1781\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6842 - val_loss: 19.1346\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6621 - val_loss: 19.0993\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6376 - val_loss: 19.0681\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6078 - val_loss: 19.0418\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5720 - val_loss: 19.0167\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4863 - val_loss: 18.9940\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.5397 - val_loss: 18.9724\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5015 - val_loss: 18.9505\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4983 - val_loss: 18.9295\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4159 - val_loss: 18.9110\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4382 - val_loss: 18.8917\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4419 - val_loss: 18.8729\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3700 - val_loss: 18.8544\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4181 - val_loss: 18.8363\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3839 - val_loss: 18.8192\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3492 - val_loss: 18.8024\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3457 - val_loss: 18.7864\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3591 - val_loss: 18.7706\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3102 - val_loss: 18.7548\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3224 - val_loss: 18.7394\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3160 - val_loss: 18.7235\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3035 - val_loss: 18.7079\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2517 - val_loss: 18.6934\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2809 - val_loss: 18.6784\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2617 - val_loss: 18.6637\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2531 - val_loss: 18.6488\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2438 - val_loss: 18.6339\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1990 - val_loss: 18.6196\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2212 - val_loss: 18.6053\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2017 - val_loss: 18.5907\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1343 - val_loss: 18.5763\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1758 - val_loss: 18.5616\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1433 - val_loss: 18.5480\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1565 - val_loss: 18.5336\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1301 - val_loss: 18.5195\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0829 - val_loss: 18.5059\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1191 - val_loss: 18.4914\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0819 - val_loss: 18.4776\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0674 - val_loss: 18.4635\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0572 - val_loss: 18.4495\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0653 - val_loss: 18.4352\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0360 - val_loss: 18.4213\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0353 - val_loss: 18.4072\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0015 - val_loss: 18.3928\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0157 - val_loss: 18.3782\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9973 - val_loss: 18.3638\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.9309 - val_loss: 18.3502\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9473 - val_loss: 18.3363\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9562 - val_loss: 18.3216\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9159 - val_loss: 18.3070\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7358 - val_loss: 18.2931\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8782 - val_loss: 18.2791\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8602 - val_loss: 18.2648\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8720 - val_loss: 18.2505\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8785 - val_loss: 18.2360\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8530 - val_loss: 18.2213\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8313 - val_loss: 18.2068\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8343 - val_loss: 18.1919\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7764 - val_loss: 18.1777\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7853 - val_loss: 18.1630\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7796 - val_loss: 18.1483\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7691 - val_loss: 18.1339\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7603 - val_loss: 18.1183\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7472 - val_loss: 18.1029\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7165 - val_loss: 18.0884\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7224 - val_loss: 18.0747\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7033 - val_loss: 18.0597\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6859 - val_loss: 18.0445\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6671 - val_loss: 18.0299\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6605 - val_loss: 18.0152\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6023 - val_loss: 18.0009\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6177 - val_loss: 17.9856\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6220 - val_loss: 17.9701\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6029 - val_loss: 17.9545\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_511 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_512 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_513 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_514 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_515 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_516 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_73 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_517 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    121\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1110\n",
      "Model:                       QuantReg   Bandwidth:                    0.004482\n",
      "Method:                 Least Squares   Sparsity:                       0.1758\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:09:32   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0081      0.007      1.222      0.222      -0.005       0.021\n",
      "three_month_yield_change      0.0803      0.171      0.469      0.639      -0.255       0.416\n",
      "term_spread_change           -0.0811      0.158     -0.513      0.608      -0.391       0.229\n",
      "TED_spread                   -0.4490      0.667     -0.673      0.501      -1.758       0.860\n",
      "credit_spread_change          0.0614      0.231      0.266      0.790      -0.391       0.514\n",
      "market_return                -0.1457      0.094     -1.545      0.123      -0.331       0.039\n",
      "real_estate_excess_return     0.0675      0.096      0.700      0.484      -0.122       0.257\n",
      "equity_volatility             1.9922      0.159     12.520      0.000       1.680       2.304\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1841\n",
      "Model:                       QuantReg   Bandwidth:                    0.007361\n",
      "Method:                 Least Squares   Sparsity:                       0.8990\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:09:32   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0390      0.016      2.491      0.013       0.008       0.070\n",
      "three_month_yield_change     -0.2236      0.469     -0.477      0.633      -1.143       0.696\n",
      "term_spread_change           -0.8906      0.425     -2.093      0.036      -1.725      -0.056\n",
      "TED_spread                   -1.1585      1.930     -0.600      0.548      -4.943       2.626\n",
      "credit_spread_change          0.1772      0.530      0.335      0.738      -0.861       1.216\n",
      "market_return                -0.0311      0.338     -0.092      0.927      -0.693       0.631\n",
      "real_estate_excess_return     0.0281      0.292      0.096      0.923      -0.544       0.600\n",
      "equity_volatility             2.3744      0.512      4.641      0.000       1.371       3.378\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4535\n",
      "Model:                       QuantReg   Bandwidth:                    0.001858\n",
      "Method:                 Least Squares   Sparsity:                      0.06109\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:09:32   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0113      0.002      5.573      0.000       0.007       0.015\n",
      "three_month_yield_change     -0.1268      0.056     -2.258      0.024      -0.237      -0.017\n",
      "term_spread_change           -0.1151      0.051     -2.254      0.024      -0.215      -0.015\n",
      "TED_spread                   -0.8392      0.221     -3.801      0.000      -1.272      -0.406\n",
      "credit_spread_change         -0.0522      0.076     -0.685      0.493      -0.202       0.097\n",
      "market_return                -0.0170      0.032     -0.539      0.590      -0.079       0.045\n",
      "real_estate_excess_return    -0.0353      0.038     -0.935      0.350      -0.109       0.039\n",
      "equity_volatility             0.5595      0.057      9.873      0.000       0.448       0.671\n",
      "institution                   0.5051      0.027     18.673      0.000       0.452       0.558\n",
      "=============================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5192\n",
      "Model:                       QuantReg   Bandwidth:                    0.003997\n",
      "Method:                 Least Squares   Sparsity:                       0.2794\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:09:32   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0353      0.004      8.103      0.000       0.027       0.044\n",
      "three_month_yield_change     -0.6728      0.131     -5.131      0.000      -0.930      -0.416\n",
      "term_spread_change           -0.5681      0.131     -4.347      0.000      -0.824      -0.312\n",
      "TED_spread                   -1.4926      0.448     -3.335      0.001      -2.370      -0.615\n",
      "credit_spread_change         -0.5342      0.159     -3.359      0.001      -0.846      -0.222\n",
      "market_return                -0.0123      0.107     -0.115      0.909      -0.223       0.198\n",
      "real_estate_excess_return    -0.0151      0.088     -0.173      0.863      -0.187       0.157\n",
      "equity_volatility             1.5311      0.173      8.852      0.000       1.192       1.870\n",
      "institution                   0.4448      0.100      4.444      0.000       0.249       0.641\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 34.3700 - val_loss: 29.2912\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 33.5188 - val_loss: 28.5840\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.4498 - val_loss: 27.9508\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.7155 - val_loss: 27.3308\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.8247 - val_loss: 26.7533\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.9310 - val_loss: 26.2146\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.1408 - val_loss: 25.6810\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.3054 - val_loss: 25.1587\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.5095 - val_loss: 24.6576\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.7920 - val_loss: 24.1683\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.0131 - val_loss: 23.7384\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.3029 - val_loss: 23.4001\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.6453 - val_loss: 23.0752\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.8534 - val_loss: 22.7579\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.4964 - val_loss: 22.4756\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0969 - val_loss: 22.2029\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6730 - val_loss: 21.9297\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.4288 - val_loss: 21.7157\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.1095 - val_loss: 21.5949\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.8538 - val_loss: 21.4983\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.6687 - val_loss: 21.4278\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.5056 - val_loss: 21.3831\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3864 - val_loss: 21.3523\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.3017 - val_loss: 21.3230\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.1982 - val_loss: 21.3017\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0593 - val_loss: 21.2902\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0039 - val_loss: 21.2866\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9707 - val_loss: 21.2877\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.9247 - val_loss: 21.2905\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8444 - val_loss: 21.2925\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.8038 - val_loss: 21.2942\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7791 - val_loss: 21.2951\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.7083 - val_loss: 21.2951\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6989 - val_loss: 21.2951\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6877 - val_loss: 21.2938\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6585 - val_loss: 21.2914\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6367 - val_loss: 21.2875\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6077 - val_loss: 21.2835\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5860 - val_loss: 21.2791\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.4550 - val_loss: 21.2742\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5516 - val_loss: 21.2696\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5229 - val_loss: 21.2645\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5078 - val_loss: 21.2588\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5099 - val_loss: 21.2526\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4775 - val_loss: 21.2462\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4874 - val_loss: 21.2398\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3568 - val_loss: 21.2323\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4138 - val_loss: 21.2249\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4208 - val_loss: 21.2175\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4131 - val_loss: 21.2094\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.4053 - val_loss: 21.2016\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3817 - val_loss: 21.1934\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3822 - val_loss: 21.1852\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3187 - val_loss: 21.1764\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3392 - val_loss: 21.1676\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3528 - val_loss: 21.1584\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2972 - val_loss: 21.1485\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3132 - val_loss: 21.1389\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.3036 - val_loss: 21.1290\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.3056 - val_loss: 21.1191\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2798 - val_loss: 21.1092\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2752 - val_loss: 21.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2533 - val_loss: 21.0884\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2414 - val_loss: 21.0778\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2160 - val_loss: 21.0672\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2368 - val_loss: 21.0569\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2107 - val_loss: 21.0460\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1582 - val_loss: 21.0348\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1432 - val_loss: 21.0238\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1895 - val_loss: 21.0130\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1619 - val_loss: 21.0020\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.1336 - val_loss: 20.9904\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1545 - val_loss: 20.9796\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1312 - val_loss: 20.9683\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0557 - val_loss: 20.9555\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.1144 - val_loss: 20.9440\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9223 - val_loss: 20.9322\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8230 - val_loss: 20.9202\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0796 - val_loss: 20.9090\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.0615 - val_loss: 20.8969\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8878 - val_loss: 20.8845\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0196 - val_loss: 20.8725\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0239 - val_loss: 20.8602\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9977 - val_loss: 20.8478\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9626 - val_loss: 20.8354\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9723 - val_loss: 20.8232\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.9814 - val_loss: 20.8109\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8325 - val_loss: 20.7977\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9377 - val_loss: 20.7853\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9278 - val_loss: 20.7725\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8203 - val_loss: 20.7580\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.9142 - val_loss: 20.7449\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8370 - val_loss: 20.7315\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8734 - val_loss: 20.7187\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8764 - val_loss: 20.7060\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8500 - val_loss: 20.6929\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7563 - val_loss: 20.6792\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8319 - val_loss: 20.6662\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7261 - val_loss: 20.6529\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.7501 - val_loss: 20.6389\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_518 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_519 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_520 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_521 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_522 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_523 (Conv1D)         (None, 7, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_74 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_524 (Conv1D)         (None, 1, 1)              193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  120\n",
      "   random_state  VaR_QRCDCNN_95_失败天数\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  124\n",
      "0             1                  117\n",
      "0             1                  128\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  119\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  121\n",
      "0             1                  121\n",
      "0             1                  127\n",
      "0             1                  120\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 25.8979 - val_loss: 24.7179\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.1583 - val_loss: 24.3061\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8633 - val_loss: 23.9255\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4363 - val_loss: 23.5590\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.9825 - val_loss: 23.2060\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.6442 - val_loss: 22.8494\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.1118 - val_loss: 22.4945\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.7763 - val_loss: 22.1424\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.2603 - val_loss: 21.8153\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.9481 - val_loss: 21.4773\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.5424 - val_loss: 21.1454\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.2204 - val_loss: 20.8439\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.8670 - val_loss: 20.5672\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5324 - val_loss: 20.3282\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.2037 - val_loss: 20.1358\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.8997 - val_loss: 19.9767\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 19.7192 - val_loss: 19.8328\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.5614 - val_loss: 19.7181\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.3438 - val_loss: 19.6270\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.2012 - val_loss: 19.5404\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.1395 - val_loss: 19.4586\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.0027 - val_loss: 19.3779\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.8845 - val_loss: 19.2990\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.8145 - val_loss: 19.2288\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.7261 - val_loss: 19.1690\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.6707 - val_loss: 19.1143\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.6305 - val_loss: 19.0636\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5904 - val_loss: 19.0191\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.5439 - val_loss: 18.9758\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3580 - val_loss: 18.9404\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4866 - val_loss: 18.9112\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.4489 - val_loss: 18.8848\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.4249 - val_loss: 18.8590\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3815 - val_loss: 18.8348\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3542 - val_loss: 18.8114\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2336 - val_loss: 18.7902\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.3141 - val_loss: 18.7695\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.3056 - val_loss: 18.7496\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2690 - val_loss: 18.7306\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2190 - val_loss: 18.7118\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1347 - val_loss: 18.6930\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2112 - val_loss: 18.6742\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.2009 - val_loss: 18.6570\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1861 - val_loss: 18.6392\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1924 - val_loss: 18.6223\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1721 - val_loss: 18.6054\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1730 - val_loss: 18.5885\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.1078 - val_loss: 18.5716\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1398 - val_loss: 18.5551\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1217 - val_loss: 18.5386\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0629 - val_loss: 18.5225\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.1016 - val_loss: 18.5059\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0650 - val_loss: 18.4904\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0447 - val_loss: 18.4746\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9005 - val_loss: 18.4587\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 18.0537 - val_loss: 18.4428\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 18.0008 - val_loss: 18.4272\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9839 - val_loss: 18.4127\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9956 - val_loss: 18.3971\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9657 - val_loss: 18.3831\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9802 - val_loss: 18.3679\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9677 - val_loss: 18.3526\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9302 - val_loss: 18.3378\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9357 - val_loss: 18.3225\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.9179 - val_loss: 18.3077\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8861 - val_loss: 18.2928\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8852 - val_loss: 18.2778\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8863 - val_loss: 18.2628\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8665 - val_loss: 18.2485\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7891 - val_loss: 18.2344\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.8466 - val_loss: 18.2197\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8333 - val_loss: 18.2048\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.8060 - val_loss: 18.1901\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6487 - val_loss: 18.1751\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.7966 - val_loss: 18.1601\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7271 - val_loss: 18.1457\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7659 - val_loss: 18.1308\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6041 - val_loss: 18.1162\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7084 - val_loss: 18.1011\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6694 - val_loss: 18.0862\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.7056 - val_loss: 18.0706\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6755 - val_loss: 18.0555\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6760 - val_loss: 18.0399\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6619 - val_loss: 18.0250\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6343 - val_loss: 18.0098\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5759 - val_loss: 17.9946\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.6153 - val_loss: 17.9789\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.6029 - val_loss: 17.9635\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5850 - val_loss: 17.9478\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.5087 - val_loss: 17.9321\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4980 - val_loss: 17.9173\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5012 - val_loss: 17.9022\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.5030 - val_loss: 17.8871\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.3817 - val_loss: 17.8719\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4970 - val_loss: 17.8562\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4717 - val_loss: 17.8410\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4547 - val_loss: 17.8255\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 17.4525 - val_loss: 17.8096\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4326 - val_loss: 17.7939\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 17.4186 - val_loss: 17.7783\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_525 (Conv1D)         (None, 8, 32)             96        \n",
      "                                                                 \n",
      " conv1d_526 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_527 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_528 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_529 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_530 (Conv1D)         (None, 8, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_75 (MaxPoolin  (None, 7, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_531 (Conv1D)         (None, 1, 1)              225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    124\n",
      "   random_state  CoVaR_QRCDCNN_95_失败天数\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    125\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    128\n",
      "0             1                    126\n",
      "0             1                    124\n",
      "0             1                    126\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    121\n",
      "0             1                    125\n",
      "0             1                    124\n",
      "0             1                    124\n",
      "0             1                    124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.05295\n",
      "Model:                       QuantReg   Bandwidth:                    0.004158\n",
      "Method:                 Least Squares   Sparsity:                       0.1678\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:10:30   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0134      0.006      2.233      0.026       0.002       0.025\n",
      "three_month_yield_change     -0.1084      0.150     -0.724      0.469      -0.402       0.185\n",
      "term_spread_change           -0.4033      0.144     -2.805      0.005      -0.685      -0.121\n",
      "TED_spread                   -0.2532      0.540     -0.469      0.639      -1.311       0.805\n",
      "credit_spread_change          0.3266      0.218      1.499      0.134      -0.101       0.754\n",
      "market_return                 0.0253      0.087      0.290      0.772      -0.146       0.196\n",
      "real_estate_excess_return     0.1478      0.091      1.627      0.104      -0.030       0.326\n",
      "equity_volatility             1.0913      0.174      6.286      0.000       0.751       1.432\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1382\n",
      "Model:                       QuantReg   Bandwidth:                    0.007126\n",
      "Method:                 Least Squares   Sparsity:                        1.033\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:10:30   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0335      0.017      2.031      0.042       0.001       0.066\n",
      "three_month_yield_change      0.2809      0.480      0.586      0.558      -0.660       1.221\n",
      "term_spread_change           -0.7357      0.442     -1.664      0.096      -1.603       0.131\n",
      "TED_spread                   -3.4017      1.773     -1.918      0.055      -6.879       0.075\n",
      "credit_spread_change          0.4311      0.539      0.800      0.424      -0.626       1.488\n",
      "market_return                 0.0987      0.353      0.280      0.780      -0.594       0.791\n",
      "real_estate_excess_return    -0.0464      0.326     -0.142      0.887      -0.686       0.593\n",
      "equity_volatility             2.4050      0.585      4.110      0.000       1.257       3.553\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4079\n",
      "Model:                       QuantReg   Bandwidth:                    0.002019\n",
      "Method:                 Least Squares   Sparsity:                      0.07436\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:10:30   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.003      2.336      0.020       0.001       0.012\n",
      "three_month_yield_change      0.0967      0.072      1.335      0.182      -0.045       0.239\n",
      "term_spread_change           -0.1046      0.063     -1.649      0.099      -0.229       0.020\n",
      "TED_spread                   -0.7498      0.290     -2.588      0.010      -1.318      -0.182\n",
      "credit_spread_change          0.1377      0.101      1.363      0.173      -0.060       0.336\n",
      "market_return                -0.0764      0.040     -1.904      0.057      -0.155       0.002\n",
      "real_estate_excess_return    -0.0967      0.045     -2.136      0.033      -0.185      -0.008\n",
      "equity_volatility             0.5211      0.072      7.268      0.000       0.380       0.662\n",
      "institution                   0.4908      0.037     13.207      0.000       0.418       0.564\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5170\n",
      "Model:                       QuantReg   Bandwidth:                    0.003627\n",
      "Method:                 Least Squares   Sparsity:                       0.2999\n",
      "Date:                Wed, 13 Sep 2023   No. Observations:                 2448\n",
      "Time:                        10:10:30   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0149      0.004      3.741      0.000       0.007       0.023\n",
      "three_month_yield_change      0.0614      0.117      0.525      0.600      -0.168       0.291\n",
      "term_spread_change           -0.0220      0.118     -0.186      0.853      -0.254       0.210\n",
      "TED_spread                   -0.8791      0.526     -1.672      0.095      -1.910       0.152\n",
      "credit_spread_change         -0.3428      0.157     -2.187      0.029      -0.650      -0.035\n",
      "market_return                -0.1409      0.107     -1.320      0.187      -0.350       0.068\n",
      "real_estate_excess_return    -0.1074      0.091     -1.182      0.238      -0.286       0.071\n",
      "equity_volatility             1.8555      0.194      9.568      0.000       1.475       2.236\n",
      "institution                   0.4419      0.112      3.948      0.000       0.222       0.661\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'E:\\华为电脑备份\\研究生的森活\\居超QRCDCNN论文\\数据\\日数据\\数据合并过程.xlsx', sheet_name='损失率+滞后',index_col='DATE')\n",
    "SP500=df.iloc[:,0]\n",
    "state_variable=df.iloc[:,39:]\n",
    "three_month_yield_change=df.iloc[:,39]\n",
    "term_spread_change=df.iloc[:,40]\n",
    "TED_spread=df.iloc[:,41]\n",
    "credit_spread_change=df.iloc[:,42]\n",
    "market_return=df.iloc[:,43]\n",
    "real_estate_excess_return=df.iloc[:,44]\n",
    "equity_volatility=df.iloc[:,45]\n",
    "\n",
    "VaR1_QRCDCNN_95=pd.DataFrame()\n",
    "VaR1_QRCDCNN_99=pd.DataFrame()\n",
    "CoVaR1_QRCDCNN_95=pd.DataFrame()\n",
    "CoVaR1_QRCDCNN_99=pd.DataFrame()\n",
    "concat_result1=pd.DataFrame()\n",
    "Dict2_VaR_QRCDCNN_95=pd.DataFrame()\n",
    "Dict2_CoVaR_QRCDCNN_95=pd.DataFrame()\n",
    "# Dict2_VaR_QRCDCNN_test_95=pd.DataFrame()\n",
    "# Dict2_CoVaR_QRCDCNN_test_95=pd.DataFrame()\n",
    "\n",
    "column_index=[]\n",
    "for i in range(1,39):\n",
    "# for i in range(1,2):\n",
    "    institution = df.iloc[:,i]\n",
    "\n",
    "    # VaR_95和VaR_95的估计\n",
    "\n",
    "    x = state_variable.to_numpy()\n",
    "    y=institution.to_numpy() #UNUM\n",
    "\n",
    "\n",
    "    for j in list(range(1,2)):\n",
    "#     for j in list(range(1,10000)):\n",
    "        # 首先将数据拆分为训练集和临时集（包含验证集和测试集）\n",
    "        x_train_95, x_temp, y_train_95, y_temp = train_test_split(x, y, test_size=0.1, random_state=j)\n",
    "\n",
    "        # 接着将临时集拆分为验证集和测试集\n",
    "        x_val_95, x_test_95, y_val_95, y_test_95 = train_test_split(x_temp, y_temp, test_size=0.5, random_state=j)\n",
    "\n",
    "        model_VaR_95,history_VaR_95 = qrcdcnn_VaR_95.model(x_train_95,y_train_95,x_val_95,y_val_95)\n",
    "\n",
    "        a_test = model_VaR_95.predict(x_test_95)\n",
    "        b_test=a_test.reshape(a_test.shape[0],1)\n",
    "        VaR_QRCDCNN_test_95 = pd.DataFrame(b_test)\n",
    " \n",
    "        sxc_VaR_QRCDCNN_test_95 = 0\n",
    "        for k in range(len(y_test_95)):\n",
    "            if y_test_95[k] > VaR_QRCDCNN_test_95[0][k]:\n",
    "                sxc_VaR_QRCDCNN_test_95+=1\n",
    "        Dict1_VaR_QRCDCNN_test_95=pd.DataFrame([sxc_VaR_QRCDCNN_test_95])\n",
    "#         Dict2_VaR_QRCDCNN_test_95=pd.concat([ Dict2_VaR_QRCDCNN_test_95, Dict1_VaR_QRCDCNN_test_95],axis=0)\n",
    "\n",
    "        \n",
    "        # a = model.predict([[-57642]])\n",
    "        a = model_VaR_95.predict(x)\n",
    "        print('a.shape',np.shape(a))\n",
    "        print(model_VaR_95.summary())\n",
    "        b=a.reshape(a.shape[0],1)\n",
    "        b.shape\n",
    "        VaR_QRCDCNN_95 = pd.DataFrame(b)\n",
    " \n",
    "        sxc_VaR_QRCDCNN_95 = 0\n",
    "        for k in range(len(y)):\n",
    "            if y[k] > VaR_QRCDCNN_95[0][k]:\n",
    "                sxc_VaR_QRCDCNN_95+=1\n",
    "#         print(sxc_VaR_QRCDCNN_95)\n",
    "\n",
    "        Dict_VaR_QRCDCNN_95 =[j,sxc_VaR_QRCDCNN_95]\n",
    "#         print(Dict_VaR_QRCDCNN_95)\n",
    "        if 122<= Dict_VaR_QRCDCNN_95[1]<=123:\n",
    "            Dict1_VaR_QRCDCNN_95=pd.DataFrame([Dict_VaR_QRCDCNN_95],columns=['random_state','VaR_QRCDCNN_95_失败天数'])\n",
    "            VaR1_QRCDCNN_95=pd.concat([VaR1_QRCDCNN_95,VaR_QRCDCNN_95],axis=1)\n",
    "            break\n",
    "        else:\n",
    "            Dict1_VaR_QRCDCNN_95=pd.DataFrame([Dict_VaR_QRCDCNN_95],columns=['random_state','VaR_QRCDCNN_95_失败天数'])\n",
    "            print(Dict1_VaR_QRCDCNN_95)\n",
    "            Dict2_VaR_QRCDCNN_95=pd.concat([ Dict2_VaR_QRCDCNN_95, Dict1_VaR_QRCDCNN_95],axis=0)\n",
    "            print(Dict2_VaR_QRCDCNN_95)\n",
    "    sxc1_VaR_QRCDCNN_95_random=Dict1_VaR_QRCDCNN_95.iloc[0,0]\n",
    "    sxc1_VaR_QRCDCNN_95=Dict1_VaR_QRCDCNN_95.iloc[0,1]\n",
    " \n",
    " \n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "#         x_train_99, x_test_99, y_train_99, y_test_99 = train_test_split(x,y,random_state=j)\n",
    "#         model_VaR_99,history_VaR_99 = qrcdcnn_VaR_99.model(x_train_99,y_train_99,x_test_99,y_test_99)\n",
    "\n",
    "\n",
    "#         # a = model.predict([[-57642]])\n",
    "#         a = model_VaR_99.predict(x)\n",
    "#         print('a.shape',np.shape(a))\n",
    "#         print(model_VaR_99.summary())\n",
    "#         b=a.reshape(a.shape[0],1)\n",
    "#         b.shape\n",
    "#         VaR_QRCDCNN_99 = pd.DataFrame(b)\n",
    "\n",
    "#         sxc_VaR_QRCDCNN_99 = 0\n",
    "#         for k in range(len(y)):\n",
    "#             if y[k] > VaR_QRCDCNN_99[0][k]:\n",
    "#                 sxc_VaR_QRCDCNN_99+=1\n",
    "# #         print('sxc_VaR_QRCDCNN_99',sxc_VaR_QRCDCNN_99)\n",
    "\n",
    "#         Dict_VaR_QRCDCNN_99 =[j,sxc_VaR_QRCDCNN_99]\n",
    "# #         print(Dict_VaR_QRCDCNN_99)\n",
    "#         if 24<= Dict_VaR_QRCDCNN_99[1]<=25:\n",
    "#             Dict1_VaR_QRCDCNN_99=pd.DataFrame([Dict_VaR_QRCDCNN_99],columns=['random_state','VaR_QRCDCNN_99_失败天数'])\n",
    "#             VaR1_QRCDCNN_99=pd.concat([VaR1_QRCDCNN_99,VaR_QRCDCNN_99],axis=1)\n",
    "#             break\n",
    "#         else:\n",
    "#             Dict1_VaR_QRCDCNN_99=pd.DataFrame([Dict_VaR_QRCDCNN_99],columns=['random_state','VaR_QRCDCNN_99_失败天数'])\n",
    "#             print(Dict1_VaR_QRCDCNN_99)\n",
    "#             Dict2_VaR_QRCDCNN_99=pd.concat([ Dict2_VaR_QRCDCNN_99, Dict1_VaR_QRCDCNN_99],axis=0)\n",
    "#             print(Dict2_VaR_QRCDCNN_99)\n",
    "#     sxc1_VaR_QRCDCNN_99_random=Dict1_VaR_QRCDCNN_99.iloc[0,0]\n",
    "#     sxc1_VaR_QRCDCNN_99=Dict1_VaR_QRCDCNN_99.iloc[0,1]\n",
    "\n",
    "\n",
    "    # CoVaR_95和CoVaR_99的估计\n",
    "\n",
    "    concat = pd.concat([state_variable,institution],axis=1)\n",
    "     # 把两个数据框合并起来，合并方式为按列合并\n",
    "    x2=concat.to_numpy()[:,0:]\n",
    "    y2=SP500.to_numpy()\n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "    for j in list(range(1,2)):        \n",
    "        # 首先将数据拆分为训练集和临时集（包含验证集和测试集）\n",
    "        x2_train_95, x2_temp, y2_train_95, y2_temp = train_test_split(x2, y2, test_size=0.1, random_state=j)\n",
    "\n",
    "        # 接着将临时集拆分为验证集和测试集\n",
    "        x2_val_95, x2_test_95, y2_val_95, y2_test_95 = train_test_split(x2_temp, y2_temp, test_size=0.5, random_state=j)\n",
    "\n",
    "        model_CoVaR_95,history_CoVaR_95 = qrcdcnn_CoVaR_95.model(x2_train_95,y2_train_95,x2_val_95,y2_val_95)\n",
    "\n",
    "        a2_test = model_CoVaR_95.predict(x2_test_95)\n",
    "        a2 = model_CoVaR_95.predict(x2)\n",
    "        print('a2.shape',np.shape(a2))\n",
    "        print(model_CoVaR_95.summary())\n",
    "        \n",
    "        \n",
    "        b2_test=a2_test.reshape(a2_test.shape[0],1)\n",
    "        b2=a2.reshape(a2.shape[0],1)\n",
    "        b2.shape\n",
    "        CoVaR_QRCDCNN_95 = pd.DataFrame(b2)\n",
    "        CoVaR_QRCDCNN_test_95 = pd.DataFrame(b2_test)\n",
    "        \n",
    "        sxc_CoVaR_QRCDCNN_test_95 = 0\n",
    "        for k in range(len(y2_test_95)):\n",
    "            if  y2_test_95[k] > CoVaR_QRCDCNN_test_95[0][k]:\n",
    "                sxc_CoVaR_QRCDCNN_test_95+=1        \n",
    "        Dict1_CoVaR_QRCDCNN_test_95=pd.DataFrame([sxc_CoVaR_QRCDCNN_test_95])\n",
    "#         Dict2_CoVaR_QRCDCNN_test_95=pd.concat([ Dict2_CoVaR_QRCDCNN_test_95, Dict1_CoVaR_QRCDCNN_test_95],axis=0)\n",
    "\n",
    "\n",
    "        sxc_CoVaR_QRCDCNN_95 = 0\n",
    "        for k in range(len(y2)):\n",
    "            if  y2[k] > CoVaR_QRCDCNN_95[0][k]:\n",
    "                sxc_CoVaR_QRCDCNN_95+=1\n",
    "#         print('sxc_CoVaR_QRCDCNN_95',sxc_CoVaR_QRCDCNN_95)\n",
    "\n",
    "        Dict_CoVaR_QRCDCNN_95 =[j,sxc_CoVaR_QRCDCNN_95]\n",
    "#         print(Dict_CoVaR_QRCDCNN_95)\n",
    "        if 122<= Dict_CoVaR_QRCDCNN_95[1]<=123:\n",
    "            Dict1_CoVaR_QRCDCNN_95=pd.DataFrame([Dict_CoVaR_QRCDCNN_95],columns=['random_state','CoVaR_QRCDCNN_95_失败天数'])\n",
    "            CoVaR1_QRCDCNN_95=pd.concat([CoVaR1_QRCDCNN_95,CoVaR_QRCDCNN_95],axis=1)\n",
    "            break\n",
    "        else:\n",
    "            Dict1_CoVaR_QRCDCNN_95=pd.DataFrame([Dict_CoVaR_QRCDCNN_95],columns=['random_state','CoVaR_QRCDCNN_95_失败天数'])\n",
    "            print(Dict1_CoVaR_QRCDCNN_95)\n",
    "            Dict2_CoVaR_QRCDCNN_95=pd.concat([ Dict2_CoVaR_QRCDCNN_95, Dict1_CoVaR_QRCDCNN_95],axis=0)\n",
    "            print(Dict2_CoVaR_QRCDCNN_95)\n",
    "    sxc1_CoVaR_QRCDCNN_95_random=Dict1_CoVaR_QRCDCNN_95.iloc[0,0]   \n",
    "    sxc1_CoVaR_QRCDCNN_95=Dict1_CoVaR_QRCDCNN_95.iloc[0,1]\n",
    "    \n",
    "\n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "#         x2_train_99, x2_test_99, y2_train_99, y2_test_99 = train_test_split(x2,y2,random_state=j)\n",
    "#         model_CoVaR_99,history_CoVaR_99 = qrcdcnn_CoVaR_99.model(x2_train_99,y2_train_99,x2_test_99,y2_test_99)\n",
    "\n",
    "\n",
    "#         a2 = model_CoVaR_99.predict(x2)\n",
    "#         print('a2.shape',np.shape(a2))\n",
    "#         print(model_CoVaR_99.summary())\n",
    "#         b2=a2.reshape(a2.shape[0],1)\n",
    "#         b2.shape\n",
    "#         CoVaR_QRCDCNN_99 = pd.DataFrame(b2)\n",
    "        \n",
    "\n",
    "#         sxc_CoVaR_QRCDCNN_99 = 0\n",
    "#         for k in range(len(y2)):\n",
    "#             if  y2[k] > CoVaR_QRCDCNN_99[0][k]:\n",
    "#                 sxc_CoVaR_QRCDCNN_99+=1\n",
    "#         print('sxc_CoVaR_QRCDCNN_99',sxc_CoVaR_QRCDCNN_99)\n",
    "\n",
    "#         Dict_CoVaR_QRCDCNN_99 =[j,sxc_CoVaR_QRCDCNN_99]\n",
    "#         print(Dict_CoVaR_QRCDCNN_99)\n",
    "#         if 24<= Dict_CoVaR_QRCDCNN_99[1]<=25:\n",
    "#             Dict1_CoVaR_QRCDCNN_99=pd.DataFrame([Dict_CoVaR_QRCDCNN_99],columns=['random_state','CoVaR_QRCDCNN_99_失败天数'])\n",
    "#             CoVaR1_QRCDCNN_99=pd.concat([CoVaR1_QRCDCNN_99,CoVaR_QRCDCNN_99],axis=1)\n",
    "#             break\n",
    "#         else:\n",
    "#             Dict1_CoVaR_QRCDCNN_99=pd.DataFrame([Dict_CoVaR_QRCDCNN_99],columns=['random_state','CoVaR_QRCDCNN_99_失败天数'])\n",
    "#             print(Dict1_CoVaR_QRCDCNN_99)\n",
    "#             Dict2_CoVaR_QRCDCNN_99=pd.concat([ Dict2_CoVaR_QRCDCNN_99, Dict1_CoVaR_QRCDCNN_99],axis=0)\n",
    "#             print(Dict2_CoVaR_QRCDCNN_99)\n",
    "            \n",
    "    \n",
    "#     sxc1_CoVaR_QRCDCNN_99_random=Dict1_CoVaR_QRCDCNN_99.iloc[0,0]\n",
    "#     sxc1_CoVaR_QRCDCNN_99=Dict1_CoVaR_QRCDCNN_99.iloc[0,1]\n",
    "\n",
    "\n",
    "    ## 线性分位数回归\n",
    "\n",
    "    import statsmodels.formula.api as smf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    mod_VaR_95 = smf.quantreg('institution ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility',df)\n",
    "    res_VaR_95 = mod_VaR_95.fit(q=0.95)\n",
    "    print(res_VaR_95.summary())\n",
    "\n",
    "    VaR_linear_95= res_VaR_95.params['Intercept']+ three_month_yield_change*res_VaR_95.params['three_month_yield_change'] + term_spread_change*res_VaR_95.params['term_spread_change']+ TED_spread*res_VaR_95.params['TED_spread']+ credit_spread_change*res_VaR_95.params['credit_spread_change']+ market_return*res_VaR_95.params['market_return']+ real_estate_excess_return*res_VaR_95.params['real_estate_excess_return']+ equity_volatility*res_VaR_95.params['equity_volatility']\n",
    "\n",
    "    sxc_VaR_linear_95 = 0\n",
    "    for k in range(len(y)):\n",
    "        if   y[k] > VaR_linear_95[k]:\n",
    "            sxc_VaR_linear_95+=1\n",
    "    print('sxc_VaR_linear_95',sxc_VaR_linear_95)\n",
    "\n",
    "    mod_VaR_99 = smf.quantreg('institution ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility',df)\n",
    "    res_VaR_99 = mod_VaR_99.fit(q=0.99)\n",
    "    print(res_VaR_99.summary())\n",
    "\n",
    "    VaR_linear_99= res_VaR_99.params['Intercept']+ three_month_yield_change*res_VaR_99.params['three_month_yield_change'] + term_spread_change*res_VaR_99.params['term_spread_change']+ TED_spread*res_VaR_99.params['TED_spread']+ credit_spread_change*res_VaR_99.params['credit_spread_change']+ market_return*res_VaR_99.params['market_return']+ real_estate_excess_return*res_VaR_99.params['real_estate_excess_return']+ equity_volatility*res_VaR_99.params['equity_volatility']\n",
    "\n",
    "    sxc_VaR_linear_99 = 0\n",
    "    for k in range(len(y)):\n",
    "        if   y[k] > VaR_linear_99[k]:\n",
    "            sxc_VaR_linear_99+=1\n",
    "    print('sxc_VaR_linear_99',sxc_VaR_linear_99)\n",
    "\n",
    "    mod_CoVaR_95 = smf.quantreg('SP500 ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility+institution',df)\n",
    "    res_CoVaR_95 = mod_CoVaR_95.fit(q=0.95)\n",
    "    print(res_CoVaR_95.summary())\n",
    "\n",
    "    CoVaR_linear_95= res_CoVaR_95.params['Intercept']+ three_month_yield_change*res_CoVaR_95.params['three_month_yield_change'] + term_spread_change*res_CoVaR_95.params['term_spread_change']+ TED_spread*res_CoVaR_95.params['TED_spread']+ credit_spread_change*res_CoVaR_95.params['credit_spread_change']+ market_return*res_CoVaR_95.params['market_return']+ real_estate_excess_return*res_CoVaR_95.params['real_estate_excess_return']+ equity_volatility*res_CoVaR_95.params['equity_volatility']+institution*res_CoVaR_95.params['institution']\n",
    "\n",
    "    sxc_CoVaR_linear_95 = 0\n",
    "    for k in range(len(y)):\n",
    "        if y2[k] > CoVaR_linear_95[k]:\n",
    "            sxc_CoVaR_linear_95+=1\n",
    "    print('sxc_CoVaR_linear_95',sxc_CoVaR_linear_95)\n",
    "\n",
    "    mod_CoVaR_99 = smf.quantreg('SP500 ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility+institution',df)\n",
    "    res_CoVaR_99 = mod_CoVaR_99.fit(q=0.99)\n",
    "    print(res_CoVaR_99.summary())\n",
    "\n",
    "    CoVaR_linear_99= res_CoVaR_99.params['Intercept']+ three_month_yield_change*res_CoVaR_99.params['three_month_yield_change'] + term_spread_change*res_CoVaR_99.params['term_spread_change']+ TED_spread*res_CoVaR_99.params['TED_spread']+ credit_spread_change*res_CoVaR_99.params['credit_spread_change']+ market_return*res_CoVaR_99.params['market_return']+ real_estate_excess_return*res_CoVaR_99.params['real_estate_excess_return']+ equity_volatility*res_CoVaR_99.params['equity_volatility']+institution*res_CoVaR_99.params['institution']\n",
    "\n",
    "    sxc_CoVaR_linear_99 = 0\n",
    "    for k in range(len(y)):\n",
    "        if y2[k] > CoVaR_linear_99[k]:\n",
    "            sxc_CoVaR_linear_99+=1\n",
    "    print('sxc_CoVaR_linear_99',sxc_CoVaR_linear_99)\n",
    "\n",
    "    Dict_95={'VaR_QRCDCNN_95_random':[sxc1_VaR_QRCDCNN_95_random],'VaR_QRCDCNN_test_95_失败天数':[sxc_VaR_QRCDCNN_test_95],'VaR_QRCDCNN_95_失败天数':[sxc1_VaR_QRCDCNN_95],'CoVaR_QRCDCNN_95_random':[sxc1_CoVaR_QRCDCNN_95_random],'CoVaR_QRCDCNN_test_95_失败天数':[sxc_CoVaR_QRCDCNN_test_95],'CoVaR_QRCDCNN_95_失败天数':[sxc1_CoVaR_QRCDCNN_95],'VaR_linear_95_失败天数':[sxc_VaR_linear_95],'CoVaR_linear_95_失败天数':[sxc_CoVaR_linear_95]}\n",
    "    result_95 = pd.DataFrame(Dict_95)\n",
    "    result_95\n",
    "\n",
    "#     Dict_99={'VaR_QRCDCNN_99_random':[sxc1_VaR_QRCDCNN_99_random],'VaR_QRCDCNN_99_失败天数':[sxc1_VaR_QRCDCNN_99],'CoVaR_QRCDCNN_99_random':[sxc1_CoVaR_QRCDCNN_99_random],'CoVaR_QRCDCNN_99_失败天数':[sxc1_CoVaR_QRCDCNN_99],'VaR_linear_99_失败天数':[sxc_VaR_linear_99],'CoVaR_linear_99_失败天数':[sxc_CoVaR_linear_99]}\n",
    "#     result_99 = pd.DataFrame(Dict_99)\n",
    "#     result_99\n",
    "\n",
    "#     concat_result = pd.concat([result_95,result_99],axis=1)\n",
    "    concat_result = pd.concat([result_95],axis=1)\n",
    "    concat_result1= pd.concat([concat_result1,concat_result],axis=0)\n",
    "    column_index.append(df.columns.values[i])\n",
    "    concat_result1.index=column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sxc_VaR_QRCDCNN_test_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_95))\n",
    "print(len(x2_test_95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.17773739,  0.01280549,  0.26466388, -0.12089658,\n",
       "           0.06346208, -0.14311224,  0.2462566 , -0.27934328,\n",
       "          -0.16388889, -0.15845047,  0.06515131,  0.19348593,\n",
       "           0.0235221 ,  0.18184395,  0.06392086, -0.14863005,\n",
       "           0.09892517,  0.23508814, -0.28408048,  0.26319516,\n",
       "           0.12771927,  0.06384887, -0.19996399, -0.04893092,\n",
       "          -0.04587531,  0.21666814, -0.20666353,  0.2701893 ,\n",
       "           0.25342718,  0.02375046,  0.13457501,  0.03708208]],\n",
       " \n",
       "        [[ 0.09895109, -0.19237877, -0.12398288,  0.05563317,\n",
       "          -0.15366353,  0.0499001 , -0.1040637 ,  0.13819231,\n",
       "           0.19085105, -0.12022215,  0.06051289, -0.10350098,\n",
       "          -0.07623843, -0.05129499, -0.03946599,  0.20035504,\n",
       "          -0.07303669,  0.09960873, -0.19455115,  0.02219025,\n",
       "           0.2589891 , -0.0213261 , -0.00698112, -0.26454705,\n",
       "          -0.2741682 , -0.22205   ,  0.1713341 ,  0.2684727 ,\n",
       "          -0.18453194,  0.24351984,  0.03583041, -0.18879144]]],\n",
       "       dtype=float32),\n",
       " array([[[ 9.49213877e-02, -9.57705174e-03, -1.04825655e-02, ...,\n",
       "           2.02921301e-01,  1.60390571e-01,  3.69876648e-06],\n",
       "         [-1.73368473e-02, -1.70641944e-01, -1.60493419e-01, ...,\n",
       "          -1.41474575e-01, -5.47601506e-02,  1.27167121e-01],\n",
       "         [-1.13676481e-01,  1.19435422e-01,  7.82260206e-03, ...,\n",
       "          -1.95826128e-01, -4.01484445e-02, -6.07795955e-04],\n",
       "         ...,\n",
       "         [-1.30597353e-01,  7.03020245e-02, -1.46545142e-01, ...,\n",
       "           1.06173225e-01,  9.03081074e-02, -7.75201470e-02],\n",
       "         [ 8.66175741e-02, -1.09402157e-01,  4.60186861e-02, ...,\n",
       "          -9.78464354e-03, -6.54782057e-02, -1.87332630e-01],\n",
       "         [ 1.44121975e-01, -1.12949556e-06, -1.07230872e-01, ...,\n",
       "          -1.83007509e-01,  1.51185021e-01, -4.67695855e-02]],\n",
       " \n",
       "        [[-3.66160013e-02,  7.13073136e-03,  6.01763800e-02, ...,\n",
       "          -1.64978690e-02, -1.98201433e-01, -1.63650811e-01],\n",
       "         [-1.67651296e-01, -1.15971141e-01, -5.37459776e-02, ...,\n",
       "           1.93001747e-01, -6.80314377e-03, -1.59330830e-01],\n",
       "         [-4.98705870e-03,  7.12058470e-02,  1.12594306e-01, ...,\n",
       "          -5.08771501e-02,  1.22563444e-01,  3.11488044e-02],\n",
       "         ...,\n",
       "         [ 2.03102335e-01,  2.98821124e-06, -2.04364717e-01, ...,\n",
       "          -1.42210290e-01,  1.02965429e-01,  2.75940318e-02],\n",
       "         [-8.94280821e-02,  3.11689023e-02, -1.98731467e-01, ...,\n",
       "           2.04722926e-01,  1.82513505e-01,  8.26656446e-02],\n",
       "         [-1.72421515e-01, -1.15448818e-01,  2.78128441e-02, ...,\n",
       "          -9.42813233e-02,  2.19692383e-02, -1.39946893e-01]]],\n",
       "       dtype=float32),\n",
       " array([[[-2.76010744e-02, -1.81259900e-01,  1.18903190e-01, ...,\n",
       "           2.05754077e-06,  6.64267763e-02, -1.75640166e-01],\n",
       "         [-8.39280710e-02,  5.60327545e-02, -6.39584735e-02, ...,\n",
       "           5.91243543e-02,  2.49521008e-06,  1.94960341e-01],\n",
       "         [-1.24215573e-01, -5.44856749e-02, -9.18310359e-02, ...,\n",
       "          -1.10137157e-01, -2.85187289e-02,  1.48493946e-01],\n",
       "         ...,\n",
       "         [-1.59093902e-01,  6.60250410e-02,  3.27844355e-05, ...,\n",
       "           1.61375016e-01, -4.96597998e-02,  8.89006630e-02],\n",
       "         [-1.30403429e-01,  1.90511972e-01,  9.14599448e-02, ...,\n",
       "           9.09010395e-02, -1.75375015e-01, -7.38470107e-02],\n",
       "         [ 9.51395109e-02,  4.52136919e-02,  5.24841696e-02, ...,\n",
       "          -1.11585986e-02,  8.51553753e-02,  1.47070989e-01]],\n",
       " \n",
       "        [[ 7.19092712e-02, -1.24227464e-01,  1.66659817e-01, ...,\n",
       "          -9.19112042e-02,  1.83151424e-01,  1.60700001e-04],\n",
       "         [-3.77607867e-02, -4.51911464e-02,  1.78471301e-02, ...,\n",
       "           1.53444558e-01, -1.11805573e-02,  1.46215588e-01],\n",
       "         [ 3.31139788e-02,  1.45278931e-01, -5.22428006e-02, ...,\n",
       "           1.44108161e-01,  3.98201272e-02,  1.89054146e-01],\n",
       "         ...,\n",
       "         [-4.14618896e-03, -2.31081294e-03,  2.19121978e-01, ...,\n",
       "          -1.15066282e-01, -1.27702862e-01, -1.03830689e-06],\n",
       "         [ 6.97096959e-02, -1.03034325e-01, -1.09731779e-01, ...,\n",
       "           1.07250422e-01, -1.61779463e-01,  7.16697425e-02],\n",
       "         [-1.69602960e-01, -8.90133977e-02, -4.71926145e-02, ...,\n",
       "           2.36084010e-03,  1.49228930e-01, -3.84423099e-02]]],\n",
       "       dtype=float32),\n",
       " array([[[-5.4405954e-02,  1.4051688e-01, -6.2935367e-02, ...,\n",
       "          -3.6127751e-03,  1.1248707e-03,  1.5757437e-01],\n",
       "         [ 1.4271055e-01, -1.0604890e-01,  1.2661332e-01, ...,\n",
       "           1.8583763e-01,  1.7477293e-01, -1.1285969e-01],\n",
       "         [ 1.1489989e-01, -1.8157296e-01,  1.5276065e-01, ...,\n",
       "           1.1097543e-01, -8.7785713e-02,  4.0440816e-02],\n",
       "         ...,\n",
       "         [ 1.4380128e-02, -2.8478598e-02, -1.1465033e-02, ...,\n",
       "           1.2693901e-01,  1.2007290e-01,  2.6785202e-02],\n",
       "         [-2.0071827e-01, -4.6675447e-02, -1.5315676e-01, ...,\n",
       "           2.7497554e-02,  8.0190070e-02,  1.0936397e-01],\n",
       "         [-1.8691492e-01, -1.5307659e-01,  2.0801210e-06, ...,\n",
       "           4.9960926e-02,  2.7976705e-02,  1.5328817e-01]],\n",
       " \n",
       "        [[-1.8363120e-01, -7.7815771e-02, -7.2093613e-02, ...,\n",
       "          -8.8636287e-02,  5.3457540e-02, -1.8377686e-01],\n",
       "         [-9.5035629e-03, -4.2334948e-02,  1.6260168e-01, ...,\n",
       "           2.4396842e-02, -8.3767802e-02, -1.7090498e-01],\n",
       "         [-1.1989495e-02,  3.8040370e-02, -1.7712301e-01, ...,\n",
       "           1.1156288e-01,  2.1540359e-01,  2.0628054e-01],\n",
       "         ...,\n",
       "         [ 9.2651464e-02,  3.9541665e-06,  8.7730937e-02, ...,\n",
       "          -7.0738405e-02, -8.8761143e-02, -1.7824231e-01],\n",
       "         [ 1.5062864e-01, -2.0838913e-01, -5.2314017e-02, ...,\n",
       "           1.1192151e-01,  1.0389297e-01,  7.1258716e-02],\n",
       "         [ 8.7025285e-02,  7.5858027e-02,  4.0904548e-02, ...,\n",
       "          -1.2884131e-01, -9.9514328e-02,  8.2099050e-02]]], dtype=float32),\n",
       " array([[[-4.62261327e-02, -1.30099356e-01,  1.46318927e-01, ...,\n",
       "          -1.91458076e-01, -1.58718750e-01,  1.01320378e-01],\n",
       "         [-1.06197700e-03,  1.12226993e-01,  1.82300478e-01, ...,\n",
       "           6.26116060e-03, -1.54683426e-01,  1.25369867e-02],\n",
       "         [-1.22455940e-01, -6.78326339e-02,  2.02115506e-01, ...,\n",
       "           9.15982276e-02,  9.12233591e-02, -5.13471588e-02],\n",
       "         ...,\n",
       "         [ 1.25984594e-01, -1.80926293e-01,  1.84330881e-01, ...,\n",
       "          -1.41662106e-01,  1.88982725e-01,  1.44186676e-01],\n",
       "         [ 8.45147148e-02, -2.34190859e-02,  1.93402752e-01, ...,\n",
       "          -4.42687310e-02, -1.13933831e-01,  1.23500928e-01],\n",
       "         [-1.42861605e-01,  7.28962943e-02, -1.30381465e-01, ...,\n",
       "          -1.66459709e-01,  3.02616507e-02, -1.44242040e-06]],\n",
       " \n",
       "        [[ 1.17952757e-01, -1.88666135e-01, -2.02579513e-01, ...,\n",
       "          -7.36197410e-03, -1.68685526e-01,  1.64970726e-01],\n",
       "         [ 1.73776180e-01,  1.65331647e-01,  1.79315761e-01, ...,\n",
       "           8.20725411e-02,  4.82817069e-02,  1.40676796e-02],\n",
       "         [ 5.60084097e-02,  7.39199892e-02, -2.74524726e-02, ...,\n",
       "           1.48756415e-01,  8.65901336e-02, -2.22914815e-02],\n",
       "         ...,\n",
       "         [ 1.88324451e-01,  8.40572491e-02, -1.58956140e-01, ...,\n",
       "          -1.12806894e-01, -7.88355693e-02,  1.80606470e-02],\n",
       "         [ 1.67493239e-01,  9.46186185e-02,  1.14649720e-01, ...,\n",
       "           8.13312307e-02, -6.65998384e-02, -2.93668881e-02],\n",
       "         [ 2.15727031e-01,  9.85511690e-02, -7.97464699e-02, ...,\n",
       "          -5.59155680e-02, -4.20681313e-02, -1.13573395e-01]]],\n",
       "       dtype=float32),\n",
       " array([[[ 0.10383074, -0.15548195,  0.05766829, ..., -0.03233206,\n",
       "           0.13002822, -0.01184391],\n",
       "         [ 0.1331243 ,  0.05660055, -0.01470002, ..., -0.06153904,\n",
       "           0.12883908,  0.01549965],\n",
       "         [-0.13648568, -0.19377802, -0.17662883, ..., -0.06372313,\n",
       "           0.02414226, -0.10135958],\n",
       "         ...,\n",
       "         [-0.10491046,  0.05343499,  0.09184612, ..., -0.196695  ,\n",
       "          -0.00043894, -0.06849205],\n",
       "         [-0.19903982, -0.04664234,  0.06961803, ..., -0.02434217,\n",
       "           0.14783692, -0.01436296],\n",
       "         [-0.12381589, -0.06250565,  0.04869693, ...,  0.11316839,\n",
       "          -0.20473906,  0.07286958]],\n",
       " \n",
       "        [[ 0.15580894,  0.02237567,  0.05950733, ..., -0.0081139 ,\n",
       "          -0.12724778,  0.03032314],\n",
       "         [-0.2111508 , -0.21295449,  0.12016706, ..., -0.10634302,\n",
       "          -0.19742696,  0.08763526],\n",
       "         [-0.13485916,  0.20107958,  0.18416217, ...,  0.18998118,\n",
       "           0.11226842,  0.12019919],\n",
       "         ...,\n",
       "         [ 0.06110431, -0.059356  ,  0.0277668 , ..., -0.05936405,\n",
       "          -0.00147971, -0.00079901],\n",
       "         [-0.11751964,  0.17660853, -0.18679687, ..., -0.10569588,\n",
       "          -0.11962583, -0.03175791],\n",
       "         [-0.01760083, -0.21181463,  0.00559535, ...,  0.05075192,\n",
       "           0.02176225,  0.07575022]]], dtype=float32),\n",
       " array([[[-1.38138935e-01],\n",
       "         [ 1.53142780e-01],\n",
       "         [ 1.66055724e-01],\n",
       "         [-9.35690477e-03],\n",
       "         [ 1.22249626e-01],\n",
       "         [ 1.23404332e-01],\n",
       "         [-5.15445648e-03],\n",
       "         [-1.22525841e-02],\n",
       "         [ 4.59899679e-02],\n",
       "         [-6.24120720e-02],\n",
       "         [-1.26890928e-01],\n",
       "         [-1.03535891e-01],\n",
       "         [-1.66016966e-01],\n",
       "         [ 1.44321620e-01],\n",
       "         [ 6.37654364e-02],\n",
       "         [ 4.82222438e-02],\n",
       "         [ 1.29900500e-01],\n",
       "         [ 4.97304201e-02],\n",
       "         [ 1.04062468e-01],\n",
       "         [ 1.13231018e-01],\n",
       "         [ 9.00746137e-02],\n",
       "         [-1.17661422e-02],\n",
       "         [ 8.66852701e-02],\n",
       "         [ 9.79819242e-03],\n",
       "         [-1.22754514e-01],\n",
       "         [-1.62510931e-01],\n",
       "         [-1.25692979e-01],\n",
       "         [-6.92688823e-02],\n",
       "         [ 1.00168690e-01],\n",
       "         [ 8.70906487e-02],\n",
       "         [ 1.41092435e-01],\n",
       "         [ 1.66419461e-01]],\n",
       " \n",
       "        [[ 1.01726308e-01],\n",
       "         [-1.64792210e-01],\n",
       "         [ 1.46795914e-01],\n",
       "         [-6.23187385e-02],\n",
       "         [ 1.00175381e-01],\n",
       "         [-3.79179604e-02],\n",
       "         [ 7.63117149e-02],\n",
       "         [-1.04248233e-01],\n",
       "         [ 5.23567805e-03],\n",
       "         [-1.38822749e-01],\n",
       "         [-7.56817684e-02],\n",
       "         [ 3.34466062e-02],\n",
       "         [ 5.71212284e-02],\n",
       "         [-1.47180751e-01],\n",
       "         [-1.25496060e-01],\n",
       "         [ 4.94077504e-02],\n",
       "         [ 6.31808341e-02],\n",
       "         [ 1.43726528e-01],\n",
       "         [-5.44254072e-02],\n",
       "         [-8.08777511e-02],\n",
       "         [-1.66749023e-02],\n",
       "         [-7.91805238e-02],\n",
       "         [-3.92648391e-02],\n",
       "         [-1.38659612e-04],\n",
       "         [-4.67348769e-02],\n",
       "         [-1.03769572e-02],\n",
       "         [ 2.35465467e-02],\n",
       "         [-1.21791869e-01],\n",
       "         [-6.41057119e-02],\n",
       "         [ 1.73655108e-01],\n",
       "         [-1.48193777e-01],\n",
       "         [ 1.04361512e-01]],\n",
       " \n",
       "        [[-7.51136392e-02],\n",
       "         [-1.37311921e-01],\n",
       "         [ 1.39902666e-01],\n",
       "         [ 4.23831604e-02],\n",
       "         [-1.38462797e-01],\n",
       "         [ 5.38626220e-03],\n",
       "         [-1.20943278e-01],\n",
       "         [-1.52538165e-01],\n",
       "         [ 4.69493642e-02],\n",
       "         [ 2.57181190e-02],\n",
       "         [-1.01325579e-01],\n",
       "         [ 3.16032059e-02],\n",
       "         [-9.97478887e-02],\n",
       "         [ 1.32460982e-01],\n",
       "         [ 9.72065181e-02],\n",
       "         [ 3.13227624e-02],\n",
       "         [ 9.75625068e-02],\n",
       "         [ 1.28772870e-01],\n",
       "         [-1.65961370e-01],\n",
       "         [ 8.03252507e-04],\n",
       "         [ 1.17056832e-01],\n",
       "         [ 1.60141021e-01],\n",
       "         [ 1.15820095e-01],\n",
       "         [ 1.52807802e-01],\n",
       "         [ 8.71138126e-02],\n",
       "         [-1.60225153e-01],\n",
       "         [ 1.86361670e-02],\n",
       "         [ 2.51048803e-02],\n",
       "         [-8.98806900e-02],\n",
       "         [-1.05287191e-02],\n",
       "         [-1.18492484e-01],\n",
       "         [ 1.34916708e-01]],\n",
       " \n",
       "        [[-3.49178538e-02],\n",
       "         [ 7.24512991e-03],\n",
       "         [ 1.50084823e-01],\n",
       "         [ 1.62693217e-01],\n",
       "         [ 1.49569795e-01],\n",
       "         [-1.26477435e-01],\n",
       "         [-1.24751851e-02],\n",
       "         [ 7.22490251e-03],\n",
       "         [ 7.26507157e-02],\n",
       "         [ 8.98996964e-02],\n",
       "         [ 1.18986107e-01],\n",
       "         [-2.91529577e-02],\n",
       "         [ 5.37146106e-02],\n",
       "         [ 4.32028808e-02],\n",
       "         [-3.72510068e-02],\n",
       "         [-2.92147361e-02],\n",
       "         [-3.40581010e-03],\n",
       "         [-1.67976052e-01],\n",
       "         [-1.22492194e-01],\n",
       "         [ 2.03623120e-02],\n",
       "         [ 1.26771167e-01],\n",
       "         [ 1.59537718e-01],\n",
       "         [-1.01424210e-01],\n",
       "         [ 1.36438921e-01],\n",
       "         [ 4.58982475e-02],\n",
       "         [-4.10191044e-02],\n",
       "         [-1.38125464e-01],\n",
       "         [ 6.67333603e-04],\n",
       "         [ 4.42906283e-03],\n",
       "         [-3.00192740e-02],\n",
       "         [ 1.80366281e-02],\n",
       "         [ 1.46191344e-01]],\n",
       " \n",
       "        [[-1.24439657e-01],\n",
       "         [ 1.17521062e-01],\n",
       "         [-1.24584787e-01],\n",
       "         [-1.48085549e-01],\n",
       "         [-1.34465799e-01],\n",
       "         [-3.94253992e-02],\n",
       "         [-7.42051527e-02],\n",
       "         [ 1.25860661e-01],\n",
       "         [ 1.57229856e-01],\n",
       "         [ 1.71617389e-01],\n",
       "         [-1.45489171e-01],\n",
       "         [ 4.09468450e-02],\n",
       "         [-4.75603994e-03],\n",
       "         [ 2.88985930e-02],\n",
       "         [ 1.12221032e-01],\n",
       "         [ 1.12290844e-01],\n",
       "         [-9.91715193e-02],\n",
       "         [-8.71618837e-02],\n",
       "         [-9.86950356e-04],\n",
       "         [ 7.93476701e-02],\n",
       "         [ 3.58547792e-02],\n",
       "         [ 1.76836446e-01],\n",
       "         [-7.83245862e-02],\n",
       "         [ 1.06475629e-01],\n",
       "         [ 8.37112591e-02],\n",
       "         [-9.29848477e-02],\n",
       "         [ 1.29350573e-01],\n",
       "         [-1.39722019e-01],\n",
       "         [ 1.39566690e-01],\n",
       "         [-1.08537123e-01],\n",
       "         [ 1.62356988e-01],\n",
       "         [ 7.25674778e-02]],\n",
       " \n",
       "        [[ 9.37641785e-02],\n",
       "         [-9.47679430e-02],\n",
       "         [ 1.81720093e-01],\n",
       "         [ 1.35495096e-01],\n",
       "         [-1.35525437e-02],\n",
       "         [-2.07685567e-02],\n",
       "         [-9.81371701e-02],\n",
       "         [-1.00602508e-02],\n",
       "         [-1.25052094e-01],\n",
       "         [-1.54653832e-01],\n",
       "         [ 1.67138219e-01],\n",
       "         [ 1.18023641e-01],\n",
       "         [ 1.52282000e-01],\n",
       "         [ 1.00426890e-01],\n",
       "         [ 2.94771176e-02],\n",
       "         [ 4.05348241e-02],\n",
       "         [ 6.17280304e-02],\n",
       "         [ 1.00857697e-01],\n",
       "         [ 1.44636244e-01],\n",
       "         [-4.77031292e-03],\n",
       "         [-1.22257601e-03],\n",
       "         [-5.99427372e-02],\n",
       "         [-1.59093544e-01],\n",
       "         [-1.18183352e-01],\n",
       "         [-4.79224771e-02],\n",
       "         [-9.71115306e-02],\n",
       "         [-2.68112123e-03],\n",
       "         [-2.12140381e-03],\n",
       "         [ 1.37723431e-01],\n",
       "         [-7.82692209e-02],\n",
       "         [-2.38981023e-02],\n",
       "         [ 1.57847345e-01]]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers = [layer for layer in model_VaR_95.layers if isinstance(layer, tf.keras.layers.Conv1D)]\n",
    "conv_weights = [layer.get_weights()[0] for layer in conv_layers]\n",
    "conv_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1d_518', (2, 1, 32)),\n",
       " ('conv1d_519', (2, 32, 32)),\n",
       " ('conv1d_520', (2, 32, 32)),\n",
       " ('conv1d_521', (2, 32, 32)),\n",
       " ('conv1d_522', (2, 32, 32)),\n",
       " ('conv1d_523', (2, 32, 32)),\n",
       " ('conv1d_524', (6, 32, 1))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers_dimensions = [(layer.name, layer.get_weights()[0].shape) for layer in conv_layers]\n",
    "conv_layers_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VaR_QRCDCNN_95_random</th>\n",
       "      <th>VaR_QRCDCNN_test_95_失败天数</th>\n",
       "      <th>VaR_QRCDCNN_95_失败天数</th>\n",
       "      <th>CoVaR_QRCDCNN_95_random</th>\n",
       "      <th>CoVaR_QRCDCNN_test_95_失败天数</th>\n",
       "      <th>CoVaR_QRCDCNN_95_失败天数</th>\n",
       "      <th>VaR_linear_95_失败天数</th>\n",
       "      <th>CoVaR_linear_95_失败天数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>纽约梅隆银行(BNY MELLON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国银行(BANK OF AMERICA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>花旗集团(CITIGROUP):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>联信银行(COMERICA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>亨廷顿银行(HUNTINGTON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩根大通(JPMORGAN CHASE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>制造商和贸易商银行(M&amp;T BANK):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNC金融服务:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>道富银行(STATE STREET):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>富国银行(WELLS FARGO):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>齐昂银行(ZIONS BANCORP):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>高盛集团(GOLDMAN SACHS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩根士丹利(MORGAN STANLEY):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嘉信理财(CHARLES SCHWAB):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>普信金融(T ROWE PRICE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国家庭人寿保险(AFLAC):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好事达保险(ALLSTATE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>怡安保险(AON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERKLEY W R:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信诺保险(CIGNA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN金融:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丘博保险(CHUBB):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>辛辛那提金融(CINCINNATI):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>哈门那(HUMANA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>林肯国民(LINCOLN NATIONAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>洛斯保险(LOEWS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>威达信(MARSH &amp; MCLENNAN):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBIA:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>前进保险(THE PROGRESSIVE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNUM保险:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国运通(AMERICAN EXPRESS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>五三银行(FIFTH THIRD):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEI INVESTMENTS:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>联合太平洋(UNION PACIFIC):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         VaR_QRCDCNN_95_random  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                  1   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                               1   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                     1   \n",
       "联信银行(COMERICA):收盘价(前复权)                                      1   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                   1   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                1   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                 1   \n",
       "PNC金融服务:收盘价(前复权)                                             1   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                  1   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                           1   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                   1   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                 1   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                 1   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                               1   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                1   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                  1   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                     1   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                     1   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                      1   \n",
       "怡安保险(AON):收盘价(前复权)                                           1   \n",
       "BERKLEY W R:收盘价(前复权)                                         1   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                         1   \n",
       "CAN金融:收盘价(前复权)                                               1   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                         1   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                  1   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                        1   \n",
       "哈门那(HUMANA):收盘价(前复权)                                         1   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                              1   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                         1   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                               1   \n",
       "MBIA:收盘价(前复权)                                                1   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                               1   \n",
       "UNUM保险:收盘价(前复权)                                              1   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                              1   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                   1   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                          1   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                     1   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                1   \n",
       "\n",
       "                                         VaR_QRCDCNN_test_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                     2   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                                  5   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                        6   \n",
       "联信银行(COMERICA):收盘价(前复权)                                         4   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                      5   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                   6   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                    5   \n",
       "PNC金融服务:收盘价(前复权)                                                6   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                     4   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                              4   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                      5   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                    5   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                    7   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                                  5   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                   4   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                     6   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                        7   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                        5   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                         5   \n",
       "怡安保险(AON):收盘价(前复权)                                              8   \n",
       "BERKLEY W R:收盘价(前复权)                                            4   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                            7   \n",
       "CAN金融:收盘价(前复权)                                                  4   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                            5   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                     5   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                           4   \n",
       "哈门那(HUMANA):收盘价(前复权)                                            5   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                                 4   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                            4   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                                  5   \n",
       "MBIA:收盘价(前复权)                                                   4   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                                  9   \n",
       "UNUM保险:收盘价(前复权)                                                 3   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                                 4   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                      4   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                             8   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                        5   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                   2   \n",
       "\n",
       "                                         VaR_QRCDCNN_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                              121   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                           124   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                 123   \n",
       "联信银行(COMERICA):收盘价(前复权)                                  124   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                               122   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                            124   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                             122   \n",
       "PNC金融服务:收盘价(前复权)                                         123   \n",
       "道富银行(STATE STREET):收盘价(前复权)                              124   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                       121   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                               121   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                             123   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                             124   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                           123   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                            117   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                              122   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                 128   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                 123   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                  126   \n",
       "怡安保险(AON):收盘价(前复权)                                       126   \n",
       "BERKLEY W R:收盘价(前复权)                                     119   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                     126   \n",
       "CAN金融:收盘价(前复权)                                           126   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                     123   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                              123   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                    122   \n",
       "哈门那(HUMANA):收盘价(前复权)                                     126   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                          121   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                     121   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                           122   \n",
       "MBIA:收盘价(前复权)                                            122   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                           123   \n",
       "UNUM保险:收盘价(前复权)                                          122   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                          127   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                               122   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                      123   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                 123   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                            120   \n",
       "\n",
       "                                         CoVaR_QRCDCNN_95_random  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                    1   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                                 1   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                       1   \n",
       "联信银行(COMERICA):收盘价(前复权)                                        1   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                     1   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                  1   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                   1   \n",
       "PNC金融服务:收盘价(前复权)                                               1   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                    1   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                             1   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                     1   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                   1   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                   1   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                                 1   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                  1   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                    1   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                       1   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                       1   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                        1   \n",
       "怡安保险(AON):收盘价(前复权)                                             1   \n",
       "BERKLEY W R:收盘价(前复权)                                           1   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                           1   \n",
       "CAN金融:收盘价(前复权)                                                 1   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                           1   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                    1   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                          1   \n",
       "哈门那(HUMANA):收盘价(前复权)                                           1   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                                1   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                           1   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                                 1   \n",
       "MBIA:收盘价(前复权)                                                  1   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                                 1   \n",
       "UNUM保险:收盘价(前复权)                                                1   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                                1   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                     1   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                            1   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                       1   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                  1   \n",
       "\n",
       "                                         CoVaR_QRCDCNN_test_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                       6   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                                    6   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                          5   \n",
       "联信银行(COMERICA):收盘价(前复权)                                           5   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                        5   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                     6   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                      5   \n",
       "PNC金融服务:收盘价(前复权)                                                  6   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                       6   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                                6   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                        6   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                      6   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                      5   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                                    6   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                     5   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                       5   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                          5   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                          6   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                           6   \n",
       "怡安保险(AON):收盘价(前复权)                                                6   \n",
       "BERKLEY W R:收盘价(前复权)                                              6   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                              6   \n",
       "CAN金融:收盘价(前复权)                                                    6   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                              5   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                       6   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                             6   \n",
       "哈门那(HUMANA):收盘价(前复权)                                              5   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                                   5   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                              6   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                                    5   \n",
       "MBIA:收盘价(前复权)                                                     5   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                                    6   \n",
       "UNUM保险:收盘价(前复权)                                                   5   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                                   6   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                        5   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                               6   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                          6   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                     6   \n",
       "\n",
       "                                         CoVaR_QRCDCNN_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                126   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                             125   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                   125   \n",
       "联信银行(COMERICA):收盘价(前复权)                                    123   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                 123   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                              124   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                               123   \n",
       "PNC金融服务:收盘价(前复权)                                           124   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                126   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                         126   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                 124   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                               124   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                               123   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                             125   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                              123   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                123   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                   123   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                   126   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                    125   \n",
       "怡安保险(AON):收盘价(前复权)                                         124   \n",
       "BERKLEY W R:收盘价(前复权)                                       124   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                       128   \n",
       "CAN金融:收盘价(前复权)                                             126   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                       123   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                124   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                      126   \n",
       "哈门那(HUMANA):收盘价(前复权)                                       125   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                            124   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                       124   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                             124   \n",
       "MBIA:收盘价(前复权)                                              123   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                             124   \n",
       "UNUM保险:收盘价(前复权)                                            121   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                            125   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                 123   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                        124   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                   124   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                              124   \n",
       "\n",
       "                                         VaR_linear_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                             125   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                          126   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                125   \n",
       "联信银行(COMERICA):收盘价(前复权)                                 127   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                              125   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                           126   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                            126   \n",
       "PNC金融服务:收盘价(前复权)                                        127   \n",
       "道富银行(STATE STREET):收盘价(前复权)                             127   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                      126   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                              127   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                            125   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                            124   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                          126   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                           127   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                             124   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                126   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                125   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                 126   \n",
       "怡安保险(AON):收盘价(前复权)                                      126   \n",
       "BERKLEY W R:收盘价(前复权)                                    125   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                    126   \n",
       "CAN金融:收盘价(前复权)                                          126   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                    125   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                             126   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                   126   \n",
       "哈门那(HUMANA):收盘价(前复权)                                    126   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                         127   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                    124   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                          126   \n",
       "MBIA:收盘价(前复权)                                           125   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                          127   \n",
       "UNUM保险:收盘价(前复权)                                         125   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                         126   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                              125   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                     125   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                127   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                           126   \n",
       "\n",
       "                                         CoVaR_linear_95_失败天数  \n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                               126  \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                            126  \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                  127  \n",
       "联信银行(COMERICA):收盘价(前复权)                                   127  \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                128  \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                             127  \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                              126  \n",
       "PNC金融服务:收盘价(前复权)                                          127  \n",
       "道富银行(STATE STREET):收盘价(前复权)                               127  \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                        127  \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                126  \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                              127  \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                              127  \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                            125  \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                             128  \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                               126  \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                  125  \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                  128  \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                   127  \n",
       "怡安保险(AON):收盘价(前复权)                                        127  \n",
       "BERKLEY W R:收盘价(前复权)                                      125  \n",
       "信诺保险(CIGNA):收盘价(前复权)                                      125  \n",
       "CAN金融:收盘价(前复权)                                            127  \n",
       "丘博保险(CHUBB):收盘价(前复权)                                      126  \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                               127  \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                     126  \n",
       "哈门那(HUMANA):收盘价(前复权)                                      126  \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                           125  \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                      126  \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                            127  \n",
       "MBIA:收盘价(前复权)                                             127  \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                            126  \n",
       "UNUM保险:收盘价(前复权)                                           127  \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                           125  \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                126  \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                       126  \n",
       "SEI INVESTMENTS:收盘价(前复权)                                  126  \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                             128  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VaR_QRCDCNN_95_random           1.000000\n",
       "VaR_QRCDCNN_test_95_失败天数        5.000000\n",
       "VaR_QRCDCNN_95_失败天数           122.947368\n",
       "CoVaR_QRCDCNN_95_random         1.000000\n",
       "CoVaR_QRCDCNN_test_95_失败天数      5.605263\n",
       "CoVaR_QRCDCNN_95_失败天数         124.236842\n",
       "VaR_linear_95_失败天数            125.763158\n",
       "CoVaR_linear_95_失败天数          126.447368\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VaR_QRCDCNN_95_random         0.000000\n",
       "VaR_QRCDCNN_test_95_失败天数      1.506742\n",
       "VaR_QRCDCNN_95_失败天数           2.204999\n",
       "CoVaR_QRCDCNN_95_random       0.000000\n",
       "CoVaR_QRCDCNN_test_95_失败天数    0.495355\n",
       "CoVaR_QRCDCNN_95_失败天数         1.303513\n",
       "VaR_linear_95_失败天数            0.883305\n",
       "CoVaR_linear_95_失败天数          0.891321\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_result1.to_excel(\"concat_result1_QRCDCNN.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('VaR_CoVaR.xlsx') as writer:\n",
    "    VaR1_QRCDCNN_95.to_excel(writer,sheet_name=\"VaR1_QRCDCNN_95\", index=False)\n",
    "    VaR1_QRCDCNN_99.to_excel(writer,sheet_name='VaR1_QRCDCNN_99', index=False)\n",
    "    CoVaR1_QRCDCNN_95.to_excel(writer,sheet_name='CoVaR1_QRCDCNN_95', index=False)\n",
    "    CoVaR1_QRCDCNN_99.to_excel(writer,sheet_name='CoVaR1_QRCDCNN_99', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
