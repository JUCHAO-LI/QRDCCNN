{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import qrcnn_VaR_95\n",
    "import qrcnn_CoVaR_95\n",
    "import qrcnn_VaR_99\n",
    "import qrcnn_CoVaR_99\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams['figure.dpi'] = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 33.7209 - val_loss: 35.8534\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.7826 - val_loss: 34.8270\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.5114 - val_loss: 33.5417\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.4186 - val_loss: 32.5132\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.4827 - val_loss: 31.5297\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.6242 - val_loss: 30.6062\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.7461 - val_loss: 29.7130\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.1441 - val_loss: 28.8279\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3980 - val_loss: 27.9412\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7080 - val_loss: 27.0520\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.8907 - val_loss: 26.1263\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4782 - val_loss: 25.3221\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9707 - val_loss: 24.6531\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6094 - val_loss: 24.0778\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2687 - val_loss: 23.6034\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0590 - val_loss: 23.2225\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8045 - val_loss: 22.9026\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6897 - val_loss: 22.6408\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5678 - val_loss: 22.4287\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3680 - val_loss: 22.2617\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3659 - val_loss: 22.1226\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2969 - val_loss: 22.0120\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0218 - val_loss: 21.9217\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1883 - val_loss: 21.8442\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1430 - val_loss: 21.7732\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0895 - val_loss: 21.7145\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0797 - val_loss: 21.6560\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9128 - val_loss: 21.6025\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9660 - val_loss: 21.5500\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9842 - val_loss: 21.4984\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9640 - val_loss: 21.4517\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9427 - val_loss: 21.4069\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9142 - val_loss: 21.3671\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9007 - val_loss: 21.3296\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8364 - val_loss: 21.2940\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8111 - val_loss: 21.2623\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8466 - val_loss: 21.2299\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7305 - val_loss: 21.2012\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8214 - val_loss: 21.1729\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7936 - val_loss: 21.1479\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5955 - val_loss: 21.1251\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7690 - val_loss: 21.1020\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6692 - val_loss: 21.0811\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7034 - val_loss: 21.0606\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7491 - val_loss: 21.0392\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7244 - val_loss: 21.0205\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7064 - val_loss: 21.0046\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7057 - val_loss: 20.9878\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6432 - val_loss: 20.9719\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6824 - val_loss: 20.9548\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6228 - val_loss: 20.9379\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6795 - val_loss: 20.9212\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6539 - val_loss: 20.9073\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6399 - val_loss: 20.8942\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6312 - val_loss: 20.8797\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6369 - val_loss: 20.8661\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5230 - val_loss: 20.8537\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3247 - val_loss: 20.8415\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5844 - val_loss: 20.8279\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5927 - val_loss: 20.8155\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5767 - val_loss: 20.8029\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5385 - val_loss: 20.7913\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5791 - val_loss: 20.7792\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5087 - val_loss: 20.7682\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5431 - val_loss: 20.7554\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4744 - val_loss: 20.7444\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5208 - val_loss: 20.7329\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5077 - val_loss: 20.7208\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4957 - val_loss: 20.7090\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4743 - val_loss: 20.6976\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4181 - val_loss: 20.6861\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4623 - val_loss: 20.6742\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4638 - val_loss: 20.6628\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4358 - val_loss: 20.6514\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4266 - val_loss: 20.6392\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4300 - val_loss: 20.6273\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4112 - val_loss: 20.6156\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3807 - val_loss: 20.6055\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3890 - val_loss: 20.5941\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2706 - val_loss: 20.5829\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3181 - val_loss: 20.5725\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3470 - val_loss: 20.5609\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3006 - val_loss: 20.5502\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2906 - val_loss: 20.5403\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3415 - val_loss: 20.5285\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3262 - val_loss: 20.5172\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3186 - val_loss: 20.5056\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3059 - val_loss: 20.4935\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2920 - val_loss: 20.4821\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2626 - val_loss: 20.4710\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2230 - val_loss: 20.4598\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2595 - val_loss: 20.4482\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9946 - val_loss: 20.4363\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2280 - val_loss: 20.4251\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1991 - val_loss: 20.4142\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1827 - val_loss: 20.4023\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1815 - val_loss: 20.3920\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1850 - val_loss: 20.3799\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1641 - val_loss: 20.3695\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1668 - val_loss: 20.3577\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 634us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.7824 - val_loss: 23.6355\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0146 - val_loss: 23.1085\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3207 - val_loss: 22.6533\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9489 - val_loss: 22.2575\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4790 - val_loss: 21.8750\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8646 - val_loss: 21.4527\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5051 - val_loss: 21.0826\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1055 - val_loss: 20.7775\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7501 - val_loss: 20.5489\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4220 - val_loss: 20.3734\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1320 - val_loss: 20.2264\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0071 - val_loss: 20.1045\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6990 - val_loss: 20.0063\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5167 - val_loss: 19.9197\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5412 - val_loss: 19.8422\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4520 - val_loss: 19.7669\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3658 - val_loss: 19.6965\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1768 - val_loss: 19.6270\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1803 - val_loss: 19.5634\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0447 - val_loss: 19.5069\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0112 - val_loss: 19.4570\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9882 - val_loss: 19.4114\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9682 - val_loss: 19.3696\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9286 - val_loss: 19.3334\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8904 - val_loss: 19.3018\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8623 - val_loss: 19.2727\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8052 - val_loss: 19.2479\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7692 - val_loss: 19.2243\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7268 - val_loss: 19.2020\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7545 - val_loss: 19.1806\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6485 - val_loss: 19.1604\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7254 - val_loss: 19.1411\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7073 - val_loss: 19.1233\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6882 - val_loss: 19.1065\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6322 - val_loss: 19.0903\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6661 - val_loss: 19.0744\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6549 - val_loss: 19.0589\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6248 - val_loss: 19.0442\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6302 - val_loss: 19.0288\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5714 - val_loss: 19.0148\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6081 - val_loss: 19.0005\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5965 - val_loss: 18.9866\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4281 - val_loss: 18.9739\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5380 - val_loss: 18.9607\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5705 - val_loss: 18.9474\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5657 - val_loss: 18.9341\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4630 - val_loss: 18.9221\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5357 - val_loss: 18.9093\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5322 - val_loss: 18.8975\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5200 - val_loss: 18.8858\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4982 - val_loss: 18.8744\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4262 - val_loss: 18.8635\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4947 - val_loss: 18.8517\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4860 - val_loss: 18.8408\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4623 - val_loss: 18.8299\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4695 - val_loss: 18.8193\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4544 - val_loss: 18.8080\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4457 - val_loss: 18.7975\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2405 - val_loss: 18.7871\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4120 - val_loss: 18.7771\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3588 - val_loss: 18.7668\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4076 - val_loss: 18.7559\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3882 - val_loss: 18.7458\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3700 - val_loss: 18.7354\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3276 - val_loss: 18.7248\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3237 - val_loss: 18.7148\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2604 - val_loss: 18.7049\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3501 - val_loss: 18.6937\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3398 - val_loss: 18.6832\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3213 - val_loss: 18.6728\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3158 - val_loss: 18.6617\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2613 - val_loss: 18.6513\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2979 - val_loss: 18.6400\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2850 - val_loss: 18.6289\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2573 - val_loss: 18.6181\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2230 - val_loss: 18.6071\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1899 - val_loss: 18.5970\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2428 - val_loss: 18.5861\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2331 - val_loss: 18.5745\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2197 - val_loss: 18.5640\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1701 - val_loss: 18.5524\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1756 - val_loss: 18.5420\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1817 - val_loss: 18.5310\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1773 - val_loss: 18.5200\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1686 - val_loss: 18.5087\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1615 - val_loss: 18.4982\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1519 - val_loss: 18.4871\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1025 - val_loss: 18.4771\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1037 - val_loss: 18.4662\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1156 - val_loss: 18.4556\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1074 - val_loss: 18.4444\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0949 - val_loss: 18.4331\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0794 - val_loss: 18.4217\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0601 - val_loss: 18.4109\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0590 - val_loss: 18.3995\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0351 - val_loss: 18.3889\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9913 - val_loss: 18.3778\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0323 - val_loss: 18.3672\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9871 - val_loss: 18.3566\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0036 - val_loss: 18.3453\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 732us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.07896\n",
      "Model:                       QuantReg   Bandwidth:                    0.004705\n",
      "Method:                 Least Squares   Sparsity:                       0.1960\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:22   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0141      0.007      2.010      0.045       0.000       0.028\n",
      "three_month_yield_change     -0.0970      0.179     -0.541      0.589      -0.448       0.255\n",
      "term_spread_change           -0.2263      0.174     -1.298      0.195      -0.568       0.116\n",
      "TED_spread                   -1.3790      0.644     -2.141      0.032      -2.642      -0.116\n",
      "credit_spread_change          0.1997      0.241      0.830      0.407      -0.272       0.671\n",
      "market_return                -0.0307      0.113     -0.273      0.785      -0.252       0.190\n",
      "real_estate_excess_return     0.0082      0.122      0.068      0.946      -0.230       0.247\n",
      "equity_volatility             1.8422      0.177     10.425      0.000       1.496       2.189\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1721\n",
      "Model:                       QuantReg   Bandwidth:                    0.007368\n",
      "Method:                 Least Squares   Sparsity:                       0.9761\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:22   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0352      0.015      2.279      0.023       0.005       0.065\n",
      "three_month_yield_change     -0.1741      0.388     -0.449      0.654      -0.935       0.587\n",
      "term_spread_change           -0.5989      0.408     -1.468      0.142      -1.399       0.201\n",
      "TED_spread                    0.6866      1.534      0.448      0.654      -2.322       3.695\n",
      "credit_spread_change         -0.2230      0.506     -0.441      0.659      -1.215       0.769\n",
      "market_return                 0.1486      0.381      0.390      0.696      -0.598       0.895\n",
      "real_estate_excess_return     0.0163      0.322      0.051      0.960      -0.616       0.648\n",
      "equity_volatility             2.7940      0.580      4.815      0.000       1.656       3.932\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4219\n",
      "Model:                       QuantReg   Bandwidth:                    0.002100\n",
      "Method:                 Least Squares   Sparsity:                      0.07287\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:22   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0193      0.003      7.538      0.000       0.014       0.024\n",
      "three_month_yield_change     -0.1857      0.074     -2.517      0.012      -0.330      -0.041\n",
      "term_spread_change           -0.2863      0.064     -4.457      0.000      -0.412      -0.160\n",
      "TED_spread                   -0.7598      0.254     -2.995      0.003      -1.257      -0.262\n",
      "credit_spread_change         -0.2385      0.092     -2.589      0.010      -0.419      -0.058\n",
      "market_return                -0.0370      0.038     -0.963      0.335      -0.112       0.038\n",
      "real_estate_excess_return    -0.0819      0.041     -2.000      0.046      -0.162      -0.002\n",
      "equity_volatility             0.6292      0.077      8.202      0.000       0.479       0.780\n",
      "institution                   0.4462      0.034     12.947      0.000       0.379       0.514\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5322\n",
      "Model:                       QuantReg   Bandwidth:                    0.003449\n",
      "Method:                 Least Squares   Sparsity:                       0.3584\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:22   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0312      0.005      5.895      0.000       0.021       0.042\n",
      "three_month_yield_change     -0.1889      0.182     -1.040      0.298      -0.545       0.167\n",
      "term_spread_change           -0.4614      0.169     -2.734      0.006      -0.792      -0.130\n",
      "TED_spread                    0.3609      0.671      0.538      0.591      -0.955       1.677\n",
      "credit_spread_change         -0.5292      0.180     -2.932      0.003      -0.883      -0.175\n",
      "market_return                 0.0102      0.112      0.091      0.927      -0.210       0.230\n",
      "real_estate_excess_return    -0.1929      0.103     -1.878      0.061      -0.394       0.009\n",
      "equity_volatility             1.0188      0.208      4.894      0.000       0.611       1.427\n",
      "institution                   0.4499      0.119      3.791      0.000       0.217       0.683\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 45.9182 - val_loss: 42.4791\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 44.3524 - val_loss: 41.0975\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 42.8072 - val_loss: 39.8822\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 41.5920 - val_loss: 38.9223\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 40.3029 - val_loss: 38.1448\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 39.6388 - val_loss: 37.5076\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.1123 - val_loss: 36.9474\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 38.3127 - val_loss: 36.2918\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.5418 - val_loss: 35.6306\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.7453 - val_loss: 35.0313\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.1540 - val_loss: 34.4797\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.3512 - val_loss: 33.9368\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.7609 - val_loss: 33.4005\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.2960 - val_loss: 32.8633\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.6194 - val_loss: 32.3192\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.0652 - val_loss: 31.7659\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.4462 - val_loss: 31.2296\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.9065 - val_loss: 30.7077\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.4095 - val_loss: 30.1808\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.9098 - val_loss: 29.6569\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.3949 - val_loss: 29.1427\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.6656 - val_loss: 28.6486\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.3280 - val_loss: 28.1672\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.9382 - val_loss: 27.6972\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.5943 - val_loss: 27.2474\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.1688 - val_loss: 26.8290\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.7908 - val_loss: 26.4399\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.4778 - val_loss: 26.0957\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.1985 - val_loss: 25.7863\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.9138 - val_loss: 25.4936\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.6373 - val_loss: 25.2201\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.4289 - val_loss: 24.9596\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1711 - val_loss: 24.7143\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0117 - val_loss: 24.4864\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8141 - val_loss: 24.2783\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6053 - val_loss: 24.0950\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3850 - val_loss: 23.9426\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2855 - val_loss: 23.8144\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1299 - val_loss: 23.7084\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.0256 - val_loss: 23.6159\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9247 - val_loss: 23.5290\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7388 - val_loss: 23.4532\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7395 - val_loss: 23.3793\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5447 - val_loss: 23.3084\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.6462 - val_loss: 23.2388\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5488 - val_loss: 23.1732\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4954 - val_loss: 23.1091\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4189 - val_loss: 23.0461\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3321 - val_loss: 22.9904\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3481 - val_loss: 22.9361\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2807 - val_loss: 22.8835\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2111 - val_loss: 22.8330\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1443 - val_loss: 22.7829\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1838 - val_loss: 22.7367\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0707 - val_loss: 22.6914\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0167 - val_loss: 22.6503\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0788 - val_loss: 22.6099\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9770 - val_loss: 22.5690\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9306 - val_loss: 22.5309\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9849 - val_loss: 22.4940\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8995 - val_loss: 22.4595\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8299 - val_loss: 22.4257\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8656 - val_loss: 22.3921\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8413 - val_loss: 22.3593\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8436 - val_loss: 22.3287\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8404 - val_loss: 22.2984\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8176 - val_loss: 22.2681\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8050 - val_loss: 22.2389\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7952 - val_loss: 22.2115\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7857 - val_loss: 22.1850\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7593 - val_loss: 22.1587\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7583 - val_loss: 22.1327\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6629 - val_loss: 22.1072\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7315 - val_loss: 22.0831\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7240 - val_loss: 22.0583\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6659 - val_loss: 22.0337\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6660 - val_loss: 22.0111\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6055 - val_loss: 21.9907\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6566 - val_loss: 21.9693\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6301 - val_loss: 21.9486\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6203 - val_loss: 21.9268\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5664 - val_loss: 21.9076\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6080 - val_loss: 21.8872\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5586 - val_loss: 21.8679\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4952 - val_loss: 21.8488\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5295 - val_loss: 21.8314\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5022 - val_loss: 21.8137\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5335 - val_loss: 21.7962\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3821 - val_loss: 21.7798\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5107 - val_loss: 21.7621\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5010 - val_loss: 21.7460\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4347 - val_loss: 21.7309\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4515 - val_loss: 21.7153\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4664 - val_loss: 21.6992\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4011 - val_loss: 21.6842\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3994 - val_loss: 21.6710\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3370 - val_loss: 21.6568\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4108 - val_loss: 21.6426\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4137 - val_loss: 21.6281\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4183 - val_loss: 21.6132\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 605us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                132\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 26.0723 - val_loss: 24.7580\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8933 - val_loss: 23.5416\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5459 - val_loss: 22.6218\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6549 - val_loss: 21.9585\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9402 - val_loss: 21.4079\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3453 - val_loss: 20.9804\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8237 - val_loss: 20.6400\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4879 - val_loss: 20.3896\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1582 - val_loss: 20.2006\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9360 - val_loss: 20.0434\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7054 - val_loss: 19.9315\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5418 - val_loss: 19.8342\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3358 - val_loss: 19.7435\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3071 - val_loss: 19.6567\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1528 - val_loss: 19.5747\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0787 - val_loss: 19.5015\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0032 - val_loss: 19.4400\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9153 - val_loss: 19.3835\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8857 - val_loss: 19.3313\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8262 - val_loss: 19.2850\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8258 - val_loss: 19.2461\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7748 - val_loss: 19.2148\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7120 - val_loss: 19.1880\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6546 - val_loss: 19.1634\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.6764 - val_loss: 19.1396\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6712 - val_loss: 19.1172\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6212 - val_loss: 19.0959\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4636 - val_loss: 19.0753\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3575 - val_loss: 19.0552\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.5984 - val_loss: 19.0352\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5583 - val_loss: 19.0171\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4991 - val_loss: 19.0002\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5574 - val_loss: 18.9830\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5437 - val_loss: 18.9676\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4937 - val_loss: 18.9520\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5216 - val_loss: 18.9358\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4666 - val_loss: 18.9204\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4988 - val_loss: 18.9065\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4782 - val_loss: 18.8925\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4757 - val_loss: 18.8778\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3959 - val_loss: 18.8648\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4634 - val_loss: 18.8513\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4334 - val_loss: 18.8383\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4311 - val_loss: 18.8252\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4266 - val_loss: 18.8116\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4024 - val_loss: 18.7992\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4035 - val_loss: 18.7868\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3826 - val_loss: 18.7746\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3685 - val_loss: 18.7619\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3667 - val_loss: 18.7495\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3576 - val_loss: 18.7381\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3463 - val_loss: 18.7257\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3387 - val_loss: 18.7131\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3289 - val_loss: 18.7007\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3019 - val_loss: 18.6892\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3012 - val_loss: 18.6769\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2823 - val_loss: 18.6644\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2379 - val_loss: 18.6527\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2598 - val_loss: 18.6403\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2584 - val_loss: 18.6280\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2228 - val_loss: 18.6159\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2300 - val_loss: 18.6037\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2205 - val_loss: 18.5918\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1758 - val_loss: 18.5794\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1900 - val_loss: 18.5675\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1905 - val_loss: 18.5559\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1636 - val_loss: 18.5437\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1507 - val_loss: 18.5313\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1372 - val_loss: 18.5193\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0927 - val_loss: 18.5073\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1229 - val_loss: 18.4950\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1235 - val_loss: 18.4819\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1067 - val_loss: 18.4695\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0517 - val_loss: 18.4575\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0711 - val_loss: 18.4456\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0633 - val_loss: 18.4332\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0563 - val_loss: 18.4210\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9982 - val_loss: 18.4085\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0368 - val_loss: 18.3953\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0081 - val_loss: 18.3826\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9826 - val_loss: 18.3692\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9351 - val_loss: 18.3570\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9384 - val_loss: 18.3442\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9528 - val_loss: 18.3317\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8380 - val_loss: 18.3187\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9426 - val_loss: 18.3057\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9353 - val_loss: 18.2919\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9095 - val_loss: 18.2783\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9149 - val_loss: 18.2650\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8969 - val_loss: 18.2524\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8619 - val_loss: 18.2390\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8575 - val_loss: 18.2263\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8198 - val_loss: 18.2131\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8406 - val_loss: 18.1999\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8303 - val_loss: 18.1868\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8160 - val_loss: 18.1733\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7926 - val_loss: 18.1601\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7751 - val_loss: 18.1460\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7740 - val_loss: 18.1322\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7335 - val_loss: 18.1192\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 811us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1419\n",
      "Model:                       QuantReg   Bandwidth:                    0.005913\n",
      "Method:                 Least Squares   Sparsity:                       0.1974\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0039      0.007      0.545      0.586      -0.010       0.018\n",
      "three_month_yield_change     -0.0903      0.169     -0.533      0.594      -0.423       0.242\n",
      "term_spread_change           -0.1354      0.158     -0.857      0.392      -0.445       0.174\n",
      "TED_spread                   -0.9915      0.676     -1.466      0.143      -2.318       0.335\n",
      "credit_spread_change          0.5070      0.260      1.951      0.051      -0.002       1.016\n",
      "market_return                -0.1400      0.112     -1.248      0.212      -0.360       0.080\n",
      "real_estate_excess_return     0.2139      0.123      1.739      0.082      -0.027       0.455\n",
      "equity_volatility             2.2885      0.199     11.471      0.000       1.897       2.680\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2079\n",
      "Model:                       QuantReg   Bandwidth:                    0.009454\n",
      "Method:                 Least Squares   Sparsity:                       0.6486\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:42   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0245      0.010      2.430      0.015       0.005       0.044\n",
      "three_month_yield_change      0.1387      0.258      0.539      0.590      -0.366       0.644\n",
      "term_spread_change           -0.0869      0.287     -0.303      0.762      -0.650       0.476\n",
      "TED_spread                   -1.2589      1.164     -1.082      0.279      -3.541       1.023\n",
      "credit_spread_change         -0.2794      0.392     -0.712      0.477      -1.049       0.490\n",
      "market_return                -0.1299      0.246     -0.528      0.597      -0.612       0.352\n",
      "real_estate_excess_return     0.3453      0.199      1.732      0.083      -0.046       0.736\n",
      "equity_volatility             4.0836      0.373     10.940      0.000       3.352       4.816\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3992\n",
      "Model:                       QuantReg   Bandwidth:                    0.002015\n",
      "Method:                 Least Squares   Sparsity:                      0.07744\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:42   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0126      0.003      4.783      0.000       0.007       0.018\n",
      "three_month_yield_change     -0.1202      0.081     -1.490      0.136      -0.278       0.038\n",
      "term_spread_change           -0.1392      0.070     -1.994      0.046      -0.276      -0.002\n",
      "TED_spread                   -0.2101      0.270     -0.778      0.437      -0.740       0.320\n",
      "credit_spread_change         -0.1412      0.084     -1.681      0.093      -0.306       0.024\n",
      "market_return                 0.0105      0.040      0.260      0.795      -0.069       0.089\n",
      "real_estate_excess_return    -0.0294      0.043     -0.682      0.495      -0.114       0.055\n",
      "equity_volatility             0.6866      0.077      8.926      0.000       0.536       0.837\n",
      "institution                   0.3513      0.029     12.244      0.000       0.295       0.408\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5184\n",
      "Model:                       QuantReg   Bandwidth:                    0.003578\n",
      "Method:                 Least Squares   Sparsity:                       0.3796\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:52:43   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0188      0.005      3.816      0.000       0.009       0.028\n",
      "three_month_yield_change     -0.2977      0.176     -1.691      0.091      -0.643       0.048\n",
      "term_spread_change           -0.3452      0.167     -2.063      0.039      -0.673      -0.017\n",
      "TED_spread                    0.0677      0.684      0.099      0.921      -1.273       1.408\n",
      "credit_spread_change         -0.1418      0.161     -0.880      0.379      -0.458       0.174\n",
      "market_return                -0.0597      0.147     -0.406      0.684      -0.348       0.228\n",
      "real_estate_excess_return    -0.1588      0.104     -1.532      0.126      -0.362       0.044\n",
      "equity_volatility             1.4015      0.252      5.566      0.000       0.908       1.895\n",
      "institution                   0.3700      0.093      3.979      0.000       0.188       0.552\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 42.3278 - val_loss: 37.4963\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 41.5440 - val_loss: 36.7460\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 40.6366 - val_loss: 36.0496\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 39.7185 - val_loss: 35.2350\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 38.6934 - val_loss: 34.4065\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.3249 - val_loss: 33.6078\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.7120 - val_loss: 32.8200\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.6567 - val_loss: 32.0149\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.6424 - val_loss: 31.2289\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.7375 - val_loss: 30.4526\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.7638 - val_loss: 29.6954\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.5448 - val_loss: 28.9926\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.8319 - val_loss: 28.3584\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.0719 - val_loss: 27.7611\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.1484 - val_loss: 27.1899\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.2308 - val_loss: 26.6448\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9283 - val_loss: 26.1374\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.2829 - val_loss: 25.6894\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.9197 - val_loss: 25.2845\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.4115 - val_loss: 24.9841\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0077 - val_loss: 24.7652\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6537 - val_loss: 24.5897\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4968 - val_loss: 24.4263\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1279 - val_loss: 24.2789\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.9905 - val_loss: 24.1549\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.8673 - val_loss: 24.0489\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7118 - val_loss: 23.9504\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.6475 - val_loss: 23.8656\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5629 - val_loss: 23.7945\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4897 - val_loss: 23.7408\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4096 - val_loss: 23.6994\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3410 - val_loss: 23.6683\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1967 - val_loss: 23.6435\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1755 - val_loss: 23.6206\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2082 - val_loss: 23.6015\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1563 - val_loss: 23.5847\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8937 - val_loss: 23.5707\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0861 - val_loss: 23.5590\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0354 - val_loss: 23.5490\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0447 - val_loss: 23.5396\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0151 - val_loss: 23.5304\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9733 - val_loss: 23.5215\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9895 - val_loss: 23.5126\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9358 - val_loss: 23.5037\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9453 - val_loss: 23.4953\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8556 - val_loss: 23.4875\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7885 - val_loss: 23.4800\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8529 - val_loss: 23.4726\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7693 - val_loss: 23.4651\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8754 - val_loss: 23.4581\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8177 - val_loss: 23.4512\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8506 - val_loss: 23.4446\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8343 - val_loss: 23.4383\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8159 - val_loss: 23.4317\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7722 - val_loss: 23.4251\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7891 - val_loss: 23.4182\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7435 - val_loss: 23.4115\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7530 - val_loss: 23.4041\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7595 - val_loss: 23.3964\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7005 - val_loss: 23.3886\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6227 - val_loss: 23.3803\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7086 - val_loss: 23.3723\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7121 - val_loss: 23.3647\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6935 - val_loss: 23.3566\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6806 - val_loss: 23.3485\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6148 - val_loss: 23.3400\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6612 - val_loss: 23.3318\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4267 - val_loss: 23.3235\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6398 - val_loss: 23.3148\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6410 - val_loss: 23.3060\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6388 - val_loss: 23.2972\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3658 - val_loss: 23.2879\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6032 - val_loss: 23.2791\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5281 - val_loss: 23.2698\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5884 - val_loss: 23.2604\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5746 - val_loss: 23.2507\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5036 - val_loss: 23.2406\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5553 - val_loss: 23.2305\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5152 - val_loss: 23.2207\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5460 - val_loss: 23.2107\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4809 - val_loss: 23.2008\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5050 - val_loss: 23.1907\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4872 - val_loss: 23.1804\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4950 - val_loss: 23.1701\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4698 - val_loss: 23.1601\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4515 - val_loss: 23.1499\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4597 - val_loss: 23.1392\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4485 - val_loss: 23.1288\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4341 - val_loss: 23.1179\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1643 - val_loss: 23.1072\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3816 - val_loss: 23.0962\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3618 - val_loss: 23.0852\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3391 - val_loss: 23.0742\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3438 - val_loss: 23.0631\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3468 - val_loss: 23.0522\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2353 - val_loss: 23.0399\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3344 - val_loss: 23.0287\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3338 - val_loss: 23.0178\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3227 - val_loss: 23.0067\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2452 - val_loss: 22.9952\n",
      "4/4 [==============================] - 0s 656us/step\n",
      "77/77 [==============================] - 0s 617us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                121\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 25.9022 - val_loss: 24.6775\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2764 - val_loss: 24.0477\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4704 - val_loss: 23.5025\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7603 - val_loss: 22.9934\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1337 - val_loss: 22.3715\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4692 - val_loss: 21.8685\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9285 - val_loss: 21.4055\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2591 - val_loss: 20.9974\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9344 - val_loss: 20.6568\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4952 - val_loss: 20.3849\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2509 - val_loss: 20.1800\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0115 - val_loss: 20.0203\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7068 - val_loss: 19.8821\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.6123 - val_loss: 19.7770\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4369 - val_loss: 19.6894\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3177 - val_loss: 19.6063\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1564 - val_loss: 19.5284\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.0100 - val_loss: 19.4571\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9836 - val_loss: 19.3873\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9277 - val_loss: 19.3204\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8608 - val_loss: 19.2642\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7645 - val_loss: 19.2138\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7443 - val_loss: 19.1663\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6602 - val_loss: 19.1234\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.6251 - val_loss: 19.0840\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3914 - val_loss: 19.0509\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5335 - val_loss: 19.0224\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5356 - val_loss: 18.9972\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5346 - val_loss: 18.9741\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4638 - val_loss: 18.9521\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4626 - val_loss: 18.9303\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4649 - val_loss: 18.9094\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3874 - val_loss: 18.8891\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4238 - val_loss: 18.8698\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4102 - val_loss: 18.8516\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3768 - val_loss: 18.8349\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3529 - val_loss: 18.8189\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3815 - val_loss: 18.8035\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3603 - val_loss: 18.7883\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3022 - val_loss: 18.7735\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3252 - val_loss: 18.7592\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3003 - val_loss: 18.7448\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3059 - val_loss: 18.7302\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3009 - val_loss: 18.7162\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2636 - val_loss: 18.7020\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2531 - val_loss: 18.6877\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2730 - val_loss: 18.6739\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2493 - val_loss: 18.6611\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2443 - val_loss: 18.6482\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2342 - val_loss: 18.6357\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2316 - val_loss: 18.6232\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2052 - val_loss: 18.6105\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2091 - val_loss: 18.5985\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1829 - val_loss: 18.5866\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1877 - val_loss: 18.5743\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1808 - val_loss: 18.5619\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1683 - val_loss: 18.5490\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1594 - val_loss: 18.5363\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1466 - val_loss: 18.5245\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1396 - val_loss: 18.5119\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0589 - val_loss: 18.5013\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1118 - val_loss: 18.4888\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0833 - val_loss: 18.4765\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0941 - val_loss: 18.4641\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0806 - val_loss: 18.4518\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0719 - val_loss: 18.4401\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0577 - val_loss: 18.4284\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0118 - val_loss: 18.4168\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9862 - val_loss: 18.4051\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0302 - val_loss: 18.3934\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0147 - val_loss: 18.3819\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0051 - val_loss: 18.3699\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9928 - val_loss: 18.3579\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9529 - val_loss: 18.3459\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9649 - val_loss: 18.3342\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8373 - val_loss: 18.3227\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9494 - val_loss: 18.3106\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9305 - val_loss: 18.2992\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9265 - val_loss: 18.2878\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8855 - val_loss: 18.2757\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9062 - val_loss: 18.2636\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8296 - val_loss: 18.2519\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8828 - val_loss: 18.2400\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8733 - val_loss: 18.2281\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7843 - val_loss: 18.2166\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7749 - val_loss: 18.2049\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7968 - val_loss: 18.1933\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7959 - val_loss: 18.1812\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8138 - val_loss: 18.1688\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7994 - val_loss: 18.1565\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7771 - val_loss: 18.1443\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7758 - val_loss: 18.1317\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7562 - val_loss: 18.1195\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.6677 - val_loss: 18.1078\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7419 - val_loss: 18.0954\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7116 - val_loss: 18.0830\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6863 - val_loss: 18.0714\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6776 - val_loss: 18.0588\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6775 - val_loss: 18.0467\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.6345 - val_loss: 18.0343\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 678us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1373\n",
      "Model:                       QuantReg   Bandwidth:                    0.005519\n",
      "Method:                 Least Squares   Sparsity:                       0.2016\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:02   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0013      0.007      0.181      0.856      -0.013       0.016\n",
      "three_month_yield_change     -0.0246      0.187     -0.132      0.895      -0.390       0.341\n",
      "term_spread_change           -0.0390      0.183     -0.213      0.832      -0.398       0.320\n",
      "TED_spread                   -0.5072      0.634     -0.800      0.424      -1.750       0.736\n",
      "credit_spread_change          0.4881      0.255      1.916      0.055      -0.011       0.987\n",
      "market_return                 0.0688      0.110      0.626      0.532      -0.147       0.284\n",
      "real_estate_excess_return     0.2281      0.126      1.805      0.071      -0.020       0.476\n",
      "equity_volatility             2.2618      0.180     12.594      0.000       1.910       2.614\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2531\n",
      "Model:                       QuantReg   Bandwidth:                    0.009704\n",
      "Method:                 Least Squares   Sparsity:                        1.114\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:02   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0142      0.017      0.850      0.396      -0.019       0.047\n",
      "three_month_yield_change      0.1044      0.458      0.228      0.820      -0.794       1.003\n",
      "term_spread_change           -0.1303      0.493     -0.264      0.792      -1.098       0.837\n",
      "TED_spread                   -2.1135      1.804     -1.172      0.241      -5.650       1.423\n",
      "credit_spread_change          0.2095      0.580      0.361      0.718      -0.928       1.347\n",
      "market_return                -0.0258      0.408     -0.063      0.950      -0.826       0.774\n",
      "real_estate_excess_return     0.2580      0.367      0.704      0.482      -0.461       0.977\n",
      "equity_volatility             4.9455      0.681      7.257      0.000       3.609       6.282\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4626\n",
      "Model:                       QuantReg   Bandwidth:                    0.001901\n",
      "Method:                 Least Squares   Sparsity:                      0.07013\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:02   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0121      0.003      4.731      0.000       0.007       0.017\n",
      "three_month_yield_change     -0.0672      0.074     -0.908      0.364      -0.212       0.078\n",
      "term_spread_change           -0.1498      0.066     -2.277      0.023      -0.279      -0.021\n",
      "TED_spread                   -0.6904      0.240     -2.882      0.004      -1.160      -0.221\n",
      "credit_spread_change         -0.0815      0.085     -0.954      0.340      -0.249       0.086\n",
      "market_return                -0.0531      0.034     -1.578      0.115      -0.119       0.013\n",
      "real_estate_excess_return    -0.0368      0.041     -0.898      0.369      -0.117       0.044\n",
      "equity_volatility             0.6240      0.066      9.423      0.000       0.494       0.754\n",
      "institution                   0.3683      0.024     15.274      0.000       0.321       0.416\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5812\n",
      "Model:                       QuantReg   Bandwidth:                    0.003085\n",
      "Method:                 Least Squares   Sparsity:                       0.2789\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:02   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0199      0.004      4.632      0.000       0.011       0.028\n",
      "three_month_yield_change     -0.1144      0.140     -0.818      0.414      -0.389       0.160\n",
      "term_spread_change           -0.3459      0.134     -2.588      0.010      -0.608      -0.084\n",
      "TED_spread                   -0.0991      0.588     -0.169      0.866      -1.252       1.054\n",
      "credit_spread_change         -0.1692      0.157     -1.076      0.282      -0.478       0.139\n",
      "market_return                -0.0700      0.092     -0.761      0.447      -0.251       0.110\n",
      "real_estate_excess_return    -0.1882      0.085     -2.218      0.027      -0.355      -0.022\n",
      "equity_volatility             0.9192      0.177      5.192      0.000       0.572       1.266\n",
      "institution                   0.3852      0.064      6.001      0.000       0.259       0.511\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 45.0643 - val_loss: 48.4403\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 44.0619 - val_loss: 47.0717\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 42.5418 - val_loss: 45.8208\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 41.3149 - val_loss: 44.8338\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 40.1691 - val_loss: 43.7573\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 39.2063 - val_loss: 42.7396\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.6891 - val_loss: 41.7391\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.9469 - val_loss: 40.4775\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.5820 - val_loss: 39.2918\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.4088 - val_loss: 38.1703\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.2944 - val_loss: 37.1697\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.1470 - val_loss: 36.2210\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.9941 - val_loss: 35.3165\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.0160 - val_loss: 34.4775\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.3564 - val_loss: 33.6807\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.4895 - val_loss: 33.0536\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9389 - val_loss: 32.5980\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.5055 - val_loss: 32.2080\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.9808 - val_loss: 31.8659\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5171 - val_loss: 31.6160\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1033 - val_loss: 31.4015\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9033 - val_loss: 31.2257\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6462 - val_loss: 31.0780\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3988 - val_loss: 30.9391\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1599 - val_loss: 30.8075\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.0405 - val_loss: 30.6871\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.9032 - val_loss: 30.5777\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.8307 - val_loss: 30.4779\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7395 - val_loss: 30.3782\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5729 - val_loss: 30.2887\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5860 - val_loss: 30.2064\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4669 - val_loss: 30.1337\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3176 - val_loss: 30.0706\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3388 - val_loss: 30.0126\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3575 - val_loss: 29.9581\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3080 - val_loss: 29.9093\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2605 - val_loss: 29.8683\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1582 - val_loss: 29.8309\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1864 - val_loss: 29.7954\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1479 - val_loss: 29.7615\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1200 - val_loss: 29.7282\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1200 - val_loss: 29.6958\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0492 - val_loss: 29.6638\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0259 - val_loss: 29.6314\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9832 - val_loss: 29.5988\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9733 - val_loss: 29.5678\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8988 - val_loss: 29.5378\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9678 - val_loss: 29.5088\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9574 - val_loss: 29.4816\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8329 - val_loss: 29.4562\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8869 - val_loss: 29.4319\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8756 - val_loss: 29.4073\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8404 - val_loss: 29.3838\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8395 - val_loss: 29.3602\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8193 - val_loss: 29.3380\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8094 - val_loss: 29.3159\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7885 - val_loss: 29.2947\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6909 - val_loss: 29.2731\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7292 - val_loss: 29.2525\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6792 - val_loss: 29.2332\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7343 - val_loss: 29.2134\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6719 - val_loss: 29.1965\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6850 - val_loss: 29.1795\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7268 - val_loss: 29.1612\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7080 - val_loss: 29.1440\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6170 - val_loss: 29.1278\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6805 - val_loss: 29.1122\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6091 - val_loss: 29.0964\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5464 - val_loss: 29.0823\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5983 - val_loss: 29.0674\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5785 - val_loss: 29.0534\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6283 - val_loss: 29.0399\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6173 - val_loss: 29.0255\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5243 - val_loss: 29.0116\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5854 - val_loss: 28.9973\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5951 - val_loss: 28.9823\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5680 - val_loss: 28.9690\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5330 - val_loss: 28.9559\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5038 - val_loss: 28.9427\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5254 - val_loss: 28.9299\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4990 - val_loss: 28.9176\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4906 - val_loss: 28.9048\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5041 - val_loss: 28.8916\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5052 - val_loss: 28.8778\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3547 - val_loss: 28.8656\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4458 - val_loss: 28.8527\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4320 - val_loss: 28.8398\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4518 - val_loss: 28.8272\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4413 - val_loss: 28.8139\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4053 - val_loss: 28.8012\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3852 - val_loss: 28.7885\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2937 - val_loss: 28.7759\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3312 - val_loss: 28.7630\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3328 - val_loss: 28.7506\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3644 - val_loss: 28.7381\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2700 - val_loss: 28.7258\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3042 - val_loss: 28.7141\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2095 - val_loss: 28.7020\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3303 - val_loss: 28.6895\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2059 - val_loss: 28.6769\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 592us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_42 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 27.3740 - val_loss: 25.8024\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1027 - val_loss: 24.7613\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6909 - val_loss: 23.4235\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2367 - val_loss: 22.4957\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4204 - val_loss: 21.8615\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7582 - val_loss: 21.3624\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1989 - val_loss: 20.9653\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7318 - val_loss: 20.6297\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4254 - val_loss: 20.3874\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0461 - val_loss: 20.1976\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.8661 - val_loss: 20.0480\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6715 - val_loss: 19.9376\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4947 - val_loss: 19.8412\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.4124 - val_loss: 19.7515\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.2370 - val_loss: 19.6682\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1519 - val_loss: 19.5866\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.0834 - val_loss: 19.5147\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.0136 - val_loss: 19.4538\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9483 - val_loss: 19.3987\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8904 - val_loss: 19.3489\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8755 - val_loss: 19.3028\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7825 - val_loss: 19.2631\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7738 - val_loss: 19.2310\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7118 - val_loss: 19.2044\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7412 - val_loss: 19.1804\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7051 - val_loss: 19.1574\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6264 - val_loss: 19.1367\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5943 - val_loss: 19.1162\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6332 - val_loss: 19.0963\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6326 - val_loss: 19.0766\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5620 - val_loss: 19.0581\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5999 - val_loss: 19.0391\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.5484 - val_loss: 19.0213\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5738 - val_loss: 19.0042\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5308 - val_loss: 18.9885\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.5441 - val_loss: 18.9730\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5247 - val_loss: 18.9576\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4790 - val_loss: 18.9430\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4637 - val_loss: 18.9283\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4410 - val_loss: 18.9142\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3665 - val_loss: 18.9004\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4735 - val_loss: 18.8864\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4029 - val_loss: 18.8738\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4299 - val_loss: 18.8610\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4444 - val_loss: 18.8480\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4237 - val_loss: 18.8350\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3241 - val_loss: 18.8236\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3944 - val_loss: 18.8118\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3992 - val_loss: 18.7996\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3980 - val_loss: 18.7872\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3832 - val_loss: 18.7752\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3559 - val_loss: 18.7636\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2794 - val_loss: 18.7530\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3624 - val_loss: 18.7413\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3552 - val_loss: 18.7298\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3377 - val_loss: 18.7180\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3289 - val_loss: 18.7064\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3232 - val_loss: 18.6949\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2992 - val_loss: 18.6835\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3016 - val_loss: 18.6720\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2831 - val_loss: 18.6603\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2339 - val_loss: 18.6484\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2384 - val_loss: 18.6374\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1996 - val_loss: 18.6266\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2046 - val_loss: 18.6152\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2369 - val_loss: 18.6036\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2272 - val_loss: 18.5922\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1619 - val_loss: 18.5812\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2046 - val_loss: 18.5693\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1831 - val_loss: 18.5577\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1505 - val_loss: 18.5467\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1593 - val_loss: 18.5354\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1649 - val_loss: 18.5237\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1309 - val_loss: 18.5119\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1371 - val_loss: 18.5001\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0795 - val_loss: 18.4887\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1184 - val_loss: 18.4766\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1083 - val_loss: 18.4646\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0895 - val_loss: 18.4525\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0564 - val_loss: 18.4426\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0511 - val_loss: 18.4317\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0568 - val_loss: 18.4204\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0358 - val_loss: 18.4091\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9757 - val_loss: 18.3973\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0035 - val_loss: 18.3856\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9913 - val_loss: 18.3733\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9985 - val_loss: 18.3611\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9454 - val_loss: 18.3508\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9810 - val_loss: 18.3385\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9702 - val_loss: 18.3270\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9486 - val_loss: 18.3149\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9437 - val_loss: 18.3030\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9313 - val_loss: 18.2907\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9274 - val_loss: 18.2786\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9017 - val_loss: 18.2667\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8724 - val_loss: 18.2549\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8833 - val_loss: 18.2427\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8277 - val_loss: 18.2311\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8570 - val_loss: 18.2195\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8432 - val_loss: 18.2064\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 627us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 8, 1)]            0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_49 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1373\n",
      "Model:                       QuantReg   Bandwidth:                    0.005932\n",
      "Method:                 Least Squares   Sparsity:                       0.1794\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:22   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0242      0.006      3.815      0.000       0.012       0.037\n",
      "three_month_yield_change     -0.1800      0.164     -1.098      0.272      -0.501       0.141\n",
      "term_spread_change           -0.6535      0.155     -4.222      0.000      -0.957      -0.350\n",
      "TED_spread                   -1.8725      0.680     -2.755      0.006      -3.205      -0.540\n",
      "credit_spread_change          0.1695      0.232      0.730      0.466      -0.286       0.625\n",
      "market_return                 0.2155      0.110      1.966      0.049       0.001       0.430\n",
      "real_estate_excess_return     0.4149      0.114      3.630      0.000       0.191       0.639\n",
      "equity_volatility             2.1010      0.188     11.176      0.000       1.732       2.470\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2525\n",
      "Model:                       QuantReg   Bandwidth:                    0.009917\n",
      "Method:                 Least Squares   Sparsity:                        1.052\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:22   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0782      0.017      4.729      0.000       0.046       0.111\n",
      "three_month_yield_change     -1.6595      0.457     -3.631      0.000      -2.556      -0.763\n",
      "term_spread_change           -2.1920      0.440     -4.983      0.000      -3.055      -1.329\n",
      "TED_spread                    1.0894      1.952      0.558      0.577      -2.739       4.918\n",
      "credit_spread_change         -0.2818      0.542     -0.520      0.603      -1.344       0.781\n",
      "market_return                 0.2706      0.378      0.717      0.474      -0.470       1.011\n",
      "real_estate_excess_return     0.3953      0.332      1.190      0.234      -0.256       1.046\n",
      "equity_volatility             3.0882      0.602      5.129      0.000       1.908       4.269\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 27\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3986\n",
      "Model:                       QuantReg   Bandwidth:                    0.002223\n",
      "Method:                 Least Squares   Sparsity:                      0.07275\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:22   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0138      0.003      5.422      0.000       0.009       0.019\n",
      "three_month_yield_change     -0.1574      0.074     -2.113      0.035      -0.303      -0.011\n",
      "term_spread_change           -0.2334      0.069     -3.387      0.001      -0.368      -0.098\n",
      "TED_spread                   -0.5072      0.266     -1.904      0.057      -1.029       0.015\n",
      "credit_spread_change         -0.1100      0.088     -1.244      0.214      -0.283       0.063\n",
      "market_return                -0.0266      0.036     -0.748      0.454      -0.096       0.043\n",
      "real_estate_excess_return    -0.0591      0.044     -1.339      0.181      -0.146       0.027\n",
      "equity_volatility             0.8186      0.071     11.603      0.000       0.680       0.957\n",
      "institution                   0.3481      0.024     14.272      0.000       0.300       0.396\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5110\n",
      "Model:                       QuantReg   Bandwidth:                    0.003859\n",
      "Method:                 Least Squares   Sparsity:                       0.2558\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:22   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0318      0.003      9.183      0.000       0.025       0.039\n",
      "three_month_yield_change     -0.5414      0.131     -4.129      0.000      -0.798      -0.284\n",
      "term_spread_change           -0.4764      0.113     -4.224      0.000      -0.698      -0.255\n",
      "TED_spread                   -0.5762      0.461     -1.249      0.212      -1.481       0.329\n",
      "credit_spread_change         -0.5319      0.117     -4.534      0.000      -0.762      -0.302\n",
      "market_return                -0.2290      0.094     -2.442      0.015      -0.413      -0.045\n",
      "real_estate_excess_return    -0.1816      0.091     -2.000      0.046      -0.360      -0.004\n",
      "equity_volatility             1.4921      0.154      9.686      0.000       1.190       1.794\n",
      "institution                   0.3710      0.064      5.794      0.000       0.245       0.497\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 40.1729 - val_loss: 39.1397\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.1488 - val_loss: 37.6160\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.1685 - val_loss: 35.4539\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.9569 - val_loss: 33.0592\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.8421 - val_loss: 30.7368\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.7140 - val_loss: 28.8196\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.0743 - val_loss: 27.3827\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.8755 - val_loss: 26.2839\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.6519 - val_loss: 25.4417\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8954 - val_loss: 24.8969\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4839 - val_loss: 24.5177\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.0744 - val_loss: 24.2257\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7280 - val_loss: 23.9511\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5337 - val_loss: 23.6986\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3160 - val_loss: 23.5022\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1477 - val_loss: 23.3502\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0113 - val_loss: 23.2378\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9250 - val_loss: 23.1415\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7183 - val_loss: 23.0707\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6675 - val_loss: 23.0135\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7040 - val_loss: 22.9633\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5761 - val_loss: 22.9263\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6161 - val_loss: 22.8968\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5305 - val_loss: 22.8693\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4939 - val_loss: 22.8454\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4716 - val_loss: 22.8240\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5239 - val_loss: 22.8044\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3823 - val_loss: 22.7869\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5113 - val_loss: 22.7692\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4096 - val_loss: 22.7538\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4641 - val_loss: 22.7393\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4799 - val_loss: 22.7266\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4664 - val_loss: 22.7147\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4488 - val_loss: 22.7030\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3972 - val_loss: 22.6914\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4107 - val_loss: 22.6801\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4088 - val_loss: 22.6685\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4053 - val_loss: 22.6572\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2367 - val_loss: 22.6465\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3503 - val_loss: 22.6354\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2471 - val_loss: 22.6247\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3618 - val_loss: 22.6135\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3629 - val_loss: 22.6021\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3010 - val_loss: 22.5918\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3224 - val_loss: 22.5813\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3103 - val_loss: 22.5705\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2665 - val_loss: 22.5603\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2939 - val_loss: 22.5497\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2986 - val_loss: 22.5390\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2211 - val_loss: 22.5286\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1654 - val_loss: 22.5180\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2674 - val_loss: 22.5069\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2557 - val_loss: 22.4963\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2473 - val_loss: 22.4857\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1542 - val_loss: 22.4748\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2066 - val_loss: 22.4640\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1927 - val_loss: 22.4529\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0313 - val_loss: 22.4421\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1928 - val_loss: 22.4314\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1719 - val_loss: 22.4205\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1798 - val_loss: 22.4092\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0333 - val_loss: 22.3986\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1486 - val_loss: 22.3873\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1260 - val_loss: 22.3764\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1279 - val_loss: 22.3656\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9773 - val_loss: 22.3547\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9868 - val_loss: 22.3439\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0934 - val_loss: 22.3324\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0410 - val_loss: 22.3212\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0573 - val_loss: 22.3095\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0492 - val_loss: 22.2981\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9974 - val_loss: 22.2864\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9579 - val_loss: 22.2750\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0127 - val_loss: 22.2630\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0173 - val_loss: 22.2510\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0103 - val_loss: 22.2391\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0019 - val_loss: 22.2272\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9768 - val_loss: 22.2149\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9543 - val_loss: 22.2031\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9182 - val_loss: 22.1915\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9411 - val_loss: 22.1793\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9326 - val_loss: 22.1676\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9206 - val_loss: 22.1556\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8520 - val_loss: 22.1442\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9043 - val_loss: 22.1320\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8832 - val_loss: 22.1200\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8633 - val_loss: 22.1082\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8509 - val_loss: 22.0961\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8356 - val_loss: 22.0835\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8367 - val_loss: 22.0713\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8250 - val_loss: 22.0590\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7996 - val_loss: 22.0466\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7847 - val_loss: 22.0346\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7341 - val_loss: 22.0223\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7630 - val_loss: 22.0098\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7622 - val_loss: 21.9975\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7221 - val_loss: 21.9850\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6983 - val_loss: 21.9723\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7268 - val_loss: 21.9594\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6251 - val_loss: 21.9474\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 507us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_60 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_62 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                121\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.2568 - val_loss: 24.8591\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.1383 - val_loss: 23.8910\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1307 - val_loss: 23.2119\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4136 - val_loss: 22.6976\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8315 - val_loss: 22.1735\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1492 - val_loss: 21.6816\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6202 - val_loss: 21.2403\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2184 - val_loss: 20.8779\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8222 - val_loss: 20.5688\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4621 - val_loss: 20.3282\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1576 - val_loss: 20.1436\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9525 - val_loss: 19.9878\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7282 - val_loss: 19.8563\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3857 - val_loss: 19.7542\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3769 - val_loss: 19.6643\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2738 - val_loss: 19.5822\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1335 - val_loss: 19.5026\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0620 - val_loss: 19.4275\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9758 - val_loss: 19.3576\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8657 - val_loss: 19.3003\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8145 - val_loss: 19.2478\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6893 - val_loss: 19.1971\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6791 - val_loss: 19.1514\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6839 - val_loss: 19.1093\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6017 - val_loss: 19.0737\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6076 - val_loss: 19.0425\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5392 - val_loss: 19.0162\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5529 - val_loss: 18.9908\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5279 - val_loss: 18.9669\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4727 - val_loss: 18.9448\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4211 - val_loss: 18.9249\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3694 - val_loss: 18.9055\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3570 - val_loss: 18.8866\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3991 - val_loss: 18.8683\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4084 - val_loss: 18.8502\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3772 - val_loss: 18.8330\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3360 - val_loss: 18.8165\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2958 - val_loss: 18.8011\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3429 - val_loss: 18.7854\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3086 - val_loss: 18.7699\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3270 - val_loss: 18.7552\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2997 - val_loss: 18.7406\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3174 - val_loss: 18.7262\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2742 - val_loss: 18.7128\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2623 - val_loss: 18.7007\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2778 - val_loss: 18.6875\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2674 - val_loss: 18.6749\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2590 - val_loss: 18.6619\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2528 - val_loss: 18.6486\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0787 - val_loss: 18.6362\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2139 - val_loss: 18.6234\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2175 - val_loss: 18.6103\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2078 - val_loss: 18.5990\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1892 - val_loss: 18.5877\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1459 - val_loss: 18.5768\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1496 - val_loss: 18.5654\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1680 - val_loss: 18.5537\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1521 - val_loss: 18.5420\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1416 - val_loss: 18.5298\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1290 - val_loss: 18.5185\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1079 - val_loss: 18.5065\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0795 - val_loss: 18.4950\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1096 - val_loss: 18.4838\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1041 - val_loss: 18.4720\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0925 - val_loss: 18.4606\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0523 - val_loss: 18.4486\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0422 - val_loss: 18.4380\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0162 - val_loss: 18.4265\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0428 - val_loss: 18.4146\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0391 - val_loss: 18.4032\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0093 - val_loss: 18.3917\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0003 - val_loss: 18.3803\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9900 - val_loss: 18.3685\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9715 - val_loss: 18.3571\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9822 - val_loss: 18.3456\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9467 - val_loss: 18.3340\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8467 - val_loss: 18.3222\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8980 - val_loss: 18.3113\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9285 - val_loss: 18.3005\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8969 - val_loss: 18.2890\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8685 - val_loss: 18.2772\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8941 - val_loss: 18.2654\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8682 - val_loss: 18.2535\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8556 - val_loss: 18.2428\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8736 - val_loss: 18.2308\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8475 - val_loss: 18.2191\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8471 - val_loss: 18.2071\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8142 - val_loss: 18.1959\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7997 - val_loss: 18.1839\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7991 - val_loss: 18.1727\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7768 - val_loss: 18.1613\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7920 - val_loss: 18.1495\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7621 - val_loss: 18.1374\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6862 - val_loss: 18.1256\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7543 - val_loss: 18.1138\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6985 - val_loss: 18.1023\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7323 - val_loss: 18.0898\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6633 - val_loss: 18.0780\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7031 - val_loss: 18.0661\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6908 - val_loss: 18.0538\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 700us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_64 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_66 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_67 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_68 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1340\n",
      "Model:                       QuantReg   Bandwidth:                    0.005540\n",
      "Method:                 Least Squares   Sparsity:                       0.2108\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0212      0.008      2.774      0.006       0.006       0.036\n",
      "three_month_yield_change     -0.3037      0.207     -1.465      0.143      -0.710       0.103\n",
      "term_spread_change           -0.5314      0.184     -2.884      0.004      -0.893      -0.170\n",
      "TED_spread                   -0.6756      0.805     -0.839      0.401      -2.254       0.903\n",
      "credit_spread_change          0.0483      0.274      0.176      0.860      -0.488       0.585\n",
      "market_return                -0.0594      0.115     -0.516      0.606      -0.285       0.166\n",
      "real_estate_excess_return     0.1107      0.128      0.864      0.388      -0.141       0.362\n",
      "equity_volatility             2.2125      0.211     10.496      0.000       1.799       2.626\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2228\n",
      "Model:                       QuantReg   Bandwidth:                    0.009170\n",
      "Method:                 Least Squares   Sparsity:                        1.025\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0765      0.018      4.187      0.000       0.041       0.112\n",
      "three_month_yield_change     -1.4413      0.552     -2.609      0.009      -2.525      -0.358\n",
      "term_spread_change           -1.6142      0.498     -3.241      0.001      -2.591      -0.638\n",
      "TED_spread                   -1.9493      1.981     -0.984      0.325      -5.835       1.936\n",
      "credit_spread_change         -0.2374      0.619     -0.383      0.702      -1.452       0.977\n",
      "market_return                 0.1765      0.280      0.629      0.529      -0.373       0.726\n",
      "real_estate_excess_return     0.1125      0.412      0.273      0.785      -0.694       0.919\n",
      "equity_volatility             2.7146      0.492      5.513      0.000       1.749       3.680\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3852\n",
      "Model:                       QuantReg   Bandwidth:                    0.002190\n",
      "Method:                 Least Squares   Sparsity:                      0.07399\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.002      3.809      0.000       0.005       0.014\n",
      "three_month_yield_change     -0.0401      0.074     -0.541      0.588      -0.185       0.105\n",
      "term_spread_change           -0.1662      0.069     -2.394      0.017      -0.302      -0.030\n",
      "TED_spread                   -0.6474      0.271     -2.390      0.017      -1.178      -0.116\n",
      "credit_spread_change         -0.0154      0.085     -0.181      0.856      -0.182       0.151\n",
      "market_return                -0.0833      0.037     -2.239      0.025      -0.156      -0.010\n",
      "real_estate_excess_return    -0.0127      0.045     -0.284      0.777      -0.100       0.075\n",
      "equity_volatility             0.8036      0.069     11.684      0.000       0.669       0.939\n",
      "institution                   0.3530      0.026     13.663      0.000       0.302       0.404\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4782\n",
      "Model:                       QuantReg   Bandwidth:                    0.004156\n",
      "Method:                 Least Squares   Sparsity:                       0.3351\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:53:44   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0330      0.005      6.485      0.000       0.023       0.043\n",
      "three_month_yield_change     -0.4524      0.151     -2.997      0.003      -0.748      -0.156\n",
      "term_spread_change           -0.3872      0.163     -2.380      0.017      -0.706      -0.068\n",
      "TED_spread                   -1.2260      0.687     -1.784      0.074      -2.573       0.121\n",
      "credit_spread_change         -0.6285      0.167     -3.759      0.000      -0.956      -0.301\n",
      "market_return                -0.0642      0.130     -0.492      0.623      -0.320       0.191\n",
      "real_estate_excess_return    -0.2479      0.103     -2.403      0.016      -0.450      -0.046\n",
      "equity_volatility             1.7867      0.200      8.914      0.000       1.394       2.180\n",
      "institution                   0.3612      0.087      4.162      0.000       0.191       0.531\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 36.2517 - val_loss: 32.9168\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.3111 - val_loss: 32.1603\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.5483 - val_loss: 31.4110\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.6052 - val_loss: 30.5982\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.6101 - val_loss: 29.6813\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.0988 - val_loss: 27.6141\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1084 - val_loss: 23.4895\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4129 - val_loss: 22.1202\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0875 - val_loss: 21.9510\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7830 - val_loss: 21.9255\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5862 - val_loss: 21.9333\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6444 - val_loss: 21.9396\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5412 - val_loss: 21.9394\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5952 - val_loss: 21.9328\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6310 - val_loss: 21.9239\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6262 - val_loss: 21.9172\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4466 - val_loss: 21.9111\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5985 - val_loss: 21.9029\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6081 - val_loss: 21.8955\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5109 - val_loss: 21.8868\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5924 - val_loss: 21.8786\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5612 - val_loss: 21.8703\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5156 - val_loss: 21.8654\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5485 - val_loss: 21.8588\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5033 - val_loss: 21.8507\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5521 - val_loss: 21.8416\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5311 - val_loss: 21.8322\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5261 - val_loss: 21.8234\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4721 - val_loss: 21.8142\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4838 - val_loss: 21.8043\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5022 - val_loss: 21.7949\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4830 - val_loss: 21.7857\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4313 - val_loss: 21.7750\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4644 - val_loss: 21.7667\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4422 - val_loss: 21.7576\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4269 - val_loss: 21.7474\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4110 - val_loss: 21.7372\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4333 - val_loss: 21.7275\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3751 - val_loss: 21.7177\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3902 - val_loss: 21.7081\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3252 - val_loss: 21.6976\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3623 - val_loss: 21.6867\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3593 - val_loss: 21.6770\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3756 - val_loss: 21.6668\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3147 - val_loss: 21.6565\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3544 - val_loss: 21.6464\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3358 - val_loss: 21.6359\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3160 - val_loss: 21.6253\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2836 - val_loss: 21.6144\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3117 - val_loss: 21.6039\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3087 - val_loss: 21.5931\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2532 - val_loss: 21.5820\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2070 - val_loss: 21.5707\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2357 - val_loss: 21.5594\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2307 - val_loss: 21.5484\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2449 - val_loss: 21.5375\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2230 - val_loss: 21.5263\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2237 - val_loss: 21.5150\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1785 - val_loss: 21.5037\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1357 - val_loss: 21.4923\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1572 - val_loss: 21.4810\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1065 - val_loss: 21.4692\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1629 - val_loss: 21.4574\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0754 - val_loss: 21.4455\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0313 - val_loss: 21.4338\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1337 - val_loss: 21.4222\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1031 - val_loss: 21.4103\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0998 - val_loss: 21.3985\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9946 - val_loss: 21.3864\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8875 - val_loss: 21.3743\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0455 - val_loss: 21.3622\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0260 - val_loss: 21.3500\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0126 - val_loss: 21.3379\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0319 - val_loss: 21.3259\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9755 - val_loss: 21.3138\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8917 - val_loss: 21.3014\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9728 - val_loss: 21.2890\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9396 - val_loss: 21.2764\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9692 - val_loss: 21.2640\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9551 - val_loss: 21.2517\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9583 - val_loss: 21.2393\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8580 - val_loss: 21.2266\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8932 - val_loss: 21.2139\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9005 - val_loss: 21.2013\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8097 - val_loss: 21.1886\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7162 - val_loss: 21.1760\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8623 - val_loss: 21.1631\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8263 - val_loss: 21.1502\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8088 - val_loss: 21.1373\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8364 - val_loss: 21.1245\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8216 - val_loss: 21.1115\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7258 - val_loss: 21.0982\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8032 - val_loss: 21.0851\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7378 - val_loss: 21.0720\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7374 - val_loss: 21.0588\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6323 - val_loss: 21.0455\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7178 - val_loss: 21.0324\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7276 - val_loss: 21.0192\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7238 - val_loss: 21.0058\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6539 - val_loss: 20.9923\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 665us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_70 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_74 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_76 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.5397 - val_loss: 24.9967\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2914 - val_loss: 23.8181\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8357 - val_loss: 22.6685\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6232 - val_loss: 21.7613\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6192 - val_loss: 21.0069\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7960 - val_loss: 20.4006\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1145 - val_loss: 19.9976\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6420 - val_loss: 19.7556\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2510 - val_loss: 19.5890\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0929 - val_loss: 19.4454\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9219 - val_loss: 19.3300\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8291 - val_loss: 19.2403\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6798 - val_loss: 19.1664\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6853 - val_loss: 19.1112\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6013 - val_loss: 19.0685\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5678 - val_loss: 19.0362\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5515 - val_loss: 19.0073\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4831 - val_loss: 18.9819\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5109 - val_loss: 18.9571\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4822 - val_loss: 18.9353\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4514 - val_loss: 18.9164\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4660 - val_loss: 18.8981\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4433 - val_loss: 18.8813\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4226 - val_loss: 18.8657\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1958 - val_loss: 18.8519\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4279 - val_loss: 18.8371\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3836 - val_loss: 18.8241\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4037 - val_loss: 18.8122\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2444 - val_loss: 18.8012\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3890 - val_loss: 18.7892\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3814 - val_loss: 18.7765\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1818 - val_loss: 18.7664\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3341 - val_loss: 18.7551\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3423 - val_loss: 18.7439\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3392 - val_loss: 18.7315\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3158 - val_loss: 18.7207\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3198 - val_loss: 18.7097\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2488 - val_loss: 18.6993\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3110 - val_loss: 18.6882\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2861 - val_loss: 18.6776\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2881 - val_loss: 18.6664\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2808 - val_loss: 18.6564\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2341 - val_loss: 18.6465\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1989 - val_loss: 18.6356\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2498 - val_loss: 18.6249\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2416 - val_loss: 18.6144\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2263 - val_loss: 18.6036\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1229 - val_loss: 18.5941\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2031 - val_loss: 18.5829\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1596 - val_loss: 18.5723\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1503 - val_loss: 18.5619\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1894 - val_loss: 18.5516\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1788 - val_loss: 18.5411\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1416 - val_loss: 18.5307\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1417 - val_loss: 18.5204\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1252 - val_loss: 18.5101\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1126 - val_loss: 18.4994\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1206 - val_loss: 18.4892\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0870 - val_loss: 18.4783\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1057 - val_loss: 18.4675\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0958 - val_loss: 18.4577\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9225 - val_loss: 18.4473\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0417 - val_loss: 18.4369\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0120 - val_loss: 18.4268\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0179 - val_loss: 18.4159\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0434 - val_loss: 18.4050\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0142 - val_loss: 18.3956\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0325 - val_loss: 18.3846\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0009 - val_loss: 18.3735\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9592 - val_loss: 18.3631\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9657 - val_loss: 18.3524\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9801 - val_loss: 18.3416\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9046 - val_loss: 18.3307\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8184 - val_loss: 18.3196\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9538 - val_loss: 18.3082\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9265 - val_loss: 18.2980\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9191 - val_loss: 18.2865\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8463 - val_loss: 18.2763\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9108 - val_loss: 18.2642\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8905 - val_loss: 18.2530\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8843 - val_loss: 18.2412\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8763 - val_loss: 18.2300\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8478 - val_loss: 18.2188\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8530 - val_loss: 18.2073\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8301 - val_loss: 18.1962\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.5867 - val_loss: 18.1855\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7911 - val_loss: 18.1744\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7743 - val_loss: 18.1623\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7746 - val_loss: 18.1504\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7197 - val_loss: 18.1400\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7310 - val_loss: 18.1280\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7273 - val_loss: 18.1166\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7418 - val_loss: 18.1045\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7327 - val_loss: 18.0928\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7140 - val_loss: 18.0808\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7016 - val_loss: 18.0681\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6974 - val_loss: 18.0552\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6322 - val_loss: 18.0442\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6679 - val_loss: 18.0315\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6480 - val_loss: 18.0190\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 777us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_78 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_80 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_82 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1483\n",
      "Model:                       QuantReg   Bandwidth:                    0.004712\n",
      "Method:                 Least Squares   Sparsity:                       0.1475\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:06   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0047      0.005      0.935      0.350      -0.005       0.015\n",
      "three_month_yield_change     -0.0094      0.130     -0.072      0.942      -0.264       0.245\n",
      "term_spread_change           -0.0585      0.129     -0.453      0.651      -0.312       0.195\n",
      "TED_spread                   -0.8395      0.473     -1.774      0.076      -1.767       0.088\n",
      "credit_spread_change          0.2283      0.182      1.257      0.209      -0.128       0.585\n",
      "market_return                -0.1059      0.084     -1.267      0.205      -0.270       0.058\n",
      "real_estate_excess_return     0.1415      0.090      1.567      0.117      -0.036       0.319\n",
      "equity_volatility             1.9982      0.149     13.396      0.000       1.706       2.291\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2353\n",
      "Model:                       QuantReg   Bandwidth:                    0.007158\n",
      "Method:                 Least Squares   Sparsity:                       0.6955\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:06   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0219      0.011      2.007      0.045       0.001       0.043\n",
      "three_month_yield_change     -0.0976      0.280     -0.348      0.728      -0.648       0.452\n",
      "term_spread_change           -0.0365      0.277     -0.132      0.895      -0.580       0.507\n",
      "TED_spread                    1.7271      1.119      1.543      0.123      -0.468       3.922\n",
      "credit_spread_change         -0.5311      0.421     -1.262      0.207      -1.357       0.294\n",
      "market_return                 0.0712      0.250      0.284      0.776      -0.420       0.562\n",
      "real_estate_excess_return    -0.0796      0.247     -0.323      0.747      -0.564       0.404\n",
      "equity_volatility             3.4454      0.383      9.004      0.000       2.695       4.196\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4368\n",
      "Model:                       QuantReg   Bandwidth:                    0.001960\n",
      "Method:                 Least Squares   Sparsity:                      0.07546\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:06   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0119      0.003      4.316      0.000       0.006       0.017\n",
      "three_month_yield_change     -0.0148      0.079     -0.188      0.851      -0.169       0.139\n",
      "term_spread_change           -0.1622      0.068     -2.373      0.018      -0.296      -0.028\n",
      "TED_spread                   -0.7806      0.261     -2.986      0.003      -1.293      -0.268\n",
      "credit_spread_change         -0.0729      0.094     -0.776      0.438      -0.257       0.111\n",
      "market_return                -0.0452      0.038     -1.191      0.234      -0.120       0.029\n",
      "real_estate_excess_return    -0.0716      0.048     -1.489      0.137      -0.166       0.023\n",
      "equity_volatility             0.7299      0.070     10.356      0.000       0.592       0.868\n",
      "institution                   0.4434      0.035     12.744      0.000       0.375       0.512\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5548\n",
      "Model:                       QuantReg   Bandwidth:                    0.003439\n",
      "Method:                 Least Squares   Sparsity:                       0.2381\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:06   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0157      0.003      4.534      0.000       0.009       0.023\n",
      "three_month_yield_change      0.0366      0.115      0.318      0.751      -0.189       0.262\n",
      "term_spread_change           -0.3158      0.105     -3.001      0.003      -0.522      -0.109\n",
      "TED_spread                   -1.4837      0.421     -3.528      0.000      -2.308      -0.659\n",
      "credit_spread_change          0.0033      0.121      0.027      0.978      -0.233       0.240\n",
      "market_return                -0.0555      0.091     -0.609      0.543      -0.234       0.123\n",
      "real_estate_excess_return    -0.1704      0.070     -2.428      0.015      -0.308      -0.033\n",
      "equity_volatility             1.2774      0.139      9.201      0.000       1.005       1.550\n",
      "institution                   0.4328      0.080      5.406      0.000       0.276       0.590\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 37.0620 - val_loss: 34.0337\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.1493 - val_loss: 33.3337\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.3065 - val_loss: 32.3231\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.7150 - val_loss: 31.2127\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.5264 - val_loss: 29.7144\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.6428 - val_loss: 28.1869\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.1543 - val_loss: 26.8418\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.7167 - val_loss: 25.7493\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.9855 - val_loss: 24.8267\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2226 - val_loss: 24.0365\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2761 - val_loss: 23.3425\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.9619 - val_loss: 22.7407\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5418 - val_loss: 22.2710\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0643 - val_loss: 21.8602\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5570 - val_loss: 21.4915\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4600 - val_loss: 21.2007\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1942 - val_loss: 21.0000\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9297 - val_loss: 20.8662\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7873 - val_loss: 20.7478\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6304 - val_loss: 20.6621\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3877 - val_loss: 20.6065\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4170 - val_loss: 20.5602\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2917 - val_loss: 20.5186\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1492 - val_loss: 20.4826\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2285 - val_loss: 20.4504\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9932 - val_loss: 20.4240\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1588 - val_loss: 20.3978\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0887 - val_loss: 20.3736\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0815 - val_loss: 20.3503\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9323 - val_loss: 20.3303\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0613 - val_loss: 20.3120\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9858 - val_loss: 20.2961\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9137 - val_loss: 20.2814\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8592 - val_loss: 20.2680\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9847 - val_loss: 20.2552\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9789 - val_loss: 20.2422\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9742 - val_loss: 20.2294\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8817 - val_loss: 20.2167\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9747 - val_loss: 20.2038\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9297 - val_loss: 20.1913\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9462 - val_loss: 20.1788\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7953 - val_loss: 20.1677\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9174 - val_loss: 20.1564\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9148 - val_loss: 20.1455\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9039 - val_loss: 20.1346\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8475 - val_loss: 20.1241\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7837 - val_loss: 20.1135\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8496 - val_loss: 20.1028\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8031 - val_loss: 20.0921\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7298 - val_loss: 20.0815\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8249 - val_loss: 20.0708\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7957 - val_loss: 20.0601\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7453 - val_loss: 20.0494\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6920 - val_loss: 20.0387\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7744 - val_loss: 20.0278\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7777 - val_loss: 20.0170\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7706 - val_loss: 20.0060\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6096 - val_loss: 19.9950\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6423 - val_loss: 19.9839\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7055 - val_loss: 19.9728\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6834 - val_loss: 19.9616\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7040 - val_loss: 19.9504\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5972 - val_loss: 19.9391\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6794 - val_loss: 19.9277\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6085 - val_loss: 19.9162\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6231 - val_loss: 19.9047\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6061 - val_loss: 19.8931\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6093 - val_loss: 19.8815\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6201 - val_loss: 19.8698\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5884 - val_loss: 19.8580\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6076 - val_loss: 19.8462\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5932 - val_loss: 19.8343\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5245 - val_loss: 19.8223\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5484 - val_loss: 19.8103\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5383 - val_loss: 19.7982\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5496 - val_loss: 19.7860\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5107 - val_loss: 19.7738\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5248 - val_loss: 19.7616\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5073 - val_loss: 19.7493\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4842 - val_loss: 19.7369\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4303 - val_loss: 19.7244\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4492 - val_loss: 19.7119\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3485 - val_loss: 19.6993\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4495 - val_loss: 19.6867\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4144 - val_loss: 19.6740\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3995 - val_loss: 19.6613\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3750 - val_loss: 19.6486\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3084 - val_loss: 19.6358\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3843 - val_loss: 19.6230\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3483 - val_loss: 19.6101\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2564 - val_loss: 19.5971\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2964 - val_loss: 19.5841\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1879 - val_loss: 19.5710\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2988 - val_loss: 19.5580\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3016 - val_loss: 19.5449\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2391 - val_loss: 19.5317\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2722 - val_loss: 19.5186\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2615 - val_loss: 19.5054\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1979 - val_loss: 19.4921\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1820 - val_loss: 19.4787\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 564us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_89 (Conv1D)          (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_90 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 24.8070 - val_loss: 23.7693\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1078 - val_loss: 23.2439\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5749 - val_loss: 22.8067\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0130 - val_loss: 22.3928\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4727 - val_loss: 21.9268\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9162 - val_loss: 21.5031\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2326 - val_loss: 21.1419\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0846 - val_loss: 20.8267\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7016 - val_loss: 20.5699\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4402 - val_loss: 20.3631\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1667 - val_loss: 20.1950\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9873 - val_loss: 20.0491\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7268 - val_loss: 19.9328\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5561 - val_loss: 19.8343\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4482 - val_loss: 19.7427\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3129 - val_loss: 19.6581\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1996 - val_loss: 19.5797\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0350 - val_loss: 19.5091\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0224 - val_loss: 19.4442\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9662 - val_loss: 19.3843\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9051 - val_loss: 19.3308\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8266 - val_loss: 19.2825\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8085 - val_loss: 19.2419\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7397 - val_loss: 19.2082\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7223 - val_loss: 19.1770\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7076 - val_loss: 19.1491\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6647 - val_loss: 19.1240\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6548 - val_loss: 19.1003\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6276 - val_loss: 19.0778\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5981 - val_loss: 19.0567\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5382 - val_loss: 19.0379\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5608 - val_loss: 19.0189\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4406 - val_loss: 19.0010\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5346 - val_loss: 18.9836\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4606 - val_loss: 18.9671\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4838 - val_loss: 18.9506\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5228 - val_loss: 18.9349\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5112 - val_loss: 18.9196\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4948 - val_loss: 18.9049\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4591 - val_loss: 18.8907\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4480 - val_loss: 18.8776\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4180 - val_loss: 18.8656\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4521 - val_loss: 18.8526\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4342 - val_loss: 18.8408\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4167 - val_loss: 18.8287\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4126 - val_loss: 18.8171\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4252 - val_loss: 18.8052\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3838 - val_loss: 18.7939\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4039 - val_loss: 18.7839\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3680 - val_loss: 18.7732\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3808 - val_loss: 18.7620\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3760 - val_loss: 18.7511\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3724 - val_loss: 18.7405\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3337 - val_loss: 18.7304\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3393 - val_loss: 18.7200\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3362 - val_loss: 18.7097\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2994 - val_loss: 18.7001\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2990 - val_loss: 18.6900\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3116 - val_loss: 18.6797\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3074 - val_loss: 18.6692\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2882 - val_loss: 18.6594\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2557 - val_loss: 18.6492\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2757 - val_loss: 18.6392\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2349 - val_loss: 18.6298\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2340 - val_loss: 18.6203\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2063 - val_loss: 18.6099\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2106 - val_loss: 18.6010\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2129 - val_loss: 18.5906\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2063 - val_loss: 18.5801\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2083 - val_loss: 18.5694\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0353 - val_loss: 18.5598\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0982 - val_loss: 18.5498\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1629 - val_loss: 18.5398\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1683 - val_loss: 18.5297\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1251 - val_loss: 18.5195\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1059 - val_loss: 18.5100\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1131 - val_loss: 18.5001\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0838 - val_loss: 18.4899\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1042 - val_loss: 18.4795\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0987 - val_loss: 18.4686\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1008 - val_loss: 18.4585\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0835 - val_loss: 18.4484\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0694 - val_loss: 18.4388\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0520 - val_loss: 18.4285\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0527 - val_loss: 18.4175\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0348 - val_loss: 18.4072\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0365 - val_loss: 18.3967\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0185 - val_loss: 18.3857\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0060 - val_loss: 18.3754\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9601 - val_loss: 18.3647\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9918 - val_loss: 18.3541\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8408 - val_loss: 18.3434\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9152 - val_loss: 18.3329\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9580 - val_loss: 18.3217\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9499 - val_loss: 18.3113\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9082 - val_loss: 18.3006\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8360 - val_loss: 18.2906\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8976 - val_loss: 18.2799\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8714 - val_loss: 18.2684\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8559 - val_loss: 18.2573\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 669us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_93 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_96 (Conv1D)          (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1664\n",
      "Model:                       QuantReg   Bandwidth:                    0.005062\n",
      "Method:                 Least Squares   Sparsity:                       0.1533\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:26   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0324      0.006      5.662      0.000       0.021       0.044\n",
      "three_month_yield_change     -0.5062      0.147     -3.445      0.001      -0.794      -0.218\n",
      "term_spread_change           -0.7396      0.125     -5.929      0.000      -0.984      -0.495\n",
      "TED_spread                   -1.3243      0.579     -2.289      0.022      -2.459      -0.190\n",
      "credit_spread_change         -0.3372      0.204     -1.654      0.098      -0.737       0.063\n",
      "market_return                 0.0290      0.088      0.331      0.740      -0.143       0.201\n",
      "real_estate_excess_return     0.1825      0.097      1.877      0.061      -0.008       0.373\n",
      "equity_volatility             2.3000      0.149     15.471      0.000       2.008       2.591\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2782\n",
      "Model:                       QuantReg   Bandwidth:                    0.007723\n",
      "Method:                 Least Squares   Sparsity:                       0.7639\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:26   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0760      0.013      5.990      0.000       0.051       0.101\n",
      "three_month_yield_change     -0.8022      0.354     -2.269      0.023      -1.495      -0.109\n",
      "term_spread_change           -1.3077      0.328     -3.989      0.000      -1.951      -0.665\n",
      "TED_spread                   -1.0716      1.450     -0.739      0.460      -3.916       1.773\n",
      "credit_spread_change         -1.1509      0.450     -2.556      0.011      -2.034      -0.268\n",
      "market_return                -0.1958      0.297     -0.660      0.510      -0.778       0.386\n",
      "real_estate_excess_return     0.0618      0.308      0.201      0.841      -0.542       0.666\n",
      "equity_volatility             2.8164      0.458      6.147      0.000       1.918       3.715\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3776\n",
      "Model:                       QuantReg   Bandwidth:                    0.002258\n",
      "Method:                 Least Squares   Sparsity:                      0.06806\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:26   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0151      0.002      6.199      0.000       0.010       0.020\n",
      "three_month_yield_change     -0.0944      0.070     -1.348      0.178      -0.232       0.043\n",
      "term_spread_change           -0.1958      0.066     -2.988      0.003      -0.324      -0.067\n",
      "TED_spread                   -1.1827      0.258     -4.577      0.000      -1.689      -0.676\n",
      "credit_spread_change         -0.1682      0.083     -2.025      0.043      -0.331      -0.005\n",
      "market_return                -0.0270      0.034     -0.786      0.432      -0.094       0.040\n",
      "real_estate_excess_return    -0.0484      0.040     -1.205      0.228      -0.127       0.030\n",
      "equity_volatility             0.9052      0.071     12.745      0.000       0.766       1.045\n",
      "institution                   0.4183      0.031     13.407      0.000       0.357       0.479\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4528\n",
      "Model:                       QuantReg   Bandwidth:                    0.004183\n",
      "Method:                 Least Squares   Sparsity:                       0.3510\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:26   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.005      7.612      0.000       0.029       0.049\n",
      "three_month_yield_change     -0.4681      0.155     -3.011      0.003      -0.773      -0.163\n",
      "term_spread_change           -0.6276      0.168     -3.736      0.000      -0.957      -0.298\n",
      "TED_spread                   -2.2947      0.650     -3.531      0.000      -3.569      -1.020\n",
      "credit_spread_change         -0.3985      0.169     -2.358      0.018      -0.730      -0.067\n",
      "market_return                -0.0612      0.135     -0.452      0.652      -0.327       0.204\n",
      "real_estate_excess_return    -0.2818      0.107     -2.625      0.009      -0.492      -0.071\n",
      "equity_volatility             1.3550      0.211      6.434      0.000       0.942       1.768\n",
      "institution                   0.4309      0.126      3.419      0.001       0.184       0.678\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 39.4930 - val_loss: 35.8365\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.4951 - val_loss: 34.9684\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.6824 - val_loss: 34.1353\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.8201 - val_loss: 33.2456\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.6908 - val_loss: 32.3175\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.6952 - val_loss: 31.5053\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.7771 - val_loss: 30.8473\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.1554 - val_loss: 30.3092\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.4714 - val_loss: 29.8208\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.0509 - val_loss: 29.3508\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.4266 - val_loss: 28.8859\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.8146 - val_loss: 28.4482\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.2507 - val_loss: 28.0386\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.8313 - val_loss: 27.6438\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.3333 - val_loss: 27.2498\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.7833 - val_loss: 26.8533\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.3836 - val_loss: 26.4745\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9893 - val_loss: 26.1090\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.4644 - val_loss: 25.7749\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.8404 - val_loss: 25.4393\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5465 - val_loss: 25.1269\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2347 - val_loss: 24.8271\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7702 - val_loss: 24.5261\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5224 - val_loss: 24.2241\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1214 - val_loss: 23.9289\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.8609 - val_loss: 23.6341\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.5212 - val_loss: 23.3540\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2681 - val_loss: 23.0921\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0745 - val_loss: 22.8584\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8123 - val_loss: 22.6517\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6438 - val_loss: 22.4732\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2585 - val_loss: 22.3168\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2818 - val_loss: 22.1911\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0798 - val_loss: 22.0942\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7278 - val_loss: 22.0073\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7195 - val_loss: 21.9260\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7421 - val_loss: 21.8608\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6336 - val_loss: 21.8077\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5381 - val_loss: 21.7587\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4091 - val_loss: 21.7121\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2894 - val_loss: 21.6680\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2654 - val_loss: 21.6240\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2089 - val_loss: 21.5826\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1232 - val_loss: 21.5481\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0844 - val_loss: 21.5220\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0180 - val_loss: 21.5051\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9231 - val_loss: 21.4933\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8200 - val_loss: 21.4826\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8153 - val_loss: 21.4719\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7485 - val_loss: 21.4615\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7112 - val_loss: 21.4512\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7409 - val_loss: 21.4411\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6932 - val_loss: 21.4311\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6969 - val_loss: 21.4211\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6793 - val_loss: 21.4111\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6607 - val_loss: 21.4011\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6223 - val_loss: 21.3910\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6184 - val_loss: 21.3809\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5919 - val_loss: 21.3707\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5861 - val_loss: 21.3606\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5288 - val_loss: 21.3504\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4564 - val_loss: 21.3401\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5262 - val_loss: 21.3297\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4970 - val_loss: 21.3194\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4825 - val_loss: 21.3089\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4667 - val_loss: 21.2984\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4776 - val_loss: 21.2879\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3435 - val_loss: 21.2774\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4556 - val_loss: 21.2667\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4257 - val_loss: 21.2561\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3675 - val_loss: 21.2455\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3088 - val_loss: 21.2348\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3684 - val_loss: 21.2241\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3792 - val_loss: 21.2133\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2072 - val_loss: 21.2024\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3693 - val_loss: 21.1915\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2901 - val_loss: 21.1805\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3395 - val_loss: 21.1695\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2258 - val_loss: 21.1584\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3213 - val_loss: 21.1473\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2752 - val_loss: 21.1361\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3131 - val_loss: 21.1249\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2219 - val_loss: 21.1136\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2807 - val_loss: 21.1023\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2586 - val_loss: 21.0909\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2550 - val_loss: 21.0795\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2295 - val_loss: 21.0680\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2390 - val_loss: 21.0565\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2082 - val_loss: 21.0450\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2201 - val_loss: 21.0334\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1213 - val_loss: 21.0218\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1384 - val_loss: 21.0101\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1755 - val_loss: 20.9984\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1582 - val_loss: 20.9866\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1533 - val_loss: 20.9748\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1344 - val_loss: 20.9629\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0980 - val_loss: 20.9510\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1177 - val_loss: 20.9391\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0168 - val_loss: 20.9271\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0679 - val_loss: 20.9151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 684us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_99 (Conv1D)          (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_102 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                125\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.9803 - val_loss: 23.9020\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2077 - val_loss: 23.1790\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 23.4389 - val_loss: 22.5849\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7801 - val_loss: 22.1187\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2718 - val_loss: 21.6906\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.7803 - val_loss: 21.2618\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.2748 - val_loss: 20.8613\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.8048 - val_loss: 20.5466\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4881 - val_loss: 20.3127\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.1474 - val_loss: 20.1312\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9204 - val_loss: 19.9721\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6809 - val_loss: 19.8219\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4321 - val_loss: 19.6912\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0826 - val_loss: 19.5799\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.1265 - val_loss: 19.4771\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0086 - val_loss: 19.3886\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9298 - val_loss: 19.3156\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8401 - val_loss: 19.2542\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7747 - val_loss: 19.2014\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6556 - val_loss: 19.1622\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7138 - val_loss: 19.1286\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6651 - val_loss: 19.0991\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6476 - val_loss: 19.0738\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5842 - val_loss: 19.0511\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5946 - val_loss: 19.0293\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5410 - val_loss: 19.0092\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5735 - val_loss: 18.9906\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5606 - val_loss: 18.9740\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.5194 - val_loss: 18.9585\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5316 - val_loss: 18.9430\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5177 - val_loss: 18.9295\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.5213 - val_loss: 18.9155\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4896 - val_loss: 18.9024\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4907 - val_loss: 18.8894\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4877 - val_loss: 18.8771\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4756 - val_loss: 18.8641\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4638 - val_loss: 18.8529\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4630 - val_loss: 18.8416\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3939 - val_loss: 18.8306\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4387 - val_loss: 18.8188\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4367 - val_loss: 18.8079\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4313 - val_loss: 18.7973\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4021 - val_loss: 18.7873\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3840 - val_loss: 18.7766\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4032 - val_loss: 18.7665\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3907 - val_loss: 18.7564\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3870 - val_loss: 18.7466\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3788 - val_loss: 18.7367\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3547 - val_loss: 18.7279\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3445 - val_loss: 18.7183\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3445 - val_loss: 18.7084\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3441 - val_loss: 18.6992\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3418 - val_loss: 18.6887\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3077 - val_loss: 18.6792\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3178 - val_loss: 18.6707\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2876 - val_loss: 18.6616\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2998 - val_loss: 18.6520\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2833 - val_loss: 18.6429\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1629 - val_loss: 18.6323\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2739 - val_loss: 18.6229\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2646 - val_loss: 18.6136\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2121 - val_loss: 18.6050\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2334 - val_loss: 18.5954\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2372 - val_loss: 18.5866\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1858 - val_loss: 18.5780\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2097 - val_loss: 18.5677\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1708 - val_loss: 18.5578\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1788 - val_loss: 18.5486\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1554 - val_loss: 18.5390\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1853 - val_loss: 18.5293\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1657 - val_loss: 18.5191\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1535 - val_loss: 18.5083\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1348 - val_loss: 18.4990\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1310 - val_loss: 18.4891\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1253 - val_loss: 18.4792\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1133 - val_loss: 18.4692\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0985 - val_loss: 18.4599\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0566 - val_loss: 18.4508\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0919 - val_loss: 18.4403\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0788 - val_loss: 18.4308\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0313 - val_loss: 18.4205\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0298 - val_loss: 18.4103\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0498 - val_loss: 18.4008\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0459 - val_loss: 18.3901\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0345 - val_loss: 18.3800\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0043 - val_loss: 18.3701\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0051 - val_loss: 18.3598\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9692 - val_loss: 18.3513\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9958 - val_loss: 18.3408\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9772 - val_loss: 18.3305\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8932 - val_loss: 18.3207\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9568 - val_loss: 18.3105\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8680 - val_loss: 18.3000\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9165 - val_loss: 18.2898\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9155 - val_loss: 18.2793\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8191 - val_loss: 18.2698\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8661 - val_loss: 18.2590\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8913 - val_loss: 18.2485\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8817 - val_loss: 18.2376\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8613 - val_loss: 18.2269\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 777us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 8, 1)]            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_105 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_108 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_111 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1369\n",
      "Model:                       QuantReg   Bandwidth:                    0.004515\n",
      "Method:                 Least Squares   Sparsity:                       0.1624\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:49   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0172      0.006      3.017      0.003       0.006       0.028\n",
      "three_month_yield_change      0.0567      0.148      0.382      0.703      -0.234       0.348\n",
      "term_spread_change           -0.2085      0.141     -1.476      0.140      -0.486       0.069\n",
      "TED_spread                   -1.2834      0.600     -2.138      0.033      -2.460      -0.107\n",
      "credit_spread_change         -0.1336      0.210     -0.635      0.525      -0.546       0.279\n",
      "market_return                -0.0748      0.096     -0.778      0.436      -0.263       0.114\n",
      "real_estate_excess_return     0.1639      0.100      1.647      0.100      -0.031       0.359\n",
      "equity_volatility             1.9198      0.157     12.203      0.000       1.611       2.228\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2608\n",
      "Model:                       QuantReg   Bandwidth:                    0.007085\n",
      "Method:                 Least Squares   Sparsity:                       0.8324\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:49   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0556      0.011      5.138      0.000       0.034       0.077\n",
      "three_month_yield_change     -0.5564      0.301     -1.847      0.065      -1.147       0.034\n",
      "term_spread_change           -0.5500      0.319     -1.727      0.084      -1.175       0.075\n",
      "TED_spread                    0.8534      1.450      0.588      0.556      -1.990       3.697\n",
      "credit_spread_change         -1.1968      0.457     -2.620      0.009      -2.093      -0.301\n",
      "market_return                 0.0816      0.287      0.284      0.776      -0.482       0.645\n",
      "real_estate_excess_return    -0.0843      0.271     -0.311      0.756      -0.615       0.447\n",
      "equity_volatility             3.2269      0.480      6.723      0.000       2.286       4.168\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4477\n",
      "Model:                       QuantReg   Bandwidth:                    0.002064\n",
      "Method:                 Least Squares   Sparsity:                      0.06189\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:49   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0191      0.002      8.778      0.000       0.015       0.023\n",
      "three_month_yield_change     -0.1645      0.065     -2.528      0.012      -0.292      -0.037\n",
      "term_spread_change           -0.1998      0.058     -3.431      0.001      -0.314      -0.086\n",
      "TED_spread                   -0.3999      0.240     -1.664      0.096      -0.871       0.071\n",
      "credit_spread_change         -0.3389      0.073     -4.656      0.000      -0.482      -0.196\n",
      "market_return                -0.0526      0.029     -1.816      0.070      -0.109       0.004\n",
      "real_estate_excess_return    -0.0410      0.039     -1.051      0.293      -0.118       0.036\n",
      "equity_volatility             0.6421      0.059     10.885      0.000       0.526       0.758\n",
      "institution                   0.4759      0.027     17.445      0.000       0.422       0.529\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5516\n",
      "Model:                       QuantReg   Bandwidth:                    0.003375\n",
      "Method:                 Least Squares   Sparsity:                       0.2652\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:54:49   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0223      0.004      6.110      0.000       0.015       0.029\n",
      "three_month_yield_change     -0.2728      0.124     -2.206      0.027      -0.515      -0.030\n",
      "term_spread_change           -0.2988      0.111     -2.704      0.007      -0.516      -0.082\n",
      "TED_spread                   -0.8866      0.487     -1.819      0.069      -1.842       0.069\n",
      "credit_spread_change         -0.2052      0.129     -1.589      0.112      -0.458       0.048\n",
      "market_return                -0.2037      0.101     -2.015      0.044      -0.402      -0.005\n",
      "real_estate_excess_return    -0.2821      0.087     -3.242      0.001      -0.453      -0.111\n",
      "equity_volatility             1.1585      0.154      7.523      0.000       0.857       1.460\n",
      "institution                   0.4977      0.083      5.976      0.000       0.334       0.661\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 7ms/step - loss: 38.7292 - val_loss: 39.1931\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.5375 - val_loss: 38.3391\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.7067 - val_loss: 37.5116\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.5805 - val_loss: 36.7570\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.6365 - val_loss: 36.0944\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.9718 - val_loss: 35.4246\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.0119 - val_loss: 34.6080\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.7547 - val_loss: 33.7372\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.8887 - val_loss: 32.6335\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.7565 - val_loss: 31.6055\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.7609 - val_loss: 30.6354\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.9337 - val_loss: 29.7321\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1799 - val_loss: 28.9302\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3941 - val_loss: 28.2097\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8798 - val_loss: 27.5537\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2099 - val_loss: 26.9599\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8744 - val_loss: 26.4621\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5053 - val_loss: 26.0407\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9619 - val_loss: 25.6722\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9374 - val_loss: 25.3595\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7875 - val_loss: 25.0752\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6438 - val_loss: 24.8357\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5482 - val_loss: 24.6180\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4151 - val_loss: 24.4407\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3194 - val_loss: 24.2923\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2915 - val_loss: 24.1677\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2043 - val_loss: 24.0615\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1272 - val_loss: 23.9788\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1071 - val_loss: 23.9120\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1007 - val_loss: 23.8604\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0005 - val_loss: 23.8217\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9718 - val_loss: 23.7896\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0152 - val_loss: 23.7608\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9556 - val_loss: 23.7348\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8237 - val_loss: 23.7109\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8874 - val_loss: 23.6902\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9323 - val_loss: 23.6704\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8589 - val_loss: 23.6521\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8669 - val_loss: 23.6342\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8416 - val_loss: 23.6159\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8260 - val_loss: 23.5975\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8623 - val_loss: 23.5810\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8540 - val_loss: 23.5646\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7995 - val_loss: 23.5483\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7413 - val_loss: 23.5328\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6935 - val_loss: 23.5184\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7851 - val_loss: 23.5044\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7197 - val_loss: 23.4903\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7560 - val_loss: 23.4774\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7189 - val_loss: 23.4643\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7418 - val_loss: 23.4509\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7336 - val_loss: 23.4376\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7109 - val_loss: 23.4246\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7197 - val_loss: 23.4112\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6695 - val_loss: 23.3987\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6929 - val_loss: 23.3862\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6790 - val_loss: 23.3743\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6563 - val_loss: 23.3627\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6659 - val_loss: 23.3508\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6114 - val_loss: 23.3387\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6472 - val_loss: 23.3278\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6397 - val_loss: 23.3160\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5764 - val_loss: 23.3042\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6099 - val_loss: 23.2923\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6043 - val_loss: 23.2806\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5273 - val_loss: 23.2690\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5544 - val_loss: 23.2571\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5284 - val_loss: 23.2456\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4684 - val_loss: 23.2340\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3501 - val_loss: 23.2226\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5252 - val_loss: 23.2110\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5222 - val_loss: 23.1994\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5117 - val_loss: 23.1876\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4907 - val_loss: 23.1760\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4251 - val_loss: 23.1644\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4381 - val_loss: 23.1535\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4701 - val_loss: 23.1415\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4042 - val_loss: 23.1299\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3316 - val_loss: 23.1183\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3813 - val_loss: 23.1068\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4009 - val_loss: 23.0949\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3154 - val_loss: 23.0836\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3915 - val_loss: 23.0714\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3786 - val_loss: 23.0592\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2803 - val_loss: 23.0475\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3405 - val_loss: 23.0357\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3437 - val_loss: 23.0238\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2436 - val_loss: 23.0115\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2054 - val_loss: 22.9998\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3153 - val_loss: 22.9878\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2880 - val_loss: 22.9760\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2508 - val_loss: 22.9643\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2384 - val_loss: 22.9525\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2070 - val_loss: 22.9408\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2571 - val_loss: 22.9285\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2429 - val_loss: 22.9161\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2284 - val_loss: 22.9040\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2154 - val_loss: 22.8918\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2006 - val_loss: 22.8795\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1984 - val_loss: 22.8670\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 681us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_114 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_117 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.6552 - val_loss: 25.4045\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0126 - val_loss: 24.8078\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.0072 - val_loss: 23.5143\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4042 - val_loss: 22.3534\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1888 - val_loss: 21.5401\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4103 - val_loss: 20.9707\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8346 - val_loss: 20.5680\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4387 - val_loss: 20.2970\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0652 - val_loss: 20.1001\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8190 - val_loss: 19.9433\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5761 - val_loss: 19.8318\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3791 - val_loss: 19.7337\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2651 - val_loss: 19.6468\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2069 - val_loss: 19.5632\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0944 - val_loss: 19.4865\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9538 - val_loss: 19.4180\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9219 - val_loss: 19.3595\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7760 - val_loss: 19.3087\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8234 - val_loss: 19.2603\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7728 - val_loss: 19.2159\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7435 - val_loss: 19.1764\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7145 - val_loss: 19.1443\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6612 - val_loss: 19.1185\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6194 - val_loss: 19.0959\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6316 - val_loss: 19.0738\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6143 - val_loss: 19.0530\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5937 - val_loss: 19.0327\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5611 - val_loss: 19.0132\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5195 - val_loss: 18.9944\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5293 - val_loss: 18.9760\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4467 - val_loss: 18.9581\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5017 - val_loss: 18.9410\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4751 - val_loss: 18.9238\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4155 - val_loss: 18.9084\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4473 - val_loss: 18.8926\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4552 - val_loss: 18.8770\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4375 - val_loss: 18.8628\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4175 - val_loss: 18.8493\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3398 - val_loss: 18.8356\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3974 - val_loss: 18.8222\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3276 - val_loss: 18.8087\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3463 - val_loss: 18.7953\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2823 - val_loss: 18.7813\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3558 - val_loss: 18.7678\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3370 - val_loss: 18.7543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3377 - val_loss: 18.7415\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3217 - val_loss: 18.7283\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3099 - val_loss: 18.7153\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3083 - val_loss: 18.7029\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2814 - val_loss: 18.6902\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2085 - val_loss: 18.6778\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2787 - val_loss: 18.6648\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1763 - val_loss: 18.6531\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2390 - val_loss: 18.6402\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2429 - val_loss: 18.6276\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2346 - val_loss: 18.6152\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2203 - val_loss: 18.6035\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2046 - val_loss: 18.5912\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1626 - val_loss: 18.5792\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1903 - val_loss: 18.5670\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1749 - val_loss: 18.5546\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1660 - val_loss: 18.5425\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1242 - val_loss: 18.5306\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1479 - val_loss: 18.5185\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1035 - val_loss: 18.5065\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1008 - val_loss: 18.4946\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0956 - val_loss: 18.4828\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9800 - val_loss: 18.4707\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0850 - val_loss: 18.4588\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0349 - val_loss: 18.4475\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0650 - val_loss: 18.4352\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0570 - val_loss: 18.4227\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0140 - val_loss: 18.4111\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0339 - val_loss: 18.3988\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0190 - val_loss: 18.3862\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0124 - val_loss: 18.3741\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8965 - val_loss: 18.3627\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8897 - val_loss: 18.3513\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9499 - val_loss: 18.3389\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9372 - val_loss: 18.3272\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9533 - val_loss: 18.3149\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9337 - val_loss: 18.3029\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9304 - val_loss: 18.2905\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8805 - val_loss: 18.2784\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9064 - val_loss: 18.2664\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8733 - val_loss: 18.2545\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8794 - val_loss: 18.2428\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8466 - val_loss: 18.2305\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8519 - val_loss: 18.2181\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8185 - val_loss: 18.2062\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8371 - val_loss: 18.1934\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7746 - val_loss: 18.1817\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7907 - val_loss: 18.1699\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7984 - val_loss: 18.1570\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7852 - val_loss: 18.1444\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7644 - val_loss: 18.1317\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7635 - val_loss: 18.1191\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6734 - val_loss: 18.1067\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7195 - val_loss: 18.0943\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5922 - val_loss: 18.0820\n",
      "4/4 [==============================] - 0s 731us/step\n",
      "77/77 [==============================] - 0s 756us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_120 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_121 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_122 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_123 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_124 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_125 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08823\n",
      "Model:                       QuantReg   Bandwidth:                    0.005171\n",
      "Method:                 Least Squares   Sparsity:                       0.1939\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:13   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0293      0.007      4.150      0.000       0.015       0.043\n",
      "three_month_yield_change     -0.1056      0.192     -0.549      0.583      -0.483       0.272\n",
      "term_spread_change           -0.3577      0.180     -1.983      0.047      -0.711      -0.004\n",
      "TED_spread                   -1.9526      0.727     -2.685      0.007      -3.379      -0.527\n",
      "credit_spread_change         -0.1451      0.259     -0.560      0.575      -0.653       0.363\n",
      "market_return                 0.0059      0.108      0.055      0.956      -0.205       0.217\n",
      "real_estate_excess_return     0.1206      0.124      0.969      0.332      -0.123       0.365\n",
      "equity_volatility             1.7453      0.201      8.667      0.000       1.350       2.140\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1924\n",
      "Model:                       QuantReg   Bandwidth:                    0.008777\n",
      "Method:                 Least Squares   Sparsity:                        1.313\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:13   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0516      0.021      2.429      0.015       0.010       0.093\n",
      "three_month_yield_change     -0.0038      0.586     -0.006      0.995      -1.153       1.146\n",
      "term_spread_change           -0.7500      0.534     -1.403      0.161      -1.798       0.298\n",
      "TED_spread                   -0.6744      2.390     -0.282      0.778      -5.360       4.012\n",
      "credit_spread_change         -0.7226      0.736     -0.982      0.326      -2.165       0.720\n",
      "market_return                 0.0485      0.465      0.104      0.917      -0.863       0.960\n",
      "real_estate_excess_return     0.4981      0.394      1.264      0.206      -0.274       1.271\n",
      "equity_volatility             4.4774      0.740      6.047      0.000       3.025       5.929\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4244\n",
      "Model:                       QuantReg   Bandwidth:                    0.002046\n",
      "Method:                 Least Squares   Sparsity:                      0.07147\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:13   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0144      0.003      5.736      0.000       0.009       0.019\n",
      "three_month_yield_change     -0.0772      0.070     -1.100      0.271      -0.215       0.060\n",
      "term_spread_change           -0.2170      0.062     -3.479      0.001      -0.339      -0.095\n",
      "TED_spread                   -0.6170      0.250     -2.471      0.014      -1.107      -0.127\n",
      "credit_spread_change         -0.1773      0.090     -1.980      0.048      -0.353      -0.002\n",
      "market_return                -0.0707      0.037     -1.902      0.057      -0.144       0.002\n",
      "real_estate_excess_return    -0.0136      0.044     -0.311      0.756      -0.100       0.072\n",
      "equity_volatility             0.7729      0.073     10.653      0.000       0.631       0.915\n",
      "institution                   0.3978      0.032     12.537      0.000       0.336       0.460\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5448\n",
      "Model:                       QuantReg   Bandwidth:                    0.003615\n",
      "Method:                 Least Squares   Sparsity:                       0.3341\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:13   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0214      0.004      5.130      0.000       0.013       0.030\n",
      "three_month_yield_change     -0.0580      0.142     -0.409      0.683      -0.336       0.220\n",
      "term_spread_change           -0.4918      0.158     -3.116      0.002      -0.801      -0.182\n",
      "TED_spread                   -1.3972      0.660     -2.117      0.034      -2.691      -0.103\n",
      "credit_spread_change          0.0060      0.157      0.038      0.970      -0.301       0.313\n",
      "market_return                -0.1084      0.119     -0.908      0.364      -0.343       0.126\n",
      "real_estate_excess_return    -0.1569      0.102     -1.542      0.123      -0.356       0.043\n",
      "equity_volatility             1.0415      0.202      5.163      0.000       0.646       1.437\n",
      "institution                   0.3809      0.113      3.375      0.001       0.160       0.602\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 44.5558 - val_loss: 44.8496\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 43.4422 - val_loss: 43.3047\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 41.3347 - val_loss: 41.1076\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 38.2529 - val_loss: 38.5842\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.5219 - val_loss: 36.2832\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.4841 - val_loss: 34.6308\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.7491 - val_loss: 33.2760\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.5297 - val_loss: 32.1889\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.5817 - val_loss: 31.2473\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.6500 - val_loss: 30.5754\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.0110 - val_loss: 30.1817\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.6166 - val_loss: 29.8728\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.3598 - val_loss: 29.6546\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7550 - val_loss: 29.5186\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.6921 - val_loss: 29.4066\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7123 - val_loss: 29.3023\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5198 - val_loss: 29.2070\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.4332 - val_loss: 29.1226\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1937 - val_loss: 29.0502\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2956 - val_loss: 28.9849\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2733 - val_loss: 28.9237\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1784 - val_loss: 28.8670\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0936 - val_loss: 28.8142\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1481 - val_loss: 28.7654\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0963 - val_loss: 28.7211\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0145 - val_loss: 28.6848\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9216 - val_loss: 28.6544\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9625 - val_loss: 28.6323\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0236 - val_loss: 28.6137\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9971 - val_loss: 28.6005\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9537 - val_loss: 28.5890\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8952 - val_loss: 28.5798\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9575 - val_loss: 28.5717\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9158 - val_loss: 28.5641\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9253 - val_loss: 28.5570\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9055 - val_loss: 28.5501\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8884 - val_loss: 28.5433\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8627 - val_loss: 28.5366\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8870 - val_loss: 28.5302\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8658 - val_loss: 28.5236\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8736 - val_loss: 28.5172\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6503 - val_loss: 28.5105\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8372 - val_loss: 28.5038\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8035 - val_loss: 28.4964\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8187 - val_loss: 28.4895\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8158 - val_loss: 28.4825\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8391 - val_loss: 28.4753\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7761 - val_loss: 28.4679\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7945 - val_loss: 28.4605\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7605 - val_loss: 28.4530\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7802 - val_loss: 28.4451\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7295 - val_loss: 28.4373\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7040 - val_loss: 28.4290\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7428 - val_loss: 28.4211\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6874 - val_loss: 28.4128\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6818 - val_loss: 28.4041\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6495 - val_loss: 28.3958\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5979 - val_loss: 28.3867\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6461 - val_loss: 28.3779\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5421 - val_loss: 28.3687\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5555 - val_loss: 28.3598\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6720 - val_loss: 28.3506\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1914 - val_loss: 28.3414\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4153 - val_loss: 28.3317\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5332 - val_loss: 28.3228\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5937 - val_loss: 28.3135\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5845 - val_loss: 28.3039\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5439 - val_loss: 28.2946\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5988 - val_loss: 28.2855\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6028 - val_loss: 28.2756\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5839 - val_loss: 28.2663\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5765 - val_loss: 28.2569\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5680 - val_loss: 28.2467\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5019 - val_loss: 28.2364\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5390 - val_loss: 28.2264\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5424 - val_loss: 28.2166\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5114 - val_loss: 28.2064\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4626 - val_loss: 28.1965\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3470 - val_loss: 28.1859\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.5044 - val_loss: 28.1760\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4845 - val_loss: 28.1660\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4931 - val_loss: 28.1559\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3383 - val_loss: 28.1454\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3342 - val_loss: 28.1350\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4457 - val_loss: 28.1251\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4427 - val_loss: 28.1147\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3888 - val_loss: 28.1038\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3540 - val_loss: 28.0937\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3931 - val_loss: 28.0826\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1368 - val_loss: 28.0714\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3738 - val_loss: 28.0608\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3134 - val_loss: 28.0501\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1948 - val_loss: 28.0392\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3371 - val_loss: 28.0289\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2594 - val_loss: 28.0183\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3226 - val_loss: 28.0076\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2772 - val_loss: 27.9962\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3024 - val_loss: 27.9855\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2279 - val_loss: 27.9743\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2767 - val_loss: 27.9631\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 704us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_126 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_127 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_128 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_129 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_132 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                118\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 25.3931 - val_loss: 24.2537\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5801 - val_loss: 23.5655\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9094 - val_loss: 22.9720\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0969 - val_loss: 22.2543\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2911 - val_loss: 21.6600\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5725 - val_loss: 21.1628\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0593 - val_loss: 20.7807\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7373 - val_loss: 20.4662\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3692 - val_loss: 20.2339\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9979 - val_loss: 20.0580\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7727 - val_loss: 19.9032\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6009 - val_loss: 19.7837\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3885 - val_loss: 19.6819\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.2897 - val_loss: 19.5859\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0923 - val_loss: 19.4949\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0218 - val_loss: 19.4070\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9481 - val_loss: 19.3294\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8611 - val_loss: 19.2632\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.6192 - val_loss: 19.2052\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7253 - val_loss: 19.1520\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6104 - val_loss: 19.1059\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6283 - val_loss: 19.0685\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6103 - val_loss: 19.0394\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5777 - val_loss: 19.0116\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5022 - val_loss: 18.9861\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5303 - val_loss: 18.9640\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4959 - val_loss: 18.9422\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4467 - val_loss: 18.9220\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4517 - val_loss: 18.9038\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4455 - val_loss: 18.8853\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4479 - val_loss: 18.8686\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3975 - val_loss: 18.8524\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4190 - val_loss: 18.8377\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4062 - val_loss: 18.8230\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3918 - val_loss: 18.8085\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3803 - val_loss: 18.7935\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2871 - val_loss: 18.7806\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3717 - val_loss: 18.7672\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3490 - val_loss: 18.7549\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3207 - val_loss: 18.7418\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3334 - val_loss: 18.7290\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3296 - val_loss: 18.7155\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2658 - val_loss: 18.7038\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3124 - val_loss: 18.6925\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2793 - val_loss: 18.6810\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2724 - val_loss: 18.6707\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2754 - val_loss: 18.6591\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.1929 - val_loss: 18.6486\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1620 - val_loss: 18.6380\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2603 - val_loss: 18.6266\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2485 - val_loss: 18.6152\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2401 - val_loss: 18.6042\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2279 - val_loss: 18.5934\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2196 - val_loss: 18.5828\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1871 - val_loss: 18.5720\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1691 - val_loss: 18.5617\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1892 - val_loss: 18.5512\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1678 - val_loss: 18.5415\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1719 - val_loss: 18.5308\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1605 - val_loss: 18.5205\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1222 - val_loss: 18.5100\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9785 - val_loss: 18.4995\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0906 - val_loss: 18.4890\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0286 - val_loss: 18.4794\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0941 - val_loss: 18.4688\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0765 - val_loss: 18.4594\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0797 - val_loss: 18.4487\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0755 - val_loss: 18.4376\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0599 - val_loss: 18.4270\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0386 - val_loss: 18.4164\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0459 - val_loss: 18.4060\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9514 - val_loss: 18.3964\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9029 - val_loss: 18.3859\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.0247 - val_loss: 18.3754\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9614 - val_loss: 18.3645\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9817 - val_loss: 18.3540\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9921 - val_loss: 18.3428\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9549 - val_loss: 18.3327\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9674 - val_loss: 18.3222\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9469 - val_loss: 18.3118\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9414 - val_loss: 18.3009\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9267 - val_loss: 18.2901\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8040 - val_loss: 18.2806\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9084 - val_loss: 18.2691\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.9025 - val_loss: 18.2584\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8856 - val_loss: 18.2476\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8698 - val_loss: 18.2362\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8601 - val_loss: 18.2256\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8519 - val_loss: 18.2151\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8444 - val_loss: 18.2035\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6686 - val_loss: 18.1919\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8107 - val_loss: 18.1802\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.8083 - val_loss: 18.1685\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8023 - val_loss: 18.1576\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6966 - val_loss: 18.1460\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7447 - val_loss: 18.1351\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7442 - val_loss: 18.1236\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7551 - val_loss: 18.1115\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7058 - val_loss: 18.1005\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 17.7413 - val_loss: 18.0881\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 769us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_133 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_134 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_135 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_136 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_137 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_138 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_139 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1605\n",
      "Model:                       QuantReg   Bandwidth:                    0.006746\n",
      "Method:                 Least Squares   Sparsity:                       0.2203\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:33   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0139      0.008      1.797      0.072      -0.001       0.029\n",
      "three_month_yield_change     -0.2869      0.215     -1.336      0.182      -0.708       0.134\n",
      "term_spread_change           -0.4933      0.195     -2.527      0.012      -0.876      -0.110\n",
      "TED_spread                   -2.1461      0.794     -2.703      0.007      -3.703      -0.589\n",
      "credit_spread_change          0.3675      0.274      1.341      0.180      -0.170       0.905\n",
      "market_return                -0.1205      0.127     -0.948      0.343      -0.370       0.129\n",
      "real_estate_excess_return     0.1015      0.118      0.857      0.392      -0.131       0.334\n",
      "equity_volatility             3.0585      0.228     13.427      0.000       2.612       3.505\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2974\n",
      "Model:                       QuantReg   Bandwidth:                     0.01135\n",
      "Method:                 Least Squares   Sparsity:                       0.9595\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:33   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0146      0.016      0.938      0.348      -0.016       0.045\n",
      "three_month_yield_change      0.4241      0.411      1.032      0.302      -0.382       1.230\n",
      "term_spread_change           -0.7679      0.405     -1.898      0.058      -1.561       0.026\n",
      "TED_spread                   -3.7956      1.696     -2.237      0.025      -7.122      -0.469\n",
      "credit_spread_change          0.9885      0.593      1.668      0.095      -0.173       2.150\n",
      "market_return                 0.0793      0.395      0.201      0.841      -0.694       0.853\n",
      "real_estate_excess_return    -0.6180      0.282     -2.195      0.028      -1.170      -0.066\n",
      "equity_volatility             4.8451      0.745      6.502      0.000       3.384       6.306\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3921\n",
      "Model:                       QuantReg   Bandwidth:                    0.002384\n",
      "Method:                 Least Squares   Sparsity:                      0.06701\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:33   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0067      0.002      3.018      0.003       0.002       0.011\n",
      "three_month_yield_change     -0.1090      0.063     -1.737      0.083      -0.232       0.014\n",
      "term_spread_change           -0.1414      0.060     -2.375      0.018      -0.258      -0.025\n",
      "TED_spread                   -0.6599      0.217     -3.036      0.002      -1.086      -0.234\n",
      "credit_spread_change          0.0613      0.077      0.792      0.428      -0.090       0.213\n",
      "market_return                -0.0234      0.036     -0.653      0.514      -0.094       0.047\n",
      "real_estate_excess_return    -0.0183      0.045     -0.403      0.687      -0.107       0.071\n",
      "equity_volatility             0.9549      0.067     14.189      0.000       0.823       1.087\n",
      "institution                   0.3125      0.021     14.765      0.000       0.271       0.354\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5215\n",
      "Model:                       QuantReg   Bandwidth:                    0.003622\n",
      "Method:                 Least Squares   Sparsity:                       0.2977\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:33   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0140      0.004      3.228      0.001       0.005       0.022\n",
      "three_month_yield_change     -0.0580      0.126     -0.459      0.646      -0.305       0.189\n",
      "term_spread_change           -0.2870      0.132     -2.176      0.030      -0.546      -0.028\n",
      "TED_spread                   -1.3604      0.543     -2.505      0.012      -2.425      -0.296\n",
      "credit_spread_change          0.1462      0.177      0.826      0.409      -0.201       0.493\n",
      "market_return                -0.1172      0.110     -1.070      0.285      -0.332       0.098\n",
      "real_estate_excess_return    -0.0586      0.120     -0.487      0.626      -0.294       0.177\n",
      "equity_volatility             1.1834      0.183      6.451      0.000       0.824       1.543\n",
      "institution                   0.3088      0.063      4.880      0.000       0.185       0.433\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 38.4206 - val_loss: 32.4520\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.2472 - val_loss: 31.2443\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.7278 - val_loss: 29.9423\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.0668 - val_loss: 28.6576\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.6642 - val_loss: 27.5804\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.3782 - val_loss: 26.6210\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.2700 - val_loss: 25.7821\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.1312 - val_loss: 24.9538\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.3137 - val_loss: 24.1828\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.4233 - val_loss: 23.5355\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.4841 - val_loss: 22.9458\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6822 - val_loss: 22.3940\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.2772 - val_loss: 21.9071\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7874 - val_loss: 21.4583\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3024 - val_loss: 21.1209\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8832 - val_loss: 20.8530\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4877 - val_loss: 20.6366\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3973 - val_loss: 20.4593\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1408 - val_loss: 20.2987\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0921 - val_loss: 20.1672\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9735 - val_loss: 20.0738\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8520 - val_loss: 20.0039\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7860 - val_loss: 19.9604\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7461 - val_loss: 19.9249\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6572 - val_loss: 19.8920\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6062 - val_loss: 19.8619\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5599 - val_loss: 19.8328\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5072 - val_loss: 19.8051\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5279 - val_loss: 19.7797\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4392 - val_loss: 19.7567\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4590 - val_loss: 19.7346\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4195 - val_loss: 19.7147\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3755 - val_loss: 19.6962\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4200 - val_loss: 19.6780\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4135 - val_loss: 19.6592\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2814 - val_loss: 19.6420\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3601 - val_loss: 19.6247\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3364 - val_loss: 19.6085\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1429 - val_loss: 19.5920\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3353 - val_loss: 19.5757\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3322 - val_loss: 19.5602\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2948 - val_loss: 19.5451\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2789 - val_loss: 19.5299\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2532 - val_loss: 19.5153\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0694 - val_loss: 19.5013\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2517 - val_loss: 19.4871\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2409 - val_loss: 19.4732\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2393 - val_loss: 19.4603\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2315 - val_loss: 19.4477\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2225 - val_loss: 19.4356\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1773 - val_loss: 19.4240\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0909 - val_loss: 19.4131\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0509 - val_loss: 19.4024\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1545 - val_loss: 19.3921\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1112 - val_loss: 19.3821\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0923 - val_loss: 19.3721\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1106 - val_loss: 19.3623\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1302 - val_loss: 19.3525\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1199 - val_loss: 19.3427\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1216 - val_loss: 19.3328\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0656 - val_loss: 19.3229\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0926 - val_loss: 19.3130\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0178 - val_loss: 19.3029\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0631 - val_loss: 19.2929\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0416 - val_loss: 19.2827\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0196 - val_loss: 19.2723\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9923 - val_loss: 19.2621\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9783 - val_loss: 19.2516\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0163 - val_loss: 19.2412\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9961 - val_loss: 19.2306\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9261 - val_loss: 19.2197\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9825 - val_loss: 19.2090\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9138 - val_loss: 19.1983\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9428 - val_loss: 19.1874\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9509 - val_loss: 19.1765\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9405 - val_loss: 19.1655\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8787 - val_loss: 19.1543\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8553 - val_loss: 19.1428\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9011 - val_loss: 19.1315\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8923 - val_loss: 19.1205\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8649 - val_loss: 19.1091\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8130 - val_loss: 19.0975\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7159 - val_loss: 19.0860\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8106 - val_loss: 19.0745\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8338 - val_loss: 19.0630\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7503 - val_loss: 19.0516\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8060 - val_loss: 19.0402\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7104 - val_loss: 19.0285\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7788 - val_loss: 19.0170\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7635 - val_loss: 19.0052\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7443 - val_loss: 18.9933\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7502 - val_loss: 18.9814\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7218 - val_loss: 18.9695\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7257 - val_loss: 18.9576\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7024 - val_loss: 18.9455\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6578 - val_loss: 18.9336\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6816 - val_loss: 18.9215\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5466 - val_loss: 18.9090\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6637 - val_loss: 18.8968\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6445 - val_loss: 18.8843\n",
      "4/4 [==============================] - 0s 793us/step\n",
      "77/77 [==============================] - 0s 561us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_140 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_141 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_142 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_143 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_144 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_145 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_146 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                121\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 26.8167 - val_loss: 25.6510\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 26.3140 - val_loss: 25.0422\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 25.2718 - val_loss: 24.0732\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step - loss: 24.4075 - val_loss: 23.3193\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 23.5377 - val_loss: 22.7151\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 22.7988 - val_loss: 22.2412\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 22.3824 - val_loss: 21.8508\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.9170 - val_loss: 21.4651\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.4852 - val_loss: 21.1065\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.0551 - val_loss: 20.8076\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.7668 - val_loss: 20.5345\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.4517 - val_loss: 20.3234\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.1929 - val_loss: 20.1579\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.9757 - val_loss: 20.0114\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.7459 - val_loss: 19.8825\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.5831 - val_loss: 19.7870\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.4346 - val_loss: 19.6987\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.3077 - val_loss: 19.6169\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.1924 - val_loss: 19.5434\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.0598 - val_loss: 19.4710\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.9650 - val_loss: 19.4030\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.9337 - val_loss: 19.3383\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.8563 - val_loss: 19.2841\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.8075 - val_loss: 19.2355\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.7609 - val_loss: 19.1896\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.7235 - val_loss: 19.1462\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.6688 - val_loss: 19.1082\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.5871 - val_loss: 19.0743\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.6208 - val_loss: 19.0462\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.5833 - val_loss: 19.0210\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.5344 - val_loss: 18.9977\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4443 - val_loss: 18.9750\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4672 - val_loss: 18.9539\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3516 - val_loss: 18.9341\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4268 - val_loss: 18.9155\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3995 - val_loss: 18.8972\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4368 - val_loss: 18.8791\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3235 - val_loss: 18.8627\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.4033 - val_loss: 18.8458\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3569 - val_loss: 18.8293\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3725 - val_loss: 18.8133\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1467 - val_loss: 18.7981\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3445 - val_loss: 18.7822\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3145 - val_loss: 18.7666\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3227 - val_loss: 18.7507\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3090 - val_loss: 18.7345\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2238 - val_loss: 18.7190\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2489 - val_loss: 18.7038\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2674 - val_loss: 18.6883\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2540 - val_loss: 18.6731\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2317 - val_loss: 18.6581\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2326 - val_loss: 18.6425\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2027 - val_loss: 18.6274\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1739 - val_loss: 18.6127\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1725 - val_loss: 18.5978\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1787 - val_loss: 18.5828\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1516 - val_loss: 18.5680\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0491 - val_loss: 18.5542\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1445 - val_loss: 18.5402\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1271 - val_loss: 18.5257\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0977 - val_loss: 18.5116\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0984 - val_loss: 18.4978\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0760 - val_loss: 18.4839\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0784 - val_loss: 18.4697\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0705 - val_loss: 18.4561\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0405 - val_loss: 18.4425\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0060 - val_loss: 18.4291\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0340 - val_loss: 18.4153\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0187 - val_loss: 18.4012\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9798 - val_loss: 18.3879\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9751 - val_loss: 18.3739\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9831 - val_loss: 18.3598\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9399 - val_loss: 18.3467\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9404 - val_loss: 18.3328\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9456 - val_loss: 18.3185\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9252 - val_loss: 18.3047\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9113 - val_loss: 18.2912\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7040 - val_loss: 18.2773\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8896 - val_loss: 18.2634\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8772 - val_loss: 18.2493\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8677 - val_loss: 18.2350\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8241 - val_loss: 18.2218\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8260 - val_loss: 18.2078\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8166 - val_loss: 18.1939\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8077 - val_loss: 18.1796\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8023 - val_loss: 18.1653\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7504 - val_loss: 18.1514\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7754 - val_loss: 18.1370\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7647 - val_loss: 18.1229\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6456 - val_loss: 18.1099\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7158 - val_loss: 18.0964\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6856 - val_loss: 18.0821\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.7011 - val_loss: 18.0677\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6889 - val_loss: 18.0539\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6852 - val_loss: 18.0397\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.5681 - val_loss: 18.0257\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6233 - val_loss: 18.0116\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6265 - val_loss: 17.9975\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.6154 - val_loss: 17.9837\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.5920 - val_loss: 17.9694\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 834us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_147 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_148 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_149 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_150 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_151 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_152 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_153 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1365\n",
      "Model:                       QuantReg   Bandwidth:                    0.004679\n",
      "Method:                 Least Squares   Sparsity:                       0.1659\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0346      0.006      5.749      0.000       0.023       0.046\n",
      "three_month_yield_change     -0.5278      0.160     -3.301      0.001      -0.841      -0.214\n",
      "term_spread_change           -0.6201      0.153     -4.051      0.000      -0.920      -0.320\n",
      "TED_spread                    0.3476      0.580      0.599      0.549      -0.790       1.486\n",
      "credit_spread_change         -0.5683      0.210     -2.708      0.007      -0.980      -0.157\n",
      "market_return                 0.0458      0.091      0.504      0.615      -0.132       0.224\n",
      "real_estate_excess_return     0.1184      0.105      1.124      0.261      -0.088       0.325\n",
      "equity_volatility             1.8630      0.153     12.197      0.000       1.563       2.162\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2696\n",
      "Model:                       QuantReg   Bandwidth:                    0.008261\n",
      "Method:                 Least Squares   Sparsity:                       0.9705\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0734      0.017      4.217      0.000       0.039       0.107\n",
      "three_month_yield_change     -1.3926      0.479     -2.908      0.004      -2.332      -0.453\n",
      "term_spread_change           -1.5084      0.484     -3.117      0.002      -2.457      -0.559\n",
      "TED_spread                    0.0145      1.778      0.008      0.993      -3.471       3.500\n",
      "credit_spread_change         -1.1263      0.568     -1.984      0.047      -2.240      -0.013\n",
      "market_return                -0.4408      0.364     -1.211      0.226      -1.155       0.273\n",
      "real_estate_excess_return     0.1112      0.315      0.353      0.724      -0.507       0.730\n",
      "equity_volatility             4.0400      0.615      6.574      0.000       2.835       5.245\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4138\n",
      "Model:                       QuantReg   Bandwidth:                    0.002127\n",
      "Method:                 Least Squares   Sparsity:                      0.09005\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0175      0.003      5.326      0.000       0.011       0.024\n",
      "three_month_yield_change     -0.0774      0.093     -0.835      0.404      -0.259       0.104\n",
      "term_spread_change           -0.1799      0.082     -2.207      0.027      -0.340      -0.020\n",
      "TED_spread                   -1.1159      0.352     -3.174      0.002      -1.805      -0.427\n",
      "credit_spread_change         -0.2464      0.116     -2.119      0.034      -0.474      -0.018\n",
      "market_return                -0.0098      0.042     -0.234      0.815      -0.091       0.072\n",
      "real_estate_excess_return     0.0097      0.054      0.180      0.858      -0.096       0.116\n",
      "equity_volatility             0.7635      0.083      9.213      0.000       0.601       0.926\n",
      "institution                   0.4192      0.039     10.761      0.000       0.343       0.496\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5415\n",
      "Model:                       QuantReg   Bandwidth:                    0.003280\n",
      "Method:                 Least Squares   Sparsity:                       0.2588\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:55:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0274      0.004      6.590      0.000       0.019       0.036\n",
      "three_month_yield_change     -0.0812      0.133     -0.612      0.540      -0.341       0.179\n",
      "term_spread_change           -0.3264      0.125     -2.616      0.009      -0.571      -0.082\n",
      "TED_spread                   -1.9873      0.497     -3.999      0.000      -2.962      -1.013\n",
      "credit_spread_change         -0.1886      0.121     -1.564      0.118      -0.425       0.048\n",
      "market_return                 0.0709      0.089      0.794      0.427      -0.104       0.246\n",
      "real_estate_excess_return    -0.1538      0.089     -1.725      0.085      -0.329       0.021\n",
      "equity_volatility             0.8082      0.149      5.431      0.000       0.516       1.100\n",
      "institution                   0.4350      0.080      5.438      0.000       0.278       0.592\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 44.3704 - val_loss: 41.2419\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 43.4621 - val_loss: 40.3273\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 42.1561 - val_loss: 38.7241\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 40.4855 - val_loss: 37.2384\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.7203 - val_loss: 35.7275\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.2781 - val_loss: 34.2818\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.0290 - val_loss: 32.8543\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.3450 - val_loss: 31.3984\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.1442 - val_loss: 29.9487\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.4978 - val_loss: 28.5694\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.2989 - val_loss: 27.3507\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.8666 - val_loss: 26.1906\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.1118 - val_loss: 25.1242\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.2022 - val_loss: 24.1745\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4030 - val_loss: 23.3329\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7912 - val_loss: 22.6382\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3382 - val_loss: 22.0944\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8878 - val_loss: 21.6919\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6074 - val_loss: 21.4169\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2855 - val_loss: 21.2134\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1532 - val_loss: 21.0438\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9892 - val_loss: 20.9199\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8409 - val_loss: 20.8137\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7846 - val_loss: 20.7222\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6833 - val_loss: 20.6422\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5699 - val_loss: 20.5686\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5103 - val_loss: 20.5039\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4490 - val_loss: 20.4458\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4453 - val_loss: 20.3936\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3733 - val_loss: 20.3477\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3844 - val_loss: 20.3107\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3132 - val_loss: 20.2802\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3562 - val_loss: 20.2544\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3138 - val_loss: 20.2318\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2543 - val_loss: 20.2122\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3160 - val_loss: 20.1956\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2893 - val_loss: 20.1807\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2577 - val_loss: 20.1665\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2603 - val_loss: 20.1536\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2312 - val_loss: 20.1407\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1982 - val_loss: 20.1280\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2297 - val_loss: 20.1159\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1780 - val_loss: 20.1038\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0847 - val_loss: 20.0918\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1691 - val_loss: 20.0801\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1454 - val_loss: 20.0688\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1655 - val_loss: 20.0577\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0288 - val_loss: 20.0466\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0095 - val_loss: 20.0352\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0513 - val_loss: 20.0244\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1342 - val_loss: 20.0132\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0984 - val_loss: 20.0024\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1287 - val_loss: 19.9913\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1006 - val_loss: 19.9802\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0772 - val_loss: 19.9693\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0867 - val_loss: 19.9585\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0296 - val_loss: 19.9481\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0756 - val_loss: 19.9375\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9978 - val_loss: 19.9272\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0475 - val_loss: 19.9170\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0342 - val_loss: 19.9066\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0261 - val_loss: 19.8961\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8729 - val_loss: 19.8858\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9866 - val_loss: 19.8753\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9609 - val_loss: 19.8649\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9714 - val_loss: 19.8545\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9504 - val_loss: 19.8440\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9597 - val_loss: 19.8335\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9351 - val_loss: 19.8229\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9108 - val_loss: 19.8123\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8884 - val_loss: 19.8016\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9124 - val_loss: 19.7908\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8926 - val_loss: 19.7801\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8765 - val_loss: 19.7692\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8144 - val_loss: 19.7584\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8556 - val_loss: 19.7474\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7749 - val_loss: 19.7365\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8533 - val_loss: 19.7255\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8209 - val_loss: 19.7144\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8326 - val_loss: 19.7033\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7014 - val_loss: 19.6920\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7883 - val_loss: 19.6808\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8025 - val_loss: 19.6695\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5855 - val_loss: 19.6582\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7644 - val_loss: 19.6468\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7553 - val_loss: 19.6354\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7316 - val_loss: 19.6239\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7281 - val_loss: 19.6125\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6733 - val_loss: 19.6010\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6916 - val_loss: 19.5894\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4927 - val_loss: 19.5778\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6285 - val_loss: 19.5661\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6732 - val_loss: 19.5545\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6530 - val_loss: 19.5427\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6463 - val_loss: 19.5310\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4186 - val_loss: 19.5191\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6043 - val_loss: 19.5073\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5601 - val_loss: 19.4954\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6005 - val_loss: 19.4835\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5827 - val_loss: 19.4715\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 703us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_154 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_155 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_156 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_157 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_158 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_159 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_160 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.0882 - val_loss: 24.8069\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2097 - val_loss: 23.8516\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0426 - val_loss: 23.0498\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2313 - val_loss: 22.4701\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5832 - val_loss: 22.0209\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0820 - val_loss: 21.6269\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6088 - val_loss: 21.2718\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2745 - val_loss: 20.9687\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9003 - val_loss: 20.6994\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6581 - val_loss: 20.4789\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3844 - val_loss: 20.3062\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1305 - val_loss: 20.1628\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8700 - val_loss: 20.0340\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7095 - val_loss: 19.9275\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6211 - val_loss: 19.8378\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4801 - val_loss: 19.7541\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3402 - val_loss: 19.6722\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2521 - val_loss: 19.5930\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1704 - val_loss: 19.5153\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0019 - val_loss: 19.4439\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9248 - val_loss: 19.3796\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9129 - val_loss: 19.3230\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8563 - val_loss: 19.2686\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8088 - val_loss: 19.2202\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7588 - val_loss: 19.1791\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6988 - val_loss: 19.1440\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5285 - val_loss: 19.1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6660 - val_loss: 19.0867\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6080 - val_loss: 19.0618\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5167 - val_loss: 19.0381\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4902 - val_loss: 19.0161\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5517 - val_loss: 18.9948\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5418 - val_loss: 18.9740\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4829 - val_loss: 18.9544\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4777 - val_loss: 18.9356\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4464 - val_loss: 18.9177\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4834 - val_loss: 18.8997\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4478 - val_loss: 18.8825\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4495 - val_loss: 18.8669\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4243 - val_loss: 18.8512\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4244 - val_loss: 18.8350\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3943 - val_loss: 18.8200\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3937 - val_loss: 18.8060\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2946 - val_loss: 18.7918\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3834 - val_loss: 18.7778\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3710 - val_loss: 18.7635\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3549 - val_loss: 18.7497\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2851 - val_loss: 18.7374\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3303 - val_loss: 18.7248\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3170 - val_loss: 18.7121\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3228 - val_loss: 18.6989\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2648 - val_loss: 18.6876\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2977 - val_loss: 18.6751\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0476 - val_loss: 18.6631\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2634 - val_loss: 18.6504\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2315 - val_loss: 18.6388\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2183 - val_loss: 18.6272\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2160 - val_loss: 18.6157\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2275 - val_loss: 18.6033\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2152 - val_loss: 18.5912\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2118 - val_loss: 18.5786\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2002 - val_loss: 18.5663\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1871 - val_loss: 18.5535\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1698 - val_loss: 18.5407\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1200 - val_loss: 18.5300\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1548 - val_loss: 18.5175\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1329 - val_loss: 18.5060\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1338 - val_loss: 18.4935\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1255 - val_loss: 18.4817\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0888 - val_loss: 18.4696\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0967 - val_loss: 18.4571\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0724 - val_loss: 18.4455\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0693 - val_loss: 18.4334\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0490 - val_loss: 18.4213\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0233 - val_loss: 18.4099\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0322 - val_loss: 18.3974\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0329 - val_loss: 18.3849\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0088 - val_loss: 18.3726\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9680 - val_loss: 18.3605\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9671 - val_loss: 18.3480\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9419 - val_loss: 18.3362\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9329 - val_loss: 18.3239\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9630 - val_loss: 18.3117\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9402 - val_loss: 18.2994\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8866 - val_loss: 18.2873\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9066 - val_loss: 18.2746\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9002 - val_loss: 18.2620\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8869 - val_loss: 18.2503\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8792 - val_loss: 18.2376\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8584 - val_loss: 18.2252\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8561 - val_loss: 18.2122\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8353 - val_loss: 18.2002\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8310 - val_loss: 18.1869\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8137 - val_loss: 18.1744\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8015 - val_loss: 18.1621\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7963 - val_loss: 18.1492\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6905 - val_loss: 18.1363\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7736 - val_loss: 18.1232\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7604 - val_loss: 18.1102\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7510 - val_loss: 18.0972\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 764us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_161 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_162 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_163 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_164 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_165 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_166 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_167 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09577\n",
      "Model:                       QuantReg   Bandwidth:                    0.005822\n",
      "Method:                 Least Squares   Sparsity:                       0.1992\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:23   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0182      0.007      2.531      0.011       0.004       0.032\n",
      "three_month_yield_change     -0.1846      0.185     -0.997      0.319      -0.548       0.179\n",
      "term_spread_change           -0.2068      0.174     -1.190      0.234      -0.548       0.134\n",
      "TED_spread                   -2.2392      0.720     -3.110      0.002      -3.651      -0.827\n",
      "credit_spread_change          0.3393      0.251      1.353      0.176      -0.152       0.831\n",
      "market_return                 0.1321      0.099      1.329      0.184      -0.063       0.327\n",
      "real_estate_excess_return     0.2325      0.130      1.787      0.074      -0.023       0.488\n",
      "equity_volatility             1.7677      0.176     10.031      0.000       1.422       2.113\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1259\n",
      "Model:                       QuantReg   Bandwidth:                    0.008623\n",
      "Method:                 Least Squares   Sparsity:                        1.141\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:23   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0833      0.018      4.614      0.000       0.048       0.119\n",
      "three_month_yield_change     -1.1166      0.555     -2.012      0.044      -2.205      -0.029\n",
      "term_spread_change           -1.0448      0.534     -1.957      0.050      -2.092       0.002\n",
      "TED_spread                   -1.8270      2.351     -0.777      0.437      -6.437       2.782\n",
      "credit_spread_change         -0.8095      0.648     -1.250      0.211      -2.079       0.460\n",
      "market_return                 0.3533      0.295      1.196      0.232      -0.226       0.932\n",
      "real_estate_excess_return     0.2945      0.457      0.645      0.519      -0.601       1.190\n",
      "equity_volatility             2.2704      0.569      3.992      0.000       1.155       3.386\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3687\n",
      "Model:                       QuantReg   Bandwidth:                    0.002147\n",
      "Method:                 Least Squares   Sparsity:                      0.07460\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:23   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0177      0.002      7.142      0.000       0.013       0.023\n",
      "three_month_yield_change     -0.1450      0.073     -1.986      0.047      -0.288      -0.002\n",
      "term_spread_change           -0.2245      0.068     -3.284      0.001      -0.359      -0.090\n",
      "TED_spread                   -0.7161      0.266     -2.696      0.007      -1.237      -0.195\n",
      "credit_spread_change         -0.2501      0.086     -2.915      0.004      -0.418      -0.082\n",
      "market_return                -0.0400      0.039     -1.020      0.308      -0.117       0.037\n",
      "real_estate_excess_return    -0.0220      0.046     -0.483      0.629      -0.111       0.067\n",
      "equity_volatility             0.7385      0.074      9.988      0.000       0.594       0.883\n",
      "institution                   0.3293      0.029     11.484      0.000       0.273       0.386\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4370\n",
      "Model:                       QuantReg   Bandwidth:                    0.004769\n",
      "Method:                 Least Squares   Sparsity:                       0.2927\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:23   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0273      0.004      6.864      0.000       0.019       0.035\n",
      "three_month_yield_change     -0.5459      0.121     -4.496      0.000      -0.784      -0.308\n",
      "term_spread_change           -0.4914      0.125     -3.916      0.000      -0.737      -0.245\n",
      "TED_spread                   -1.3650      0.549     -2.486      0.013      -2.442      -0.288\n",
      "credit_spread_change         -0.4082      0.142     -2.867      0.004      -0.687      -0.129\n",
      "market_return                -0.0131      0.114     -0.115      0.908      -0.236       0.210\n",
      "real_estate_excess_return    -0.1458      0.100     -1.465      0.143      -0.341       0.049\n",
      "equity_volatility             2.1663      0.176     12.317      0.000       1.821       2.511\n",
      "institution                   0.2969      0.084      3.529      0.000       0.132       0.462\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 38.8521 - val_loss: 38.8608\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.7044 - val_loss: 37.6854\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.2600 - val_loss: 36.4286\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.9733 - val_loss: 35.0567\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.3698 - val_loss: 33.5625\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.6391 - val_loss: 31.6285\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.4747 - val_loss: 29.6267\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.6194 - val_loss: 28.0526\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3538 - val_loss: 26.8299\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2369 - val_loss: 25.8495\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5584 - val_loss: 25.1213\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8747 - val_loss: 24.6846\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4534 - val_loss: 24.3529\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0405 - val_loss: 24.0675\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7114 - val_loss: 23.8582\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5620 - val_loss: 23.6811\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4640 - val_loss: 23.5519\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3327 - val_loss: 23.4499\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1662 - val_loss: 23.3684\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0345 - val_loss: 23.2986\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0543 - val_loss: 23.2358\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9594 - val_loss: 23.1811\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9304 - val_loss: 23.1296\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8239 - val_loss: 23.0867\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8315 - val_loss: 23.0470\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7972 - val_loss: 23.0131\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6361 - val_loss: 22.9829\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7459 - val_loss: 22.9571\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6675 - val_loss: 22.9358\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7439 - val_loss: 22.9173\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6814 - val_loss: 22.9009\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6670 - val_loss: 22.8857\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6842 - val_loss: 22.8700\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6628 - val_loss: 22.8551\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6102 - val_loss: 22.8407\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6141 - val_loss: 22.8268\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5255 - val_loss: 22.8131\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6178 - val_loss: 22.7993\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4899 - val_loss: 22.7866\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5419 - val_loss: 22.7745\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5638 - val_loss: 22.7621\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5513 - val_loss: 22.7501\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5324 - val_loss: 22.7386\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5435 - val_loss: 22.7276\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4889 - val_loss: 22.7169\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5079 - val_loss: 22.7064\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5174 - val_loss: 22.6960\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4876 - val_loss: 22.6857\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4439 - val_loss: 22.6753\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4737 - val_loss: 22.6650\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4442 - val_loss: 22.6549\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4474 - val_loss: 22.6447\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4340 - val_loss: 22.6345\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3744 - val_loss: 22.6243\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4009 - val_loss: 22.6143\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4126 - val_loss: 22.6041\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4016 - val_loss: 22.5938\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3764 - val_loss: 22.5835\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3704 - val_loss: 22.5731\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3803 - val_loss: 22.5627\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3546 - val_loss: 22.5522\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3543 - val_loss: 22.5417\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3445 - val_loss: 22.5310\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2853 - val_loss: 22.5204\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3139 - val_loss: 22.5097\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3146 - val_loss: 22.4989\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2674 - val_loss: 22.4881\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2537 - val_loss: 22.4773\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1646 - val_loss: 22.4665\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1817 - val_loss: 22.4557\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2549 - val_loss: 22.4447\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1961 - val_loss: 22.4338\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2068 - val_loss: 22.4227\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2183 - val_loss: 22.4117\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1696 - val_loss: 22.4006\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1666 - val_loss: 22.3894\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2011 - val_loss: 22.3783\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1846 - val_loss: 22.3671\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1369 - val_loss: 22.3559\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1603 - val_loss: 22.3446\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1131 - val_loss: 22.3333\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1239 - val_loss: 22.3220\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1306 - val_loss: 22.3105\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0801 - val_loss: 22.2991\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1005 - val_loss: 22.2877\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0804 - val_loss: 22.2761\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0412 - val_loss: 22.2646\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0697 - val_loss: 22.2530\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0199 - val_loss: 22.2413\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0328 - val_loss: 22.2296\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0339 - val_loss: 22.2179\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0183 - val_loss: 22.2061\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8497 - val_loss: 22.1944\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9453 - val_loss: 22.1826\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9450 - val_loss: 22.1708\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8579 - val_loss: 22.1588\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8692 - val_loss: 22.1469\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9496 - val_loss: 22.1348\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9342 - val_loss: 22.1228\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8472 - val_loss: 22.1107\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 716us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_168 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_169 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_170 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_171 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_172 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_173 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_174 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                125\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.0289 - val_loss: 23.0526\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3169 - val_loss: 22.5489\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8226 - val_loss: 22.1086\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2058 - val_loss: 21.7307\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8339 - val_loss: 21.3835\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5020 - val_loss: 21.0725\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1501 - val_loss: 20.7972\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8545 - val_loss: 20.5624\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5521 - val_loss: 20.3646\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2858 - val_loss: 20.2023\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9489 - val_loss: 20.0661\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8766 - val_loss: 19.9435\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6413 - val_loss: 19.8375\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5067 - val_loss: 19.7495\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3086 - val_loss: 19.6708\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3056 - val_loss: 19.5957\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2027 - val_loss: 19.5228\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1101 - val_loss: 19.4517\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9911 - val_loss: 19.3848\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8865 - val_loss: 19.3259\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8647 - val_loss: 19.2716\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7523 - val_loss: 19.2208\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7382 - val_loss: 19.1736\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6875 - val_loss: 19.1293\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6836 - val_loss: 19.0889\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6224 - val_loss: 19.0533\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6076 - val_loss: 19.0220\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5411 - val_loss: 18.9951\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5261 - val_loss: 18.9711\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5200 - val_loss: 18.9477\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4714 - val_loss: 18.9261\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4772 - val_loss: 18.9055\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4302 - val_loss: 18.8859\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4018 - val_loss: 18.8670\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3728 - val_loss: 18.8481\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3966 - val_loss: 18.8304\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3712 - val_loss: 18.8129\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3404 - val_loss: 18.7959\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3696 - val_loss: 18.7785\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3412 - val_loss: 18.7629\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3152 - val_loss: 18.7480\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3287 - val_loss: 18.7325\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3066 - val_loss: 18.7180\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2863 - val_loss: 18.7046\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2658 - val_loss: 18.6916\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2777 - val_loss: 18.6782\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2878 - val_loss: 18.6644\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2523 - val_loss: 18.6514\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2662 - val_loss: 18.6376\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2388 - val_loss: 18.6251\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2463 - val_loss: 18.6123\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2316 - val_loss: 18.6001\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2177 - val_loss: 18.5877\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1567 - val_loss: 18.5760\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1807 - val_loss: 18.5645\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1919 - val_loss: 18.5523\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0678 - val_loss: 18.5416\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1691 - val_loss: 18.5296\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1449 - val_loss: 18.5174\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1390 - val_loss: 18.5058\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1375 - val_loss: 18.4943\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1249 - val_loss: 18.4829\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1211 - val_loss: 18.4714\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1009 - val_loss: 18.4594\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0997 - val_loss: 18.4475\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0824 - val_loss: 18.4358\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0400 - val_loss: 18.4258\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0549 - val_loss: 18.4143\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0531 - val_loss: 18.4025\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0369 - val_loss: 18.3912\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8691 - val_loss: 18.3802\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0165 - val_loss: 18.3692\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9970 - val_loss: 18.3574\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9979 - val_loss: 18.3461\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9672 - val_loss: 18.3348\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9613 - val_loss: 18.3234\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9659 - val_loss: 18.3113\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9532 - val_loss: 18.3001\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9369 - val_loss: 18.2882\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9153 - val_loss: 18.2771\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9033 - val_loss: 18.2660\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8992 - val_loss: 18.2542\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8290 - val_loss: 18.2420\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8844 - val_loss: 18.2299\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8529 - val_loss: 18.2183\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8518 - val_loss: 18.2074\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8452 - val_loss: 18.1950\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7717 - val_loss: 18.1835\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7927 - val_loss: 18.1718\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8136 - val_loss: 18.1593\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7610 - val_loss: 18.1476\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7899 - val_loss: 18.1352\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7486 - val_loss: 18.1238\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7485 - val_loss: 18.1115\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7515 - val_loss: 18.0988\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7439 - val_loss: 18.0862\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5528 - val_loss: 18.0747\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7100 - val_loss: 18.0626\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6975 - val_loss: 18.0511\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6946 - val_loss: 18.0388\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 706us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_175 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_176 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_177 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_178 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_179 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_180 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_181 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1016\n",
      "Model:                       QuantReg   Bandwidth:                    0.004987\n",
      "Method:                 Least Squares   Sparsity:                       0.1876\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:44   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0032      0.007      0.435      0.663      -0.011       0.018\n",
      "three_month_yield_change      0.0992      0.181      0.549      0.583      -0.255       0.453\n",
      "term_spread_change           -0.0735      0.149     -0.495      0.621      -0.365       0.218\n",
      "TED_spread                   -0.4284      0.616     -0.695      0.487      -1.637       0.780\n",
      "credit_spread_change          0.3456      0.259      1.334      0.182      -0.162       0.854\n",
      "market_return                 0.0480      0.101      0.477      0.634      -0.149       0.245\n",
      "real_estate_excess_return     0.1006      0.108      0.934      0.350      -0.111       0.312\n",
      "equity_volatility             1.9026      0.193      9.884      0.000       1.525       2.280\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2274\n",
      "Model:                       QuantReg   Bandwidth:                    0.007818\n",
      "Method:                 Least Squares   Sparsity:                       0.5971\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:45   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0078      0.010      0.802      0.423      -0.011       0.027\n",
      "three_month_yield_change      0.4940      0.256      1.932      0.053      -0.007       0.995\n",
      "term_spread_change            0.1579      0.240      0.658      0.511      -0.313       0.628\n",
      "TED_spread                    3.0374      0.931      3.263      0.001       1.212       4.863\n",
      "credit_spread_change         -0.2371      0.335     -0.708      0.479      -0.894       0.420\n",
      "market_return                -0.2520      0.244     -1.032      0.302      -0.731       0.227\n",
      "real_estate_excess_return    -0.0215      0.233     -0.092      0.927      -0.479       0.436\n",
      "equity_volatility             3.4253      0.396      8.656      0.000       2.649       4.201\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4358\n",
      "Model:                       QuantReg   Bandwidth:                    0.001977\n",
      "Method:                 Least Squares   Sparsity:                      0.07744\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0147      0.003      4.949      0.000       0.009       0.021\n",
      "three_month_yield_change     -0.1053      0.084     -1.247      0.213      -0.271       0.060\n",
      "term_spread_change           -0.1105      0.073     -1.522      0.128      -0.253       0.032\n",
      "TED_spread                   -0.5692      0.279     -2.039      0.042      -1.117      -0.022\n",
      "credit_spread_change         -0.2187      0.096     -2.281      0.023      -0.407      -0.031\n",
      "market_return                -0.0596      0.040     -1.471      0.142      -0.139       0.020\n",
      "real_estate_excess_return    -0.0384      0.044     -0.873      0.383      -0.125       0.048\n",
      "equity_volatility             0.6341      0.076      8.399      0.000       0.486       0.782\n",
      "institution                   0.4256      0.036     11.970      0.000       0.356       0.495\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5349\n",
      "Model:                       QuantReg   Bandwidth:                    0.003057\n",
      "Method:                 Least Squares   Sparsity:                       0.3316\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:56:45   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0086      0.006      1.400      0.162      -0.003       0.021\n",
      "three_month_yield_change      0.0482      0.197      0.244      0.807      -0.339       0.435\n",
      "term_spread_change           -0.1324      0.177     -0.749      0.454      -0.479       0.214\n",
      "TED_spread                    0.3830      0.600      0.638      0.523      -0.794       1.560\n",
      "credit_spread_change          0.1124      0.176      0.639      0.523      -0.233       0.458\n",
      "market_return                 0.0472      0.117      0.404      0.686      -0.182       0.276\n",
      "real_estate_excess_return    -0.1621      0.109     -1.483      0.138      -0.376       0.052\n",
      "equity_volatility             0.9488      0.188      5.034      0.000       0.579       1.318\n",
      "institution                   0.4474      0.091      4.928      0.000       0.269       0.625\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 6ms/step - loss: 41.7644 - val_loss: 40.0021\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 40.5058 - val_loss: 38.9404\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.4889 - val_loss: 37.6015\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 37.8105 - val_loss: 35.6051\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.0926 - val_loss: 33.5663\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.9178 - val_loss: 31.9695\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.4299 - val_loss: 30.4784\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.7852 - val_loss: 29.2975\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.3797 - val_loss: 28.3461\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.4937 - val_loss: 27.5906\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.6669 - val_loss: 26.9765\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2172 - val_loss: 26.5317\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6166 - val_loss: 26.1893\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.3218 - val_loss: 25.9426\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9511 - val_loss: 25.7280\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7560 - val_loss: 25.5670\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4135 - val_loss: 25.4357\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3882 - val_loss: 25.3245\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3897 - val_loss: 25.2253\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2426 - val_loss: 25.1454\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2424 - val_loss: 25.0783\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0555 - val_loss: 25.0261\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1266 - val_loss: 24.9834\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0645 - val_loss: 24.9464\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8598 - val_loss: 24.9126\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9867 - val_loss: 24.8796\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8899 - val_loss: 24.8503\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9835 - val_loss: 24.8265\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0191 - val_loss: 24.8024\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0059 - val_loss: 24.7793\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9794 - val_loss: 24.7597\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9647 - val_loss: 24.7399\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9414 - val_loss: 24.7203\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9448 - val_loss: 24.7021\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9472 - val_loss: 24.6843\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9185 - val_loss: 24.6690\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8652 - val_loss: 24.6548\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8956 - val_loss: 24.6398\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8288 - val_loss: 24.6257\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8699 - val_loss: 24.6116\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7888 - val_loss: 24.5973\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8533 - val_loss: 24.5819\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8001 - val_loss: 24.5691\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8256 - val_loss: 24.5568\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8576 - val_loss: 24.5431\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7548 - val_loss: 24.5309\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8264 - val_loss: 24.5205\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7898 - val_loss: 24.5096\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.8051 - val_loss: 24.4998\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7916 - val_loss: 24.4897\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7090 - val_loss: 24.4786\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7738 - val_loss: 24.4671\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7806 - val_loss: 24.4569\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5697 - val_loss: 24.4462\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5730 - val_loss: 24.4360\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6308 - val_loss: 24.4271\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5500 - val_loss: 24.4183\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7090 - val_loss: 24.4087\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7343 - val_loss: 24.3975\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6766 - val_loss: 24.3882\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7044 - val_loss: 24.3767\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6972 - val_loss: 24.3660\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6796 - val_loss: 24.3554\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6797 - val_loss: 24.3457\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6809 - val_loss: 24.3359\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6346 - val_loss: 24.3261\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6424 - val_loss: 24.3152\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6043 - val_loss: 24.3066\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4712 - val_loss: 24.2969\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6125 - val_loss: 24.2868\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5989 - val_loss: 24.2766\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5043 - val_loss: 24.2670\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4945 - val_loss: 24.2581\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5827 - val_loss: 24.2481\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5604 - val_loss: 24.2379\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4907 - val_loss: 24.2282\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5573 - val_loss: 24.2168\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4978 - val_loss: 24.2066\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2806 - val_loss: 24.1969\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5188 - val_loss: 24.1867\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4961 - val_loss: 24.1775\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5031 - val_loss: 24.1672\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4789 - val_loss: 24.1564\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4773 - val_loss: 24.1460\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4381 - val_loss: 24.1366\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4534 - val_loss: 24.1273\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4148 - val_loss: 24.1167\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4425 - val_loss: 24.1060\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4108 - val_loss: 24.0952\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4276 - val_loss: 24.0848\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4118 - val_loss: 24.0752\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3888 - val_loss: 24.0651\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3943 - val_loss: 24.0543\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3750 - val_loss: 24.0437\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3674 - val_loss: 24.0328\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2339 - val_loss: 24.0226\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2654 - val_loss: 24.0122\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3200 - val_loss: 24.0023\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2878 - val_loss: 23.9915\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3196 - val_loss: 23.9793\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 709us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_182 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_183 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_184 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_185 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_186 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_187 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_188 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.9594 - val_loss: 23.6926\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0682 - val_loss: 22.9040\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1421 - val_loss: 22.2649\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3709 - val_loss: 21.6729\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6947 - val_loss: 21.0410\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9983 - val_loss: 20.5392\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4282 - val_loss: 20.1838\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0110 - val_loss: 19.9337\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6393 - val_loss: 19.7356\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3808 - val_loss: 19.5809\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1593 - val_loss: 19.4461\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9406 - val_loss: 19.3256\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7647 - val_loss: 19.2236\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6980 - val_loss: 19.1416\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6830 - val_loss: 19.0715\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5993 - val_loss: 19.0222\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4645 - val_loss: 18.9848\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5356 - val_loss: 18.9508\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4525 - val_loss: 18.9213\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4713 - val_loss: 18.8941\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4152 - val_loss: 18.8712\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4375 - val_loss: 18.8489\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2876 - val_loss: 18.8294\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4048 - val_loss: 18.8109\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3749 - val_loss: 18.7945\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3761 - val_loss: 18.7778\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3743 - val_loss: 18.7619\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3570 - val_loss: 18.7481\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3471 - val_loss: 18.7346\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3344 - val_loss: 18.7212\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3152 - val_loss: 18.7086\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3244 - val_loss: 18.6953\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2989 - val_loss: 18.6839\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3112 - val_loss: 18.6729\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2954 - val_loss: 18.6608\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2830 - val_loss: 18.6505\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1649 - val_loss: 18.6391\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2075 - val_loss: 18.6292\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1982 - val_loss: 18.6205\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2063 - val_loss: 18.6111\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2409 - val_loss: 18.6003\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2289 - val_loss: 18.5904\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2004 - val_loss: 18.5808\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2254 - val_loss: 18.5707\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1847 - val_loss: 18.5602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2014 - val_loss: 18.5498\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1649 - val_loss: 18.5397\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1047 - val_loss: 18.5300\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1557 - val_loss: 18.5196\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1622 - val_loss: 18.5089\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1527 - val_loss: 18.4982\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1254 - val_loss: 18.4888\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1370 - val_loss: 18.4782\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1100 - val_loss: 18.4682\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1147 - val_loss: 18.4578\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1068 - val_loss: 18.4478\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0890 - val_loss: 18.4375\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0754 - val_loss: 18.4279\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0706 - val_loss: 18.4178\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0598 - val_loss: 18.4081\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0028 - val_loss: 18.3993\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0479 - val_loss: 18.3894\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0335 - val_loss: 18.3783\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0047 - val_loss: 18.3683\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0079 - val_loss: 18.3585\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9827 - val_loss: 18.3490\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9886 - val_loss: 18.3389\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9746 - val_loss: 18.3286\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9515 - val_loss: 18.3189\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9393 - val_loss: 18.3083\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9415 - val_loss: 18.2981\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9071 - val_loss: 18.2877\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9273 - val_loss: 18.2760\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9135 - val_loss: 18.2648\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9038 - val_loss: 18.2543\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8935 - val_loss: 18.2433\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8680 - val_loss: 18.2339\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8658 - val_loss: 18.2232\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8258 - val_loss: 18.2126\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8372 - val_loss: 18.2015\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8392 - val_loss: 18.1905\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8280 - val_loss: 18.1801\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8182 - val_loss: 18.1684\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8108 - val_loss: 18.1575\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7545 - val_loss: 18.1473\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7851 - val_loss: 18.1363\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6475 - val_loss: 18.1259\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7486 - val_loss: 18.1153\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7532 - val_loss: 18.1044\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7388 - val_loss: 18.0930\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7105 - val_loss: 18.0820\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7120 - val_loss: 18.0702\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7133 - val_loss: 18.0584\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6702 - val_loss: 18.0473\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6226 - val_loss: 18.0367\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6427 - val_loss: 18.0257\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6683 - val_loss: 18.0133\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6479 - val_loss: 18.0015\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6291 - val_loss: 17.9898\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6269 - val_loss: 17.9776\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 726us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_189 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_190 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_191 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_192 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_193 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_194 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_195 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1109\n",
      "Model:                       QuantReg   Bandwidth:                    0.005876\n",
      "Method:                 Least Squares   Sparsity:                       0.2370\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:08   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    -0.0100      0.009     -1.092      0.275      -0.028       0.008\n",
      "three_month_yield_change      0.2366      0.212      1.118      0.264      -0.178       0.651\n",
      "term_spread_change            0.2006      0.195      1.028      0.304      -0.182       0.583\n",
      "TED_spread                    0.1931      0.785      0.246      0.806      -1.346       1.732\n",
      "credit_spread_change          0.8097      0.317      2.552      0.011       0.188       1.432\n",
      "market_return                 0.0842      0.123      0.685      0.494      -0.157       0.325\n",
      "real_estate_excess_return     0.1871      0.145      1.291      0.197      -0.097       0.471\n",
      "equity_volatility             2.0206      0.210      9.605      0.000       1.608       2.433\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2369\n",
      "Model:                       QuantReg   Bandwidth:                    0.009637\n",
      "Method:                 Least Squares   Sparsity:                        1.070\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:08   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0019      0.018      0.102      0.919      -0.034       0.038\n",
      "three_month_yield_change      0.1956      0.467      0.419      0.676      -0.721       1.112\n",
      "term_spread_change           -0.0649      0.468     -0.139      0.890      -0.983       0.853\n",
      "TED_spread                    1.3527      2.084      0.649      0.516      -2.733       5.439\n",
      "credit_spread_change          0.6648      0.609      1.092      0.275      -0.529       1.859\n",
      "market_return                -0.2147      0.437     -0.492      0.623      -1.071       0.642\n",
      "real_estate_excess_return    -0.0417      0.446     -0.093      0.926      -0.917       0.833\n",
      "equity_volatility             3.8201      0.713      5.360      0.000       2.423       5.218\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4425\n",
      "Model:                       QuantReg   Bandwidth:                    0.002080\n",
      "Method:                 Least Squares   Sparsity:                      0.07276\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:08   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0100      0.003      3.913      0.000       0.005       0.015\n",
      "three_month_yield_change     -0.1317      0.072     -1.821      0.069      -0.273       0.010\n",
      "term_spread_change           -0.1467      0.065     -2.247      0.025      -0.275      -0.019\n",
      "TED_spread                   -0.5361      0.252     -2.129      0.033      -1.030      -0.042\n",
      "credit_spread_change         -0.0081      0.088     -0.091      0.927      -0.181       0.165\n",
      "market_return                -0.0300      0.037     -0.815      0.415      -0.102       0.042\n",
      "real_estate_excess_return    -0.0653      0.041     -1.594      0.111      -0.146       0.015\n",
      "equity_volatility             0.6687      0.073      9.211      0.000       0.526       0.811\n",
      "institution                   0.3602      0.027     13.337      0.000       0.307       0.413\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5549\n",
      "Model:                       QuantReg   Bandwidth:                    0.003365\n",
      "Method:                 Least Squares   Sparsity:                       0.2715\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:08   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0185      0.004      4.550      0.000       0.011       0.026\n",
      "three_month_yield_change     -0.0912      0.146     -0.624      0.532      -0.377       0.195\n",
      "term_spread_change           -0.3617      0.142     -2.556      0.011      -0.639      -0.084\n",
      "TED_spread                   -1.2739      0.523     -2.437      0.015      -2.299      -0.249\n",
      "credit_spread_change         -0.0118      0.114     -0.104      0.917      -0.235       0.211\n",
      "market_return                 0.0544      0.089      0.615      0.539      -0.119       0.228\n",
      "real_estate_excess_return    -0.1285      0.075     -1.702      0.089      -0.277       0.020\n",
      "equity_volatility             1.1200      0.159      7.043      0.000       0.808       1.432\n",
      "institution                   0.3818      0.064      5.997      0.000       0.257       0.507\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 41.0232 - val_loss: 35.8541\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.8390 - val_loss: 34.4046\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.7588 - val_loss: 32.5001\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.7992 - val_loss: 30.9261\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.1221 - val_loss: 29.5757\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.3911 - val_loss: 28.1868\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.9281 - val_loss: 26.6692\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.3762 - val_loss: 25.2487\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.2326 - val_loss: 23.9426\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1775 - val_loss: 22.9166\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1984 - val_loss: 22.0702\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6101 - val_loss: 21.3609\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.1302 - val_loss: 20.8593\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6422 - val_loss: 20.5413\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3640 - val_loss: 20.3676\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1140 - val_loss: 20.2268\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9421 - val_loss: 20.1220\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6906 - val_loss: 20.0298\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5541 - val_loss: 19.9471\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5688 - val_loss: 19.8713\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3537 - val_loss: 19.8049\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4341 - val_loss: 19.7496\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3943 - val_loss: 19.6989\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2247 - val_loss: 19.6528\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2477 - val_loss: 19.6134\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2995 - val_loss: 19.5823\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2563 - val_loss: 19.5606\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2415 - val_loss: 19.5461\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1645 - val_loss: 19.5381\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1281 - val_loss: 19.5340\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1632 - val_loss: 19.5303\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1277 - val_loss: 19.5270\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1675 - val_loss: 19.5242\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1224 - val_loss: 19.5210\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1326 - val_loss: 19.5173\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0956 - val_loss: 19.5129\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0938 - val_loss: 19.5082\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0964 - val_loss: 19.5036\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0684 - val_loss: 19.4980\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9838 - val_loss: 19.4927\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0168 - val_loss: 19.4889\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0351 - val_loss: 19.4848\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0322 - val_loss: 19.4805\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8596 - val_loss: 19.4754\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0290 - val_loss: 19.4709\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9926 - val_loss: 19.4660\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0105 - val_loss: 19.4618\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0154 - val_loss: 19.4561\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9552 - val_loss: 19.4506\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8487 - val_loss: 19.4446\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9503 - val_loss: 19.4383\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9364 - val_loss: 19.4327\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9493 - val_loss: 19.4249\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8944 - val_loss: 19.4173\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9128 - val_loss: 19.4085\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9288 - val_loss: 19.4010\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9135 - val_loss: 19.3927\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8689 - val_loss: 19.3832\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8529 - val_loss: 19.3745\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8806 - val_loss: 19.3663\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7710 - val_loss: 19.3570\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8283 - val_loss: 19.3469\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8505 - val_loss: 19.3358\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7389 - val_loss: 19.3247\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8362 - val_loss: 19.3169\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8286 - val_loss: 19.3073\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7248 - val_loss: 19.2967\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7745 - val_loss: 19.2868\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7882 - val_loss: 19.2769\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7607 - val_loss: 19.2673\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5963 - val_loss: 19.2555\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7429 - val_loss: 19.2464\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7369 - val_loss: 19.2365\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7279 - val_loss: 19.2254\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6281 - val_loss: 19.2124\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7112 - val_loss: 19.2031\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6778 - val_loss: 19.1919\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7000 - val_loss: 19.1817\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6738 - val_loss: 19.1722\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6532 - val_loss: 19.1622\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6484 - val_loss: 19.1513\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6395 - val_loss: 19.1409\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6328 - val_loss: 19.1319\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6389 - val_loss: 19.1203\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5221 - val_loss: 19.1081\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5203 - val_loss: 19.0962\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5763 - val_loss: 19.0835\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4319 - val_loss: 19.0717\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5725 - val_loss: 19.0591\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5358 - val_loss: 19.0470\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4822 - val_loss: 19.0351\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5472 - val_loss: 19.0258\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4968 - val_loss: 19.0151\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5186 - val_loss: 19.0030\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4660 - val_loss: 18.9920\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3207 - val_loss: 18.9792\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4666 - val_loss: 18.9681\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4649 - val_loss: 18.9561\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4641 - val_loss: 18.9446\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4424 - val_loss: 18.9330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 732us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_196 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_197 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_198 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_199 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_200 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_201 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_202 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                118\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.4013 - val_loss: 25.0229\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4676 - val_loss: 24.2930\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5461 - val_loss: 23.2899\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3397 - val_loss: 22.4239\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4685 - val_loss: 21.7745\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6677 - val_loss: 21.2039\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1228 - val_loss: 20.7509\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5851 - val_loss: 20.4076\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2561 - val_loss: 20.1695\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8155 - val_loss: 19.9825\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6627 - val_loss: 19.8441\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4969 - val_loss: 19.7360\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3031 - val_loss: 19.6404\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1694 - val_loss: 19.5518\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0785 - val_loss: 19.4674\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9356 - val_loss: 19.3917\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9329 - val_loss: 19.3257\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8558 - val_loss: 19.2680\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7808 - val_loss: 19.2157\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7474 - val_loss: 19.1675\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6608 - val_loss: 19.1265\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6435 - val_loss: 19.0920\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6145 - val_loss: 19.0625\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5706 - val_loss: 19.0355\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5483 - val_loss: 19.0107\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4147 - val_loss: 18.9883\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5024 - val_loss: 18.9660\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4804 - val_loss: 18.9464\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4849 - val_loss: 18.9270\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4760 - val_loss: 18.9075\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4384 - val_loss: 18.8891\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4273 - val_loss: 18.8717\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3887 - val_loss: 18.8557\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4042 - val_loss: 18.8404\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3995 - val_loss: 18.8246\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3877 - val_loss: 18.8092\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2157 - val_loss: 18.7953\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2875 - val_loss: 18.7822\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3343 - val_loss: 18.7695\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3357 - val_loss: 18.7561\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3373 - val_loss: 18.7423\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3249 - val_loss: 18.7292\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2980 - val_loss: 18.7160\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3122 - val_loss: 18.7029\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1897 - val_loss: 18.6908\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1157 - val_loss: 18.6785\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2608 - val_loss: 18.6660\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2649 - val_loss: 18.6529\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2340 - val_loss: 18.6417\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1442 - val_loss: 18.6309\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2326 - val_loss: 18.6187\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2050 - val_loss: 18.6073\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2095 - val_loss: 18.5952\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1635 - val_loss: 18.5842\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1731 - val_loss: 18.5726\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1700 - val_loss: 18.5615\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1696 - val_loss: 18.5498\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1165 - val_loss: 18.5382\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1206 - val_loss: 18.5275\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1423 - val_loss: 18.5161\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1075 - val_loss: 18.5047\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0727 - val_loss: 18.4938\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1130 - val_loss: 18.4820\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0293 - val_loss: 18.4709\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0572 - val_loss: 18.4595\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0681 - val_loss: 18.4475\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0103 - val_loss: 18.4362\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0212 - val_loss: 18.4250\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0338 - val_loss: 18.4136\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0047 - val_loss: 18.4020\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0238 - val_loss: 18.3899\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9913 - val_loss: 18.3786\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9993 - val_loss: 18.3660\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9809 - val_loss: 18.3560\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9609 - val_loss: 18.3444\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9561 - val_loss: 18.3329\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9580 - val_loss: 18.3211\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9389 - val_loss: 18.3092\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9236 - val_loss: 18.2970\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9228 - val_loss: 18.2860\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9124 - val_loss: 18.2738\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7527 - val_loss: 18.2624\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8928 - val_loss: 18.2510\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8390 - val_loss: 18.2400\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8280 - val_loss: 18.2286\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8427 - val_loss: 18.2175\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8136 - val_loss: 18.2055\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8207 - val_loss: 18.1938\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8138 - val_loss: 18.1821\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7960 - val_loss: 18.1702\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7770 - val_loss: 18.1579\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7529 - val_loss: 18.1460\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7716 - val_loss: 18.1334\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7304 - val_loss: 18.1216\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7413 - val_loss: 18.1093\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7357 - val_loss: 18.0971\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7252 - val_loss: 18.0845\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7088 - val_loss: 18.0713\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6860 - val_loss: 18.0587\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6505 - val_loss: 18.0458\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 770us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_203 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_204 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_205 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_206 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_207 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_208 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_209 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.06039\n",
      "Model:                       QuantReg   Bandwidth:                    0.005858\n",
      "Method:                 Least Squares   Sparsity:                       0.2265\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:32   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0188      0.008      2.214      0.027       0.002       0.035\n",
      "three_month_yield_change      0.1649      0.211      0.784      0.433      -0.248       0.578\n",
      "term_spread_change           -0.1876      0.197     -0.951      0.342      -0.575       0.199\n",
      "TED_spread                   -1.9347      0.829     -2.333      0.020      -3.561      -0.309\n",
      "credit_spread_change          0.2439      0.303      0.805      0.421      -0.350       0.838\n",
      "market_return                -0.1575      0.115     -1.374      0.169      -0.382       0.067\n",
      "real_estate_excess_return     0.1438      0.125      1.147      0.252      -0.102       0.390\n",
      "equity_volatility             1.6774      0.198      8.489      0.000       1.290       2.065\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1030\n",
      "Model:                       QuantReg   Bandwidth:                    0.008279\n",
      "Method:                 Least Squares   Sparsity:                       0.9801\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:32   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0618      0.015      4.013      0.000       0.032       0.092\n",
      "three_month_yield_change     -0.1327      0.443     -0.300      0.764      -1.001       0.735\n",
      "term_spread_change           -0.2755      0.447     -0.616      0.538      -1.152       0.601\n",
      "TED_spread                    2.9713      1.649      1.802      0.072      -0.262       6.205\n",
      "credit_spread_change         -1.2972      0.534     -2.429      0.015      -2.344      -0.250\n",
      "market_return                -0.3694      0.276     -1.341      0.180      -0.910       0.171\n",
      "real_estate_excess_return    -0.2728      0.291     -0.936      0.349      -0.844       0.299\n",
      "equity_volatility             2.4809      0.463      5.364      0.000       1.574       3.388\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3872\n",
      "Model:                       QuantReg   Bandwidth:                    0.002116\n",
      "Method:                 Least Squares   Sparsity:                      0.08346\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:32   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0163      0.003      5.839      0.000       0.011       0.022\n",
      "three_month_yield_change     -0.1352      0.085     -1.591      0.112      -0.302       0.031\n",
      "term_spread_change           -0.2189      0.078     -2.798      0.005      -0.372      -0.066\n",
      "TED_spread                   -0.7354      0.311     -2.364      0.018      -1.345      -0.125\n",
      "credit_spread_change         -0.1866      0.097     -1.917      0.055      -0.377       0.004\n",
      "market_return                 0.0326      0.045      0.721      0.471      -0.056       0.121\n",
      "real_estate_excess_return    -0.0289      0.054     -0.537      0.591      -0.134       0.077\n",
      "equity_volatility             0.7273      0.083      8.717      0.000       0.564       0.891\n",
      "institution                   0.3485      0.031     11.073      0.000       0.287       0.410\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4642\n",
      "Model:                       QuantReg   Bandwidth:                    0.003871\n",
      "Method:                 Least Squares   Sparsity:                       0.4151\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:32   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0358      0.006      5.720      0.000       0.024       0.048\n",
      "three_month_yield_change     -0.4656      0.178     -2.613      0.009      -0.815      -0.116\n",
      "term_spread_change           -0.5501      0.184     -2.983      0.003      -0.912      -0.188\n",
      "TED_spread                   -1.9573      0.856     -2.286      0.022      -3.636      -0.279\n",
      "credit_spread_change         -0.3982      0.244     -1.631      0.103      -0.877       0.080\n",
      "market_return                 0.0417      0.178      0.235      0.815      -0.307       0.391\n",
      "real_estate_excess_return    -0.1566      0.174     -0.899      0.369      -0.498       0.185\n",
      "equity_volatility             1.2643      0.274      4.611      0.000       0.727       1.802\n",
      "institution                   0.3599      0.113      3.198      0.001       0.139       0.581\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 37.3693 - val_loss: 30.4116\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.0095 - val_loss: 29.2385\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.1616 - val_loss: 27.7368\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.9876 - val_loss: 26.5692\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.4212 - val_loss: 25.6421\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.0879 - val_loss: 24.8090\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.7716 - val_loss: 24.0717\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.7361 - val_loss: 23.4172\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7642 - val_loss: 22.8701\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9836 - val_loss: 22.3885\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3808 - val_loss: 21.9406\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8877 - val_loss: 21.5825\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5303 - val_loss: 21.3065\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1189 - val_loss: 21.0919\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7888 - val_loss: 20.9086\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4359 - val_loss: 20.7621\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4358 - val_loss: 20.6464\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2182 - val_loss: 20.5597\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0357 - val_loss: 20.4881\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9775 - val_loss: 20.4210\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7653 - val_loss: 20.3607\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7721 - val_loss: 20.3043\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6914 - val_loss: 20.2511\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6615 - val_loss: 20.2022\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5951 - val_loss: 20.1587\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4992 - val_loss: 20.1205\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4685 - val_loss: 20.0852\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4884 - val_loss: 20.0510\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4686 - val_loss: 20.0191\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4599 - val_loss: 19.9893\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4238 - val_loss: 19.9606\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3653 - val_loss: 19.9373\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3767 - val_loss: 19.9179\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1836 - val_loss: 19.9026\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3063 - val_loss: 19.8896\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3300 - val_loss: 19.8782\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2886 - val_loss: 19.8676\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2680 - val_loss: 19.8573\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2641 - val_loss: 19.8472\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2494 - val_loss: 19.8372\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1720 - val_loss: 19.8274\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2236 - val_loss: 19.8177\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1796 - val_loss: 19.8079\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2116 - val_loss: 19.7983\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1806 - val_loss: 19.7888\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1610 - val_loss: 19.7792\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1710 - val_loss: 19.7695\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1526 - val_loss: 19.7598\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1411 - val_loss: 19.7500\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8998 - val_loss: 19.7402\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1163 - val_loss: 19.7303\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0497 - val_loss: 19.7204\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1002 - val_loss: 19.7104\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0955 - val_loss: 19.7003\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0257 - val_loss: 19.6902\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0526 - val_loss: 19.6801\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0573 - val_loss: 19.6699\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0233 - val_loss: 19.6596\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0227 - val_loss: 19.6493\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0295 - val_loss: 19.6390\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0192 - val_loss: 19.6285\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9718 - val_loss: 19.6181\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0016 - val_loss: 19.6076\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9922 - val_loss: 19.5970\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9004 - val_loss: 19.5864\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9593 - val_loss: 19.5757\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9567 - val_loss: 19.5650\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9413 - val_loss: 19.5542\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9367 - val_loss: 19.5434\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9211 - val_loss: 19.5326\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8946 - val_loss: 19.5217\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8580 - val_loss: 19.5107\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8854 - val_loss: 19.4997\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7914 - val_loss: 19.4887\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8609 - val_loss: 19.4777\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8576 - val_loss: 19.4665\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8509 - val_loss: 19.4553\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8402 - val_loss: 19.4441\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8195 - val_loss: 19.4328\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6692 - val_loss: 19.4215\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8057 - val_loss: 19.4101\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7867 - val_loss: 19.3987\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7776 - val_loss: 19.3872\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7522 - val_loss: 19.3757\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7529 - val_loss: 19.3642\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7070 - val_loss: 19.3525\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7294 - val_loss: 19.3409\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7057 - val_loss: 19.3292\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6954 - val_loss: 19.3174\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6703 - val_loss: 19.3057\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5842 - val_loss: 19.2939\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6353 - val_loss: 19.2820\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6488 - val_loss: 19.2701\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5819 - val_loss: 19.2582\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6244 - val_loss: 19.2462\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5760 - val_loss: 19.2342\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5971 - val_loss: 19.2221\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5982 - val_loss: 19.2099\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5512 - val_loss: 19.1977\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5202 - val_loss: 19.1855\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 616us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_210 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_211 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_212 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_213 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_214 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_215 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_216 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                125\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 23.9684 - val_loss: 23.0467\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3536 - val_loss: 22.5673\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7895 - val_loss: 22.1212\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2575 - val_loss: 21.7147\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8493 - val_loss: 21.3368\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3234 - val_loss: 20.9915\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0300 - val_loss: 20.6940\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5753 - val_loss: 20.4471\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4209 - val_loss: 20.2542\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1739 - val_loss: 20.0957\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9277 - val_loss: 19.9613\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7298 - val_loss: 19.8461\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5644 - val_loss: 19.7533\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4050 - val_loss: 19.6707\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2991 - val_loss: 19.5901\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1709 - val_loss: 19.5149\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0504 - val_loss: 19.4439\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9977 - val_loss: 19.3775\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9411 - val_loss: 19.3129\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8297 - val_loss: 19.2536\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8062 - val_loss: 19.2010\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7231 - val_loss: 19.1552\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6624 - val_loss: 19.1141\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6678 - val_loss: 19.0781\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5735 - val_loss: 19.0470\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6052 - val_loss: 19.0208\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5761 - val_loss: 18.9978\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3901 - val_loss: 18.9766\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5473 - val_loss: 18.9556\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5121 - val_loss: 18.9355\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4987 - val_loss: 18.9162\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4883 - val_loss: 18.8981\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4765 - val_loss: 18.8814\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4686 - val_loss: 18.8645\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4375 - val_loss: 18.8488\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4322 - val_loss: 18.8333\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4291 - val_loss: 18.8181\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4119 - val_loss: 18.8033\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4034 - val_loss: 18.7893\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3840 - val_loss: 18.7758\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3626 - val_loss: 18.7626\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3736 - val_loss: 18.7495\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3338 - val_loss: 18.7376\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3523 - val_loss: 18.7250\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1996 - val_loss: 18.7135\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3258 - val_loss: 18.7014\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2269 - val_loss: 18.6900\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3193 - val_loss: 18.6780\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2960 - val_loss: 18.6667\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2965 - val_loss: 18.6553\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2614 - val_loss: 18.6451\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2678 - val_loss: 18.6340\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2281 - val_loss: 18.6241\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2531 - val_loss: 18.6132\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2229 - val_loss: 18.6037\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2208 - val_loss: 18.5937\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2208 - val_loss: 18.5829\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1959 - val_loss: 18.5730\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2038 - val_loss: 18.5634\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2068 - val_loss: 18.5533\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1855 - val_loss: 18.5430\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1508 - val_loss: 18.5328\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1466 - val_loss: 18.5232\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1653 - val_loss: 18.5131\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1459 - val_loss: 18.5035\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1539 - val_loss: 18.4927\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1390 - val_loss: 18.4824\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0790 - val_loss: 18.4728\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0954 - val_loss: 18.4634\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0719 - val_loss: 18.4529\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0999 - val_loss: 18.4425\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0521 - val_loss: 18.4324\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0750 - val_loss: 18.4227\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0706 - val_loss: 18.4119\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0451 - val_loss: 18.4011\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0281 - val_loss: 18.3920\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0067 - val_loss: 18.3820\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0117 - val_loss: 18.3717\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0187 - val_loss: 18.3614\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9424 - val_loss: 18.3521\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9430 - val_loss: 18.3421\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9895 - val_loss: 18.3313\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9197 - val_loss: 18.3214\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9681 - val_loss: 18.3104\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9135 - val_loss: 18.3001\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9406 - val_loss: 18.2893\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9374 - val_loss: 18.2783\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9020 - val_loss: 18.2681\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8824 - val_loss: 18.2581\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8858 - val_loss: 18.2475\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8797 - val_loss: 18.2369\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8816 - val_loss: 18.2261\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8512 - val_loss: 18.2166\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8489 - val_loss: 18.2062\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8441 - val_loss: 18.1952\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7685 - val_loss: 18.1845\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8300 - val_loss: 18.1722\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7363 - val_loss: 18.1623\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8096 - val_loss: 18.1511\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7607 - val_loss: 18.1409\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 836us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_217 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_218 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_219 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_220 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_221 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_222 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_223 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09500\n",
      "Model:                       QuantReg   Bandwidth:                    0.004714\n",
      "Method:                 Least Squares   Sparsity:                       0.1961\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:54   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0246      0.007      3.525      0.000       0.011       0.038\n",
      "three_month_yield_change     -0.1514      0.188     -0.807      0.420      -0.519       0.217\n",
      "term_spread_change           -0.0647      0.166     -0.391      0.696      -0.390       0.260\n",
      "TED_spread                   -0.1585      0.710     -0.223      0.823      -1.551       1.234\n",
      "credit_spread_change         -0.6789      0.248     -2.733      0.006      -1.166      -0.192\n",
      "market_return                -0.1224      0.099     -1.234      0.217      -0.317       0.072\n",
      "real_estate_excess_return     0.0457      0.110      0.416      0.677      -0.170       0.261\n",
      "equity_volatility             2.4728      0.201     12.326      0.000       2.079       2.866\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2143\n",
      "Model:                       QuantReg   Bandwidth:                    0.007588\n",
      "Method:                 Least Squares   Sparsity:                       0.7042\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:54   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0144      0.013      1.114      0.265      -0.011       0.040\n",
      "three_month_yield_change      0.7641      0.356      2.147      0.032       0.066       1.462\n",
      "term_spread_change            0.2101      0.339      0.620      0.535      -0.455       0.875\n",
      "TED_spread                    0.5648      1.429      0.395      0.693      -2.237       3.366\n",
      "credit_spread_change         -0.2798      0.438     -0.638      0.523      -1.140       0.580\n",
      "market_return                -0.1240      0.196     -0.632      0.527      -0.508       0.260\n",
      "real_estate_excess_return    -0.7174      0.267     -2.690      0.007      -1.240      -0.194\n",
      "equity_volatility             3.5829      0.379      9.450      0.000       2.839       4.326\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5051\n",
      "Model:                       QuantReg   Bandwidth:                    0.001681\n",
      "Method:                 Least Squares   Sparsity:                      0.06286\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:54   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.002      4.322      0.000       0.005       0.014\n",
      "three_month_yield_change     -0.0183      0.058     -0.314      0.753      -0.133       0.096\n",
      "term_spread_change           -0.1378      0.053     -2.623      0.009      -0.241      -0.035\n",
      "TED_spread                   -0.1450      0.220     -0.660      0.509      -0.576       0.286\n",
      "credit_spread_change         -0.1023      0.077     -1.330      0.184      -0.253       0.049\n",
      "market_return                 0.0116      0.034      0.341      0.733      -0.055       0.078\n",
      "real_estate_excess_return    -0.0291      0.038     -0.761      0.446      -0.104       0.046\n",
      "equity_volatility             0.5488      0.063      8.778      0.000       0.426       0.671\n",
      "institution                   0.5182      0.032     16.077      0.000       0.455       0.581\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5778\n",
      "Model:                       QuantReg   Bandwidth:                    0.003109\n",
      "Method:                 Least Squares   Sparsity:                       0.2758\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:57:54   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0254      0.004      5.689      0.000       0.017       0.034\n",
      "three_month_yield_change     -0.2806      0.122     -2.300      0.022      -0.520      -0.041\n",
      "term_spread_change           -0.0355      0.114     -0.311      0.756      -0.259       0.188\n",
      "TED_spread                   -0.4435      0.529     -0.839      0.402      -1.480       0.593\n",
      "credit_spread_change         -0.6986      0.159     -4.394      0.000      -1.010      -0.387\n",
      "market_return                 0.0484      0.095      0.511      0.609      -0.137       0.234\n",
      "real_estate_excess_return     0.0284      0.096      0.294      0.769      -0.161       0.217\n",
      "equity_volatility             1.3978      0.150      9.300      0.000       1.103       1.693\n",
      "institution                   0.4977      0.085      5.874      0.000       0.332       0.664\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 32.2512 - val_loss: 38.7874\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.7139 - val_loss: 36.5452\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.8041 - val_loss: 34.5146\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.2008 - val_loss: 32.8631\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8111 - val_loss: 31.3263\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8106 - val_loss: 30.0177\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9319 - val_loss: 29.0611\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6120 - val_loss: 28.3432\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1496 - val_loss: 27.8144\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9122 - val_loss: 27.3929\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6149 - val_loss: 27.0435\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3977 - val_loss: 26.7374\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2427 - val_loss: 26.4766\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1034 - val_loss: 26.2588\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9838 - val_loss: 26.0735\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9093 - val_loss: 25.9261\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8179 - val_loss: 25.7968\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7200 - val_loss: 25.6836\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6118 - val_loss: 25.5823\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6322 - val_loss: 25.4926\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5691 - val_loss: 25.4130\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5573 - val_loss: 25.3404\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4719 - val_loss: 25.2763\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4534 - val_loss: 25.2221\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4334 - val_loss: 25.1776\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4053 - val_loss: 25.1443\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4001 - val_loss: 25.1135\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3543 - val_loss: 25.0851\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3348 - val_loss: 25.0593\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3674 - val_loss: 25.0333\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3164 - val_loss: 25.0098\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1195 - val_loss: 24.9884\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3333 - val_loss: 24.9665\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2903 - val_loss: 24.9467\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3112 - val_loss: 24.9272\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2299 - val_loss: 24.9106\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2848 - val_loss: 24.8933\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2640 - val_loss: 24.8751\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1527 - val_loss: 24.8582\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2645 - val_loss: 24.8434\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1353 - val_loss: 24.8310\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1937 - val_loss: 24.8179\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2306 - val_loss: 24.8043\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1948 - val_loss: 24.7912\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1776 - val_loss: 24.7795\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2059 - val_loss: 24.7660\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1718 - val_loss: 24.7536\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1706 - val_loss: 24.7415\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9539 - val_loss: 24.7293\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1313 - val_loss: 24.7186\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1402 - val_loss: 24.7064\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1330 - val_loss: 24.6955\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1363 - val_loss: 24.6833\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1343 - val_loss: 24.6719\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1250 - val_loss: 24.6605\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0886 - val_loss: 24.6498\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1002 - val_loss: 24.6395\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0611 - val_loss: 24.6292\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0650 - val_loss: 24.6186\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0679 - val_loss: 24.6062\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0335 - val_loss: 24.5952\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9944 - val_loss: 24.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9933 - val_loss: 24.5743\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0170 - val_loss: 24.5631\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0248 - val_loss: 24.5520\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0034 - val_loss: 24.5403\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8864 - val_loss: 24.5301\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9694 - val_loss: 24.5196\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9791 - val_loss: 24.5101\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8766 - val_loss: 24.4997\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9330 - val_loss: 24.4905\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9148 - val_loss: 24.4794\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8918 - val_loss: 24.4696\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9207 - val_loss: 24.4592\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9095 - val_loss: 24.4475\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8997 - val_loss: 24.4357\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8881 - val_loss: 24.4240\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8738 - val_loss: 24.4125\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8531 - val_loss: 24.4018\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8420 - val_loss: 24.3902\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8089 - val_loss: 24.3794\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8289 - val_loss: 24.3676\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6700 - val_loss: 24.3569\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7714 - val_loss: 24.3449\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7920 - val_loss: 24.3332\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6413 - val_loss: 24.3235\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4720 - val_loss: 24.3120\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6792 - val_loss: 24.3006\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7507 - val_loss: 24.2891\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7384 - val_loss: 24.2774\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6944 - val_loss: 24.2653\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6118 - val_loss: 24.2529\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6779 - val_loss: 24.2412\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6854 - val_loss: 24.2290\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6709 - val_loss: 24.2162\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6641 - val_loss: 24.2037\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6580 - val_loss: 24.1917\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6163 - val_loss: 24.1797\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6371 - val_loss: 24.1679\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5713 - val_loss: 24.1562\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "77/77 [==============================] - 0s 690us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_224 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_225 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_226 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_227 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_228 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_229 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_230 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                127\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 25.7552 - val_loss: 24.6665\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.1988 - val_loss: 23.9891\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3614 - val_loss: 23.3355\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5504 - val_loss: 22.7471\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9013 - val_loss: 22.1908\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1557 - val_loss: 21.6876\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6919 - val_loss: 21.2474\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1819 - val_loss: 20.8752\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7510 - val_loss: 20.5660\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3880 - val_loss: 20.3358\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1359 - val_loss: 20.1576\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9036 - val_loss: 20.0053\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6927 - val_loss: 19.8888\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5545 - val_loss: 19.7934\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2813 - val_loss: 19.7110\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2923 - val_loss: 19.6328\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1842 - val_loss: 19.5578\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0905 - val_loss: 19.4883\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0070 - val_loss: 19.4238\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9388 - val_loss: 19.3652\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8811 - val_loss: 19.3109\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8181 - val_loss: 19.2617\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7015 - val_loss: 19.2169\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6774 - val_loss: 19.1765\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6741 - val_loss: 19.1423\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6328 - val_loss: 19.1132\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6388 - val_loss: 19.0872\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5806 - val_loss: 19.0639\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5620 - val_loss: 19.0415\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5666 - val_loss: 19.0205\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5524 - val_loss: 18.9997\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5178 - val_loss: 18.9794\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4545 - val_loss: 18.9595\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4933 - val_loss: 18.9412\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4668 - val_loss: 18.9248\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4229 - val_loss: 18.9080\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4183 - val_loss: 18.8918\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4110 - val_loss: 18.8759\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4219 - val_loss: 18.8596\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3540 - val_loss: 18.8442\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3813 - val_loss: 18.8288\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3763 - val_loss: 18.8135\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3721 - val_loss: 18.7994\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3664 - val_loss: 18.7853\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2949 - val_loss: 18.7714\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2960 - val_loss: 18.7577\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3281 - val_loss: 18.7442\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3122 - val_loss: 18.7307\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3120 - val_loss: 18.7170\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2925 - val_loss: 18.7045\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2368 - val_loss: 18.6918\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2763 - val_loss: 18.6784\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2664 - val_loss: 18.6654\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2176 - val_loss: 18.6524\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2049 - val_loss: 18.6393\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2291 - val_loss: 18.6266\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1024 - val_loss: 18.6142\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1282 - val_loss: 18.6022\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1709 - val_loss: 18.5898\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1899 - val_loss: 18.5772\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1732 - val_loss: 18.5643\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1686 - val_loss: 18.5516\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1624 - val_loss: 18.5397\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0243 - val_loss: 18.5279\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1116 - val_loss: 18.5157\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1123 - val_loss: 18.5040\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1052 - val_loss: 18.4921\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0462 - val_loss: 18.4805\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0370 - val_loss: 18.4687\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0608 - val_loss: 18.4568\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0054 - val_loss: 18.4444\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9873 - val_loss: 18.4318\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0497 - val_loss: 18.4200\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0379 - val_loss: 18.4084\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0288 - val_loss: 18.3962\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0147 - val_loss: 18.3838\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9781 - val_loss: 18.3713\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9753 - val_loss: 18.3591\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9846 - val_loss: 18.3465\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9662 - val_loss: 18.3342\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9192 - val_loss: 18.3227\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8777 - val_loss: 18.3110\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9288 - val_loss: 18.2993\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9116 - val_loss: 18.2871\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9162 - val_loss: 18.2747\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8832 - val_loss: 18.2623\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7830 - val_loss: 18.2509\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8781 - val_loss: 18.2390\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8666 - val_loss: 18.2261\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8374 - val_loss: 18.2140\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8354 - val_loss: 18.2014\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8301 - val_loss: 18.1893\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7614 - val_loss: 18.1775\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7732 - val_loss: 18.1649\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7931 - val_loss: 18.1525\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7596 - val_loss: 18.1395\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7510 - val_loss: 18.1275\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6703 - val_loss: 18.1149\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6637 - val_loss: 18.1031\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7218 - val_loss: 18.0909\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 837us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_231 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_232 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_233 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_234 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_235 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_236 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_237 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1404\n",
      "Model:                       QuantReg   Bandwidth:                    0.004565\n",
      "Method:                 Least Squares   Sparsity:                       0.1699\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:18   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0132      0.006      2.254      0.024       0.002       0.025\n",
      "three_month_yield_change     -0.4009      0.153     -2.626      0.009      -0.700      -0.102\n",
      "term_spread_change           -0.3192      0.155     -2.058      0.040      -0.623      -0.015\n",
      "TED_spread                   -1.2311      0.590     -2.086      0.037      -2.388      -0.074\n",
      "credit_spread_change          0.1099      0.212      0.520      0.603      -0.305       0.525\n",
      "market_return                -0.0276      0.098     -0.283      0.778      -0.219       0.164\n",
      "real_estate_excess_return     0.0176      0.104      0.169      0.866      -0.186       0.221\n",
      "equity_volatility             2.0613      0.171     12.040      0.000       1.726       2.397\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3195\n",
      "Model:                       QuantReg   Bandwidth:                    0.007509\n",
      "Method:                 Least Squares   Sparsity:                       0.6251\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:18   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0077      0.011      0.715      0.475      -0.013       0.029\n",
      "three_month_yield_change     -0.0567      0.302     -0.188      0.851      -0.649       0.536\n",
      "term_spread_change           -0.0818      0.297     -0.276      0.783      -0.664       0.500\n",
      "TED_spread                   -3.3262      1.383     -2.405      0.016      -6.039      -0.614\n",
      "credit_spread_change          0.2418      0.366      0.662      0.508      -0.475       0.959\n",
      "market_return                -0.1991      0.266     -0.750      0.453      -0.720       0.322\n",
      "real_estate_excess_return    -0.3730      0.265     -1.409      0.159      -0.892       0.146\n",
      "equity_volatility             4.6435      0.429     10.812      0.000       3.801       5.486\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4173\n",
      "Model:                       QuantReg   Bandwidth:                    0.001998\n",
      "Method:                 Least Squares   Sparsity:                      0.09581\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:18   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0078      0.004      2.217      0.027       0.001       0.015\n",
      "three_month_yield_change      0.0133      0.097      0.137      0.891      -0.177       0.203\n",
      "term_spread_change           -0.1596      0.083     -1.919      0.055      -0.323       0.003\n",
      "TED_spread                   -0.6759      0.338     -2.001      0.045      -1.338      -0.014\n",
      "credit_spread_change          0.0284      0.120      0.236      0.813      -0.207       0.264\n",
      "market_return                 0.0019      0.053      0.036      0.972      -0.102       0.106\n",
      "real_estate_excess_return    -0.0377      0.058     -0.653      0.514      -0.151       0.076\n",
      "equity_volatility             0.7249      0.094      7.719      0.000       0.541       0.909\n",
      "institution                   0.5024      0.052      9.587      0.000       0.400       0.605\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5211\n",
      "Model:                       QuantReg   Bandwidth:                    0.003253\n",
      "Method:                 Least Squares   Sparsity:                       0.2799\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:18   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0115      0.005      2.476      0.013       0.002       0.021\n",
      "three_month_yield_change      0.0808      0.131      0.619      0.536      -0.175       0.337\n",
      "term_spread_change           -0.1706      0.134     -1.277      0.202      -0.433       0.091\n",
      "TED_spread                    2.2662      0.499      4.541      0.000       1.288       3.245\n",
      "credit_spread_change         -0.2076      0.158     -1.311      0.190      -0.518       0.103\n",
      "market_return                -0.0938      0.129     -0.730      0.465      -0.346       0.158\n",
      "real_estate_excess_return    -0.1010      0.082     -1.239      0.216      -0.261       0.059\n",
      "equity_volatility             1.1275      0.193      5.842      0.000       0.749       1.506\n",
      "institution                   0.4167      0.134      3.105      0.002       0.153       0.680\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 6ms/step - loss: 30.5070 - val_loss: 31.0910\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.3287 - val_loss: 29.7345\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.6031 - val_loss: 28.0797\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8840 - val_loss: 26.6712\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5704 - val_loss: 25.6214\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7151 - val_loss: 24.8345\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8767 - val_loss: 24.2752\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3669 - val_loss: 23.8603\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9419 - val_loss: 23.5407\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5702 - val_loss: 23.2739\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1933 - val_loss: 23.0643\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0050 - val_loss: 22.9048\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8286 - val_loss: 22.7850\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5462 - val_loss: 22.6862\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5201 - val_loss: 22.5942\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4210 - val_loss: 22.5121\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3445 - val_loss: 22.4397\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2595 - val_loss: 22.3772\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1985 - val_loss: 22.3288\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1610 - val_loss: 22.2893\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0697 - val_loss: 22.2597\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0732 - val_loss: 22.2378\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9927 - val_loss: 22.2209\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9461 - val_loss: 22.2067\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9749 - val_loss: 22.1945\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9414 - val_loss: 22.1831\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9240 - val_loss: 22.1726\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9401 - val_loss: 22.1623\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9113 - val_loss: 22.1524\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8984 - val_loss: 22.1425\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8800 - val_loss: 22.1329\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8723 - val_loss: 22.1235\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8320 - val_loss: 22.1139\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8158 - val_loss: 22.1045\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6293 - val_loss: 22.0952\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8053 - val_loss: 22.0857\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6936 - val_loss: 22.0762\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7460 - val_loss: 22.0668\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7749 - val_loss: 22.0573\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7653 - val_loss: 22.0477\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7449 - val_loss: 22.0382\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6479 - val_loss: 22.0285\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6035 - val_loss: 22.0190\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6972 - val_loss: 22.0096\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7084 - val_loss: 21.9999\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7019 - val_loss: 21.9903\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6885 - val_loss: 21.9806\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5632 - val_loss: 21.9710\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6734 - val_loss: 21.9614\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6553 - val_loss: 21.9517\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5990 - val_loss: 21.9419\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5705 - val_loss: 21.9321\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5296 - val_loss: 21.9223\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5681 - val_loss: 21.9122\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5811 - val_loss: 21.9023\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6022 - val_loss: 21.8922\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5564 - val_loss: 21.8822\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5804 - val_loss: 21.8721\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5336 - val_loss: 21.8620\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5561 - val_loss: 21.8519\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5166 - val_loss: 21.8417\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5407 - val_loss: 21.8314\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5220 - val_loss: 21.8212\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4856 - val_loss: 21.8110\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4909 - val_loss: 21.8006\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4729 - val_loss: 21.7902\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4913 - val_loss: 21.7798\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4338 - val_loss: 21.7694\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4633 - val_loss: 21.7588\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4504 - val_loss: 21.7483\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4520 - val_loss: 21.7376\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3059 - val_loss: 21.7270\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4279 - val_loss: 21.7162\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4164 - val_loss: 21.7054\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4106 - val_loss: 21.6945\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3523 - val_loss: 21.6839\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3780 - val_loss: 21.6730\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3116 - val_loss: 21.6623\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3634 - val_loss: 21.6513\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3566 - val_loss: 21.6404\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1945 - val_loss: 21.6295\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2946 - val_loss: 21.6185\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2413 - val_loss: 21.6074\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2981 - val_loss: 21.5962\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2983 - val_loss: 21.5851\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2830 - val_loss: 21.5739\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2738 - val_loss: 21.5626\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2392 - val_loss: 21.5514\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1153 - val_loss: 21.5401\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2141 - val_loss: 21.5288\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2055 - val_loss: 21.5174\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2208 - val_loss: 21.5059\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1869 - val_loss: 21.4945\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0762 - val_loss: 21.4830\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1796 - val_loss: 21.4714\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1577 - val_loss: 21.4599\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0364 - val_loss: 21.4484\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1447 - val_loss: 21.4368\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1098 - val_loss: 21.4252\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1323 - val_loss: 21.4135\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 636us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_238 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_239 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_240 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_241 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_242 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_243 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_244 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.5420 - val_loss: 25.0546\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3378 - val_loss: 24.0387\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2539 - val_loss: 23.2006\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2600 - val_loss: 22.4839\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4954 - val_loss: 21.9091\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8776 - val_loss: 21.4170\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4146 - val_loss: 21.0285\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9047 - val_loss: 20.7071\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6156 - val_loss: 20.4583\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3379 - val_loss: 20.2688\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0939 - val_loss: 20.1118\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8950 - val_loss: 19.9780\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6563 - val_loss: 19.8745\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5552 - val_loss: 19.7872\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3913 - val_loss: 19.7077\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2987 - val_loss: 19.6321\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1776 - val_loss: 19.5593\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0992 - val_loss: 19.4901\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0393 - val_loss: 19.4273\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9061 - val_loss: 19.3709\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8958 - val_loss: 19.3200\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8197 - val_loss: 19.2734\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8060 - val_loss: 19.2308\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7395 - val_loss: 19.1903\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6245 - val_loss: 19.1536\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6931 - val_loss: 19.1207\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6595 - val_loss: 19.0922\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5693 - val_loss: 19.0669\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5500 - val_loss: 19.0434\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5558 - val_loss: 19.0208\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5215 - val_loss: 18.9990\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5371 - val_loss: 18.9776\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4946 - val_loss: 18.9578\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4865 - val_loss: 18.9389\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4717 - val_loss: 18.9206\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4466 - val_loss: 18.9025\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3782 - val_loss: 18.8848\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4317 - val_loss: 18.8685\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4258 - val_loss: 18.8523\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3417 - val_loss: 18.8369\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3783 - val_loss: 18.8215\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3563 - val_loss: 18.8070\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3231 - val_loss: 18.7922\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3575 - val_loss: 18.7775\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3435 - val_loss: 18.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3346 - val_loss: 18.7485\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2888 - val_loss: 18.7348\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3087 - val_loss: 18.7207\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2820 - val_loss: 18.7067\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2929 - val_loss: 18.6925\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2666 - val_loss: 18.6789\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2347 - val_loss: 18.6656\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2185 - val_loss: 18.6524\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2407 - val_loss: 18.6391\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2309 - val_loss: 18.6250\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2207 - val_loss: 18.6114\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2102 - val_loss: 18.5977\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1993 - val_loss: 18.5843\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1223 - val_loss: 18.5716\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1649 - val_loss: 18.5596\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1224 - val_loss: 18.5471\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0949 - val_loss: 18.5344\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1150 - val_loss: 18.5226\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0892 - val_loss: 18.5098\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0849 - val_loss: 18.4974\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0883 - val_loss: 18.4851\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0987 - val_loss: 18.4731\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0733 - val_loss: 18.4611\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0335 - val_loss: 18.4487\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0720 - val_loss: 18.4363\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0429 - val_loss: 18.4237\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0471 - val_loss: 18.4110\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0328 - val_loss: 18.3983\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0217 - val_loss: 18.3855\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9963 - val_loss: 18.3730\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9911 - val_loss: 18.3606\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9477 - val_loss: 18.3483\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9434 - val_loss: 18.3360\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9601 - val_loss: 18.3235\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9434 - val_loss: 18.3106\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9425 - val_loss: 18.2981\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9079 - val_loss: 18.2858\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9140 - val_loss: 18.2730\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8927 - val_loss: 18.2610\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7853 - val_loss: 18.2482\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8720 - val_loss: 18.2352\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8558 - val_loss: 18.2224\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8426 - val_loss: 18.2097\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8348 - val_loss: 18.1971\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8254 - val_loss: 18.1847\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8064 - val_loss: 18.1718\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7596 - val_loss: 18.1586\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7525 - val_loss: 18.1459\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7768 - val_loss: 18.1328\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7664 - val_loss: 18.1197\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7488 - val_loss: 18.1063\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7155 - val_loss: 18.0934\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7141 - val_loss: 18.0806\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6969 - val_loss: 18.0682\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6855 - val_loss: 18.0550\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 745us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_245 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_246 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_247 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_248 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_249 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_250 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_251 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1148\n",
      "Model:                       QuantReg   Bandwidth:                    0.004023\n",
      "Method:                 Least Squares   Sparsity:                       0.1492\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0093      0.005      1.786      0.074      -0.001       0.019\n",
      "three_month_yield_change      0.1550      0.146      1.062      0.288      -0.131       0.441\n",
      "term_spread_change           -0.0753      0.137     -0.552      0.581      -0.343       0.192\n",
      "TED_spread                   -1.6156      0.574     -2.815      0.005      -2.741      -0.490\n",
      "credit_spread_change         -0.0344      0.184     -0.186      0.852      -0.396       0.327\n",
      "market_return                -0.0036      0.085     -0.042      0.966      -0.171       0.163\n",
      "real_estate_excess_return     0.0543      0.089      0.611      0.541      -0.120       0.229\n",
      "equity_volatility             1.9287      0.161     11.949      0.000       1.612       2.245\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2766\n",
      "Model:                       QuantReg   Bandwidth:                    0.005886\n",
      "Method:                 Least Squares   Sparsity:                       0.7090\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0326      0.011      2.872      0.004       0.010       0.055\n",
      "three_month_yield_change      0.0573      0.299      0.192      0.848      -0.529       0.644\n",
      "term_spread_change            0.1622      0.286      0.568      0.570      -0.398       0.723\n",
      "TED_spread                   -0.8800      1.280     -0.687      0.492      -3.390       1.630\n",
      "credit_spread_change         -0.8957      0.459     -1.953      0.051      -1.795       0.003\n",
      "market_return                -0.0357      0.227     -0.157      0.875      -0.482       0.410\n",
      "real_estate_excess_return    -0.1856      0.225     -0.825      0.410      -0.627       0.256\n",
      "equity_volatility             3.0425      0.494      6.155      0.000       2.073       4.012\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3725\n",
      "Model:                       QuantReg   Bandwidth:                    0.002013\n",
      "Method:                 Least Squares   Sparsity:                      0.07725\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0107      0.003      3.793      0.000       0.005       0.016\n",
      "three_month_yield_change     -0.0325      0.075     -0.435      0.664      -0.179       0.114\n",
      "term_spread_change           -0.1235      0.062     -2.002      0.045      -0.244      -0.003\n",
      "TED_spread                   -0.2916      0.270     -1.078      0.281      -0.822       0.239\n",
      "credit_spread_change         -0.0858      0.105     -0.815      0.415      -0.292       0.120\n",
      "market_return                -0.0714      0.038     -1.877      0.061      -0.146       0.003\n",
      "real_estate_excess_return     0.0065      0.044      0.148      0.882      -0.079       0.092\n",
      "equity_volatility             0.6331      0.074      8.596      0.000       0.489       0.778\n",
      "institution                   0.5618      0.042     13.530      0.000       0.480       0.643\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4573\n",
      "Model:                       QuantReg   Bandwidth:                    0.003788\n",
      "Method:                 Least Squares   Sparsity:                       0.3814\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:58:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0331      0.007      4.957      0.000       0.020       0.046\n",
      "three_month_yield_change     -0.4114      0.155     -2.659      0.008      -0.715      -0.108\n",
      "term_spread_change           -0.6709      0.148     -4.533      0.000      -0.961      -0.381\n",
      "TED_spread                   -0.6654      0.616     -1.080      0.280      -1.873       0.543\n",
      "credit_spread_change         -0.2758      0.245     -1.125      0.260      -0.756       0.205\n",
      "market_return                 0.1282      0.151      0.850      0.395      -0.168       0.424\n",
      "real_estate_excess_return     0.1501      0.140      1.072      0.284      -0.124       0.425\n",
      "equity_volatility             1.1631      0.232      5.008      0.000       0.708       1.619\n",
      "institution                   0.5386      0.154      3.507      0.000       0.237       0.840\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 38.7856 - val_loss: 44.3461\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.8756 - val_loss: 43.5641\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.0413 - val_loss: 42.7994\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.4164 - val_loss: 42.0620\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.5934 - val_loss: 41.2439\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.7073 - val_loss: 40.3635\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.7047 - val_loss: 39.4942\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.8042 - val_loss: 38.5348\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.7806 - val_loss: 37.3622\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.9304 - val_loss: 36.1491\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.7237 - val_loss: 34.9612\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.8083 - val_loss: 33.9545\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.8224 - val_loss: 33.0721\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1470 - val_loss: 32.2340\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.6452 - val_loss: 31.4756\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1212 - val_loss: 30.7596\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6203 - val_loss: 30.1792\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2757 - val_loss: 29.6757\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8905 - val_loss: 29.2592\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7693 - val_loss: 28.9318\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3221 - val_loss: 28.6692\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4077 - val_loss: 28.4356\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2767 - val_loss: 28.2302\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1303 - val_loss: 28.0413\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1120 - val_loss: 27.8854\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9888 - val_loss: 27.7505\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9824 - val_loss: 27.6226\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9023 - val_loss: 27.5056\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8436 - val_loss: 27.4005\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6678 - val_loss: 27.3116\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7699 - val_loss: 27.2316\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7731 - val_loss: 27.1609\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7454 - val_loss: 27.0955\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5794 - val_loss: 27.0391\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6974 - val_loss: 26.9773\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2256 - val_loss: 26.9254\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6459 - val_loss: 26.8705\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6205 - val_loss: 26.8168\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6255 - val_loss: 26.7710\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5036 - val_loss: 26.7295\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5900 - val_loss: 26.6850\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5790 - val_loss: 26.6446\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4487 - val_loss: 26.6089\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5371 - val_loss: 26.5730\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5263 - val_loss: 26.5396\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5040 - val_loss: 26.5054\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5168 - val_loss: 26.4706\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4174 - val_loss: 26.4381\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4875 - val_loss: 26.4033\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4553 - val_loss: 26.3724\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4362 - val_loss: 26.3415\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4251 - val_loss: 26.3197\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3670 - val_loss: 26.2951\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4251 - val_loss: 26.2691\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4163 - val_loss: 26.2453\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3468 - val_loss: 26.2243\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3516 - val_loss: 26.2047\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2533 - val_loss: 26.1827\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3245 - val_loss: 26.1616\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3352 - val_loss: 26.1414\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2615 - val_loss: 26.1242\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2833 - val_loss: 26.1061\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2742 - val_loss: 26.0867\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1292 - val_loss: 26.0710\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2189 - val_loss: 26.0529\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2808 - val_loss: 26.0354\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2789 - val_loss: 26.0187\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2330 - val_loss: 26.0035\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1349 - val_loss: 25.9880\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1860 - val_loss: 25.9724\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1676 - val_loss: 25.9571\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1434 - val_loss: 25.9423\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1880 - val_loss: 25.9270\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1692 - val_loss: 25.9135\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0248 - val_loss: 25.8988\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1908 - val_loss: 25.8838\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1720 - val_loss: 25.8690\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1470 - val_loss: 25.8544\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1313 - val_loss: 25.8424\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1262 - val_loss: 25.8276\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0046 - val_loss: 25.8152\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1157 - val_loss: 25.8026\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1060 - val_loss: 25.7885\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1025 - val_loss: 25.7735\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0097 - val_loss: 25.7622\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0712 - val_loss: 25.7491\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0449 - val_loss: 25.7368\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0287 - val_loss: 25.7247\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0285 - val_loss: 25.7122\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0199 - val_loss: 25.7005\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9431 - val_loss: 25.6877\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9887 - val_loss: 25.6746\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9857 - val_loss: 25.6622\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8313 - val_loss: 25.6516\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9673 - val_loss: 25.6398\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9492 - val_loss: 25.6269\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9402 - val_loss: 25.6133\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9203 - val_loss: 25.6020\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8054 - val_loss: 25.5897\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8906 - val_loss: 25.5786\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 744us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_252 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_253 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_254 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_255 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_256 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_257 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_258 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                127\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 27.7953 - val_loss: 26.0160\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4013 - val_loss: 24.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8745 - val_loss: 23.7024\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7754 - val_loss: 22.9071\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9337 - val_loss: 22.2890\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2271 - val_loss: 21.7944\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7410 - val_loss: 21.3799\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2538 - val_loss: 21.0471\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8671 - val_loss: 20.7593\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6275 - val_loss: 20.5310\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3121 - val_loss: 20.3467\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1518 - val_loss: 20.1960\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9434 - val_loss: 20.0607\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7620 - val_loss: 19.9572\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5822 - val_loss: 19.8723\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4508 - val_loss: 19.7943\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3745 - val_loss: 19.7218\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2625 - val_loss: 19.6524\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1433 - val_loss: 19.5854\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1016 - val_loss: 19.5229\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0125 - val_loss: 19.4624\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9842 - val_loss: 19.4075\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9124 - val_loss: 19.3583\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8831 - val_loss: 19.3135\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7892 - val_loss: 19.2733\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7597 - val_loss: 19.2352\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7261 - val_loss: 19.1989\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7323 - val_loss: 19.1663\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6959 - val_loss: 19.1390\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6556 - val_loss: 19.1143\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6166 - val_loss: 19.0918\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6264 - val_loss: 19.0702\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5518 - val_loss: 19.0501\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5642 - val_loss: 19.0302\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5324 - val_loss: 19.0110\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5202 - val_loss: 18.9926\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5054 - val_loss: 18.9751\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4797 - val_loss: 18.9573\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4580 - val_loss: 18.9399\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4790 - val_loss: 18.9228\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4361 - val_loss: 18.9067\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3698 - val_loss: 18.8907\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4477 - val_loss: 18.8746\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4200 - val_loss: 18.8591\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4039 - val_loss: 18.8436\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3973 - val_loss: 18.8286\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2937 - val_loss: 18.8136\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3707 - val_loss: 18.7990\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3285 - val_loss: 18.7841\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3462 - val_loss: 18.7708\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2824 - val_loss: 18.7579\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3326 - val_loss: 18.7440\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3287 - val_loss: 18.7305\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3094 - val_loss: 18.7178\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2932 - val_loss: 18.7045\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2927 - val_loss: 18.6909\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2714 - val_loss: 18.6779\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2147 - val_loss: 18.6654\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2565 - val_loss: 18.6523\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2183 - val_loss: 18.6404\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2284 - val_loss: 18.6288\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1916 - val_loss: 18.6169\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2025 - val_loss: 18.6042\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2012 - val_loss: 18.5914\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2012 - val_loss: 18.5788\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1728 - val_loss: 18.5668\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1693 - val_loss: 18.5547\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1261 - val_loss: 18.5430\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1253 - val_loss: 18.5307\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1451 - val_loss: 18.5185\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1334 - val_loss: 18.5058\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1045 - val_loss: 18.4941\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0737 - val_loss: 18.4823\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0788 - val_loss: 18.4704\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0712 - val_loss: 18.4583\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0753 - val_loss: 18.4464\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0561 - val_loss: 18.4342\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0549 - val_loss: 18.4216\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0428 - val_loss: 18.4095\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0210 - val_loss: 18.3972\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0122 - val_loss: 18.3846\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9935 - val_loss: 18.3723\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9637 - val_loss: 18.3602\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9787 - val_loss: 18.3478\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9604 - val_loss: 18.3353\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9331 - val_loss: 18.3229\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9251 - val_loss: 18.3107\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9340 - val_loss: 18.2981\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9222 - val_loss: 18.2853\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9131 - val_loss: 18.2733\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8505 - val_loss: 18.2612\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8796 - val_loss: 18.2487\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8527 - val_loss: 18.2361\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8613 - val_loss: 18.2233\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8544 - val_loss: 18.2109\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8427 - val_loss: 18.1976\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8070 - val_loss: 18.1852\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7714 - val_loss: 18.1728\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7739 - val_loss: 18.1603\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7656 - val_loss: 18.1476\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 669us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_259 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_260 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_261 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_263 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_264 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1701\n",
      "Model:                       QuantReg   Bandwidth:                    0.005783\n",
      "Method:                 Least Squares   Sparsity:                       0.1719\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:03   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0139      0.006      2.396      0.017       0.003       0.025\n",
      "three_month_yield_change     -0.1727      0.163     -1.058      0.290      -0.493       0.147\n",
      "term_spread_change           -0.2301      0.158     -1.454      0.146      -0.541       0.080\n",
      "TED_spread                   -2.2352      0.638     -3.501      0.000      -3.487      -0.983\n",
      "credit_spread_change          0.0502      0.208      0.241      0.810      -0.359       0.459\n",
      "market_return                -0.1499      0.095     -1.578      0.115      -0.336       0.036\n",
      "real_estate_excess_return     0.0493      0.106      0.467      0.641      -0.158       0.256\n",
      "equity_volatility             2.7913      0.192     14.570      0.000       2.416       3.167\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2823\n",
      "Model:                       QuantReg   Bandwidth:                    0.009315\n",
      "Method:                 Least Squares   Sparsity:                       0.8138\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:03   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0275      0.014      1.984      0.047       0.000       0.055\n",
      "three_month_yield_change     -0.8274      0.358     -2.313      0.021      -1.529      -0.126\n",
      "term_spread_change           -1.2341      0.349     -3.538      0.000      -1.918      -0.550\n",
      "TED_spread                   -2.1536      1.574     -1.368      0.171      -5.240       0.933\n",
      "credit_spread_change          0.5139      0.491      1.047      0.295      -0.449       1.477\n",
      "market_return                -0.5021      0.326     -1.541      0.123      -1.141       0.137\n",
      "real_estate_excess_return    -0.6275      0.319     -1.970      0.049      -1.252      -0.003\n",
      "equity_volatility             5.2440      0.543      9.651      0.000       4.179       6.310\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4038\n",
      "Model:                       QuantReg   Bandwidth:                    0.002006\n",
      "Method:                 Least Squares   Sparsity:                      0.08708\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:03   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0135      0.003      4.178      0.000       0.007       0.020\n",
      "three_month_yield_change     -0.0143      0.088     -0.162      0.872      -0.188       0.159\n",
      "term_spread_change           -0.1408      0.080     -1.770      0.077      -0.297       0.015\n",
      "TED_spread                   -0.8488      0.330     -2.576      0.010      -1.495      -0.203\n",
      "credit_spread_change         -0.1183      0.117     -1.014      0.311      -0.347       0.110\n",
      "market_return                -0.0197      0.049     -0.400      0.689      -0.116       0.077\n",
      "real_estate_excess_return    -0.0367      0.051     -0.714      0.475      -0.137       0.064\n",
      "equity_volatility             0.6236      0.084      7.406      0.000       0.459       0.789\n",
      "institution                   0.3741      0.034     10.983      0.000       0.307       0.441\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5071\n",
      "Model:                       QuantReg   Bandwidth:                    0.003388\n",
      "Method:                 Least Squares   Sparsity:                       0.3316\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:03   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0069      0.006      1.180      0.238      -0.005       0.018\n",
      "three_month_yield_change      0.3266      0.162      2.011      0.044       0.008       0.645\n",
      "term_spread_change           -0.0114      0.171     -0.067      0.947      -0.346       0.324\n",
      "TED_spread                   -2.1876      0.632     -3.462      0.001      -3.427      -0.948\n",
      "credit_spread_change          0.2871      0.199      1.445      0.148      -0.102       0.677\n",
      "market_return                -0.0666      0.109     -0.614      0.540      -0.279       0.146\n",
      "real_estate_excess_return    -0.1299      0.098     -1.329      0.184      -0.322       0.062\n",
      "equity_volatility             1.1968      0.193      6.187      0.000       0.817       1.576\n",
      "institution                   0.3671      0.092      3.976      0.000       0.186       0.548\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 30.1126 - val_loss: 29.7951\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.7934 - val_loss: 28.4981\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.6311 - val_loss: 27.5118\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.7297 - val_loss: 26.7144\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0028 - val_loss: 26.0167\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1844 - val_loss: 25.3401\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6313 - val_loss: 24.7056\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1194 - val_loss: 24.1291\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5408 - val_loss: 23.6251\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0215 - val_loss: 23.1623\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7393 - val_loss: 22.7283\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3524 - val_loss: 22.3639\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0367 - val_loss: 22.0414\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8553 - val_loss: 21.7460\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6005 - val_loss: 21.4693\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3529 - val_loss: 21.2181\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1098 - val_loss: 21.0125\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9675 - val_loss: 20.8332\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6843 - val_loss: 20.6756\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6696 - val_loss: 20.5339\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5215 - val_loss: 20.4061\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2679 - val_loss: 20.2868\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3039 - val_loss: 20.1762\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2116 - val_loss: 20.0743\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0996 - val_loss: 19.9859\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0208 - val_loss: 19.9078\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9970 - val_loss: 19.8364\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9341 - val_loss: 19.7730\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8518 - val_loss: 19.7200\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8217 - val_loss: 19.6738\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.7852 - val_loss: 19.6337\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7239 - val_loss: 19.5964\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7131 - val_loss: 19.5631\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7008 - val_loss: 19.5328\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6677 - val_loss: 19.5055\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6713 - val_loss: 19.4800\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5893 - val_loss: 19.4576\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5820 - val_loss: 19.4362\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6159 - val_loss: 19.4149\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6037 - val_loss: 19.3951\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5251 - val_loss: 19.3764\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5382 - val_loss: 19.3592\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4447 - val_loss: 19.3434\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.5243 - val_loss: 19.3284\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5158 - val_loss: 19.3134\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4509 - val_loss: 19.2995\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4924 - val_loss: 19.2861\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4590 - val_loss: 19.2726\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4893 - val_loss: 19.2593\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4811 - val_loss: 19.2466\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4452 - val_loss: 19.2342\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4045 - val_loss: 19.2222\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4102 - val_loss: 19.2103\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4403 - val_loss: 19.1983\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4082 - val_loss: 19.1870\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4076 - val_loss: 19.1758\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3318 - val_loss: 19.1649\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3962 - val_loss: 19.1537\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2371 - val_loss: 19.1429\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3804 - val_loss: 19.1319\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3032 - val_loss: 19.1210\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3600 - val_loss: 19.1100\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2630 - val_loss: 19.0991\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3080 - val_loss: 19.0884\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3214 - val_loss: 19.0773\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3184 - val_loss: 19.0665\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3114 - val_loss: 19.0557\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2850 - val_loss: 19.0448\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2326 - val_loss: 19.0339\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2749 - val_loss: 19.0229\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2620 - val_loss: 19.0118\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2296 - val_loss: 19.0010\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2111 - val_loss: 18.9904\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2028 - val_loss: 18.9795\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2235 - val_loss: 18.9685\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2052 - val_loss: 18.9575\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.2044 - val_loss: 18.9465\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1549 - val_loss: 18.9354\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1525 - val_loss: 18.9244\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1546 - val_loss: 18.9133\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1587 - val_loss: 18.9022\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1300 - val_loss: 18.8913\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1287 - val_loss: 18.8804\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1047 - val_loss: 18.8691\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.0950 - val_loss: 18.8580\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1002 - val_loss: 18.8468\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0799 - val_loss: 18.8355\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0762 - val_loss: 18.8242\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0692 - val_loss: 18.8128\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0522 - val_loss: 18.8014\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0419 - val_loss: 18.7899\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9774 - val_loss: 18.7786\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0058 - val_loss: 18.7671\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9419 - val_loss: 18.7556\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9794 - val_loss: 18.7441\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9896 - val_loss: 18.7325\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9772 - val_loss: 18.7208\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9621 - val_loss: 18.7092\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.9469 - val_loss: 18.6976\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.8917 - val_loss: 18.6860\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 688us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_266 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_267 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_269 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_270 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_271 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_272 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                127\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 25.7471 - val_loss: 24.5358\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.0677 - val_loss: 23.9264\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3208 - val_loss: 23.3646\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7254 - val_loss: 22.8074\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9764 - val_loss: 22.1186\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0146 - val_loss: 21.4748\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3933 - val_loss: 20.9064\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7405 - val_loss: 20.4324\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1900 - val_loss: 20.1395\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7567 - val_loss: 19.9218\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4865 - val_loss: 19.7612\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3722 - val_loss: 19.6325\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1827 - val_loss: 19.5150\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0173 - val_loss: 19.4088\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9308 - val_loss: 19.3131\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7557 - val_loss: 19.2323\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6947 - val_loss: 19.1637\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6762 - val_loss: 19.1056\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5823 - val_loss: 19.0598\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4572 - val_loss: 19.0231\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4856 - val_loss: 18.9912\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4988 - val_loss: 18.9638\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4897 - val_loss: 18.9390\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4563 - val_loss: 18.9174\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4307 - val_loss: 18.8961\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4359 - val_loss: 18.8770\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3786 - val_loss: 18.8579\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3610 - val_loss: 18.8399\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3156 - val_loss: 18.8231\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3772 - val_loss: 18.8063\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3568 - val_loss: 18.7907\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3144 - val_loss: 18.7761\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3332 - val_loss: 18.7608\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3249 - val_loss: 18.7453\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2916 - val_loss: 18.7306\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2947 - val_loss: 18.7175\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2662 - val_loss: 18.7044\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2826 - val_loss: 18.6915\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2765 - val_loss: 18.6784\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2589 - val_loss: 18.6663\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2431 - val_loss: 18.6543\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2043 - val_loss: 18.6421\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2370 - val_loss: 18.6303\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2290 - val_loss: 18.6186\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2143 - val_loss: 18.6071\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2120 - val_loss: 18.5970\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0868 - val_loss: 18.5860\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1911 - val_loss: 18.5749\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1650 - val_loss: 18.5651\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1689 - val_loss: 18.5544\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1664 - val_loss: 18.5436\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1548 - val_loss: 18.5322\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1092 - val_loss: 18.5221\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0587 - val_loss: 18.5114\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1044 - val_loss: 18.5006\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0750 - val_loss: 18.4905\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0786 - val_loss: 18.4801\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0857 - val_loss: 18.4696\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0573 - val_loss: 18.4587\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0657 - val_loss: 18.4482\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0326 - val_loss: 18.4369\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0602 - val_loss: 18.4263\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0200 - val_loss: 18.4160\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9877 - val_loss: 18.4053\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0266 - val_loss: 18.3935\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0000 - val_loss: 18.3828\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0080 - val_loss: 18.3717\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9820 - val_loss: 18.3609\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9705 - val_loss: 18.3498\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9577 - val_loss: 18.3392\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9665 - val_loss: 18.3283\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9372 - val_loss: 18.3168\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9381 - val_loss: 18.3048\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8251 - val_loss: 18.2943\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9209 - val_loss: 18.2829\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8496 - val_loss: 18.2719\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8730 - val_loss: 18.2602\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8430 - val_loss: 18.2481\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8381 - val_loss: 18.2370\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7448 - val_loss: 18.2254\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8569 - val_loss: 18.2134\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8262 - val_loss: 18.2019\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7947 - val_loss: 18.1905\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8037 - val_loss: 18.1784\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7437 - val_loss: 18.1671\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7834 - val_loss: 18.1551\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7837 - val_loss: 18.1431\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7235 - val_loss: 18.1327\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7509 - val_loss: 18.1209\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7479 - val_loss: 18.1088\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7352 - val_loss: 18.0972\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7097 - val_loss: 18.0855\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6753 - val_loss: 18.0741\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6834 - val_loss: 18.0622\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6811 - val_loss: 18.0503\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6646 - val_loss: 18.0382\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6533 - val_loss: 18.0265\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6423 - val_loss: 18.0142\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6336 - val_loss: 18.0019\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6155 - val_loss: 17.9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 751us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_273 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_274 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_275 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_276 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_277 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_278 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_279 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08061\n",
      "Model:                       QuantReg   Bandwidth:                    0.003346\n",
      "Method:                 Least Squares   Sparsity:                       0.1324\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:27   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0181      0.004      4.125      0.000       0.009       0.027\n",
      "three_month_yield_change     -0.1292      0.121     -1.066      0.286      -0.367       0.108\n",
      "term_spread_change           -0.0461      0.118     -0.390      0.696      -0.278       0.185\n",
      "TED_spread                   -0.2280      0.512     -0.445      0.656      -1.232       0.776\n",
      "credit_spread_change         -0.2372      0.158     -1.499      0.134      -0.547       0.073\n",
      "market_return                -0.1128      0.067     -1.688      0.091      -0.244       0.018\n",
      "real_estate_excess_return     0.2071      0.078      2.661      0.008       0.055       0.360\n",
      "equity_volatility             1.0263      0.143      7.164      0.000       0.745       1.307\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1021\n",
      "Model:                       QuantReg   Bandwidth:                    0.004840\n",
      "Method:                 Least Squares   Sparsity:                       0.6519\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:27   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0257      0.010      2.521      0.012       0.006       0.046\n",
      "three_month_yield_change      0.2828      0.282      1.004      0.316      -0.270       0.835\n",
      "term_spread_change            0.0760      0.270      0.282      0.778      -0.453       0.605\n",
      "TED_spread                   -2.8616      1.462     -1.958      0.050      -5.728       0.005\n",
      "credit_spread_change          0.2347      0.406      0.577      0.564      -0.562       1.032\n",
      "market_return                -0.0081      0.191     -0.042      0.966      -0.383       0.367\n",
      "real_estate_excess_return    -0.2048      0.272     -0.752      0.452      -0.738       0.329\n",
      "equity_volatility             1.2199      0.411      2.968      0.003       0.414       2.026\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3357\n",
      "Model:                       QuantReg   Bandwidth:                    0.002160\n",
      "Method:                 Least Squares   Sparsity:                      0.09053\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:27   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0091      0.003      2.653      0.008       0.002       0.016\n",
      "three_month_yield_change      0.0359      0.093      0.386      0.699      -0.146       0.218\n",
      "term_spread_change           -0.1324      0.078     -1.702      0.089      -0.285       0.020\n",
      "TED_spread                   -1.1176      0.339     -3.302      0.001      -1.781      -0.454\n",
      "credit_spread_change          0.0116      0.116      0.101      0.920      -0.215       0.238\n",
      "market_return                -0.0202      0.045     -0.449      0.654      -0.109       0.068\n",
      "real_estate_excess_return    -0.0046      0.055     -0.084      0.933      -0.113       0.103\n",
      "equity_volatility             0.8734      0.082     10.665      0.000       0.713       1.034\n",
      "institution                   0.5057      0.052      9.758      0.000       0.404       0.607\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4206\n",
      "Model:                       QuantReg   Bandwidth:                    0.004505\n",
      "Method:                 Least Squares   Sparsity:                       0.5490\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:27   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0235      0.010      2.465      0.014       0.005       0.042\n",
      "three_month_yield_change     -0.1361      0.273     -0.499      0.618      -0.671       0.398\n",
      "term_spread_change           -0.2989      0.227     -1.318      0.188      -0.744       0.146\n",
      "TED_spread                   -1.7067      0.977     -1.747      0.081      -3.623       0.209\n",
      "credit_spread_change         -0.3600      0.320     -1.123      0.261      -0.988       0.268\n",
      "market_return                 0.1261      0.211      0.597      0.551      -0.288       0.540\n",
      "real_estate_excess_return    -0.0994      0.174     -0.573      0.567      -0.440       0.241\n",
      "equity_volatility             2.2550      0.338      6.664      0.000       1.591       2.919\n",
      "institution                   0.4359      0.218      1.996      0.046       0.008       0.864\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 27\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 29.8005 - val_loss: 29.0835\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.5939 - val_loss: 27.7066\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.3253 - val_loss: 26.4121\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0156 - val_loss: 25.2356\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9345 - val_loss: 24.1153\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9478 - val_loss: 23.2244\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1922 - val_loss: 22.4695\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4057 - val_loss: 21.8195\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9370 - val_loss: 21.3090\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4403 - val_loss: 20.8924\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8971 - val_loss: 20.5410\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7605 - val_loss: 20.2581\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4941 - val_loss: 20.0221\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2797 - val_loss: 19.8448\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1368 - val_loss: 19.6964\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0141 - val_loss: 19.5614\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9043 - val_loss: 19.4499\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8090 - val_loss: 19.3547\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7391 - val_loss: 19.2741\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7057 - val_loss: 19.2029\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6773 - val_loss: 19.1329\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6487 - val_loss: 19.0663\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6291 - val_loss: 19.0030\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5979 - val_loss: 18.9516\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5749 - val_loss: 18.9053\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4753 - val_loss: 18.8635\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5495 - val_loss: 18.8284\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4266 - val_loss: 18.7977\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4539 - val_loss: 18.7715\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4804 - val_loss: 18.7482\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4582 - val_loss: 18.7274\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4600 - val_loss: 18.7106\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4362 - val_loss: 18.6955\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4210 - val_loss: 18.6825\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4480 - val_loss: 18.6695\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4309 - val_loss: 18.6574\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3816 - val_loss: 18.6460\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4055 - val_loss: 18.6351\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4105 - val_loss: 18.6244\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4057 - val_loss: 18.6142\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3624 - val_loss: 18.6040\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2157 - val_loss: 18.5940\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3547 - val_loss: 18.5845\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3593 - val_loss: 18.5745\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3144 - val_loss: 18.5645\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3062 - val_loss: 18.5544\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3357 - val_loss: 18.5445\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3128 - val_loss: 18.5345\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3186 - val_loss: 18.5245\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2927 - val_loss: 18.5142\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2883 - val_loss: 18.5042\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2828 - val_loss: 18.4940\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2332 - val_loss: 18.4837\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2528 - val_loss: 18.4735\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2516 - val_loss: 18.4631\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2364 - val_loss: 18.4527\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2296 - val_loss: 18.4423\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9582 - val_loss: 18.4319\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2193 - val_loss: 18.4215\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2026 - val_loss: 18.4110\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1848 - val_loss: 18.4003\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1590 - val_loss: 18.3899\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1690 - val_loss: 18.3790\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1461 - val_loss: 18.3685\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1510 - val_loss: 18.3577\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1393 - val_loss: 18.3469\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1190 - val_loss: 18.3360\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1233 - val_loss: 18.3249\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0799 - val_loss: 18.3140\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0128 - val_loss: 18.3030\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0255 - val_loss: 18.2921\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9179 - val_loss: 18.2809\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9526 - val_loss: 18.2698\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0369 - val_loss: 18.2587\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0422 - val_loss: 18.2473\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0025 - val_loss: 18.2360\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0170 - val_loss: 18.2246\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0071 - val_loss: 18.2132\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9430 - val_loss: 18.2019\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9345 - val_loss: 18.1903\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9503 - val_loss: 18.1787\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9640 - val_loss: 18.1670\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9492 - val_loss: 18.1554\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9347 - val_loss: 18.1437\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9242 - val_loss: 18.1319\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9172 - val_loss: 18.1202\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.8218 - val_loss: 18.1084\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8502 - val_loss: 18.0966\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8723 - val_loss: 18.0847\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8619 - val_loss: 18.0728\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8505 - val_loss: 18.0609\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8043 - val_loss: 18.0491\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8271 - val_loss: 18.0371\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7296 - val_loss: 18.0252\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8058 - val_loss: 18.0130\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7893 - val_loss: 18.0009\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7549 - val_loss: 17.9888\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7669 - val_loss: 17.9767\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7607 - val_loss: 17.9644\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6277 - val_loss: 17.9522\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 684us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_280 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_281 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_282 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_283 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_284 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_285 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_286 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                120\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 25.8190 - val_loss: 24.5728\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9154 - val_loss: 23.7696\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1054 - val_loss: 23.1671\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4280 - val_loss: 22.6461\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8736 - val_loss: 22.1729\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2132 - val_loss: 21.6857\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6310 - val_loss: 21.2496\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0547 - val_loss: 20.8413\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6747 - val_loss: 20.5066\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3381 - val_loss: 20.2655\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0876 - val_loss: 20.0808\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8341 - val_loss: 19.9251\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5339 - val_loss: 19.8093\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3934 - val_loss: 19.7108\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3194 - val_loss: 19.6196\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2019 - val_loss: 19.5341\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0774 - val_loss: 19.4549\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9517 - val_loss: 19.3818\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9035 - val_loss: 19.3177\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7297 - val_loss: 19.2601\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7472 - val_loss: 19.2070\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7244 - val_loss: 19.1601\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6634 - val_loss: 19.1187\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6544 - val_loss: 19.0831\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5724 - val_loss: 19.0532\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5765 - val_loss: 19.0261\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4342 - val_loss: 19.0018\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4887 - val_loss: 18.9799\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4668 - val_loss: 18.9584\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4897 - val_loss: 18.9373\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4574 - val_loss: 18.9173\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4458 - val_loss: 18.8985\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4241 - val_loss: 18.8804\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4296 - val_loss: 18.8639\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3918 - val_loss: 18.8479\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3748 - val_loss: 18.8325\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3640 - val_loss: 18.8171\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3634 - val_loss: 18.8024\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3543 - val_loss: 18.7871\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3038 - val_loss: 18.7734\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3003 - val_loss: 18.7593\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3236 - val_loss: 18.7457\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3182 - val_loss: 18.7315\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2846 - val_loss: 18.7185\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2879 - val_loss: 18.7052\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2471 - val_loss: 18.6920\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2376 - val_loss: 18.6788\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2602 - val_loss: 18.6656\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2482 - val_loss: 18.6534\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2248 - val_loss: 18.6401\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2226 - val_loss: 18.6272\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2228 - val_loss: 18.6149\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.1986 - val_loss: 18.6022\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1823 - val_loss: 18.5901\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1568 - val_loss: 18.5779\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1512 - val_loss: 18.5657\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1719 - val_loss: 18.5533\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0717 - val_loss: 18.5410\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1140 - val_loss: 18.5286\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1346 - val_loss: 18.5161\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1248 - val_loss: 18.5048\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1036 - val_loss: 18.4926\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1073 - val_loss: 18.4804\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0936 - val_loss: 18.4683\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0822 - val_loss: 18.4561\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0260 - val_loss: 18.4442\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0410 - val_loss: 18.4324\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0310 - val_loss: 18.4215\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0228 - val_loss: 18.4098\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0216 - val_loss: 18.3978\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0012 - val_loss: 18.3864\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0065 - val_loss: 18.3742\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9852 - val_loss: 18.3622\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9667 - val_loss: 18.3505\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9222 - val_loss: 18.3389\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8955 - val_loss: 18.3275\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9308 - val_loss: 18.3160\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9315 - val_loss: 18.3037\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9159 - val_loss: 18.2919\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9058 - val_loss: 18.2801\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8952 - val_loss: 18.2683\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8953 - val_loss: 18.2559\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8305 - val_loss: 18.2445\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8429 - val_loss: 18.2332\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8577 - val_loss: 18.2205\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8303 - val_loss: 18.2083\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8250 - val_loss: 18.1960\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7831 - val_loss: 18.1845\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7675 - val_loss: 18.1717\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8042 - val_loss: 18.1595\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7862 - val_loss: 18.1470\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7533 - val_loss: 18.1347\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6787 - val_loss: 18.1226\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7378 - val_loss: 18.1103\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7224 - val_loss: 18.0981\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6851 - val_loss: 18.0855\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6825 - val_loss: 18.0732\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6656 - val_loss: 18.0607\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6637 - val_loss: 18.0484\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6435 - val_loss: 18.0356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 730us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_287 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_288 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_289 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_290 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_291 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_292 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_293 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1327\n",
      "Model:                       QuantReg   Bandwidth:                    0.003505\n",
      "Method:                 Least Squares   Sparsity:                       0.1179\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0281      0.004      6.977      0.000       0.020       0.036\n",
      "three_month_yield_change     -0.5368      0.106     -5.078      0.000      -0.744      -0.330\n",
      "term_spread_change           -0.4707      0.108     -4.353      0.000      -0.683      -0.259\n",
      "TED_spread                   -0.1677      0.420     -0.399      0.690      -0.991       0.656\n",
      "credit_spread_change         -0.4237      0.137     -3.083      0.002      -0.693      -0.154\n",
      "market_return                -0.1211      0.069     -1.749      0.080      -0.257       0.015\n",
      "real_estate_excess_return    -0.1084      0.069     -1.578      0.115      -0.243       0.026\n",
      "equity_volatility             1.4284      0.115     12.395      0.000       1.202       1.654\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3121\n",
      "Model:                       QuantReg   Bandwidth:                    0.006166\n",
      "Method:                 Least Squares   Sparsity:                       0.6029\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:51   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0439      0.009      4.652      0.000       0.025       0.062\n",
      "three_month_yield_change     -0.7922      0.286     -2.774      0.006      -1.352      -0.232\n",
      "term_spread_change           -0.7126      0.278     -2.565      0.010      -1.257      -0.168\n",
      "TED_spread                    0.1140      1.118      0.102      0.919      -2.078       2.306\n",
      "credit_spread_change         -0.9496      0.300     -3.160      0.002      -1.539      -0.360\n",
      "market_return                -0.0637      0.234     -0.272      0.786      -0.523       0.396\n",
      "real_estate_excess_return    -0.2715      0.196     -1.387      0.166      -0.655       0.112\n",
      "equity_volatility             3.4067      0.379      8.993      0.000       2.664       4.149\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3617\n",
      "Model:                       QuantReg   Bandwidth:                    0.002225\n",
      "Method:                 Least Squares   Sparsity:                      0.08026\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:51   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0088      0.003      3.208      0.001       0.003       0.014\n",
      "three_month_yield_change      0.0424      0.075      0.568      0.570      -0.104       0.189\n",
      "term_spread_change           -0.0918      0.071     -1.286      0.199      -0.232       0.048\n",
      "TED_spread                   -0.8489      0.305     -2.787      0.005      -1.446      -0.252\n",
      "credit_spread_change          0.0036      0.098      0.037      0.970      -0.189       0.196\n",
      "market_return                -0.0370      0.042     -0.886      0.376      -0.119       0.045\n",
      "real_estate_excess_return    -0.0278      0.045     -0.621      0.535      -0.116       0.060\n",
      "equity_volatility             0.8520      0.082     10.336      0.000       0.690       1.014\n",
      "institution                   0.5375      0.054     10.034      0.000       0.432       0.643\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4798\n",
      "Model:                       QuantReg   Bandwidth:                    0.003574\n",
      "Method:                 Least Squares   Sparsity:                       0.3359\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        19:59:51   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0121      0.005      2.382      0.017       0.002       0.022\n",
      "three_month_yield_change      0.1294      0.160      0.807      0.420      -0.185       0.444\n",
      "term_spread_change           -0.2529      0.165     -1.531      0.126      -0.577       0.071\n",
      "TED_spread                   -1.8013      0.689     -2.616      0.009      -3.151      -0.451\n",
      "credit_spread_change          0.3412      0.179      1.903      0.057      -0.010       0.693\n",
      "market_return                -0.0584      0.082     -0.712      0.477      -0.219       0.102\n",
      "real_estate_excess_return    -0.1498      0.136     -1.105      0.269      -0.416       0.116\n",
      "equity_volatility             0.9379      0.200      4.679      0.000       0.545       1.331\n",
      "institution                   0.4730      0.138      3.416      0.001       0.201       0.745\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 7ms/step - loss: 37.8449 - val_loss: 41.4216\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.9541 - val_loss: 40.7648\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.4326 - val_loss: 40.0926\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.5421 - val_loss: 39.3304\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.9198 - val_loss: 38.5523\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.1295 - val_loss: 37.6417\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.9177 - val_loss: 36.1961\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.6498 - val_loss: 34.8819\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.3859 - val_loss: 33.6907\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.0409 - val_loss: 32.5532\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.8413 - val_loss: 31.4721\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0864 - val_loss: 30.4615\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9955 - val_loss: 29.4912\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3113 - val_loss: 28.6775\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6873 - val_loss: 28.0185\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0569 - val_loss: 27.4665\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6864 - val_loss: 26.9819\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2664 - val_loss: 26.6084\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0816 - val_loss: 26.3091\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8492 - val_loss: 26.0618\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6101 - val_loss: 25.8535\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5776 - val_loss: 25.6783\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5687 - val_loss: 25.5289\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5127 - val_loss: 25.4124\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4040 - val_loss: 25.3164\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4192 - val_loss: 25.2287\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3990 - val_loss: 25.1477\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3579 - val_loss: 25.0760\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3307 - val_loss: 25.0039\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3161 - val_loss: 24.9366\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2734 - val_loss: 24.8725\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2316 - val_loss: 24.8179\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2088 - val_loss: 24.7686\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1790 - val_loss: 24.7211\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1650 - val_loss: 24.6769\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1406 - val_loss: 24.6364\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9936 - val_loss: 24.5981\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0506 - val_loss: 24.5643\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1136 - val_loss: 24.5301\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0830 - val_loss: 24.5000\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0730 - val_loss: 24.4722\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0681 - val_loss: 24.4476\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0526 - val_loss: 24.4222\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9853 - val_loss: 24.4002\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0214 - val_loss: 24.3779\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9786 - val_loss: 24.3570\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9856 - val_loss: 24.3366\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9951 - val_loss: 24.3155\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9758 - val_loss: 24.2948\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9674 - val_loss: 24.2776\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9050 - val_loss: 24.2600\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8460 - val_loss: 24.2426\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9209 - val_loss: 24.2242\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8476 - val_loss: 24.2061\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8754 - val_loss: 24.1876\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8806 - val_loss: 24.1709\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8785 - val_loss: 24.1545\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7387 - val_loss: 24.1393\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8401 - val_loss: 24.1223\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7841 - val_loss: 24.1071\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8351 - val_loss: 24.0913\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8325 - val_loss: 24.0753\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8216 - val_loss: 24.0612\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6302 - val_loss: 24.0472\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7923 - val_loss: 24.0331\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7804 - val_loss: 24.0195\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7322 - val_loss: 24.0068\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7210 - val_loss: 23.9940\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7452 - val_loss: 23.9818\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7127 - val_loss: 23.9696\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6524 - val_loss: 23.9578\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6694 - val_loss: 23.9454\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5681 - val_loss: 23.9331\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6617 - val_loss: 23.9214\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6818 - val_loss: 23.9084\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6652 - val_loss: 23.8955\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6401 - val_loss: 23.8827\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4987 - val_loss: 23.8704\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5141 - val_loss: 23.8586\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5962 - val_loss: 23.8463\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5974 - val_loss: 23.8336\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5688 - val_loss: 23.8205\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5345 - val_loss: 23.8077\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5627 - val_loss: 23.7947\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5324 - val_loss: 23.7820\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3634 - val_loss: 23.7694\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3979 - val_loss: 23.7564\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5056 - val_loss: 23.7446\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5102 - val_loss: 23.7321\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4461 - val_loss: 23.7193\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3941 - val_loss: 23.7070\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4642 - val_loss: 23.6939\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4422 - val_loss: 23.6814\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4297 - val_loss: 23.6684\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3140 - val_loss: 23.6553\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4205 - val_loss: 23.6420\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4079 - val_loss: 23.6291\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3622 - val_loss: 23.6161\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3713 - val_loss: 23.6035\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2992 - val_loss: 23.5904\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 689us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_294 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_295 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_296 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_297 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_298 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_299 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_300 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                125\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.2165 - val_loss: 22.9970\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1642 - val_loss: 22.2956\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4068 - val_loss: 21.7745\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9119 - val_loss: 21.3374\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3687 - val_loss: 20.9611\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9755 - val_loss: 20.6347\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6459 - val_loss: 20.3431\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2504 - val_loss: 20.1271\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8782 - val_loss: 19.9582\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6607 - val_loss: 19.8178\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5541 - val_loss: 19.7095\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3735 - val_loss: 19.6161\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2423 - val_loss: 19.5275\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0890 - val_loss: 19.4459\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0243 - val_loss: 19.3679\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9299 - val_loss: 19.2975\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7492 - val_loss: 19.2354\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7563 - val_loss: 19.1787\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7157 - val_loss: 19.1281\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6640 - val_loss: 19.0844\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6151 - val_loss: 19.0478\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5982 - val_loss: 19.0173\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4503 - val_loss: 18.9902\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4974 - val_loss: 18.9663\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5327 - val_loss: 18.9436\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4938 - val_loss: 18.9236\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4970 - val_loss: 18.9047\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4223 - val_loss: 18.8850\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4625 - val_loss: 18.8662\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4272 - val_loss: 18.8509\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4407 - val_loss: 18.8343\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4255 - val_loss: 18.8185\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4162 - val_loss: 18.8036\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3513 - val_loss: 18.7903\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3904 - val_loss: 18.7771\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3494 - val_loss: 18.7636\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3637 - val_loss: 18.7519\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3094 - val_loss: 18.7407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3490 - val_loss: 18.7285\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3305 - val_loss: 18.7163\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3312 - val_loss: 18.7042\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2735 - val_loss: 18.6939\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3159 - val_loss: 18.6832\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2918 - val_loss: 18.6729\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2736 - val_loss: 18.6630\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2197 - val_loss: 18.6527\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2749 - val_loss: 18.6426\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2784 - val_loss: 18.6325\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1768 - val_loss: 18.6226\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2496 - val_loss: 18.6126\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2508 - val_loss: 18.6023\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2347 - val_loss: 18.5931\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2088 - val_loss: 18.5839\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1776 - val_loss: 18.5747\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1745 - val_loss: 18.5649\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1950 - val_loss: 18.5552\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1840 - val_loss: 18.5452\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1612 - val_loss: 18.5353\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1321 - val_loss: 18.5255\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1674 - val_loss: 18.5155\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1609 - val_loss: 18.5061\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1500 - val_loss: 18.4958\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0726 - val_loss: 18.4865\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1101 - val_loss: 18.4767\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1225 - val_loss: 18.4673\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0588 - val_loss: 18.4587\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1069 - val_loss: 18.4491\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0849 - val_loss: 18.4401\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0081 - val_loss: 18.4306\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0757 - val_loss: 18.4201\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0642 - val_loss: 18.4107\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0622 - val_loss: 18.4007\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0442 - val_loss: 18.3911\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0124 - val_loss: 18.3816\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9893 - val_loss: 18.3731\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0155 - val_loss: 18.3632\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9796 - val_loss: 18.3533\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9910 - val_loss: 18.3434\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9483 - val_loss: 18.3332\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9630 - val_loss: 18.3223\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9677 - val_loss: 18.3110\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9597 - val_loss: 18.3005\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9105 - val_loss: 18.2904\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9389 - val_loss: 18.2800\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9058 - val_loss: 18.2703\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9162 - val_loss: 18.2598\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8942 - val_loss: 18.2490\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7276 - val_loss: 18.2397\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8627 - val_loss: 18.2294\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8429 - val_loss: 18.2193\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6975 - val_loss: 18.2100\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7959 - val_loss: 18.2003\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8243 - val_loss: 18.1900\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8175 - val_loss: 18.1793\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8265 - val_loss: 18.1678\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8106 - val_loss: 18.1574\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7163 - val_loss: 18.1469\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7573 - val_loss: 18.1363\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7463 - val_loss: 18.1257\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7520 - val_loss: 18.1151\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 711us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_301 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_302 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_303 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_304 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_305 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_306 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_307 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08973\n",
      "Model:                       QuantReg   Bandwidth:                    0.004931\n",
      "Method:                 Least Squares   Sparsity:                       0.1713\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0133      0.006      2.124      0.034       0.001       0.026\n",
      "three_month_yield_change      0.1650      0.176      0.937      0.349      -0.180       0.510\n",
      "term_spread_change           -0.3006      0.160     -1.882      0.060      -0.614       0.013\n",
      "TED_spread                   -1.4645      0.699     -2.094      0.036      -2.836      -0.093\n",
      "credit_spread_change          0.3153      0.213      1.481      0.139      -0.102       0.733\n",
      "market_return                -0.1079      0.087     -1.238      0.216      -0.279       0.063\n",
      "real_estate_excess_return     0.1204      0.105      1.146      0.252      -0.086       0.326\n",
      "equity_volatility             1.5513      0.166      9.326      0.000       1.225       1.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1843\n",
      "Model:                       QuantReg   Bandwidth:                    0.008162\n",
      "Method:                 Least Squares   Sparsity:                       0.9629\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0345      0.017      2.001      0.045       0.001       0.068\n",
      "three_month_yield_change     -0.1019      0.455     -0.224      0.823      -0.994       0.790\n",
      "term_spread_change           -0.3844      0.374     -1.028      0.304      -1.117       0.349\n",
      "TED_spread                   -3.3143      1.885     -1.758      0.079      -7.010       0.382\n",
      "credit_spread_change         -0.0794      0.603     -0.132      0.895      -1.262       1.104\n",
      "market_return                 0.0512      0.361      0.142      0.887      -0.656       0.759\n",
      "real_estate_excess_return    -0.0215      0.305     -0.070      0.944      -0.620       0.577\n",
      "equity_volatility             3.7473      0.598      6.266      0.000       2.575       4.920\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3340\n",
      "Model:                       QuantReg   Bandwidth:                    0.002438\n",
      "Method:                 Least Squares   Sparsity:                      0.08385\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:14   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0079      0.003      2.818      0.005       0.002       0.013\n",
      "three_month_yield_change      0.0661      0.081      0.815      0.415      -0.093       0.225\n",
      "term_spread_change           -0.0692      0.074     -0.940      0.347      -0.214       0.075\n",
      "TED_spread                   -0.6224      0.311     -2.001      0.046      -1.232      -0.012\n",
      "credit_spread_change          0.0012      0.100      0.011      0.991      -0.195       0.198\n",
      "market_return                -0.0358      0.043     -0.829      0.407      -0.121       0.049\n",
      "real_estate_excess_return    -0.0284      0.048     -0.591      0.554      -0.123       0.066\n",
      "equity_volatility             0.8845      0.081     10.910      0.000       0.726       1.043\n",
      "institution                   0.3752      0.039      9.708      0.000       0.299       0.451\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4436\n",
      "Model:                       QuantReg   Bandwidth:                    0.003664\n",
      "Method:                 Least Squares   Sparsity:                       0.3934\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:14   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0129      0.006      2.102      0.036       0.001       0.025\n",
      "three_month_yield_change      0.1129      0.195      0.580      0.562      -0.269       0.495\n",
      "term_spread_change           -0.1382      0.196     -0.706      0.480      -0.522       0.246\n",
      "TED_spread                   -1.0673      0.809     -1.319      0.187      -2.654       0.519\n",
      "credit_spread_change          0.1520      0.233      0.652      0.515      -0.305       0.609\n",
      "market_return                 0.0016      0.159      0.010      0.992      -0.310       0.313\n",
      "real_estate_excess_return    -0.1698      0.109     -1.560      0.119      -0.383       0.044\n",
      "equity_volatility             1.1212      0.249      4.502      0.000       0.633       1.610\n",
      "institution                   0.3771      0.144      2.614      0.009       0.094       0.660\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 33.6409 - val_loss: 31.8584\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.4908 - val_loss: 30.5779\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.1424 - val_loss: 29.4851\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.3217 - val_loss: 28.5775\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.3021 - val_loss: 27.5948\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.1669 - val_loss: 26.5144\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0438 - val_loss: 25.4726\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0616 - val_loss: 24.4785\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.0907 - val_loss: 23.6016\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4351 - val_loss: 22.8110\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4588 - val_loss: 22.1862\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1865 - val_loss: 21.6723\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6936 - val_loss: 21.2299\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3728 - val_loss: 20.8674\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0726 - val_loss: 20.5701\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8073 - val_loss: 20.3305\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4719 - val_loss: 20.1555\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4464 - val_loss: 20.0130\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3093 - val_loss: 19.8891\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0363 - val_loss: 19.7766\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0944 - val_loss: 19.6806\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0509 - val_loss: 19.6019\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0009 - val_loss: 19.5361\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9168 - val_loss: 19.4783\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8718 - val_loss: 19.4235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8358 - val_loss: 19.3722\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7504 - val_loss: 19.3261\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7202 - val_loss: 19.2855\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7506 - val_loss: 19.2453\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6845 - val_loss: 19.2109\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7375 - val_loss: 19.1759\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7150 - val_loss: 19.1444\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7164 - val_loss: 19.1137\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6567 - val_loss: 19.0861\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6781 - val_loss: 19.0596\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6628 - val_loss: 19.0344\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6441 - val_loss: 19.0105\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5842 - val_loss: 18.9876\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6285 - val_loss: 18.9644\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6044 - val_loss: 18.9426\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6037 - val_loss: 18.9211\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5911 - val_loss: 18.9004\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5863 - val_loss: 18.8818\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5563 - val_loss: 18.8645\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5109 - val_loss: 18.8466\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5188 - val_loss: 18.8301\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5408 - val_loss: 18.8125\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5041 - val_loss: 18.7956\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5151 - val_loss: 18.7788\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4968 - val_loss: 18.7633\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4958 - val_loss: 18.7471\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4876 - val_loss: 18.7321\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4682 - val_loss: 18.7174\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4571 - val_loss: 18.7031\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3993 - val_loss: 18.6892\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4340 - val_loss: 18.6747\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4380 - val_loss: 18.6607\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3923 - val_loss: 18.6478\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3904 - val_loss: 18.6334\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4019 - val_loss: 18.6187\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3855 - val_loss: 18.6064\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3390 - val_loss: 18.5937\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3536 - val_loss: 18.5798\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3061 - val_loss: 18.5671\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1827 - val_loss: 18.5539\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3335 - val_loss: 18.5404\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1128 - val_loss: 18.5287\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2602 - val_loss: 18.5152\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2897 - val_loss: 18.5021\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2310 - val_loss: 18.4895\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2542 - val_loss: 18.4761\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2639 - val_loss: 18.4627\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2626 - val_loss: 18.4494\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1626 - val_loss: 18.4375\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2304 - val_loss: 18.4241\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2160 - val_loss: 18.4118\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2011 - val_loss: 18.3990\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9818 - val_loss: 18.3872\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1809 - val_loss: 18.3736\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1535 - val_loss: 18.3609\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1611 - val_loss: 18.3484\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0602 - val_loss: 18.3353\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1419 - val_loss: 18.3225\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1167 - val_loss: 18.3103\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0240 - val_loss: 18.2971\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0767 - val_loss: 18.2846\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0304 - val_loss: 18.2721\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0609 - val_loss: 18.2600\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0668 - val_loss: 18.2464\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0630 - val_loss: 18.2331\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9331 - val_loss: 18.2204\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0270 - val_loss: 18.2071\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9926 - val_loss: 18.1948\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9851 - val_loss: 18.1825\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9834 - val_loss: 18.1694\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9811 - val_loss: 18.1565\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9619 - val_loss: 18.1431\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9374 - val_loss: 18.1314\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9327 - val_loss: 18.1179\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9345 - val_loss: 18.1045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 621us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_308 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_309 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_310 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_311 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_312 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_313 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_314 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.4135 - val_loss: 23.4485\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6903 - val_loss: 22.9065\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1823 - val_loss: 22.4171\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6299 - val_loss: 22.0043\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0379 - val_loss: 21.6492\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6347 - val_loss: 21.3292\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4329 - val_loss: 21.0482\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0802 - val_loss: 20.7949\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7485 - val_loss: 20.5773\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4762 - val_loss: 20.4053\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2749 - val_loss: 20.2654\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1379 - val_loss: 20.1448\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8737 - val_loss: 20.0392\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8001 - val_loss: 19.9478\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6466 - val_loss: 19.8673\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4936 - val_loss: 19.7907\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3874 - val_loss: 19.7178\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1434 - val_loss: 19.6478\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2034 - val_loss: 19.5777\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1209 - val_loss: 19.5101\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0366 - val_loss: 19.4464\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9457 - val_loss: 19.3895\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9397 - val_loss: 19.3370\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8684 - val_loss: 19.2908\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7921 - val_loss: 19.2505\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7537 - val_loss: 19.2141\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7530 - val_loss: 19.1835\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6890 - val_loss: 19.1578\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7054 - val_loss: 19.1332\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6876 - val_loss: 19.1101\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6399 - val_loss: 19.0884\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6322 - val_loss: 19.0670\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6040 - val_loss: 19.0472\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5968 - val_loss: 19.0279\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5584 - val_loss: 19.0088\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5654 - val_loss: 18.9912\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5540 - val_loss: 18.9735\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5465 - val_loss: 18.9571\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5103 - val_loss: 18.9415\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5238 - val_loss: 18.9266\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4728 - val_loss: 18.9118\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5017 - val_loss: 18.8977\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4615 - val_loss: 18.8837\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4548 - val_loss: 18.8707\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4184 - val_loss: 18.8584\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4181 - val_loss: 18.8456\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4540 - val_loss: 18.8329\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4054 - val_loss: 18.8208\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4080 - val_loss: 18.8093\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4206 - val_loss: 18.7968\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3923 - val_loss: 18.7843\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4032 - val_loss: 18.7720\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3880 - val_loss: 18.7603\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2979 - val_loss: 18.7488\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3755 - val_loss: 18.7367\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3570 - val_loss: 18.7257\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3019 - val_loss: 18.7157\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3438 - val_loss: 18.7032\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2974 - val_loss: 18.6920\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3198 - val_loss: 18.6807\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3068 - val_loss: 18.6697\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2931 - val_loss: 18.6590\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2980 - val_loss: 18.6480\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2570 - val_loss: 18.6375\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2524 - val_loss: 18.6265\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1759 - val_loss: 18.6156\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.2308 - val_loss: 18.6047\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2350 - val_loss: 18.5938\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2231 - val_loss: 18.5834\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2184 - val_loss: 18.5721\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1756 - val_loss: 18.5620\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1882 - val_loss: 18.5514\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1833 - val_loss: 18.5414\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1506 - val_loss: 18.5313\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1550 - val_loss: 18.5201\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1621 - val_loss: 18.5093\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1483 - val_loss: 18.4988\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1171 - val_loss: 18.4883\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1063 - val_loss: 18.4772\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1194 - val_loss: 18.4657\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1018 - val_loss: 18.4543\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0946 - val_loss: 18.4437\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0843 - val_loss: 18.4334\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0702 - val_loss: 18.4216\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9853 - val_loss: 18.4116\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0528 - val_loss: 18.3996\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0443 - val_loss: 18.3883\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0226 - val_loss: 18.3770\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0174 - val_loss: 18.3660\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0087 - val_loss: 18.3543\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9901 - val_loss: 18.3435\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9682 - val_loss: 18.3326\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9538 - val_loss: 18.3218\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9390 - val_loss: 18.3109\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9567 - val_loss: 18.2991\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8926 - val_loss: 18.2887\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9221 - val_loss: 18.2776\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9232 - val_loss: 18.2663\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8777 - val_loss: 18.2546\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8844 - val_loss: 18.2431\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 774us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_315 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_316 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_317 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_318 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_319 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_320 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_321 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1332\n",
      "Model:                       QuantReg   Bandwidth:                    0.003865\n",
      "Method:                 Least Squares   Sparsity:                       0.1370\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0229      0.005      4.883      0.000       0.014       0.032\n",
      "three_month_yield_change     -0.2562      0.128     -2.002      0.045      -0.507      -0.005\n",
      "term_spread_change           -0.3075      0.122     -2.525      0.012      -0.546      -0.069\n",
      "TED_spread                   -0.7192      0.472     -1.524      0.128      -1.645       0.206\n",
      "credit_spread_change         -0.2939      0.171     -1.720      0.086      -0.629       0.041\n",
      "market_return                 0.0082      0.076      0.108      0.914      -0.140       0.157\n",
      "real_estate_excess_return    -0.0417      0.079     -0.529      0.597      -0.196       0.113\n",
      "equity_volatility             1.5943      0.135     11.832      0.000       1.330       1.859\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2858\n",
      "Model:                       QuantReg   Bandwidth:                    0.006856\n",
      "Method:                 Least Squares   Sparsity:                       0.7720\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:36   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.013      3.041      0.002       0.014       0.063\n",
      "three_month_yield_change     -0.4325      0.387     -1.119      0.263      -1.191       0.326\n",
      "term_spread_change           -0.1096      0.348     -0.315      0.753      -0.792       0.573\n",
      "TED_spread                    2.4083      1.281      1.879      0.060      -0.104       4.921\n",
      "credit_spread_change         -1.3634      0.474     -2.875      0.004      -2.293      -0.434\n",
      "market_return                -0.2442      0.255     -0.959      0.338      -0.744       0.255\n",
      "real_estate_excess_return    -0.4523      0.209     -2.160      0.031      -0.863      -0.042\n",
      "equity_volatility             4.1796      0.438      9.534      0.000       3.320       5.039\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3819\n",
      "Model:                       QuantReg   Bandwidth:                    0.002247\n",
      "Method:                 Least Squares   Sparsity:                      0.07619\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0124      0.003      4.591      0.000       0.007       0.018\n",
      "three_month_yield_change     -0.0161      0.078     -0.206      0.837      -0.170       0.137\n",
      "term_spread_change           -0.1908      0.066     -2.891      0.004      -0.320      -0.061\n",
      "TED_spread                   -0.4716      0.274     -1.724      0.085      -1.008       0.065\n",
      "credit_spread_change         -0.1301      0.092     -1.409      0.159      -0.311       0.051\n",
      "market_return                -0.0495      0.035     -1.406      0.160      -0.118       0.019\n",
      "real_estate_excess_return    -0.0214      0.044     -0.484      0.629      -0.108       0.065\n",
      "equity_volatility             0.8564      0.076     11.290      0.000       0.708       1.005\n",
      "institution                   0.5049      0.042     12.112      0.000       0.423       0.587\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4925\n",
      "Model:                       QuantReg   Bandwidth:                    0.003719\n",
      "Method:                 Least Squares   Sparsity:                       0.3233\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:36   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0179      0.005      3.895      0.000       0.009       0.027\n",
      "three_month_yield_change     -0.0175      0.151     -0.116      0.908      -0.313       0.278\n",
      "term_spread_change           -0.4355      0.163     -2.672      0.008      -0.755      -0.116\n",
      "TED_spread                   -1.1285      0.599     -1.885      0.060      -2.302       0.046\n",
      "credit_spread_change          0.0547      0.152      0.360      0.719      -0.243       0.353\n",
      "market_return                -0.0442      0.105     -0.422      0.673      -0.249       0.161\n",
      "real_estate_excess_return    -0.0277      0.101     -0.275      0.784      -0.225       0.170\n",
      "equity_volatility             1.2085      0.185      6.545      0.000       0.846       1.571\n",
      "institution                   0.4326      0.143      3.026      0.003       0.152       0.713\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 32.5563 - val_loss: 34.5282\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.7805 - val_loss: 33.4292\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.5224 - val_loss: 32.1331\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.5442 - val_loss: 31.0076\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.5080 - val_loss: 29.8109\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.0439 - val_loss: 27.7343\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3296 - val_loss: 26.1593\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1667 - val_loss: 24.9023\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1467 - val_loss: 23.9096\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3492 - val_loss: 23.1498\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.8371 - val_loss: 22.5399\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4217 - val_loss: 22.0885\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0447 - val_loss: 21.7700\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8259 - val_loss: 21.5387\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6906 - val_loss: 21.3553\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5918 - val_loss: 21.2239\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3602 - val_loss: 21.1334\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3906 - val_loss: 21.0563\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3055 - val_loss: 20.9910\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2976 - val_loss: 20.9382\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2519 - val_loss: 20.8907\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2053 - val_loss: 20.8480\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1795 - val_loss: 20.8108\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1469 - val_loss: 20.7763\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0601 - val_loss: 20.7459\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1072 - val_loss: 20.7165\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1013 - val_loss: 20.6908\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0816 - val_loss: 20.6682\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0211 - val_loss: 20.6477\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0486 - val_loss: 20.6281\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0412 - val_loss: 20.6093\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0207 - val_loss: 20.5914\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9496 - val_loss: 20.5750\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0051 - val_loss: 20.5602\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0029 - val_loss: 20.5456\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9470 - val_loss: 20.5319\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8936 - val_loss: 20.5186\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9738 - val_loss: 20.5059\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.8950 - val_loss: 20.4940\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.8188 - val_loss: 20.4820\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9405 - val_loss: 20.4696\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8874 - val_loss: 20.4580\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9015 - val_loss: 20.4465\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8994 - val_loss: 20.4349\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8901 - val_loss: 20.4236\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8904 - val_loss: 20.4119\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8723 - val_loss: 20.4010\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8660 - val_loss: 20.3899\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8671 - val_loss: 20.3784\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8525 - val_loss: 20.3675\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8445 - val_loss: 20.3567\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8278 - val_loss: 20.3457\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8113 - val_loss: 20.3352\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8083 - val_loss: 20.3242\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.7843 - val_loss: 20.3139\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7895 - val_loss: 20.3025\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7712 - val_loss: 20.2917\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.7690 - val_loss: 20.2806\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7591 - val_loss: 20.2697\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7291 - val_loss: 20.2587\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7060 - val_loss: 20.2484\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6988 - val_loss: 20.2377\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7185 - val_loss: 20.2263\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6578 - val_loss: 20.2158\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6730 - val_loss: 20.2045\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6522 - val_loss: 20.1932\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6127 - val_loss: 20.1821\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6557 - val_loss: 20.1705\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5728 - val_loss: 20.1588\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6427 - val_loss: 20.1470\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6206 - val_loss: 20.1352\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.6050 - val_loss: 20.1235\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5449 - val_loss: 20.1127\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5294 - val_loss: 20.1012\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5402 - val_loss: 20.0897\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5621 - val_loss: 20.0781\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5181 - val_loss: 20.0664\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3906 - val_loss: 20.0547\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5225 - val_loss: 20.0428\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4749 - val_loss: 20.0312\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5140 - val_loss: 20.0195\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4836 - val_loss: 20.0078\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4772 - val_loss: 19.9961\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3891 - val_loss: 19.9848\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3239 - val_loss: 19.9732\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4438 - val_loss: 19.9609\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4315 - val_loss: 19.9489\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4197 - val_loss: 19.9371\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4154 - val_loss: 19.9245\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3635 - val_loss: 19.9124\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3498 - val_loss: 19.9008\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3367 - val_loss: 19.8885\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3395 - val_loss: 19.8761\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3493 - val_loss: 19.8639\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3225 - val_loss: 19.8515\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3302 - val_loss: 19.8387\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2977 - val_loss: 19.8260\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3111 - val_loss: 19.8136\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1945 - val_loss: 19.8015\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2806 - val_loss: 19.7893\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 676us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_322 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_323 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_324 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_325 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_326 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_327 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_328 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.3198 - val_loss: 23.2802\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6536 - val_loss: 22.7550\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0779 - val_loss: 22.2747\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4313 - val_loss: 21.7735\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7799 - val_loss: 21.3603\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4310 - val_loss: 21.0214\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0578 - val_loss: 20.7448\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7271 - val_loss: 20.5210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4494 - val_loss: 20.3483\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2690 - val_loss: 20.2084\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0496 - val_loss: 20.0856\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8931 - val_loss: 19.9820\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7163 - val_loss: 19.8952\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6172 - val_loss: 19.8185\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4707 - val_loss: 19.7460\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3798 - val_loss: 19.6768\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2807 - val_loss: 19.6086\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1249 - val_loss: 19.5430\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0781 - val_loss: 19.4806\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9699 - val_loss: 19.4215\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9532 - val_loss: 19.3648\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9145 - val_loss: 19.3132\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8737 - val_loss: 19.2653\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8035 - val_loss: 19.2224\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7864 - val_loss: 19.1848\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5841 - val_loss: 19.1530\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6971 - val_loss: 19.1252\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6602 - val_loss: 19.1004\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6693 - val_loss: 19.0781\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6286 - val_loss: 19.0562\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6089 - val_loss: 19.0355\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5744 - val_loss: 19.0158\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5159 - val_loss: 18.9955\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5653 - val_loss: 18.9755\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4631 - val_loss: 18.9574\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5388 - val_loss: 18.9390\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4995 - val_loss: 18.9225\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4971 - val_loss: 18.9056\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4772 - val_loss: 18.8891\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4135 - val_loss: 18.8735\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4595 - val_loss: 18.8581\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4243 - val_loss: 18.8427\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3860 - val_loss: 18.8296\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3622 - val_loss: 18.8150\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3842 - val_loss: 18.8012\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3880 - val_loss: 18.7878\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4018 - val_loss: 18.7747\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3459 - val_loss: 18.7617\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3446 - val_loss: 18.7488\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3536 - val_loss: 18.7366\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3164 - val_loss: 18.7247\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3328 - val_loss: 18.7128\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3368 - val_loss: 18.7004\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3188 - val_loss: 18.6881\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2909 - val_loss: 18.6754\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2666 - val_loss: 18.6632\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2951 - val_loss: 18.6516\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2803 - val_loss: 18.6396\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2712 - val_loss: 18.6282\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2469 - val_loss: 18.6170\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0983 - val_loss: 18.6051\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2432 - val_loss: 18.5932\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1941 - val_loss: 18.5817\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1887 - val_loss: 18.5698\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2104 - val_loss: 18.5577\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1218 - val_loss: 18.5464\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1583 - val_loss: 18.5350\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1692 - val_loss: 18.5234\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1667 - val_loss: 18.5119\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1379 - val_loss: 18.5001\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1456 - val_loss: 18.4880\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1272 - val_loss: 18.4771\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0938 - val_loss: 18.4659\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0821 - val_loss: 18.4543\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9385 - val_loss: 18.4427\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0859 - val_loss: 18.4309\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0670 - val_loss: 18.4193\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0430 - val_loss: 18.4076\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0408 - val_loss: 18.3961\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0318 - val_loss: 18.3840\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0329 - val_loss: 18.3717\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0167 - val_loss: 18.3593\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9950 - val_loss: 18.3472\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9842 - val_loss: 18.3350\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9734 - val_loss: 18.3228\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9698 - val_loss: 18.3103\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9450 - val_loss: 18.2983\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9432 - val_loss: 18.2857\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9348 - val_loss: 18.2738\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9043 - val_loss: 18.2618\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9109 - val_loss: 18.2497\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8933 - val_loss: 18.2380\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8905 - val_loss: 18.2267\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8800 - val_loss: 18.2140\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8596 - val_loss: 18.2019\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8064 - val_loss: 18.1901\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8428 - val_loss: 18.1775\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8313 - val_loss: 18.1648\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7530 - val_loss: 18.1531\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6746 - val_loss: 18.1414\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 709us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_48 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_329 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_330 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_331 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_332 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_333 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_334 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_335 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1314\n",
      "Model:                       QuantReg   Bandwidth:                    0.003718\n",
      "Method:                 Least Squares   Sparsity:                       0.1353\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0284      0.005      5.938      0.000       0.019       0.038\n",
      "three_month_yield_change     -0.4026      0.126     -3.184      0.001      -0.651      -0.155\n",
      "term_spread_change           -0.4193      0.116     -3.622      0.000      -0.646      -0.192\n",
      "TED_spread                    0.0590      0.435      0.136      0.892      -0.793       0.912\n",
      "credit_spread_change         -0.5183      0.168     -3.081      0.002      -0.848      -0.188\n",
      "market_return                -0.0152      0.075     -0.202      0.840      -0.162       0.132\n",
      "real_estate_excess_return     0.0369      0.078      0.472      0.637      -0.116       0.190\n",
      "equity_volatility             1.5164      0.147     10.293      0.000       1.227       1.805\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3156\n",
      "Model:                       QuantReg   Bandwidth:                    0.006434\n",
      "Method:                 Least Squares   Sparsity:                       0.5902\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:58   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0386      0.010      3.772      0.000       0.019       0.059\n",
      "three_month_yield_change     -0.3992      0.281     -1.422      0.155      -0.950       0.151\n",
      "term_spread_change           -0.6014      0.248     -2.429      0.015      -1.087      -0.116\n",
      "TED_spread                   -0.1392      0.994     -0.140      0.889      -2.089       1.811\n",
      "credit_spread_change         -0.8141      0.359     -2.269      0.023      -1.518      -0.110\n",
      "market_return                -0.1387      0.228     -0.608      0.543      -0.586       0.309\n",
      "real_estate_excess_return    -0.3365      0.236     -1.426      0.154      -0.799       0.126\n",
      "equity_volatility             3.5938      0.359     10.005      0.000       2.889       4.298\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 30\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3687\n",
      "Model:                       QuantReg   Bandwidth:                    0.002165\n",
      "Method:                 Least Squares   Sparsity:                      0.07518\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0072      0.003      2.741      0.006       0.002       0.012\n",
      "three_month_yield_change      0.1032      0.073      1.422      0.155      -0.039       0.246\n",
      "term_spread_change           -0.0562      0.067     -0.840      0.401      -0.188       0.075\n",
      "TED_spread                   -0.8738      0.278     -3.139      0.002      -1.420      -0.328\n",
      "credit_spread_change         -0.0195      0.093     -0.210      0.834      -0.201       0.162\n",
      "market_return                -0.0817      0.038     -2.176      0.030      -0.155      -0.008\n",
      "real_estate_excess_return    -0.0169      0.044     -0.381      0.703      -0.104       0.070\n",
      "equity_volatility             0.9226      0.071     13.057      0.000       0.784       1.061\n",
      "institution                   0.5078      0.049     10.460      0.000       0.413       0.603\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4662\n",
      "Model:                       QuantReg   Bandwidth:                    0.003876\n",
      "Method:                 Least Squares   Sparsity:                       0.3546\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:00:58   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    -0.0061      0.005     -1.181      0.238      -0.016       0.004\n",
      "three_month_yield_change      0.5008      0.178      2.817      0.005       0.152       0.849\n",
      "term_spread_change           -0.0919      0.199     -0.461      0.645      -0.483       0.299\n",
      "TED_spread                   -2.3643      0.796     -2.972      0.003      -3.924      -0.804\n",
      "credit_spread_change          0.9539      0.184      5.180      0.000       0.593       1.315\n",
      "market_return                -0.0921      0.116     -0.793      0.428      -0.320       0.136\n",
      "real_estate_excess_return    -0.1332      0.124     -1.072      0.284      -0.377       0.111\n",
      "equity_volatility             1.0309      0.244      4.227      0.000       0.553       1.509\n",
      "institution                   0.4148      0.171      2.421      0.016       0.079       0.751\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 32.3549 - val_loss: 29.1105\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.4813 - val_loss: 28.2250\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.4220 - val_loss: 27.1234\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.8874 - val_loss: 25.7638\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.6531 - val_loss: 24.7357\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0516 - val_loss: 23.7577\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4263 - val_loss: 22.8253\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3657 - val_loss: 22.0463\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8984 - val_loss: 21.3707\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3538 - val_loss: 20.8348\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8099 - val_loss: 20.4265\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4879 - val_loss: 20.1502\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2222 - val_loss: 19.9363\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0463 - val_loss: 19.7599\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9039 - val_loss: 19.6071\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7965 - val_loss: 19.4634\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6936 - val_loss: 19.3385\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6052 - val_loss: 19.2379\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4941 - val_loss: 19.1510\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4727 - val_loss: 19.0723\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3462 - val_loss: 19.0033\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3012 - val_loss: 18.9471\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3599 - val_loss: 18.8962\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1732 - val_loss: 18.8545\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3095 - val_loss: 18.8185\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2933 - val_loss: 18.7863\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2349 - val_loss: 18.7587\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2381 - val_loss: 18.7359\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2081 - val_loss: 18.7135\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2328 - val_loss: 18.6911\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1394 - val_loss: 18.6732\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2226 - val_loss: 18.6537\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1283 - val_loss: 18.6375\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1973 - val_loss: 18.6187\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1413 - val_loss: 18.6026\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1715 - val_loss: 18.5867\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1650 - val_loss: 18.5691\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9617 - val_loss: 18.5530\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0881 - val_loss: 18.5390\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0490 - val_loss: 18.5265\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0674 - val_loss: 18.5120\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9345 - val_loss: 18.4991\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.0858 - val_loss: 18.4856\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1010 - val_loss: 18.4735\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0783 - val_loss: 18.4606\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0743 - val_loss: 18.4478\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0618 - val_loss: 18.4353\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9214 - val_loss: 18.4243\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9673 - val_loss: 18.4130\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0367 - val_loss: 18.4016\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0072 - val_loss: 18.3902\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0205 - val_loss: 18.3800\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9938 - val_loss: 18.3689\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9940 - val_loss: 18.3574\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0020 - val_loss: 18.3459\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9551 - val_loss: 18.3358\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9262 - val_loss: 18.3246\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7988 - val_loss: 18.3142\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8429 - val_loss: 18.3037\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8328 - val_loss: 18.2928\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9295 - val_loss: 18.2822\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9288 - val_loss: 18.2710\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9100 - val_loss: 18.2602\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9047 - val_loss: 18.2490\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8883 - val_loss: 18.2379\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8654 - val_loss: 18.2268\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8636 - val_loss: 18.2154\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8556 - val_loss: 18.2040\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8063 - val_loss: 18.1931\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8293 - val_loss: 18.1824\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7535 - val_loss: 18.1712\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7647 - val_loss: 18.1604\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7586 - val_loss: 18.1492\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7457 - val_loss: 18.1383\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6062 - val_loss: 18.1270\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7643 - val_loss: 18.1157\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7566 - val_loss: 18.1044\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6987 - val_loss: 18.0932\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7141 - val_loss: 18.0817\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7337 - val_loss: 18.0704\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7080 - val_loss: 18.0592\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6246 - val_loss: 18.0487\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6638 - val_loss: 18.0376\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6714 - val_loss: 18.0263\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6629 - val_loss: 18.0146\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6642 - val_loss: 18.0031\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5669 - val_loss: 17.9918\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6362 - val_loss: 17.9802\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5850 - val_loss: 17.9687\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5755 - val_loss: 17.9571\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5984 - val_loss: 17.9456\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5673 - val_loss: 17.9337\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5824 - val_loss: 17.9220\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5662 - val_loss: 17.9098\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5196 - val_loss: 17.8982\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5140 - val_loss: 17.8864\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4504 - val_loss: 17.8747\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4969 - val_loss: 17.8630\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4986 - val_loss: 17.8510\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4468 - val_loss: 17.8392\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 641us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_336 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_337 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_338 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_339 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_340 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_341 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_342 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                125\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 25.9160 - val_loss: 24.5501\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9494 - val_loss: 23.7380\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9850 - val_loss: 23.0215\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2111 - val_loss: 22.4606\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6247 - val_loss: 22.0387\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1109 - val_loss: 21.6417\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5631 - val_loss: 21.1396\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0465 - val_loss: 20.7369\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6550 - val_loss: 20.4385\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3363 - val_loss: 20.2203\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0197 - val_loss: 20.0457\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7142 - val_loss: 19.9065\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5839 - val_loss: 19.7976\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3998 - val_loss: 19.7029\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2631 - val_loss: 19.6167\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1709 - val_loss: 19.5349\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9638 - val_loss: 19.4607\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9690 - val_loss: 19.3953\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9292 - val_loss: 19.3395\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8571 - val_loss: 19.2859\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7588 - val_loss: 19.2373\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7524 - val_loss: 19.1942\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7413 - val_loss: 19.1565\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6606 - val_loss: 19.1239\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6534 - val_loss: 19.0944\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6389 - val_loss: 19.0693\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5948 - val_loss: 19.0477\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5387 - val_loss: 19.0268\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5497 - val_loss: 19.0067\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5452 - val_loss: 18.9866\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5433 - val_loss: 18.9674\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5219 - val_loss: 18.9487\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5103 - val_loss: 18.9299\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5006 - val_loss: 18.9124\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4678 - val_loss: 18.8958\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4639 - val_loss: 18.8799\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4473 - val_loss: 18.8645\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4364 - val_loss: 18.8500\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4408 - val_loss: 18.8350\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4188 - val_loss: 18.8212\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3681 - val_loss: 18.8075\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4093 - val_loss: 18.7935\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3810 - val_loss: 18.7810\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3766 - val_loss: 18.7686\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3577 - val_loss: 18.7558\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3695 - val_loss: 18.7434\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3441 - val_loss: 18.7325\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3473 - val_loss: 18.7202\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2719 - val_loss: 18.7096\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3364 - val_loss: 18.6982\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3203 - val_loss: 18.6873\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2331 - val_loss: 18.6767\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2951 - val_loss: 18.6656\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2868 - val_loss: 18.6555\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2797 - val_loss: 18.6447\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2705 - val_loss: 18.6342\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2505 - val_loss: 18.6235\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2437 - val_loss: 18.6129\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2457 - val_loss: 18.6021\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2119 - val_loss: 18.5918\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2147 - val_loss: 18.5811\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1347 - val_loss: 18.5708\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2154 - val_loss: 18.5601\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2034 - val_loss: 18.5495\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1716 - val_loss: 18.5411\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1384 - val_loss: 18.5310\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1723 - val_loss: 18.5210\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1079 - val_loss: 18.5116\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1456 - val_loss: 18.5023\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1107 - val_loss: 18.4923\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1400 - val_loss: 18.4818\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1215 - val_loss: 18.4717\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1096 - val_loss: 18.4614\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0575 - val_loss: 18.4513\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0878 - val_loss: 18.4404\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9985 - val_loss: 18.4303\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0209 - val_loss: 18.4197\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0251 - val_loss: 18.4090\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0503 - val_loss: 18.3977\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0130 - val_loss: 18.3872\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0227 - val_loss: 18.3764\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0144 - val_loss: 18.3656\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9858 - val_loss: 18.3546\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8758 - val_loss: 18.3445\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9462 - val_loss: 18.3338\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9783 - val_loss: 18.3235\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9303 - val_loss: 18.3128\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9483 - val_loss: 18.3017\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8632 - val_loss: 18.2916\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.9329 - val_loss: 18.2805\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8570 - val_loss: 18.2698\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9069 - val_loss: 18.2587\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9042 - val_loss: 18.2472\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8649 - val_loss: 18.2365\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8713 - val_loss: 18.2250\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8370 - val_loss: 18.2147\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8506 - val_loss: 18.2038\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8453 - val_loss: 18.1924\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8143 - val_loss: 18.1818\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8219 - val_loss: 18.1705\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 695us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_343 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_344 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_345 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_346 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_347 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_348 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_349 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1486\n",
      "Model:                       QuantReg   Bandwidth:                    0.004225\n",
      "Method:                 Least Squares   Sparsity:                       0.1267\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:19   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0411      0.004      9.742      0.000       0.033       0.049\n",
      "three_month_yield_change     -0.8377      0.125     -6.687      0.000      -1.083      -0.592\n",
      "term_spread_change           -0.5977      0.124     -4.833      0.000      -0.840      -0.355\n",
      "TED_spread                    0.0707      0.489      0.145      0.885      -0.888       1.029\n",
      "credit_spread_change         -0.9449      0.145     -6.528      0.000      -1.229      -0.661\n",
      "market_return                -0.1254      0.066     -1.900      0.058      -0.255       0.004\n",
      "real_estate_excess_return    -0.0110      0.074     -0.150      0.881      -0.156       0.134\n",
      "equity_volatility             2.1684      0.119     18.204      0.000       1.935       2.402\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3221\n",
      "Model:                       QuantReg   Bandwidth:                    0.007339\n",
      "Method:                 Least Squares   Sparsity:                       0.5044\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:19   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0542      0.008      7.160      0.000       0.039       0.069\n",
      "three_month_yield_change     -1.1402      0.293     -3.885      0.000      -1.716      -0.565\n",
      "term_spread_change           -0.7875      0.269     -2.926      0.003      -1.315      -0.260\n",
      "TED_spread                    2.3095      1.036      2.230      0.026       0.279       4.340\n",
      "credit_spread_change         -1.5241      0.221     -6.888      0.000      -1.958      -1.090\n",
      "market_return                -0.2506      0.179     -1.398      0.162      -0.602       0.101\n",
      "real_estate_excess_return    -0.0845      0.161     -0.525      0.600      -0.400       0.231\n",
      "equity_volatility             3.7827      0.282     13.429      0.000       3.230       4.335\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3729\n",
      "Model:                       QuantReg   Bandwidth:                    0.002120\n",
      "Method:                 Least Squares   Sparsity:                      0.08669\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:19   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0093      0.003      2.848      0.004       0.003       0.016\n",
      "three_month_yield_change      0.0624      0.089      0.701      0.483      -0.112       0.237\n",
      "term_spread_change           -0.1799      0.074     -2.434      0.015      -0.325      -0.035\n",
      "TED_spread                   -1.0500      0.317     -3.313      0.001      -1.671      -0.429\n",
      "credit_spread_change          0.0508      0.114      0.443      0.657      -0.174       0.275\n",
      "market_return                 0.0259      0.047      0.551      0.582      -0.066       0.118\n",
      "real_estate_excess_return    -0.0057      0.051     -0.112      0.911      -0.106       0.094\n",
      "equity_volatility             0.7555      0.092      8.183      0.000       0.574       0.937\n",
      "institution                   0.5203      0.044     11.839      0.000       0.434       0.607\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4935\n",
      "Model:                       QuantReg   Bandwidth:                    0.004278\n",
      "Method:                 Least Squares   Sparsity:                       0.2896\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:19   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0276      0.005      6.064      0.000       0.019       0.037\n",
      "three_month_yield_change      0.1485      0.144      1.032      0.302      -0.134       0.431\n",
      "term_spread_change           -0.5649      0.133     -4.259      0.000      -0.825      -0.305\n",
      "TED_spread                   -3.5412      0.604     -5.863      0.000      -4.726      -2.357\n",
      "credit_spread_change          0.0941      0.174      0.542      0.588      -0.246       0.435\n",
      "market_return                 0.0311      0.118      0.264      0.792      -0.200       0.262\n",
      "real_estate_excess_return    -0.0334      0.091     -0.369      0.712      -0.211       0.144\n",
      "equity_volatility             1.0680      0.186      5.731      0.000       0.703       1.433\n",
      "institution                   0.4662      0.124      3.755      0.000       0.223       0.710\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 36.9571 - val_loss: 40.2089\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.7574 - val_loss: 39.0877\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.5772 - val_loss: 37.9611\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.4684 - val_loss: 36.9536\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.3339 - val_loss: 35.9383\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.2254 - val_loss: 34.6820\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.8186 - val_loss: 33.5483\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.3585 - val_loss: 32.5585\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.4699 - val_loss: 31.6523\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7784 - val_loss: 30.8919\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0041 - val_loss: 30.2182\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2985 - val_loss: 29.5932\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8447 - val_loss: 29.0852\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2054 - val_loss: 28.7022\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0627 - val_loss: 28.3585\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8365 - val_loss: 28.0845\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5645 - val_loss: 27.8422\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3578 - val_loss: 27.6534\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2589 - val_loss: 27.5125\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1122 - val_loss: 27.3993\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1097 - val_loss: 27.2936\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0816 - val_loss: 27.2151\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0174 - val_loss: 27.1543\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9170 - val_loss: 27.1129\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9723 - val_loss: 27.0868\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9323 - val_loss: 27.0649\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8703 - val_loss: 27.0459\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8705 - val_loss: 27.0281\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8117 - val_loss: 27.0108\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8247 - val_loss: 26.9935\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8198 - val_loss: 26.9768\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7632 - val_loss: 26.9615\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7430 - val_loss: 26.9467\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6804 - val_loss: 26.9322\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7149 - val_loss: 26.9186\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7031 - val_loss: 26.9056\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6902 - val_loss: 26.8937\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6914 - val_loss: 26.8828\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5904 - val_loss: 26.8727\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6829 - val_loss: 26.8629\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6731 - val_loss: 26.8532\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6547 - val_loss: 26.8436\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6265 - val_loss: 26.8339\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4124 - val_loss: 26.8241\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6209 - val_loss: 26.8145\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6093 - val_loss: 26.8048\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6081 - val_loss: 26.7951\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5988 - val_loss: 26.7853\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5566 - val_loss: 26.7754\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4473 - val_loss: 26.7654\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4773 - val_loss: 26.7554\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4339 - val_loss: 26.7453\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5346 - val_loss: 26.7352\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5238 - val_loss: 26.7250\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5269 - val_loss: 26.7147\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5074 - val_loss: 26.7043\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4323 - val_loss: 26.6940\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3948 - val_loss: 26.6836\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4647 - val_loss: 26.6730\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4059 - val_loss: 26.6625\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3280 - val_loss: 26.6518\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4397 - val_loss: 26.6412\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3245 - val_loss: 26.6304\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3187 - val_loss: 26.6196\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4057 - val_loss: 26.6087\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4144 - val_loss: 26.5977\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3906 - val_loss: 26.5868\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3981 - val_loss: 26.5757\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3770 - val_loss: 26.5646\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2167 - val_loss: 26.5534\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3089 - val_loss: 26.5422\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2958 - val_loss: 26.5309\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3140 - val_loss: 26.5195\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3153 - val_loss: 26.5081\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3118 - val_loss: 26.4967\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2878 - val_loss: 26.4853\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2743 - val_loss: 26.4738\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.2793 - val_loss: 26.4623\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1862 - val_loss: 26.4508\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2564 - val_loss: 26.4392\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1617 - val_loss: 26.4275\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 22.1887 - val_loss: 26.4157\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2245 - val_loss: 26.4039\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1755 - val_loss: 26.3921\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1647 - val_loss: 26.3802\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1195 - val_loss: 26.3683\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1593 - val_loss: 26.3563\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1006 - val_loss: 26.3443\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1351 - val_loss: 26.3322\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1301 - val_loss: 26.3201\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1098 - val_loss: 26.3079\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1004 - val_loss: 26.2957\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0224 - val_loss: 26.2835\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9931 - val_loss: 26.2713\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0747 - val_loss: 26.2589\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0421 - val_loss: 26.2466\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0284 - val_loss: 26.2343\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6111 - val_loss: 26.2219\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9820 - val_loss: 26.2095\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0108 - val_loss: 26.1970\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "77/77 [==============================] - 0s 687us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_350 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_351 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_352 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_353 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_354 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_355 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_356 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 27.6803 - val_loss: 26.0738\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.7513 - val_loss: 25.4498\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0219 - val_loss: 24.8878\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4178 - val_loss: 24.3499\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8509 - val_loss: 23.8786\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3494 - val_loss: 23.4553\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8055 - val_loss: 22.9891\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1297 - val_loss: 22.3902\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3072 - val_loss: 21.8211\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8141 - val_loss: 21.3261\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2772 - val_loss: 20.9356\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8422 - val_loss: 20.6059\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4866 - val_loss: 20.3692\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1390 - val_loss: 20.1907\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9401 - val_loss: 20.0332\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7479 - val_loss: 19.9213\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5617 - val_loss: 19.8266\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3909 - val_loss: 19.7396\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2945 - val_loss: 19.6619\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1224 - val_loss: 19.5850\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1217 - val_loss: 19.5127\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0156 - val_loss: 19.4494\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9741 - val_loss: 19.3951\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9171 - val_loss: 19.3469\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8349 - val_loss: 19.3029\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7708 - val_loss: 19.2612\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7641 - val_loss: 19.2229\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7657 - val_loss: 19.1901\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7043 - val_loss: 19.1645\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6732 - val_loss: 19.1418\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6492 - val_loss: 19.1207\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6424 - val_loss: 19.1008\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6279 - val_loss: 19.0813\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5839 - val_loss: 19.0629\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6018 - val_loss: 19.0444\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5491 - val_loss: 19.0269\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5361 - val_loss: 19.0097\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5344 - val_loss: 18.9932\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4506 - val_loss: 18.9773\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5132 - val_loss: 18.9611\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4803 - val_loss: 18.9455\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4665 - val_loss: 18.9298\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4469 - val_loss: 18.9142\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4532 - val_loss: 18.8986\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3815 - val_loss: 18.8841\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4374 - val_loss: 18.8688\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4011 - val_loss: 18.8534\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4077 - val_loss: 18.8379\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3953 - val_loss: 18.8230\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3400 - val_loss: 18.8089\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3789 - val_loss: 18.7946\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3598 - val_loss: 18.7803\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3346 - val_loss: 18.7660\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3422 - val_loss: 18.7518\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3314 - val_loss: 18.7372\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3138 - val_loss: 18.7232\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3006 - val_loss: 18.7089\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2888 - val_loss: 18.6952\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2676 - val_loss: 18.6815\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2335 - val_loss: 18.6679\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2583 - val_loss: 18.6540\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1578 - val_loss: 18.6406\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2298 - val_loss: 18.6268\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1566 - val_loss: 18.6133\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1967 - val_loss: 18.5996\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1439 - val_loss: 18.5859\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1708 - val_loss: 18.5724\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1395 - val_loss: 18.5587\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1438 - val_loss: 18.5450\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1127 - val_loss: 18.5313\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1298 - val_loss: 18.5174\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0575 - val_loss: 18.5041\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0942 - val_loss: 18.4907\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0274 - val_loss: 18.4775\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0735 - val_loss: 18.4639\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0701 - val_loss: 18.4502\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0391 - val_loss: 18.4370\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0195 - val_loss: 18.4237\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0129 - val_loss: 18.4101\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0189 - val_loss: 18.3963\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9869 - val_loss: 18.3825\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9968 - val_loss: 18.3690\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9169 - val_loss: 18.3556\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9582 - val_loss: 18.3421\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9512 - val_loss: 18.3284\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9355 - val_loss: 18.3143\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9242 - val_loss: 18.3003\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9031 - val_loss: 18.2865\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8763 - val_loss: 18.2733\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8885 - val_loss: 18.2588\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8535 - val_loss: 18.2452\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6573 - val_loss: 18.2320\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8079 - val_loss: 18.2182\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7865 - val_loss: 18.2041\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8211 - val_loss: 18.1898\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5948 - val_loss: 18.1761\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7906 - val_loss: 18.1619\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7545 - val_loss: 18.1477\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7549 - val_loss: 18.1333\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7372 - val_loss: 18.1197\n",
      "4/4 [==============================] - 0s 942us/step\n",
      "77/77 [==============================] - 0s 641us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_52 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_357 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_358 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_359 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_360 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_361 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_362 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_363 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1366\n",
      "Model:                       QuantReg   Bandwidth:                    0.005426\n",
      "Method:                 Least Squares   Sparsity:                       0.1997\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0003      0.007      0.048      0.962      -0.013       0.014\n",
      "three_month_yield_change     -0.3610      0.186     -1.936      0.053      -0.727       0.005\n",
      "term_spread_change           -0.2084      0.183     -1.136      0.256      -0.568       0.151\n",
      "TED_spread                    0.6317      0.673      0.939      0.348      -0.688       1.951\n",
      "credit_spread_change          0.4283      0.245      1.750      0.080      -0.052       0.908\n",
      "market_return                 0.0831      0.106      0.781      0.435      -0.126       0.292\n",
      "real_estate_excess_return     0.0568      0.126      0.450      0.653      -0.191       0.304\n",
      "equity_volatility             2.3357      0.208     11.225      0.000       1.928       2.744\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3279\n",
      "Model:                       QuantReg   Bandwidth:                    0.009052\n",
      "Method:                 Least Squares   Sparsity:                       0.9229\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:41   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0049      0.014      0.353      0.724      -0.022       0.032\n",
      "three_month_yield_change      0.2939      0.394      0.745      0.456      -0.479       1.067\n",
      "term_spread_change           -0.2017      0.387     -0.521      0.602      -0.960       0.557\n",
      "TED_spread                    0.2385      1.551      0.154      0.878      -2.802       3.279\n",
      "credit_spread_change          0.5309      0.507      1.048      0.295      -0.463       1.525\n",
      "market_return                 0.2808      0.355      0.792      0.429      -0.415       0.976\n",
      "real_estate_excess_return    -0.1696      0.366     -0.463      0.643      -0.888       0.548\n",
      "equity_volatility             3.9839      0.571      6.977      0.000       2.864       5.104\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 27\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3666\n",
      "Model:                       QuantReg   Bandwidth:                    0.002270\n",
      "Method:                 Least Squares   Sparsity:                      0.08539\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0110      0.003      3.781      0.000       0.005       0.017\n",
      "three_month_yield_change      0.0485      0.081      0.602      0.547      -0.110       0.206\n",
      "term_spread_change           -0.2840      0.074     -3.859      0.000      -0.428      -0.140\n",
      "TED_spread                   -0.5823      0.297     -1.958      0.050      -1.166       0.001\n",
      "credit_spread_change         -0.0049      0.108     -0.046      0.963      -0.217       0.207\n",
      "market_return                -0.1196      0.044     -2.721      0.007      -0.206      -0.033\n",
      "real_estate_excess_return    -0.0764      0.052     -1.456      0.145      -0.179       0.026\n",
      "equity_volatility             0.7838      0.084      9.277      0.000       0.618       0.950\n",
      "institution                   0.3607      0.039      9.168      0.000       0.284       0.438\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4797\n",
      "Model:                       QuantReg   Bandwidth:                    0.003644\n",
      "Method:                 Least Squares   Sparsity:                       0.3304\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:01:41   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0258      0.005      5.363      0.000       0.016       0.035\n",
      "three_month_yield_change     -0.2443      0.161     -1.521      0.128      -0.559       0.071\n",
      "term_spread_change           -0.5294      0.162     -3.274      0.001      -0.847      -0.212\n",
      "TED_spread                   -1.3775      0.553     -2.492      0.013      -2.461      -0.294\n",
      "credit_spread_change         -0.0689      0.183     -0.377      0.706      -0.427       0.289\n",
      "market_return                -0.2180      0.112     -1.950      0.051      -0.437       0.001\n",
      "real_estate_excess_return    -0.1805      0.117     -1.547      0.122      -0.409       0.048\n",
      "equity_volatility             1.0918      0.244      4.467      0.000       0.613       1.571\n",
      "institution                   0.3614      0.128      2.830      0.005       0.111       0.612\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 36.0175 - val_loss: 40.1963\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.9054 - val_loss: 38.8456\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.1990 - val_loss: 36.9169\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.3112 - val_loss: 35.1481\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 29.6277 - val_loss: 33.5020\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.2638 - val_loss: 32.0798\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0622 - val_loss: 30.8548\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9845 - val_loss: 29.8223\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2163 - val_loss: 29.0014\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6278 - val_loss: 28.3063\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0397 - val_loss: 27.7344\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6823 - val_loss: 27.2295\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2813 - val_loss: 26.8298\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0302 - val_loss: 26.4966\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8311 - val_loss: 26.2329\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5665 - val_loss: 26.0100\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5033 - val_loss: 25.8315\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3785 - val_loss: 25.6709\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0726 - val_loss: 25.5218\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1409 - val_loss: 25.3865\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9973 - val_loss: 25.2692\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9709 - val_loss: 25.1613\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8847 - val_loss: 25.0646\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9218 - val_loss: 24.9697\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8542 - val_loss: 24.8872\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7548 - val_loss: 24.8134\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6983 - val_loss: 24.7475\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7585 - val_loss: 24.6855\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5199 - val_loss: 24.6325\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6716 - val_loss: 24.5856\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6947 - val_loss: 24.5411\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5570 - val_loss: 24.4995\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4962 - val_loss: 24.4617\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6311 - val_loss: 24.4231\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6145 - val_loss: 24.3836\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5325 - val_loss: 24.3494\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5704 - val_loss: 24.3167\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3867 - val_loss: 24.2846\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5521 - val_loss: 24.2548\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3237 - val_loss: 24.2273\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5149 - val_loss: 24.1997\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3045 - val_loss: 24.1743\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4671 - val_loss: 24.1499\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4224 - val_loss: 24.1261\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4343 - val_loss: 24.1012\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4456 - val_loss: 24.0795\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4452 - val_loss: 24.0586\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3495 - val_loss: 24.0384\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3318 - val_loss: 24.0181\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2640 - val_loss: 23.9974\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3873 - val_loss: 23.9801\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3180 - val_loss: 23.9612\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3695 - val_loss: 23.9432\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3606 - val_loss: 23.9247\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3492 - val_loss: 23.9098\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3255 - val_loss: 23.8935\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3221 - val_loss: 23.8778\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3087 - val_loss: 23.8611\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3043 - val_loss: 23.8457\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2910 - val_loss: 23.8311\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2709 - val_loss: 23.8168\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2872 - val_loss: 23.8014\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2478 - val_loss: 23.7871\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2080 - val_loss: 23.7734\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2376 - val_loss: 23.7575\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2216 - val_loss: 23.7448\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1893 - val_loss: 23.7330\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1860 - val_loss: 23.7190\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1812 - val_loss: 23.7066\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1639 - val_loss: 23.6942\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1727 - val_loss: 23.6828\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1490 - val_loss: 23.6693\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0796 - val_loss: 23.6586\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1221 - val_loss: 23.6460\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1173 - val_loss: 23.6367\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1183 - val_loss: 23.6233\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1109 - val_loss: 23.6105\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0847 - val_loss: 23.5972\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0726 - val_loss: 23.5839\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0716 - val_loss: 23.5718\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0450 - val_loss: 23.5604\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0491 - val_loss: 23.5484\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0184 - val_loss: 23.5360\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0034 - val_loss: 23.5229\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0054 - val_loss: 23.5118\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9877 - val_loss: 23.4992\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9410 - val_loss: 23.4869\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9633 - val_loss: 23.4747\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9567 - val_loss: 23.4618\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8866 - val_loss: 23.4501\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9384 - val_loss: 23.4384\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9043 - val_loss: 23.4292\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9174 - val_loss: 23.4169\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8939 - val_loss: 23.4034\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8733 - val_loss: 23.3891\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8885 - val_loss: 23.3770\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8717 - val_loss: 23.3642\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7667 - val_loss: 23.3528\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8124 - val_loss: 23.3392\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8045 - val_loss: 23.3246\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 648us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_364 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_365 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_366 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_367 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_368 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_369 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_370 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                127\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 27.9449 - val_loss: 26.3256\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 26.8285 - val_loss: 25.4798\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6871 - val_loss: 24.1377\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0187 - val_loss: 22.7419\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5406 - val_loss: 21.7577\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6233 - val_loss: 21.0719\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8788 - val_loss: 20.6138\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4337 - val_loss: 20.3370\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0669 - val_loss: 20.1253\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8200 - val_loss: 19.9803\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6066 - val_loss: 19.8626\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3577 - val_loss: 19.7616\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1416 - val_loss: 19.6690\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1807 - val_loss: 19.5861\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1135 - val_loss: 19.5164\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0245 - val_loss: 19.4569\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9865 - val_loss: 19.4018\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8430 - val_loss: 19.3539\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8815 - val_loss: 19.3159\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8515 - val_loss: 19.2845\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8183 - val_loss: 19.2578\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7764 - val_loss: 19.2323\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7525 - val_loss: 19.2083\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7325 - val_loss: 19.1869\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6893 - val_loss: 19.1675\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7005 - val_loss: 19.1481\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6775 - val_loss: 19.1293\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6230 - val_loss: 19.1112\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6067 - val_loss: 19.0943\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6057 - val_loss: 19.0773\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6388 - val_loss: 19.0605\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6230 - val_loss: 19.0437\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6065 - val_loss: 19.0280\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6001 - val_loss: 19.0123\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5653 - val_loss: 18.9970\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5714 - val_loss: 18.9821\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5656 - val_loss: 18.9682\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5239 - val_loss: 18.9557\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5244 - val_loss: 18.9424\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5262 - val_loss: 18.9294\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5185 - val_loss: 18.9167\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5050 - val_loss: 18.9045\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5069 - val_loss: 18.8917\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4871 - val_loss: 18.8790\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4711 - val_loss: 18.8675\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4149 - val_loss: 18.8561\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4618 - val_loss: 18.8441\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4420 - val_loss: 18.8336\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3544 - val_loss: 18.8219\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3693 - val_loss: 18.8104\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4234 - val_loss: 18.7986\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3963 - val_loss: 18.7874\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4059 - val_loss: 18.7761\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3875 - val_loss: 18.7644\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3508 - val_loss: 18.7540\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3699 - val_loss: 18.7422\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3435 - val_loss: 18.7309\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3496 - val_loss: 18.7195\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3438 - val_loss: 18.7082\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3044 - val_loss: 18.6972\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2767 - val_loss: 18.6856\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2818 - val_loss: 18.6738\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2972 - val_loss: 18.6623\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2829 - val_loss: 18.6517\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2735 - val_loss: 18.6402\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2621 - val_loss: 18.6288\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2471 - val_loss: 18.6173\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2454 - val_loss: 18.6055\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2201 - val_loss: 18.5940\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2175 - val_loss: 18.5834\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1729 - val_loss: 18.5724\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0812 - val_loss: 18.5622\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1888 - val_loss: 18.5505\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1802 - val_loss: 18.5386\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1719 - val_loss: 18.5266\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1175 - val_loss: 18.5152\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1533 - val_loss: 18.5039\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1339 - val_loss: 18.4923\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0975 - val_loss: 18.4810\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0472 - val_loss: 18.4701\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0907 - val_loss: 18.4584\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0803 - val_loss: 18.4472\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0646 - val_loss: 18.4354\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0678 - val_loss: 18.4236\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0528 - val_loss: 18.4121\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0466 - val_loss: 18.4002\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9685 - val_loss: 18.3887\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9310 - val_loss: 18.3767\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9951 - val_loss: 18.3655\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9665 - val_loss: 18.3539\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8987 - val_loss: 18.3420\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9716 - val_loss: 18.3299\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9285 - val_loss: 18.3183\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9305 - val_loss: 18.3062\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9426 - val_loss: 18.2941\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9280 - val_loss: 18.2815\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8814 - val_loss: 18.2694\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8891 - val_loss: 18.2567\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8711 - val_loss: 18.2450\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8755 - val_loss: 18.2324\n",
      "4/4 [==============================] - 0s 946us/step\n",
      "77/77 [==============================] - 0s 695us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_371 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_372 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_373 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_374 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_375 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_376 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_377 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  128\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.05782\n",
      "Model:                       QuantReg   Bandwidth:                    0.004660\n",
      "Method:                 Least Squares   Sparsity:                       0.1696\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:03   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.006      1.650      0.099      -0.002       0.021\n",
      "three_month_yield_change      0.1882      0.164      1.148      0.251      -0.133       0.510\n",
      "term_spread_change           -0.1291      0.142     -0.909      0.363      -0.408       0.149\n",
      "TED_spread                   -0.5914      0.661     -0.895      0.371      -1.888       0.705\n",
      "credit_spread_change          0.1624      0.212      0.765      0.444      -0.254       0.579\n",
      "market_return                -0.0297      0.091     -0.326      0.745      -0.208       0.149\n",
      "real_estate_excess_return    -0.0148      0.091     -0.162      0.871      -0.193       0.164\n",
      "equity_volatility             1.7730      0.182      9.750      0.000       1.416       2.130\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1490\n",
      "Model:                       QuantReg   Bandwidth:                    0.007677\n",
      "Method:                 Least Squares   Sparsity:                        1.067\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:03   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0199      0.018      1.108      0.268      -0.015       0.055\n",
      "three_month_yield_change     -0.1563      0.492     -0.318      0.751      -1.121       0.809\n",
      "term_spread_change           -0.7914      0.400     -1.980      0.048      -1.575      -0.007\n",
      "TED_spread                   -1.0598      2.079     -0.510      0.610      -5.136       3.017\n",
      "credit_spread_change          0.9397      0.679      1.384      0.166      -0.392       2.271\n",
      "market_return                 0.0743      0.380      0.196      0.845      -0.671       0.819\n",
      "real_estate_excess_return    -0.1314      0.306     -0.429      0.668      -0.732       0.469\n",
      "equity_volatility             2.4383      0.635      3.837      0.000       1.192       3.684\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.2478\n",
      "Model:                       QuantReg   Bandwidth:                    0.002497\n",
      "Method:                 Least Squares   Sparsity:                       0.1035\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:03   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.004      1.814      0.070      -0.001       0.013\n",
      "three_month_yield_change      0.1027      0.095      1.078      0.281      -0.084       0.290\n",
      "term_spread_change            0.0166      0.089      0.188      0.851      -0.157       0.190\n",
      "TED_spread                   -0.9283      0.364     -2.550      0.011      -1.642      -0.214\n",
      "credit_spread_change          0.0257      0.131      0.196      0.845      -0.232       0.283\n",
      "market_return                 0.0004      0.056      0.008      0.994      -0.110       0.111\n",
      "real_estate_excess_return     0.0164      0.061      0.269      0.788      -0.103       0.136\n",
      "equity_volatility             0.9518      0.104      9.134      0.000       0.747       1.156\n",
      "institution                   0.3064      0.048      6.335      0.000       0.212       0.401\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3609\n",
      "Model:                       QuantReg   Bandwidth:                    0.004096\n",
      "Method:                 Least Squares   Sparsity:                       0.5971\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:03   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0108      0.009      1.247      0.213      -0.006       0.028\n",
      "three_month_yield_change      0.1849      0.237      0.779      0.436      -0.280       0.650\n",
      "term_spread_change           -0.0298      0.287     -0.104      0.917      -0.592       0.533\n",
      "TED_spread                   -0.6630      0.996     -0.666      0.506      -2.617       1.291\n",
      "credit_spread_change          0.1017      0.371      0.275      0.784      -0.625       0.828\n",
      "market_return                -0.0752      0.226     -0.332      0.740      -0.518       0.368\n",
      "real_estate_excess_return    -0.2751      0.232     -1.185      0.236      -0.730       0.180\n",
      "equity_volatility             1.6975      0.397      4.275      0.000       0.919       2.476\n",
      "institution                   0.3338      0.211      1.585      0.113      -0.079       0.747\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 46.7920 - val_loss: 43.2627\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 45.9866 - val_loss: 42.4933\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 44.8383 - val_loss: 41.7546\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 43.9097 - val_loss: 40.8028\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 42.4185 - val_loss: 39.7371\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 41.4150 - val_loss: 38.7810\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 40.2587 - val_loss: 37.8836\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.8973 - val_loss: 36.9874\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.8032 - val_loss: 36.1283\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 36.6751 - val_loss: 35.3074\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.4664 - val_loss: 34.4987\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.3512 - val_loss: 33.6947\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.5786 - val_loss: 32.9599\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.6556 - val_loss: 32.2876\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.8807 - val_loss: 31.6420\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.2309 - val_loss: 31.0256\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.5678 - val_loss: 30.4806\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.9768 - val_loss: 29.9409\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.4344 - val_loss: 29.4777\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.9734 - val_loss: 29.1161\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.0993 - val_loss: 28.7695\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9085 - val_loss: 28.4464\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.8443 - val_loss: 28.1498\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.6144 - val_loss: 27.8791\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.5088 - val_loss: 27.6204\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.4529 - val_loss: 27.3675\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1369 - val_loss: 27.1350\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0939 - val_loss: 26.9303\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0168 - val_loss: 26.7590\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.9705 - val_loss: 26.6110\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.8636 - val_loss: 26.4878\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.8524 - val_loss: 26.3767\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.7303 - val_loss: 26.2713\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5765 - val_loss: 26.1778\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.7243 - val_loss: 26.0941\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5971 - val_loss: 26.0290\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3046 - val_loss: 25.9666\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.6397 - val_loss: 25.9149\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.6185 - val_loss: 25.8711\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5973 - val_loss: 25.8327\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5513 - val_loss: 25.8019\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4461 - val_loss: 25.7745\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5342 - val_loss: 25.7497\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5150 - val_loss: 25.7280\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4237 - val_loss: 25.7087\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4081 - val_loss: 25.6908\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0730 - val_loss: 25.6741\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4007 - val_loss: 25.6597\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4158 - val_loss: 25.6467\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4347 - val_loss: 25.6348\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4089 - val_loss: 25.6235\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3910 - val_loss: 25.6127\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3529 - val_loss: 25.6024\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3916 - val_loss: 25.5923\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3264 - val_loss: 25.5827\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2865 - val_loss: 25.5730\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3148 - val_loss: 25.5635\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3457 - val_loss: 25.5540\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3048 - val_loss: 25.5445\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3154 - val_loss: 25.5350\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3094 - val_loss: 25.5255\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3080 - val_loss: 25.5159\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2597 - val_loss: 25.5063\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2333 - val_loss: 25.4966\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2325 - val_loss: 25.4869\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2629 - val_loss: 25.4772\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2453 - val_loss: 25.4674\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2257 - val_loss: 25.4575\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1998 - val_loss: 25.4477\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2072 - val_loss: 25.4378\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1985 - val_loss: 25.4278\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1995 - val_loss: 25.4177\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1846 - val_loss: 25.4076\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1009 - val_loss: 25.3975\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1045 - val_loss: 25.3874\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1537 - val_loss: 25.3773\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9785 - val_loss: 25.3671\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1335 - val_loss: 25.3569\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0959 - val_loss: 25.3466\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1161 - val_loss: 25.3363\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1072 - val_loss: 25.3259\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9539 - val_loss: 25.3154\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9769 - val_loss: 25.3050\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0658 - val_loss: 25.2945\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0258 - val_loss: 25.2839\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0500 - val_loss: 25.2733\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7903 - val_loss: 25.2627\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0295 - val_loss: 25.2520\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0145 - val_loss: 25.2413\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9532 - val_loss: 25.2305\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9703 - val_loss: 25.2197\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9043 - val_loss: 25.2089\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9375 - val_loss: 25.1980\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9417 - val_loss: 25.1871\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9464 - val_loss: 25.1761\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8159 - val_loss: 25.1651\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9034 - val_loss: 25.1541\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8455 - val_loss: 25.1430\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7568 - val_loss: 25.1318\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8994 - val_loss: 25.1207\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 728us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_378 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_379 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_380 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_381 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_382 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_383 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_384 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                119\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.0322 - val_loss: 23.0786\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1606 - val_loss: 22.4951\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5581 - val_loss: 21.9043\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9365 - val_loss: 21.3596\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2492 - val_loss: 20.8229\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7038 - val_loss: 20.4181\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2317 - val_loss: 20.1295\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8680 - val_loss: 19.9214\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4383 - val_loss: 19.7791\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3389 - val_loss: 19.6531\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0479 - val_loss: 19.5366\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0657 - val_loss: 19.4342\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9391 - val_loss: 19.3463\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8518 - val_loss: 19.2738\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7282 - val_loss: 19.2146\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5928 - val_loss: 19.1665\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7096 - val_loss: 19.1289\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6241 - val_loss: 19.0985\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6068 - val_loss: 19.0705\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6022 - val_loss: 19.0439\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5528 - val_loss: 19.0190\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5440 - val_loss: 18.9967\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5198 - val_loss: 18.9761\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4172 - val_loss: 18.9573\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5273 - val_loss: 18.9379\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5101 - val_loss: 18.9207\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4486 - val_loss: 18.9063\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4833 - val_loss: 18.8904\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3424 - val_loss: 18.8774\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4620 - val_loss: 18.8628\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4589 - val_loss: 18.8485\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3719 - val_loss: 18.8368\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2769 - val_loss: 18.8236\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4321 - val_loss: 18.8114\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4104 - val_loss: 18.8000\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2822 - val_loss: 18.7894\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3592 - val_loss: 18.7785\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3953 - val_loss: 18.7667\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3368 - val_loss: 18.7559\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3539 - val_loss: 18.7453\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3665 - val_loss: 18.7343\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3527 - val_loss: 18.7228\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3143 - val_loss: 18.7129\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2983 - val_loss: 18.7031\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3316 - val_loss: 18.6920\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3195 - val_loss: 18.6817\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3025 - val_loss: 18.6712\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2736 - val_loss: 18.6616\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2894 - val_loss: 18.6516\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2628 - val_loss: 18.6407\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2714 - val_loss: 18.6302\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2499 - val_loss: 18.6201\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2355 - val_loss: 18.6098\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2220 - val_loss: 18.5994\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1985 - val_loss: 18.5895\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2241 - val_loss: 18.5780\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2116 - val_loss: 18.5680\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1745 - val_loss: 18.5583\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1701 - val_loss: 18.5480\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1461 - val_loss: 18.5376\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1771 - val_loss: 18.5274\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9813 - val_loss: 18.5179\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1310 - val_loss: 18.5085\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1283 - val_loss: 18.4982\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0364 - val_loss: 18.4889\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1058 - val_loss: 18.4779\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1184 - val_loss: 18.4668\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1080 - val_loss: 18.4554\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0765 - val_loss: 18.4445\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0270 - val_loss: 18.4342\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0741 - val_loss: 18.4238\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0572 - val_loss: 18.4122\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0590 - val_loss: 18.4013\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0390 - val_loss: 18.3908\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0183 - val_loss: 18.3787\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9901 - val_loss: 18.3684\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0030 - val_loss: 18.3574\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9673 - val_loss: 18.3459\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9544 - val_loss: 18.3348\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9526 - val_loss: 18.3233\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9633 - val_loss: 18.3119\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9396 - val_loss: 18.3036\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9398 - val_loss: 18.2925\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9184 - val_loss: 18.2810\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9176 - val_loss: 18.2704\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8451 - val_loss: 18.2598\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8980 - val_loss: 18.2480\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17.8618 - val_loss: 18.2362\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8299 - val_loss: 18.2250\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8559 - val_loss: 18.2134\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8401 - val_loss: 18.2018\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8434 - val_loss: 18.1899\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8236 - val_loss: 18.1791\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8222 - val_loss: 18.1676\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7390 - val_loss: 18.1559\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7736 - val_loss: 18.1450\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7167 - val_loss: 18.1336\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7652 - val_loss: 18.1220\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7585 - val_loss: 18.1104\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7123 - val_loss: 18.0984\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 839us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_385 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_386 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_387 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_388 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_389 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_390 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_391 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1400\n",
      "Model:                       QuantReg   Bandwidth:                    0.006988\n",
      "Method:                 Least Squares   Sparsity:                       0.2729\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:25   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0343      0.010      3.534      0.000       0.015       0.053\n",
      "three_month_yield_change     -0.3876      0.254     -1.528      0.127      -0.885       0.110\n",
      "term_spread_change           -0.7536      0.247     -3.056      0.002      -1.237      -0.270\n",
      "TED_spread                   -1.4252      0.940     -1.516      0.130      -3.269       0.418\n",
      "credit_spread_change         -0.1777      0.347     -0.513      0.608      -0.857       0.502\n",
      "market_return                 0.0131      0.155      0.085      0.933      -0.291       0.318\n",
      "real_estate_excess_return     0.2637      0.180      1.464      0.143      -0.090       0.617\n",
      "equity_volatility             2.9296      0.256     11.426      0.000       2.427       3.432\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2847\n",
      "Model:                       QuantReg   Bandwidth:                     0.01207\n",
      "Method:                 Least Squares   Sparsity:                        1.214\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:25   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.1113      0.016      7.068      0.000       0.080       0.142\n",
      "three_month_yield_change     -2.2245      0.531     -4.190      0.000      -3.266      -1.183\n",
      "term_spread_change           -2.3767      0.549     -4.329      0.000      -3.453      -1.300\n",
      "TED_spread                    1.0455      2.026      0.516      0.606      -2.928       5.019\n",
      "credit_spread_change         -1.9576      0.582     -3.366      0.001      -3.098      -0.817\n",
      "market_return                -0.1619      0.460     -0.352      0.725      -1.063       0.740\n",
      "real_estate_excess_return    -0.0095      0.370     -0.026      0.980      -0.736       0.717\n",
      "equity_volatility             6.4285      0.740      8.683      0.000       4.977       7.880\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4407\n",
      "Model:                       QuantReg   Bandwidth:                    0.001900\n",
      "Method:                 Least Squares   Sparsity:                      0.08209\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:25   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0131      0.003      4.547      0.000       0.007       0.019\n",
      "three_month_yield_change     -0.1471      0.086     -1.712      0.087      -0.316       0.021\n",
      "term_spread_change           -0.1750      0.076     -2.290      0.022      -0.325      -0.025\n",
      "TED_spread                   -0.3075      0.287     -1.073      0.283      -0.869       0.254\n",
      "credit_spread_change         -0.1622      0.099     -1.631      0.103      -0.357       0.033\n",
      "market_return                -0.0628      0.038     -1.648      0.100      -0.138       0.012\n",
      "real_estate_excess_return    -0.0373      0.053     -0.706      0.480      -0.141       0.066\n",
      "equity_volatility             0.7145      0.072      9.941      0.000       0.574       0.855\n",
      "institution                   0.3063      0.025     12.348      0.000       0.258       0.355\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5280\n",
      "Model:                       QuantReg   Bandwidth:                    0.002917\n",
      "Method:                 Least Squares   Sparsity:                       0.2923\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:25   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0206      0.004      4.843      0.000       0.012       0.029\n",
      "three_month_yield_change     -0.3820      0.156     -2.445      0.015      -0.688      -0.076\n",
      "term_spread_change           -0.4054      0.155     -2.623      0.009      -0.709      -0.102\n",
      "TED_spread                    0.0292      0.595      0.049      0.961      -1.137       1.195\n",
      "credit_spread_change         -0.0941      0.146     -0.645      0.519      -0.380       0.192\n",
      "market_return                -0.1843      0.100     -1.851      0.064      -0.380       0.011\n",
      "real_estate_excess_return    -0.0393      0.099     -0.398      0.691      -0.233       0.154\n",
      "equity_volatility             0.8847      0.167      5.286      0.000       0.557       1.213\n",
      "institution                   0.3232      0.064      5.047      0.000       0.198       0.449\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 32.0157 - val_loss: 29.7608\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.9157 - val_loss: 28.8752\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.8844 - val_loss: 28.0221\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.9426 - val_loss: 27.3213\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.1113 - val_loss: 26.7383\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.3397 - val_loss: 26.2215\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7006 - val_loss: 25.7479\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1626 - val_loss: 25.3146\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5467 - val_loss: 24.8962\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.1631 - val_loss: 24.4880\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6695 - val_loss: 24.0924\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2602 - val_loss: 23.7098\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4960 - val_loss: 23.3446\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5062 - val_loss: 22.9868\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1836 - val_loss: 22.6543\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9300 - val_loss: 22.3423\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5697 - val_loss: 22.0541\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.4400 - val_loss: 21.7922\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2960 - val_loss: 21.5644\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1311 - val_loss: 21.3656\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9224 - val_loss: 21.1909\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8727 - val_loss: 21.0338\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7354 - val_loss: 20.8938\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5883 - val_loss: 20.7677\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5658 - val_loss: 20.6516\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4724 - val_loss: 20.5533\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3814 - val_loss: 20.4648\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2307 - val_loss: 20.3855\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3024 - val_loss: 20.3115\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2455 - val_loss: 20.2472\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1846 - val_loss: 20.1918\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1319 - val_loss: 20.1401\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0761 - val_loss: 20.0930\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0095 - val_loss: 20.0503\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0467 - val_loss: 20.0084\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0247 - val_loss: 19.9671\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9887 - val_loss: 19.9319\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9798 - val_loss: 19.8994\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6897 - val_loss: 19.8699\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8943 - val_loss: 19.8419\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8667 - val_loss: 19.8150\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8843 - val_loss: 19.7884\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8073 - val_loss: 19.7633\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8450 - val_loss: 19.7402\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8233 - val_loss: 19.7181\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7993 - val_loss: 19.6973\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7566 - val_loss: 19.6778\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7806 - val_loss: 19.6596\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7446 - val_loss: 19.6430\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7789 - val_loss: 19.6259\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7366 - val_loss: 19.6094\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3682 - val_loss: 19.5946\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7465 - val_loss: 19.5796\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7159 - val_loss: 19.5656\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7183 - val_loss: 19.5515\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7190 - val_loss: 19.5377\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6395 - val_loss: 19.5252\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6766 - val_loss: 19.5131\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6628 - val_loss: 19.5011\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6142 - val_loss: 19.4889\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6569 - val_loss: 19.4776\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6469 - val_loss: 19.4660\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5226 - val_loss: 19.4546\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6140 - val_loss: 19.4434\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6176 - val_loss: 19.4316\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6096 - val_loss: 19.4201\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5993 - val_loss: 19.4093\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4340 - val_loss: 19.3985\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5688 - val_loss: 19.3877\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5727 - val_loss: 19.3765\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5458 - val_loss: 19.3655\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5455 - val_loss: 19.3545\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5326 - val_loss: 19.3436\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5150 - val_loss: 19.3332\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4916 - val_loss: 19.3227\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5046 - val_loss: 19.3121\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4074 - val_loss: 19.3018\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4015 - val_loss: 19.2913\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4790 - val_loss: 19.2805\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3994 - val_loss: 19.2700\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4370 - val_loss: 19.2596\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4214 - val_loss: 19.2488\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3794 - val_loss: 19.2381\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4108 - val_loss: 19.2275\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3883 - val_loss: 19.2169\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3968 - val_loss: 19.2060\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3707 - val_loss: 19.1953\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3832 - val_loss: 19.1846\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1449 - val_loss: 19.1735\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3423 - val_loss: 19.1627\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3010 - val_loss: 19.1517\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3450 - val_loss: 19.1408\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2036 - val_loss: 19.1297\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3057 - val_loss: 19.1186\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3023 - val_loss: 19.1074\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2077 - val_loss: 19.0969\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2500 - val_loss: 19.0861\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2476 - val_loss: 19.0749\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2626 - val_loss: 19.0639\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1683 - val_loss: 19.0529\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 719us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_392 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_393 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_394 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_395 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_396 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_397 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_398 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                119\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.0864 - val_loss: 24.7774\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2626 - val_loss: 24.0813\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3084 - val_loss: 23.1988\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3381 - val_loss: 22.3530\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3700 - val_loss: 21.6790\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6535 - val_loss: 21.1311\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0241 - val_loss: 20.7109\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6026 - val_loss: 20.3870\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2412 - val_loss: 20.1601\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9405 - val_loss: 19.9826\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6458 - val_loss: 19.8367\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4873 - val_loss: 19.7314\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2116 - val_loss: 19.6350\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1886 - val_loss: 19.5461\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0243 - val_loss: 19.4605\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9939 - val_loss: 19.3809\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8826 - val_loss: 19.3120\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8148 - val_loss: 19.2536\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7441 - val_loss: 19.1995\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7278 - val_loss: 19.1522\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6863 - val_loss: 19.1095\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6551 - val_loss: 19.0751\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5965 - val_loss: 19.0470\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5813 - val_loss: 19.0222\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5605 - val_loss: 18.9994\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5260 - val_loss: 18.9777\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4521 - val_loss: 18.9565\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4878 - val_loss: 18.9367\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4810 - val_loss: 18.9161\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2843 - val_loss: 18.8966\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4464 - val_loss: 18.8777\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4200 - val_loss: 18.8598\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3705 - val_loss: 18.8424\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3961 - val_loss: 18.8256\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3455 - val_loss: 18.8091\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3360 - val_loss: 18.7936\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3501 - val_loss: 18.7784\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3347 - val_loss: 18.7637\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2204 - val_loss: 18.7493\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3182 - val_loss: 18.7352\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3132 - val_loss: 18.7213\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2895 - val_loss: 18.7079\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2599 - val_loss: 18.6944\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2144 - val_loss: 18.6819\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2708 - val_loss: 18.6697\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2526 - val_loss: 18.6576\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2267 - val_loss: 18.6456\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2370 - val_loss: 18.6330\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2302 - val_loss: 18.6216\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2208 - val_loss: 18.6097\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1643 - val_loss: 18.5978\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1579 - val_loss: 18.5862\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2028 - val_loss: 18.5737\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0282 - val_loss: 18.5623\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1744 - val_loss: 18.5502\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1330 - val_loss: 18.5386\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1303 - val_loss: 18.5268\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1332 - val_loss: 18.5154\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1380 - val_loss: 18.5033\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0953 - val_loss: 18.4910\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1175 - val_loss: 18.4788\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1004 - val_loss: 18.4668\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0840 - val_loss: 18.4558\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0781 - val_loss: 18.4439\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0560 - val_loss: 18.4319\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0416 - val_loss: 18.4198\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.0467 - val_loss: 18.4073\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0043 - val_loss: 18.3957\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9643 - val_loss: 18.3840\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9745 - val_loss: 18.3725\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0071 - val_loss: 18.3598\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9897 - val_loss: 18.3477\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9878 - val_loss: 18.3364\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9714 - val_loss: 18.3246\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9540 - val_loss: 18.3130\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9428 - val_loss: 18.3013\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9339 - val_loss: 18.2891\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8989 - val_loss: 18.2769\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8815 - val_loss: 18.2652\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8831 - val_loss: 18.2531\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8866 - val_loss: 18.2407\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8565 - val_loss: 18.2287\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8572 - val_loss: 18.2164\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8513 - val_loss: 18.2040\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8378 - val_loss: 18.1914\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8254 - val_loss: 18.1790\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7877 - val_loss: 18.1668\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7760 - val_loss: 18.1546\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6689 - val_loss: 18.1423\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7587 - val_loss: 18.1297\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7686 - val_loss: 18.1168\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7370 - val_loss: 18.1040\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7234 - val_loss: 18.0916\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7234 - val_loss: 18.0789\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6940 - val_loss: 18.0661\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6702 - val_loss: 18.0541\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6687 - val_loss: 18.0415\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6800 - val_loss: 18.0284\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6638 - val_loss: 18.0160\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.4871 - val_loss: 18.0038\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 733us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_399 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_400 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_401 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_402 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_403 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_404 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_405 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1536\n",
      "Model:                       QuantReg   Bandwidth:                    0.004041\n",
      "Method:                 Least Squares   Sparsity:                       0.1331\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:47   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0233      0.005      5.090      0.000       0.014       0.032\n",
      "three_month_yield_change     -0.4419      0.129     -3.432      0.001      -0.694      -0.189\n",
      "term_spread_change           -0.4177      0.122     -3.423      0.001      -0.657      -0.178\n",
      "TED_spread                   -0.1014      0.500     -0.203      0.839      -1.081       0.878\n",
      "credit_spread_change         -0.3980      0.160     -2.490      0.013      -0.711      -0.085\n",
      "market_return                -0.0658      0.072     -0.913      0.361      -0.207       0.075\n",
      "real_estate_excess_return     0.0303      0.081      0.373      0.709      -0.129       0.190\n",
      "equity_volatility             1.9872      0.134     14.815      0.000       1.724       2.250\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.3591\n",
      "Model:                       QuantReg   Bandwidth:                    0.007033\n",
      "Method:                 Least Squares   Sparsity:                       0.6183\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:47   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0417      0.009      4.783      0.000       0.025       0.059\n",
      "three_month_yield_change     -0.6573      0.266     -2.475      0.013      -1.178      -0.136\n",
      "term_spread_change           -0.7721      0.305     -2.531      0.011      -1.370      -0.174\n",
      "TED_spread                   -0.4220      0.907     -0.465      0.642      -2.201       1.357\n",
      "credit_spread_change         -0.8009      0.349     -2.295      0.022      -1.485      -0.117\n",
      "market_return                -0.7998      0.182     -4.405      0.000      -1.156      -0.444\n",
      "real_estate_excess_return    -0.1368      0.230     -0.595      0.552      -0.588       0.314\n",
      "equity_volatility             4.1362      0.304     13.599      0.000       3.540       4.733\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4426\n",
      "Model:                       QuantReg   Bandwidth:                    0.001905\n",
      "Method:                 Least Squares   Sparsity:                      0.06687\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:47   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0124      0.002      5.049      0.000       0.008       0.017\n",
      "three_month_yield_change     -0.0422      0.071     -0.594      0.552      -0.181       0.097\n",
      "term_spread_change           -0.1555      0.060     -2.586      0.010      -0.273      -0.038\n",
      "TED_spread                   -1.1281      0.257     -4.396      0.000      -1.631      -0.625\n",
      "credit_spread_change         -0.0830      0.085     -0.977      0.329      -0.249       0.084\n",
      "market_return                -0.0176      0.030     -0.581      0.561      -0.077       0.042\n",
      "real_estate_excess_return    -0.0285      0.041     -0.698      0.485      -0.108       0.052\n",
      "equity_volatility             0.6781      0.069      9.817      0.000       0.543       0.814\n",
      "institution                   0.5674      0.029     19.270      0.000       0.510       0.625\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5047\n",
      "Model:                       QuantReg   Bandwidth:                    0.003483\n",
      "Method:                 Least Squares   Sparsity:                       0.2103\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:02:47   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0239      0.004      6.574      0.000       0.017       0.031\n",
      "three_month_yield_change     -0.0897      0.107     -0.835      0.404      -0.300       0.121\n",
      "term_spread_change           -0.4941      0.100     -4.931      0.000      -0.691      -0.298\n",
      "TED_spread                   -2.3592      0.410     -5.749      0.000      -3.164      -1.555\n",
      "credit_spread_change         -0.0180      0.135     -0.134      0.894      -0.282       0.246\n",
      "market_return                 0.2036      0.080      2.550      0.011       0.047       0.360\n",
      "real_estate_excess_return     0.1001      0.086      1.170      0.242      -0.068       0.268\n",
      "equity_volatility             1.0380      0.157      6.622      0.000       0.731       1.345\n",
      "institution                   0.5514      0.074      7.476      0.000       0.407       0.696\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 28.1027 - val_loss: 30.6623\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.9431 - val_loss: 29.4027\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4317 - val_loss: 27.7681\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8662 - val_loss: 26.0293\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2923 - val_loss: 24.4528\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1113 - val_loss: 23.4690\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3628 - val_loss: 22.9024\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8747 - val_loss: 22.5589\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5608 - val_loss: 22.3355\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2882 - val_loss: 22.1916\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2061 - val_loss: 22.1005\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0872 - val_loss: 22.0361\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0466 - val_loss: 21.9880\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9591 - val_loss: 21.9516\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9373 - val_loss: 21.9263\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9096 - val_loss: 21.9070\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9059 - val_loss: 21.8904\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8824 - val_loss: 21.8777\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8164 - val_loss: 21.8675\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8006 - val_loss: 21.8584\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7885 - val_loss: 21.8496\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8370 - val_loss: 21.8415\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.8025 - val_loss: 21.8340\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7871 - val_loss: 21.8269\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7836 - val_loss: 21.8201\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7996 - val_loss: 21.8133\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7266 - val_loss: 21.8063\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7928 - val_loss: 21.7991\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7718 - val_loss: 21.7920\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6788 - val_loss: 21.7847\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7579 - val_loss: 21.7773\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.6929 - val_loss: 21.7698\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7416 - val_loss: 21.7622\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7083 - val_loss: 21.7544\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7240 - val_loss: 21.7466\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6913 - val_loss: 21.7385\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6357 - val_loss: 21.7303\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6954 - val_loss: 21.7219\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6404 - val_loss: 21.7135\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6364 - val_loss: 21.7048\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6217 - val_loss: 21.6961\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6316 - val_loss: 21.6869\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6095 - val_loss: 21.6779\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4705 - val_loss: 21.6686\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6315 - val_loss: 21.6595\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6213 - val_loss: 21.6506\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6202 - val_loss: 21.6415\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5941 - val_loss: 21.6323\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5673 - val_loss: 21.6229\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5277 - val_loss: 21.6133\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5608 - val_loss: 21.6040\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5670 - val_loss: 21.5943\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5265 - val_loss: 21.5844\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5175 - val_loss: 21.5743\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5394 - val_loss: 21.5646\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4211 - val_loss: 21.5543\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4966 - val_loss: 21.5440\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4753 - val_loss: 21.5341\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4806 - val_loss: 21.5238\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4585 - val_loss: 21.5133\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3809 - val_loss: 21.5030\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4510 - val_loss: 21.4926\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4581 - val_loss: 21.4822\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4374 - val_loss: 21.4719\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4181 - val_loss: 21.4611\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4175 - val_loss: 21.4506\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3888 - val_loss: 21.4399\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3164 - val_loss: 21.4288\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3759 - val_loss: 21.4180\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3294 - val_loss: 21.4071\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3672 - val_loss: 21.3964\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3310 - val_loss: 21.3854\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3157 - val_loss: 21.3743\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3352 - val_loss: 21.3629\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3171 - val_loss: 21.3519\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2061 - val_loss: 21.3399\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2954 - val_loss: 21.3286\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2869 - val_loss: 21.3171\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1404 - val_loss: 21.3056\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2611 - val_loss: 21.2941\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.2162 - val_loss: 21.2826\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1983 - val_loss: 21.2712\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1905 - val_loss: 21.2592\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1956 - val_loss: 21.2473\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2090 - val_loss: 21.2359\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1693 - val_loss: 21.2242\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1805 - val_loss: 21.2124\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1460 - val_loss: 21.2005\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1616 - val_loss: 21.1891\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1449 - val_loss: 21.1771\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1326 - val_loss: 21.1654\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0126 - val_loss: 21.1530\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1112 - val_loss: 21.1410\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0940 - val_loss: 21.1289\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0940 - val_loss: 21.1168\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0196 - val_loss: 21.1041\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0467 - val_loss: 21.0918\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0461 - val_loss: 21.0796\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0398 - val_loss: 21.0673\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0225 - val_loss: 21.0551\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 630us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_406 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_407 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_408 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_409 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_410 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_411 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_412 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 25.4495 - val_loss: 24.2790\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7513 - val_loss: 23.6843\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9746 - val_loss: 23.1752\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3158 - val_loss: 22.7128\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8460 - val_loss: 22.2628\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4420 - val_loss: 21.8943\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9697 - val_loss: 21.5633\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5686 - val_loss: 21.2642\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2972 - val_loss: 21.0043\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9674 - val_loss: 20.7691\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7834 - val_loss: 20.5669\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5473 - val_loss: 20.3982\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2782 - val_loss: 20.2595\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1385 - val_loss: 20.1383\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8668 - val_loss: 20.0296\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8133 - val_loss: 19.9350\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6599 - val_loss: 19.8551\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5049 - val_loss: 19.7842\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4399 - val_loss: 19.7179\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3312 - val_loss: 19.6546\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2142 - val_loss: 19.5928\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1809 - val_loss: 19.5304\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0907 - val_loss: 19.4693\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0331 - val_loss: 19.4121\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9409 - val_loss: 19.3604\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8768 - val_loss: 19.3108\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8224 - val_loss: 19.2651\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7261 - val_loss: 19.2207\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7568 - val_loss: 19.1790\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7140 - val_loss: 19.1415\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6560 - val_loss: 19.1079\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6516 - val_loss: 19.0781\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6246 - val_loss: 19.0516\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5852 - val_loss: 19.0271\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5696 - val_loss: 19.0035\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4694 - val_loss: 18.9823\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4459 - val_loss: 18.9613\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5073 - val_loss: 18.9408\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4817 - val_loss: 18.9202\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4061 - val_loss: 18.9017\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4071 - val_loss: 18.8833\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4371 - val_loss: 18.8659\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2148 - val_loss: 18.8493\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4117 - val_loss: 18.8328\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3445 - val_loss: 18.8171\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3438 - val_loss: 18.8021\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3630 - val_loss: 18.7872\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3663 - val_loss: 18.7722\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3168 - val_loss: 18.7574\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3145 - val_loss: 18.7430\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3277 - val_loss: 18.7284\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3078 - val_loss: 18.7141\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2843 - val_loss: 18.6999\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2967 - val_loss: 18.6852\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2879 - val_loss: 18.6713\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2540 - val_loss: 18.6575\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2526 - val_loss: 18.6440\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2548 - val_loss: 18.6306\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1943 - val_loss: 18.6175\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2260 - val_loss: 18.6044\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2052 - val_loss: 18.5922\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2050 - val_loss: 18.5791\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1779 - val_loss: 18.5666\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0652 - val_loss: 18.5544\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1739 - val_loss: 18.5418\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1598 - val_loss: 18.5292\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1363 - val_loss: 18.5167\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1233 - val_loss: 18.5047\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1044 - val_loss: 18.4922\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1152 - val_loss: 18.4804\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1046 - val_loss: 18.4681\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0935 - val_loss: 18.4561\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0056 - val_loss: 18.4440\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0356 - val_loss: 18.4323\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0464 - val_loss: 18.4205\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0431 - val_loss: 18.4080\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0389 - val_loss: 18.3955\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0167 - val_loss: 18.3835\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0184 - val_loss: 18.3713\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0051 - val_loss: 18.3590\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9731 - val_loss: 18.3468\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9349 - val_loss: 18.3351\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9657 - val_loss: 18.3228\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9611 - val_loss: 18.3101\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9241 - val_loss: 18.2980\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9217 - val_loss: 18.2862\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9164 - val_loss: 18.2744\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9040 - val_loss: 18.2624\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8869 - val_loss: 18.2504\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8842 - val_loss: 18.2383\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8778 - val_loss: 18.2262\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7907 - val_loss: 18.2135\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8489 - val_loss: 18.2006\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8107 - val_loss: 18.1887\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8310 - val_loss: 18.1754\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8158 - val_loss: 18.1623\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8048 - val_loss: 18.1499\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7841 - val_loss: 18.1374\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7735 - val_loss: 18.1253\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7401 - val_loss: 18.1134\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 807us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_413 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_414 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_415 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_416 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_417 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_418 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_419 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.09198\n",
      "Model:                       QuantReg   Bandwidth:                    0.003351\n",
      "Method:                 Least Squares   Sparsity:                       0.1220\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:09   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0177      0.004      4.210      0.000       0.009       0.026\n",
      "three_month_yield_change     -0.0322      0.112     -0.288      0.773      -0.251       0.187\n",
      "term_spread_change            0.0041      0.105      0.039      0.969      -0.202       0.210\n",
      "TED_spread                   -0.9586      0.412     -2.327      0.020      -1.767      -0.151\n",
      "credit_spread_change         -0.3520      0.152     -2.319      0.020      -0.650      -0.054\n",
      "market_return                -0.0101      0.068     -0.148      0.883      -0.144       0.124\n",
      "real_estate_excess_return     0.1583      0.073      2.168      0.030       0.015       0.301\n",
      "equity_volatility             1.3707      0.126     10.873      0.000       1.123       1.618\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2239\n",
      "Model:                       QuantReg   Bandwidth:                    0.005442\n",
      "Method:                 Least Squares   Sparsity:                       0.5975\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:09   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0373      0.008      4.428      0.000       0.021       0.054\n",
      "three_month_yield_change     -0.0176      0.254     -0.069      0.945      -0.515       0.480\n",
      "term_spread_change           -0.4696      0.307     -1.528      0.127      -1.072       0.133\n",
      "TED_spread                   -1.2682      1.089     -1.165      0.244      -3.403       0.867\n",
      "credit_spread_change         -0.6035      0.270     -2.232      0.026      -1.134      -0.073\n",
      "market_return                 0.0513      0.236      0.217      0.828      -0.412       0.515\n",
      "real_estate_excess_return    -0.0706      0.166     -0.427      0.670      -0.395       0.254\n",
      "equity_volatility             2.3235      0.449      5.173      0.000       1.443       3.204\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4374\n",
      "Model:                       QuantReg   Bandwidth:                    0.001965\n",
      "Method:                 Least Squares   Sparsity:                      0.07305\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:09   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0080      0.003      2.998      0.003       0.003       0.013\n",
      "three_month_yield_change      0.0202      0.074      0.271      0.786      -0.126       0.166\n",
      "term_spread_change           -0.1333      0.062     -2.135      0.033      -0.256      -0.011\n",
      "TED_spread                   -0.6063      0.265     -2.288      0.022      -1.126      -0.087\n",
      "credit_spread_change         -0.0216      0.093     -0.231      0.817      -0.205       0.162\n",
      "market_return                -0.0683      0.037     -1.831      0.067      -0.141       0.005\n",
      "real_estate_excess_return    -0.0289      0.042     -0.685      0.494      -0.112       0.054\n",
      "equity_volatility             0.8285      0.071     11.658      0.000       0.689       0.968\n",
      "institution                   0.6505      0.044     14.821      0.000       0.564       0.737\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5391\n",
      "Model:                       QuantReg   Bandwidth:                    0.003295\n",
      "Method:                 Least Squares   Sparsity:                       0.3856\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:09   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0253      0.008      3.331      0.001       0.010       0.040\n",
      "three_month_yield_change     -0.1190      0.190     -0.627      0.531      -0.491       0.253\n",
      "term_spread_change           -0.3228      0.186     -1.739      0.082      -0.687       0.041\n",
      "TED_spread                   -0.4262      0.594     -0.717      0.473      -1.592       0.740\n",
      "credit_spread_change         -0.4097      0.267     -1.535      0.125      -0.933       0.114\n",
      "market_return                -0.1184      0.143     -0.829      0.407      -0.399       0.162\n",
      "real_estate_excess_return     0.0143      0.112      0.127      0.899      -0.206       0.235\n",
      "equity_volatility             1.3775      0.230      5.988      0.000       0.926       1.829\n",
      "institution                   0.6266      0.182      3.436      0.001       0.269       0.984\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 31\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 55.6714 - val_loss: 62.3250\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 54.6339 - val_loss: 61.4070\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 53.7836 - val_loss: 60.0968\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 52.3417 - val_loss: 58.8492\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 51.2029 - val_loss: 57.5704\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 49.9916 - val_loss: 56.2421\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 48.7119 - val_loss: 54.8266\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 47.3595 - val_loss: 53.2091\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 45.8156 - val_loss: 51.3188\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 43.5867 - val_loss: 48.6952\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 41.2946 - val_loss: 45.9169\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 38.4972 - val_loss: 43.2855\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.7522 - val_loss: 40.6594\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.6099 - val_loss: 38.2727\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.6588 - val_loss: 36.2939\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.1500 - val_loss: 34.7793\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.9604 - val_loss: 33.6592\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.9542 - val_loss: 32.7472\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.5928 - val_loss: 32.0559\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0460 - val_loss: 31.5107\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.9628 - val_loss: 31.0809\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7035 - val_loss: 30.7253\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.6747 - val_loss: 30.4401\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.5752 - val_loss: 30.2461\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4793 - val_loss: 30.0978\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5185 - val_loss: 29.9846\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.4461 - val_loss: 29.9040\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4931 - val_loss: 29.8409\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3813 - val_loss: 29.7925\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3088 - val_loss: 29.7527\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3832 - val_loss: 29.7137\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2703 - val_loss: 29.6875\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3725 - val_loss: 29.6593\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3837 - val_loss: 29.6370\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2722 - val_loss: 29.6181\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2996 - val_loss: 29.6012\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3438 - val_loss: 29.5849\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3428 - val_loss: 29.5680\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.3199 - val_loss: 29.5514\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1611 - val_loss: 29.5372\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1911 - val_loss: 29.5238\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2983 - val_loss: 29.5115\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2831 - val_loss: 29.4984\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2703 - val_loss: 29.4870\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2731 - val_loss: 29.4743\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2647 - val_loss: 29.4618\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2659 - val_loss: 29.4500\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.2373 - val_loss: 29.4386\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2340 - val_loss: 29.4264\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2384 - val_loss: 29.4149\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9424 - val_loss: 29.4043\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1960 - val_loss: 29.3924\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1708 - val_loss: 29.3808\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1405 - val_loss: 29.3695\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1395 - val_loss: 29.3583\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1625 - val_loss: 29.3468\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1291 - val_loss: 29.3349\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1474 - val_loss: 29.3237\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.1226 - val_loss: 29.3124\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0988 - val_loss: 29.3014\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0688 - val_loss: 29.2900\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1192 - val_loss: 29.2783\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0737 - val_loss: 29.2674\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0605 - val_loss: 29.2556\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0752 - val_loss: 29.2437\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0847 - val_loss: 29.2318\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.0496 - val_loss: 29.2196\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9269 - val_loss: 29.2078\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9915 - val_loss: 29.1958\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9425 - val_loss: 29.1841\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.0236 - val_loss: 29.1725\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9850 - val_loss: 29.1609\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9682 - val_loss: 29.1488\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9539 - val_loss: 29.1370\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7828 - val_loss: 29.1261\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8221 - val_loss: 29.1141\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8885 - val_loss: 29.1022\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8094 - val_loss: 29.0900\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8081 - val_loss: 29.0783\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8975 - val_loss: 29.0656\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8778 - val_loss: 29.0540\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.8731 - val_loss: 29.0418\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8323 - val_loss: 29.0296\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6813 - val_loss: 29.0177\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8090 - val_loss: 29.0053\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6194 - val_loss: 28.9930\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8175 - val_loss: 28.9805\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8041 - val_loss: 28.9677\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7873 - val_loss: 28.9547\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6981 - val_loss: 28.9421\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7147 - val_loss: 28.9295\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.7270 - val_loss: 28.9166\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6738 - val_loss: 28.9040\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7317 - val_loss: 28.8908\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7095 - val_loss: 28.8780\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6037 - val_loss: 28.8652\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6801 - val_loss: 28.8525\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6593 - val_loss: 28.8395\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5678 - val_loss: 28.8269\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.6342 - val_loss: 28.8140\n",
      "4/4 [==============================] - 0s 830us/step\n",
      "77/77 [==============================] - 0s 682us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_420 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_421 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_422 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_423 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_424 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_425 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_426 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "0             1                124\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 7ms/step - loss: 26.6686 - val_loss: 25.3362\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9827 - val_loss: 24.8483\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3470 - val_loss: 24.2323\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6750 - val_loss: 23.6558\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9830 - val_loss: 23.1738\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3754 - val_loss: 22.5150\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6262 - val_loss: 21.9570\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8625 - val_loss: 21.4811\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4085 - val_loss: 21.0613\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0135 - val_loss: 20.7153\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6202 - val_loss: 20.4192\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2750 - val_loss: 20.1908\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0265 - val_loss: 20.0173\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7724 - val_loss: 19.8562\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4412 - val_loss: 19.7310\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3789 - val_loss: 19.6300\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1829 - val_loss: 19.5372\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1010 - val_loss: 19.4532\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9762 - val_loss: 19.3732\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9086 - val_loss: 19.2952\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8113 - val_loss: 19.2277\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6665 - val_loss: 19.1703\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6870 - val_loss: 19.1167\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5955 - val_loss: 19.0684\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5700 - val_loss: 19.0224\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5490 - val_loss: 18.9819\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5115 - val_loss: 18.9498\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4402 - val_loss: 18.9245\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4303 - val_loss: 18.9006\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3672 - val_loss: 18.8779\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3994 - val_loss: 18.8559\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3839 - val_loss: 18.8366\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3014 - val_loss: 18.8174\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3449 - val_loss: 18.7990\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3263 - val_loss: 18.7802\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2715 - val_loss: 18.7626\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2769 - val_loss: 18.7454\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2555 - val_loss: 18.7292\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2724 - val_loss: 18.7129\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2102 - val_loss: 18.6967\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2467 - val_loss: 18.6811\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2120 - val_loss: 18.6662\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1896 - val_loss: 18.6514\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2109 - val_loss: 18.6367\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1743 - val_loss: 18.6222\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1879 - val_loss: 18.6080\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1251 - val_loss: 18.5945\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1517 - val_loss: 18.5814\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1162 - val_loss: 18.5680\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1243 - val_loss: 18.5549\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1266 - val_loss: 18.5426\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0800 - val_loss: 18.5297\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0926 - val_loss: 18.5170\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1060 - val_loss: 18.5049\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0849 - val_loss: 18.4925\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0712 - val_loss: 18.4798\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0708 - val_loss: 18.4674\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9931 - val_loss: 18.4553\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9898 - val_loss: 18.4438\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0368 - val_loss: 18.4312\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0177 - val_loss: 18.4194\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9928 - val_loss: 18.4076\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9772 - val_loss: 18.3952\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9582 - val_loss: 18.3828\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9849 - val_loss: 18.3702\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9641 - val_loss: 18.3583\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9173 - val_loss: 18.3459\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9520 - val_loss: 18.3330\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8957 - val_loss: 18.3208\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9273 - val_loss: 18.3088\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9070 - val_loss: 18.2963\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8966 - val_loss: 18.2839\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8677 - val_loss: 18.2711\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8485 - val_loss: 18.2585\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8704 - val_loss: 18.2462\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8273 - val_loss: 18.2338\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8427 - val_loss: 18.2217\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7550 - val_loss: 18.2099\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8215 - val_loss: 18.1980\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7925 - val_loss: 18.1855\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8045 - val_loss: 18.1734\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7890 - val_loss: 18.1614\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7714 - val_loss: 18.1495\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7717 - val_loss: 18.1370\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7560 - val_loss: 18.1244\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7463 - val_loss: 18.1125\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7333 - val_loss: 18.1002\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6989 - val_loss: 18.0887\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6980 - val_loss: 18.0765\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6850 - val_loss: 18.0645\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6789 - val_loss: 18.0520\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6513 - val_loss: 18.0394\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6550 - val_loss: 18.0263\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6370 - val_loss: 18.0136\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6261 - val_loss: 18.0016\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5802 - val_loss: 17.9889\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5752 - val_loss: 17.9766\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5875 - val_loss: 17.9638\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5870 - val_loss: 17.9513\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.5543 - val_loss: 17.9393\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 707us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_427 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_428 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_429 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_430 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_431 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_432 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_433 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.04343\n",
      "Model:                       QuantReg   Bandwidth:                    0.007674\n",
      "Method:                 Least Squares   Sparsity:                       0.3232\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:30   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0310      0.011      2.768      0.006       0.009       0.053\n",
      "three_month_yield_change     -0.2546      0.301     -0.846      0.397      -0.845       0.335\n",
      "term_spread_change            0.0621      0.262      0.237      0.813      -0.452       0.576\n",
      "TED_spread                   -0.6051      1.204     -0.503      0.615      -2.965       1.755\n",
      "credit_spread_change         -0.0831      0.407     -0.204      0.838      -0.881       0.715\n",
      "market_return                -0.1531      0.171     -0.893      0.372      -0.489       0.183\n",
      "real_estate_excess_return    -0.2115      0.178     -1.187      0.235      -0.561       0.138\n",
      "equity_volatility             2.1458      0.338      6.357      0.000       1.484       2.808\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1424\n",
      "Model:                       QuantReg   Bandwidth:                     0.01136\n",
      "Method:                 Least Squares   Sparsity:                        1.323\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:30   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.1061      0.025      4.240      0.000       0.057       0.155\n",
      "three_month_yield_change     -0.9975      0.615     -1.623      0.105      -2.203       0.208\n",
      "term_spread_change           -0.5729      0.523     -1.096      0.273      -1.598       0.452\n",
      "TED_spread                   -2.1422      2.193     -0.977      0.329      -6.443       2.159\n",
      "credit_spread_change         -1.3194      0.889     -1.484      0.138      -3.063       0.424\n",
      "market_return                 0.1767      0.333      0.530      0.596      -0.477       0.830\n",
      "real_estate_excess_return    -0.5025      0.420     -1.195      0.232      -1.327       0.322\n",
      "equity_volatility             2.5684      0.569      4.511      0.000       1.452       3.685\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.1944\n",
      "Model:                       QuantReg   Bandwidth:                    0.002634\n",
      "Method:                 Least Squares   Sparsity:                       0.1135\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:30   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.004      1.633      0.103      -0.001       0.014\n",
      "three_month_yield_change      0.1222      0.104      1.177      0.239      -0.081       0.326\n",
      "term_spread_change           -0.0376      0.099     -0.381      0.703      -0.231       0.156\n",
      "TED_spread                   -1.7742      0.412     -4.303      0.000      -2.583      -0.966\n",
      "credit_spread_change          0.0835      0.142      0.587      0.557      -0.195       0.362\n",
      "market_return                -0.0150      0.062     -0.239      0.811      -0.137       0.108\n",
      "real_estate_excess_return    -0.0200      0.068     -0.294      0.768      -0.153       0.113\n",
      "equity_volatility             1.2757      0.113     11.287      0.000       1.054       1.497\n",
      "institution                   0.1123      0.033      3.400      0.001       0.048       0.177\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3216\n",
      "Model:                       QuantReg   Bandwidth:                    0.004769\n",
      "Method:                 Least Squares   Sparsity:                       0.5293\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:30   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0168      0.008      2.034      0.042       0.001       0.033\n",
      "three_month_yield_change      0.1691      0.204      0.828      0.408      -0.232       0.570\n",
      "term_spread_change           -0.4176      0.243     -1.715      0.086      -0.895       0.060\n",
      "TED_spread                   -2.0796      0.802     -2.593      0.010      -3.652      -0.507\n",
      "credit_spread_change          0.0590      0.325      0.182      0.856      -0.579       0.697\n",
      "market_return                -0.0589      0.183     -0.321      0.748      -0.418       0.300\n",
      "real_estate_excess_return    -0.2181      0.155     -1.406      0.160      -0.522       0.086\n",
      "equity_volatility             2.4299      0.314      7.741      0.000       1.814       3.045\n",
      "institution                   0.1159      0.109      1.064      0.288      -0.098       0.330\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 6ms/step - loss: 30.0765 - val_loss: 26.2612\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.9970 - val_loss: 25.3503\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.9574 - val_loss: 24.4553\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.8750 - val_loss: 23.6603\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9571 - val_loss: 22.8845\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.9051 - val_loss: 22.0582\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8689 - val_loss: 21.3470\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0490 - val_loss: 20.7999\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.3557 - val_loss: 20.3645\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7937 - val_loss: 19.9806\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3815 - val_loss: 19.6743\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8961 - val_loss: 19.4087\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6087 - val_loss: 19.2338\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4128 - val_loss: 19.0893\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2369 - val_loss: 18.9676\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0462 - val_loss: 18.8947\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9568 - val_loss: 18.8567\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8217 - val_loss: 18.8319\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7854 - val_loss: 18.8237\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7606 - val_loss: 18.8189\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.6686 - val_loss: 18.8178\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6636 - val_loss: 18.8215\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.6290 - val_loss: 18.8282\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5793 - val_loss: 18.8358\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.5780 - val_loss: 18.8421\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5627 - val_loss: 18.8460\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.5511 - val_loss: 18.8472\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5342 - val_loss: 18.8475\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.5051 - val_loss: 18.8470\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 19.5136 - val_loss: 18.8457\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4707 - val_loss: 18.8430\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4653 - val_loss: 18.8401\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4877 - val_loss: 18.8384\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4523 - val_loss: 18.8348\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4645 - val_loss: 18.8324\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4375 - val_loss: 18.8282\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4042 - val_loss: 18.8238\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3940 - val_loss: 18.8190\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3682 - val_loss: 18.8140\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3225 - val_loss: 18.8091\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.4107 - val_loss: 18.8047\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3970 - val_loss: 18.7998\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3106 - val_loss: 18.7946\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3820 - val_loss: 18.7895\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3706 - val_loss: 18.7837\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2623 - val_loss: 18.7776\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3511 - val_loss: 18.7723\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3400 - val_loss: 18.7673\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3252 - val_loss: 18.7611\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.3282 - val_loss: 18.7554\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3018 - val_loss: 18.7487\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2990 - val_loss: 18.7424\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2068 - val_loss: 18.7358\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1793 - val_loss: 18.7285\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1555 - val_loss: 18.7213\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2530 - val_loss: 18.7144\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.2544 - val_loss: 18.7066\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1672 - val_loss: 18.6983\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2141 - val_loss: 18.6900\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.1944 - val_loss: 18.6803\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0113 - val_loss: 18.6708\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1501 - val_loss: 18.6616\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1834 - val_loss: 18.6523\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0871 - val_loss: 18.6429\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1772 - val_loss: 18.6345\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1587 - val_loss: 18.6250\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1362 - val_loss: 18.6151\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0925 - val_loss: 18.6053\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0821 - val_loss: 18.5955\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1175 - val_loss: 18.5851\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1080 - val_loss: 18.5763\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0475 - val_loss: 18.5657\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0451 - val_loss: 18.5536\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0768 - val_loss: 18.5435\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0381 - val_loss: 18.5329\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0168 - val_loss: 18.5225\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9023 - val_loss: 18.5116\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0322 - val_loss: 18.5008\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0061 - val_loss: 18.4901\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0120 - val_loss: 18.4793\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9726 - val_loss: 18.4689\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9990 - val_loss: 18.4575\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9800 - val_loss: 18.4474\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8873 - val_loss: 18.4362\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9483 - val_loss: 18.4256\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8384 - val_loss: 18.4140\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9344 - val_loss: 18.4030\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9282 - val_loss: 18.3922\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9126 - val_loss: 18.3807\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.8158 - val_loss: 18.3689\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8005 - val_loss: 18.3589\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8745 - val_loss: 18.3478\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7902 - val_loss: 18.3367\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7554 - val_loss: 18.3247\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8218 - val_loss: 18.3128\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8330 - val_loss: 18.3012\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8136 - val_loss: 18.2899\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7826 - val_loss: 18.2781\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7437 - val_loss: 18.2655\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7715 - val_loss: 18.2536\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 693us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_434 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_435 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_436 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_437 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_438 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_439 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_440 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 24.7724 - val_loss: 23.7309\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0085 - val_loss: 23.0370\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0666 - val_loss: 22.3414\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3056 - val_loss: 21.7468\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6699 - val_loss: 21.1449\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0705 - val_loss: 20.6838\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3805 - val_loss: 20.2684\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0512 - val_loss: 19.9776\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6044 - val_loss: 19.7843\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3626 - val_loss: 19.6300\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1735 - val_loss: 19.4862\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9986 - val_loss: 19.3509\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8388 - val_loss: 19.2450\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7137 - val_loss: 19.1709\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7077 - val_loss: 19.1167\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6326 - val_loss: 19.0751\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5948 - val_loss: 19.0405\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5785 - val_loss: 19.0110\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5314 - val_loss: 18.9863\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5364 - val_loss: 18.9629\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5033 - val_loss: 18.9424\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4443 - val_loss: 18.9238\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4841 - val_loss: 18.9092\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4879 - val_loss: 18.8948\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4367 - val_loss: 18.8807\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4414 - val_loss: 18.8664\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4685 - val_loss: 18.8522\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4524 - val_loss: 18.8396\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4314 - val_loss: 18.8284\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3162 - val_loss: 18.8166\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4041 - val_loss: 18.8051\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4082 - val_loss: 18.7943\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3383 - val_loss: 18.7838\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3615 - val_loss: 18.7739\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3946 - val_loss: 18.7632\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3713 - val_loss: 18.7538\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3771 - val_loss: 18.7433\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3745 - val_loss: 18.7341\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3583 - val_loss: 18.7243\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3519 - val_loss: 18.7145\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3103 - val_loss: 18.7045\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3396 - val_loss: 18.6942\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3025 - val_loss: 18.6848\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2727 - val_loss: 18.6745\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3069 - val_loss: 18.6644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2992 - val_loss: 18.6553\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2544 - val_loss: 18.6469\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2682 - val_loss: 18.6359\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2476 - val_loss: 18.6266\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2507 - val_loss: 18.6172\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2547 - val_loss: 18.6081\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1989 - val_loss: 18.5993\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1585 - val_loss: 18.5905\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1919 - val_loss: 18.5808\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2184 - val_loss: 18.5707\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2085 - val_loss: 18.5596\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1935 - val_loss: 18.5494\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1567 - val_loss: 18.5395\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1764 - val_loss: 18.5307\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1666 - val_loss: 18.5205\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1483 - val_loss: 18.5098\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1090 - val_loss: 18.4999\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0630 - val_loss: 18.4897\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1180 - val_loss: 18.4792\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1160 - val_loss: 18.4692\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0984 - val_loss: 18.4602\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0793 - val_loss: 18.4500\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0479 - val_loss: 18.4404\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0670 - val_loss: 18.4301\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0699 - val_loss: 18.4200\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0394 - val_loss: 18.4102\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0288 - val_loss: 18.3988\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0384 - val_loss: 18.3893\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9492 - val_loss: 18.3789\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0122 - val_loss: 18.3691\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0042 - val_loss: 18.3587\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9752 - val_loss: 18.3481\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9881 - val_loss: 18.3366\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9291 - val_loss: 18.3265\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9676 - val_loss: 18.3152\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9163 - val_loss: 18.3042\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9453 - val_loss: 18.2926\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9056 - val_loss: 18.2816\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8863 - val_loss: 18.2712\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8725 - val_loss: 18.2604\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8723 - val_loss: 18.2498\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8661 - val_loss: 18.2403\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8685 - val_loss: 18.2289\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8466 - val_loss: 18.2175\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8489 - val_loss: 18.2050\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8437 - val_loss: 18.1949\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8138 - val_loss: 18.1833\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8228 - val_loss: 18.1719\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8153 - val_loss: 18.1600\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7958 - val_loss: 18.1495\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7773 - val_loss: 18.1383\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7730 - val_loss: 18.1264\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7664 - val_loss: 18.1143\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7315 - val_loss: 18.1033\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7169 - val_loss: 18.0925\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 729us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_64 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_441 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_442 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_443 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_444 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_445 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_446 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_447 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.07939\n",
      "Model:                       QuantReg   Bandwidth:                    0.003642\n",
      "Method:                 Least Squares   Sparsity:                       0.1537\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:52   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0185      0.006      3.358      0.001       0.008       0.029\n",
      "three_month_yield_change      0.0608      0.140      0.435      0.664      -0.213       0.335\n",
      "term_spread_change           -0.1937      0.146     -1.325      0.185      -0.480       0.093\n",
      "TED_spread                   -1.2675      0.542     -2.340      0.019      -2.330      -0.205\n",
      "credit_spread_change         -0.1403      0.198     -0.709      0.478      -0.528       0.248\n",
      "market_return                -0.0527      0.088     -0.602      0.547      -0.224       0.119\n",
      "real_estate_excess_return    -0.0867      0.097     -0.889      0.374      -0.278       0.104\n",
      "equity_volatility             1.2552      0.178      7.058      0.000       0.906       1.604\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1877\n",
      "Model:                       QuantReg   Bandwidth:                    0.006024\n",
      "Method:                 Least Squares   Sparsity:                       0.7645\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:52   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0434      0.014      3.125      0.002       0.016       0.071\n",
      "three_month_yield_change      0.2276      0.385      0.591      0.554      -0.527       0.982\n",
      "term_spread_change           -0.7849      0.376     -2.089      0.037      -1.522      -0.048\n",
      "TED_spread                   -5.2498      1.315     -3.992      0.000      -7.829      -2.671\n",
      "credit_spread_change          0.2374      0.484      0.490      0.624      -0.712       1.187\n",
      "market_return                -0.1217      0.184     -0.660      0.509      -0.483       0.240\n",
      "real_estate_excess_return     0.2074      0.322      0.644      0.520      -0.424       0.839\n",
      "equity_volatility             1.5683      0.391      4.008      0.000       0.801       2.336\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.3453\n",
      "Model:                       QuantReg   Bandwidth:                    0.002321\n",
      "Method:                 Least Squares   Sparsity:                      0.08365\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:52   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0154      0.003      5.034      0.000       0.009       0.021\n",
      "three_month_yield_change     -0.1319      0.077     -1.709      0.088      -0.283       0.019\n",
      "term_spread_change           -0.1998      0.068     -2.927      0.003      -0.334      -0.066\n",
      "TED_spread                   -0.4950      0.299     -1.655      0.098      -1.082       0.092\n",
      "credit_spread_change         -0.1811      0.114     -1.591      0.112      -0.404       0.042\n",
      "market_return                -0.0804      0.044     -1.842      0.066      -0.166       0.005\n",
      "real_estate_excess_return    -0.1251      0.049     -2.540      0.011      -0.222      -0.029\n",
      "equity_volatility             0.8454      0.084     10.029      0.000       0.680       1.011\n",
      "institution                   0.5641      0.049     11.520      0.000       0.468       0.660\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4613\n",
      "Model:                       QuantReg   Bandwidth:                    0.004158\n",
      "Method:                 Least Squares   Sparsity:                       0.3398\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:03:52   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0192      0.005      4.136      0.000       0.010       0.028\n",
      "three_month_yield_change     -0.0340      0.123     -0.275      0.783      -0.276       0.208\n",
      "term_spread_change           -0.3195      0.137     -2.329      0.020      -0.589      -0.051\n",
      "TED_spread                   -0.7132      0.565     -1.263      0.207      -1.821       0.394\n",
      "credit_spread_change         -0.2015      0.179     -1.129      0.259      -0.552       0.149\n",
      "market_return                 0.1295      0.136      0.956      0.339      -0.136       0.395\n",
      "real_estate_excess_return     0.0105      0.104      0.100      0.920      -0.194       0.215\n",
      "equity_volatility             1.6955      0.206      8.232      0.000       1.292       2.099\n",
      "institution                   0.5586      0.143      3.902      0.000       0.278       0.839\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 42.4323 - val_loss: 40.9331\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 41.4520 - val_loss: 40.1754\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 40.5758 - val_loss: 39.4030\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.9483 - val_loss: 38.5973\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.7654 - val_loss: 37.4559\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 37.4060 - val_loss: 36.3273\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.0701 - val_loss: 35.3033\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.6423 - val_loss: 34.4200\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.6495 - val_loss: 33.5907\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.5694 - val_loss: 32.8183\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.4918 - val_loss: 32.1474\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.7048 - val_loss: 31.5053\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.8248 - val_loss: 30.9187\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.0900 - val_loss: 30.3697\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.3356 - val_loss: 29.8241\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.7929 - val_loss: 29.2825\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.3231 - val_loss: 28.7666\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.8833 - val_loss: 28.2572\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.3705 - val_loss: 27.8132\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.1632 - val_loss: 27.4481\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9239 - val_loss: 27.1324\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6680 - val_loss: 26.8521\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4814 - val_loss: 26.6242\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3547 - val_loss: 26.4725\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.2239 - val_loss: 26.3594\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1877 - val_loss: 26.2541\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 25.0730 - val_loss: 26.1586\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.0477 - val_loss: 26.0697\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9502 - val_loss: 25.9871\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8970 - val_loss: 25.9144\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8944 - val_loss: 25.8434\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8145 - val_loss: 25.7795\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7897 - val_loss: 25.7203\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3949 - val_loss: 25.6667\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7589 - val_loss: 25.6158\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7287 - val_loss: 25.5700\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6310 - val_loss: 25.5286\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6997 - val_loss: 25.4892\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5629 - val_loss: 25.4529\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5436 - val_loss: 25.4208\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6286 - val_loss: 25.3928\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6015 - val_loss: 25.3682\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5959 - val_loss: 25.3447\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5641 - val_loss: 25.3234\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5439 - val_loss: 25.3036\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5586 - val_loss: 25.2843\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4991 - val_loss: 25.2651\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5267 - val_loss: 25.2469\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4829 - val_loss: 25.2286\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2255 - val_loss: 25.2105\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3822 - val_loss: 25.1937\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4035 - val_loss: 25.1762\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4409 - val_loss: 25.1587\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4326 - val_loss: 25.1409\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.4087 - val_loss: 25.1233\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3957 - val_loss: 25.1067\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3973 - val_loss: 25.0899\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3405 - val_loss: 25.0733\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3740 - val_loss: 25.0576\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3628 - val_loss: 25.0415\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2958 - val_loss: 25.0260\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.3260 - val_loss: 25.0111\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3243 - val_loss: 24.9959\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.3036 - val_loss: 24.9813\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2921 - val_loss: 24.9666\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1859 - val_loss: 24.9528\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2638 - val_loss: 24.9392\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2306 - val_loss: 24.9252\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2365 - val_loss: 24.9117\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2417 - val_loss: 24.8985\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2311 - val_loss: 24.8856\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9961 - val_loss: 24.8729\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2152 - val_loss: 24.8600\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1972 - val_loss: 24.8470\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8496 - val_loss: 24.8345\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0375 - val_loss: 24.8227\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8308 - val_loss: 24.8109\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9064 - val_loss: 24.7982\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8923 - val_loss: 24.7860\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8516 - val_loss: 24.7745\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.1003 - val_loss: 24.7627\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9500 - val_loss: 24.7513\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0981 - val_loss: 24.7384\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9801 - val_loss: 24.7266\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0717 - val_loss: 24.7142\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0356 - val_loss: 24.7019\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0050 - val_loss: 24.6903\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9657 - val_loss: 24.6775\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9816 - val_loss: 24.6650\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9379 - val_loss: 24.6527\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0023 - val_loss: 24.6400\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9782 - val_loss: 24.6272\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9970 - val_loss: 24.6151\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8356 - val_loss: 24.6027\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9429 - val_loss: 24.5903\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9182 - val_loss: 24.5779\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9260 - val_loss: 24.5655\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.9327 - val_loss: 24.5526\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8759 - val_loss: 24.5403\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7365 - val_loss: 24.5284\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 670us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_448 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_449 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_450 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_451 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_452 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_453 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_454 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                121\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "0             1                124\n",
      "0             1                121\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 24.6357 - val_loss: 23.5803\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8622 - val_loss: 22.8059\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9217 - val_loss: 22.1218\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2104 - val_loss: 21.6020\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6073 - val_loss: 21.1868\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0502 - val_loss: 20.8298\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6485 - val_loss: 20.5029\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3319 - val_loss: 20.2800\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0291 - val_loss: 20.1096\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8109 - val_loss: 19.9767\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6402 - val_loss: 19.8672\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3871 - val_loss: 19.7694\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3407 - val_loss: 19.6780\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1953 - val_loss: 19.5951\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1408 - val_loss: 19.5196\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0563 - val_loss: 19.4548\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9741 - val_loss: 19.4014\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9366 - val_loss: 19.3536\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9043 - val_loss: 19.3142\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8416 - val_loss: 19.2808\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7667 - val_loss: 19.2526\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7777 - val_loss: 19.2258\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7803 - val_loss: 19.2009\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7538 - val_loss: 19.1786\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7386 - val_loss: 19.1565\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7026 - val_loss: 19.1374\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6370 - val_loss: 19.1202\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6619 - val_loss: 19.1025\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6804 - val_loss: 19.0857\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6496 - val_loss: 19.0708\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6348 - val_loss: 19.0572\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6466 - val_loss: 19.0428\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6073 - val_loss: 19.0296\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6358 - val_loss: 19.0164\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6166 - val_loss: 19.0044\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6109 - val_loss: 18.9923\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6028 - val_loss: 18.9807\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5857 - val_loss: 18.9696\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5846 - val_loss: 18.9596\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5814 - val_loss: 18.9495\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5846 - val_loss: 18.9399\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5692 - val_loss: 18.9302\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5449 - val_loss: 18.9215\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5547 - val_loss: 18.9115\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5252 - val_loss: 18.9024\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5282 - val_loss: 18.8937\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5298 - val_loss: 18.8841\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5043 - val_loss: 18.8752\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4706 - val_loss: 18.8662\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4852 - val_loss: 18.8572\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4960 - val_loss: 18.8473\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3991 - val_loss: 18.8388\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4609 - val_loss: 18.8299\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4346 - val_loss: 18.8205\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4494 - val_loss: 18.8108\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4418 - val_loss: 18.8020\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4265 - val_loss: 18.7937\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4104 - val_loss: 18.7855\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4231 - val_loss: 18.7769\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3631 - val_loss: 18.7690\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4083 - val_loss: 18.7600\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3606 - val_loss: 18.7520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3863 - val_loss: 18.7429\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2538 - val_loss: 18.7336\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3646 - val_loss: 18.7249\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3177 - val_loss: 18.7162\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2736 - val_loss: 18.7069\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2936 - val_loss: 18.6971\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2846 - val_loss: 18.6882\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2420 - val_loss: 18.6795\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3135 - val_loss: 18.6700\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3114 - val_loss: 18.6609\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2906 - val_loss: 18.6511\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2872 - val_loss: 18.6414\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2720 - val_loss: 18.6322\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2694 - val_loss: 18.6224\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2587 - val_loss: 18.6127\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1578 - val_loss: 18.6041\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2307 - val_loss: 18.5950\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1797 - val_loss: 18.5859\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2208 - val_loss: 18.5762\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2133 - val_loss: 18.5670\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1973 - val_loss: 18.5573\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1862 - val_loss: 18.5474\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1713 - val_loss: 18.5378\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1765 - val_loss: 18.5278\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1295 - val_loss: 18.5190\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1521 - val_loss: 18.5089\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1474 - val_loss: 18.4996\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1174 - val_loss: 18.4901\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1189 - val_loss: 18.4797\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1157 - val_loss: 18.4694\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0875 - val_loss: 18.4602\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0699 - val_loss: 18.4509\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0889 - val_loss: 18.4398\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0734 - val_loss: 18.4299\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0617 - val_loss: 18.4202\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0579 - val_loss: 18.4114\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0474 - val_loss: 18.4012\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0354 - val_loss: 18.3902\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 746us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_66 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_455 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_456 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_457 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_458 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_459 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_460 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_461 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  127\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1282\n",
      "Model:                       QuantReg   Bandwidth:                    0.005735\n",
      "Method:                 Least Squares   Sparsity:                       0.2209\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0448      0.008      5.892      0.000       0.030       0.060\n",
      "three_month_yield_change     -0.4106      0.202     -2.034      0.042      -0.807      -0.015\n",
      "term_spread_change           -0.9291      0.195     -4.753      0.000      -1.312      -0.546\n",
      "TED_spread                   -2.2239      0.813     -2.734      0.006      -3.819      -0.629\n",
      "credit_spread_change         -0.4179      0.280     -1.491      0.136      -0.968       0.132\n",
      "market_return                -0.1710      0.122     -1.406      0.160      -0.409       0.067\n",
      "real_estate_excess_return    -0.0297      0.122     -0.243      0.808      -0.269       0.210\n",
      "equity_volatility             2.3425      0.234     10.005      0.000       1.883       2.802\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2857\n",
      "Model:                       QuantReg   Bandwidth:                     0.01013\n",
      "Method:                 Least Squares   Sparsity:                        1.091\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:14   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0890      0.016      5.502      0.000       0.057       0.121\n",
      "three_month_yield_change     -1.0173      0.452     -2.251      0.024      -1.904      -0.131\n",
      "term_spread_change           -1.4350      0.510     -2.811      0.005      -2.436      -0.434\n",
      "TED_spread                    0.0006      1.855      0.000      1.000      -3.636       3.638\n",
      "credit_spread_change         -2.1212      0.567     -3.739      0.000      -3.234      -1.009\n",
      "market_return                -0.6611      0.398     -1.662      0.097      -1.441       0.119\n",
      "real_estate_excess_return    -0.4739      0.346     -1.370      0.171      -1.152       0.204\n",
      "equity_volatility             6.3697      0.658      9.681      0.000       5.079       7.660\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4099\n",
      "Model:                       QuantReg   Bandwidth:                    0.001983\n",
      "Method:                 Least Squares   Sparsity:                      0.08423\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:14   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0152      0.003      5.281      0.000       0.010       0.021\n",
      "three_month_yield_change     -0.1638      0.085     -1.924      0.054      -0.331       0.003\n",
      "term_spread_change           -0.1481      0.077     -1.928      0.054      -0.299       0.003\n",
      "TED_spread                   -0.4963      0.309     -1.607      0.108      -1.102       0.109\n",
      "credit_spread_change         -0.2154      0.098     -2.199      0.028      -0.407      -0.023\n",
      "market_return                 0.0161      0.043      0.373      0.709      -0.068       0.100\n",
      "real_estate_excess_return    -0.0023      0.055     -0.042      0.967      -0.110       0.105\n",
      "equity_volatility             0.6946      0.078      8.949      0.000       0.542       0.847\n",
      "institution                   0.3566      0.028     12.905      0.000       0.302       0.411\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5178\n",
      "Model:                       QuantReg   Bandwidth:                    0.003390\n",
      "Method:                 Least Squares   Sparsity:                       0.3333\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:14   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0317      0.005      6.210      0.000       0.022       0.042\n",
      "three_month_yield_change     -0.3475      0.161     -2.159      0.031      -0.663      -0.032\n",
      "term_spread_change           -0.3382      0.156     -2.165      0.030      -0.644      -0.032\n",
      "TED_spread                   -0.7696      0.680     -1.131      0.258      -2.103       0.564\n",
      "credit_spread_change         -0.5903      0.173     -3.412      0.001      -0.930      -0.251\n",
      "market_return                -0.1636      0.128     -1.275      0.202      -0.415       0.088\n",
      "real_estate_excess_return    -0.0112      0.140     -0.080      0.936      -0.286       0.264\n",
      "equity_volatility             1.2687      0.200      6.344      0.000       0.877       1.661\n",
      "institution                   0.3502      0.082      4.264      0.000       0.189       0.511\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 33.8964 - val_loss: 35.6219\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.9673 - val_loss: 34.7215\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.9184 - val_loss: 33.7772\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.8689 - val_loss: 32.8968\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.8421 - val_loss: 32.0557\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.8536 - val_loss: 31.2843\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.8163 - val_loss: 30.5430\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.1085 - val_loss: 29.8642\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.4344 - val_loss: 29.2253\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7618 - val_loss: 28.6275\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.1635 - val_loss: 28.0922\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.6627 - val_loss: 27.6252\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9871 - val_loss: 27.1685\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7231 - val_loss: 26.7553\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0723 - val_loss: 26.4254\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0497 - val_loss: 26.1373\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.7294 - val_loss: 25.8911\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.6070 - val_loss: 25.6628\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4379 - val_loss: 25.4527\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2980 - val_loss: 25.2649\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.1836 - val_loss: 25.0982\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9908 - val_loss: 24.9487\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9978 - val_loss: 24.8127\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9074 - val_loss: 24.7022\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7464 - val_loss: 24.6163\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7895 - val_loss: 24.5378\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7926 - val_loss: 24.4657\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7659 - val_loss: 24.4019\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6924 - val_loss: 24.3472\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5442 - val_loss: 24.2923\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6884 - val_loss: 24.2394\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6574 - val_loss: 24.1900\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5415 - val_loss: 24.1435\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6327 - val_loss: 24.0956\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5952 - val_loss: 24.0517\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5800 - val_loss: 24.0122\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5867 - val_loss: 23.9711\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5755 - val_loss: 23.9358\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4368 - val_loss: 23.8993\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5040 - val_loss: 23.8674\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5111 - val_loss: 23.8348\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4665 - val_loss: 23.8026\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4973 - val_loss: 23.7736\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5087 - val_loss: 23.7448\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3953 - val_loss: 23.7208\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4812 - val_loss: 23.6979\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4524 - val_loss: 23.6797\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4543 - val_loss: 23.6588\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4145 - val_loss: 23.6413\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4106 - val_loss: 23.6269\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4318 - val_loss: 23.6106\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3121 - val_loss: 23.5986\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4074 - val_loss: 23.5855\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4094 - val_loss: 23.5711\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3271 - val_loss: 23.5592\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3810 - val_loss: 23.5438\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2178 - val_loss: 23.5329\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3542 - val_loss: 23.5219\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3426 - val_loss: 23.5085\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2500 - val_loss: 23.4963\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3280 - val_loss: 23.4852\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3266 - val_loss: 23.4729\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2099 - val_loss: 23.4638\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1788 - val_loss: 23.4541\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2905 - val_loss: 23.4426\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2695 - val_loss: 23.4302\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2737 - val_loss: 23.4202\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2176 - val_loss: 23.4084\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2458 - val_loss: 23.3956\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2456 - val_loss: 23.3843\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2249 - val_loss: 23.3756\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2044 - val_loss: 23.3656\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2024 - val_loss: 23.3538\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2036 - val_loss: 23.3423\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0701 - val_loss: 23.3342\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1672 - val_loss: 23.3236\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1039 - val_loss: 23.3129\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1308 - val_loss: 23.3013\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1299 - val_loss: 23.2920\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1355 - val_loss: 23.2796\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1188 - val_loss: 23.2674\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1034 - val_loss: 23.2556\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0900 - val_loss: 23.2436\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9122 - val_loss: 23.2325\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0595 - val_loss: 23.2230\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9576 - val_loss: 23.2129\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0239 - val_loss: 23.2019\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0204 - val_loss: 23.1924\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9303 - val_loss: 23.1813\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8455 - val_loss: 23.1718\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9735 - val_loss: 23.1611\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8868 - val_loss: 23.1506\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9628 - val_loss: 23.1406\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9707 - val_loss: 23.1273\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9180 - val_loss: 23.1170\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9535 - val_loss: 23.1043\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9328 - val_loss: 23.0907\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9149 - val_loss: 23.0787\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8583 - val_loss: 23.0677\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20.9005 - val_loss: 23.0557\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 692us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_462 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_463 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_464 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_465 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_466 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_467 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_468 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                128\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                128\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 7ms/step - loss: 25.8699 - val_loss: 24.4299\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4028 - val_loss: 23.0745\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0135 - val_loss: 22.0501\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8912 - val_loss: 21.3173\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2431 - val_loss: 20.8056\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6583 - val_loss: 20.4320\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3037 - val_loss: 20.1905\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9892 - val_loss: 20.0016\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7160 - val_loss: 19.8615\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5283 - val_loss: 19.7540\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3544 - val_loss: 19.6545\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2309 - val_loss: 19.5609\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1017 - val_loss: 19.4721\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8488 - val_loss: 19.3960\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9218 - val_loss: 19.3316\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8364 - val_loss: 19.2713\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7656 - val_loss: 19.2191\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7685 - val_loss: 19.1725\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6218 - val_loss: 19.1351\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6495 - val_loss: 19.1061\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6185 - val_loss: 19.0800\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5692 - val_loss: 19.0572\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5485 - val_loss: 19.0360\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5789 - val_loss: 19.0163\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5501 - val_loss: 18.9972\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5529 - val_loss: 18.9788\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5359 - val_loss: 18.9605\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4928 - val_loss: 18.9431\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5126 - val_loss: 18.9256\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4963 - val_loss: 18.9088\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4224 - val_loss: 18.8931\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4710 - val_loss: 18.8768\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4575 - val_loss: 18.8622\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4353 - val_loss: 18.8480\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4313 - val_loss: 18.8337\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3991 - val_loss: 18.8209\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4214 - val_loss: 18.8079\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4123 - val_loss: 18.7954\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3920 - val_loss: 18.7833\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3782 - val_loss: 18.7714\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3602 - val_loss: 18.7592\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3309 - val_loss: 18.7475\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2375 - val_loss: 18.7356\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3517 - val_loss: 18.7236\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3386 - val_loss: 18.7118\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3219 - val_loss: 18.6999\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2506 - val_loss: 18.6890\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2795 - val_loss: 18.6784\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2970 - val_loss: 18.6661\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2558 - val_loss: 18.6547\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1800 - val_loss: 18.6440\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2768 - val_loss: 18.6321\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2294 - val_loss: 18.6212\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2547 - val_loss: 18.6096\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2381 - val_loss: 18.5976\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2238 - val_loss: 18.5860\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2129 - val_loss: 18.5743\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0003 - val_loss: 18.5631\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0249 - val_loss: 18.5529\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1857 - val_loss: 18.5412\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1734 - val_loss: 18.5298\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1655 - val_loss: 18.5181\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1012 - val_loss: 18.5074\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1330 - val_loss: 18.4960\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1310 - val_loss: 18.4842\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1225 - val_loss: 18.4732\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1103 - val_loss: 18.4615\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0908 - val_loss: 18.4504\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0859 - val_loss: 18.4392\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0607 - val_loss: 18.4283\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0397 - val_loss: 18.4169\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0386 - val_loss: 18.4064\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0405 - val_loss: 18.3951\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0321 - val_loss: 18.3834\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0168 - val_loss: 18.3714\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9987 - val_loss: 18.3593\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9760 - val_loss: 18.3480\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9898 - val_loss: 18.3361\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9762 - val_loss: 18.3247\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9709 - val_loss: 18.3124\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9485 - val_loss: 18.3006\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9323 - val_loss: 18.2895\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9218 - val_loss: 18.2775\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9212 - val_loss: 18.2650\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9070 - val_loss: 18.2533\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8933 - val_loss: 18.2414\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8701 - val_loss: 18.2296\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8726 - val_loss: 18.2171\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8367 - val_loss: 18.2052\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8437 - val_loss: 18.1932\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7254 - val_loss: 18.1831\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8059 - val_loss: 18.1722\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6460 - val_loss: 18.1607\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8014 - val_loss: 18.1477\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7654 - val_loss: 18.1352\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7759 - val_loss: 18.1220\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7677 - val_loss: 18.1099\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7098 - val_loss: 18.0971\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7176 - val_loss: 18.0846\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6855 - val_loss: 18.0733\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 691us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_469 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_470 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_471 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_472 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_473 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_474 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_475 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1398\n",
      "Model:                       QuantReg   Bandwidth:                    0.004509\n",
      "Method:                 Least Squares   Sparsity:                       0.1819\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:35   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0264      0.006      4.363      0.000       0.015       0.038\n",
      "three_month_yield_change     -0.4618      0.168     -2.756      0.006      -0.790      -0.133\n",
      "term_spread_change           -0.5186      0.153     -3.398      0.001      -0.818      -0.219\n",
      "TED_spread                   -1.1136      0.591     -1.885      0.060      -2.272       0.045\n",
      "credit_spread_change         -0.1993      0.223     -0.895      0.371      -0.636       0.238\n",
      "market_return                -0.0098      0.101     -0.097      0.923      -0.209       0.189\n",
      "real_estate_excess_return     0.0424      0.112      0.380      0.704      -0.177       0.261\n",
      "equity_volatility             1.9124      0.187     10.251      0.000       1.547       2.278\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2997\n",
      "Model:                       QuantReg   Bandwidth:                    0.007610\n",
      "Method:                 Least Squares   Sparsity:                       0.6767\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:35   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0418      0.011      3.637      0.000       0.019       0.064\n",
      "three_month_yield_change     -0.5555      0.267     -2.078      0.038      -1.080      -0.031\n",
      "term_spread_change           -0.4382      0.289     -1.514      0.130      -1.005       0.129\n",
      "TED_spread                   -0.7870      1.076     -0.732      0.464      -2.896       1.322\n",
      "credit_spread_change         -0.8132      0.435     -1.868      0.062      -1.667       0.040\n",
      "market_return                -0.2050      0.256     -0.801      0.423      -0.707       0.297\n",
      "real_estate_excess_return    -0.2455      0.267     -0.919      0.358      -0.769       0.278\n",
      "equity_volatility             3.7577      0.419      8.965      0.000       2.936       4.580\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4160\n",
      "Model:                       QuantReg   Bandwidth:                    0.001968\n",
      "Method:                 Least Squares   Sparsity:                      0.07781\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:35   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0109      0.003      3.882      0.000       0.005       0.016\n",
      "three_month_yield_change     -0.1428      0.079     -1.817      0.069      -0.297       0.011\n",
      "term_spread_change           -0.2130      0.073     -2.910      0.004      -0.357      -0.069\n",
      "TED_spread                   -0.6224      0.284     -2.191      0.029      -1.179      -0.065\n",
      "credit_spread_change          0.0066      0.097      0.068      0.946      -0.184       0.198\n",
      "market_return                -0.0279      0.038     -0.743      0.458      -0.102       0.046\n",
      "real_estate_excess_return     0.0291      0.044      0.668      0.504      -0.056       0.115\n",
      "equity_volatility             0.6593      0.068      9.631      0.000       0.525       0.793\n",
      "institution                   0.5069      0.038     13.313      0.000       0.432       0.582\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4717\n",
      "Model:                       QuantReg   Bandwidth:                    0.003226\n",
      "Method:                 Least Squares   Sparsity:                       0.3167\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:35   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0218      0.005      4.401      0.000       0.012       0.032\n",
      "three_month_yield_change     -0.1440      0.133     -1.085      0.278      -0.404       0.116\n",
      "term_spread_change           -0.2887      0.131     -2.200      0.028      -0.546      -0.031\n",
      "TED_spread                    0.9430      0.593      1.590      0.112      -0.220       2.106\n",
      "credit_spread_change         -0.4513      0.185     -2.436      0.015      -0.815      -0.088\n",
      "market_return                 0.0031      0.106      0.029      0.977      -0.205       0.212\n",
      "real_estate_excess_return    -0.0966      0.099     -0.977      0.329      -0.290       0.097\n",
      "equity_volatility             1.3627      0.176      7.725      0.000       1.017       1.709\n",
      "institution                   0.4097      0.119      3.456      0.001       0.177       0.642\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 39.2904 - val_loss: 39.9532\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.5588 - val_loss: 39.3073\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.7190 - val_loss: 38.6221\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.9331 - val_loss: 37.8486\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 35.8650 - val_loss: 36.9424\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.8124 - val_loss: 36.0181\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 33.7090 - val_loss: 35.1461\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.8273 - val_loss: 34.3776\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.7953 - val_loss: 33.6801\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.8229 - val_loss: 32.9922\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.0141 - val_loss: 32.1944\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.9459 - val_loss: 31.2974\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9507 - val_loss: 30.4551\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.2672 - val_loss: 29.7137\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.5129 - val_loss: 29.0647\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.9864 - val_loss: 28.4988\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.4414 - val_loss: 27.8890\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.7009 - val_loss: 27.3879\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.7096 - val_loss: 27.0757\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1445 - val_loss: 26.8682\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2513 - val_loss: 26.7092\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.0956 - val_loss: 26.5847\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9902 - val_loss: 26.4937\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9611 - val_loss: 26.4251\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7729 - val_loss: 26.3770\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7602 - val_loss: 26.3452\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8051 - val_loss: 26.3225\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7851 - val_loss: 26.3028\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7670 - val_loss: 26.2852\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4924 - val_loss: 26.2691\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.7340 - val_loss: 26.2535\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 23.6323 - val_loss: 26.2391\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6790 - val_loss: 26.2260\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6809 - val_loss: 26.2125\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6600 - val_loss: 26.1996\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6473 - val_loss: 26.1875\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6516 - val_loss: 26.1755\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6359 - val_loss: 26.1639\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5948 - val_loss: 26.1527\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6274 - val_loss: 26.1419\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5940 - val_loss: 26.1310\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.6001 - val_loss: 26.1206\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5534 - val_loss: 26.1102\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5684 - val_loss: 26.0997\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5026 - val_loss: 26.0893\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5453 - val_loss: 26.0790\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2996 - val_loss: 26.0684\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5218 - val_loss: 26.0579\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5215 - val_loss: 26.0476\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4987 - val_loss: 26.0373\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.5045 - val_loss: 26.0270\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4904 - val_loss: 26.0161\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4589 - val_loss: 26.0062\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4489 - val_loss: 25.9960\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4800 - val_loss: 25.9862\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3892 - val_loss: 25.9764\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.4343 - val_loss: 25.9663\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4280 - val_loss: 25.9562\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1282 - val_loss: 25.9462\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3222 - val_loss: 25.9359\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3949 - val_loss: 25.9261\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3945 - val_loss: 25.9160\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3488 - val_loss: 25.9060\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3739 - val_loss: 25.8959\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2784 - val_loss: 25.8861\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3504 - val_loss: 25.8761\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3491 - val_loss: 25.8657\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3362 - val_loss: 25.8554\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3275 - val_loss: 25.8455\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3206 - val_loss: 25.8351\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3061 - val_loss: 25.8252\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3095 - val_loss: 25.8150\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2895 - val_loss: 25.8044\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2833 - val_loss: 25.7939\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1597 - val_loss: 25.7835\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2349 - val_loss: 25.7729\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2639 - val_loss: 25.7621\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.2452 - val_loss: 25.7511\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1233 - val_loss: 25.7407\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0782 - val_loss: 25.7302\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1986 - val_loss: 25.7194\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1958 - val_loss: 25.7085\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1385 - val_loss: 25.6978\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1330 - val_loss: 25.6873\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1658 - val_loss: 25.6765\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1337 - val_loss: 25.6657\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1559 - val_loss: 25.6548\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.1423 - val_loss: 25.6433\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.1371 - val_loss: 25.6322\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0989 - val_loss: 25.6212\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9543 - val_loss: 25.6101\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0811 - val_loss: 25.5992\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0864 - val_loss: 25.5883\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0600 - val_loss: 25.5773\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0580 - val_loss: 25.5662\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0035 - val_loss: 25.5550\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0239 - val_loss: 25.5437\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0091 - val_loss: 25.5323\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.9887 - val_loss: 25.5215\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.8780 - val_loss: 25.5103\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 709us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_476 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_477 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_478 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_479 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_480 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_481 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_482 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                119\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                128\n",
      "0             1                119\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 7ms/step - loss: 25.7324 - val_loss: 24.4630\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9729 - val_loss: 23.8079\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.1688 - val_loss: 23.1918\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4964 - val_loss: 22.6965\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9513 - val_loss: 22.2642\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3717 - val_loss: 21.8566\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9690 - val_loss: 21.4709\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5480 - val_loss: 21.1246\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1471 - val_loss: 20.8242\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8066 - val_loss: 20.5454\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4782 - val_loss: 20.3196\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1400 - val_loss: 20.1520\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8999 - val_loss: 20.0082\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.7637 - val_loss: 19.8977\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5810 - val_loss: 19.8067\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4294 - val_loss: 19.7251\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2461 - val_loss: 19.6503\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2378 - val_loss: 19.5798\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0774 - val_loss: 19.5118\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0681 - val_loss: 19.4475\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9682 - val_loss: 19.3904\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8898 - val_loss: 19.3407\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7629 - val_loss: 19.2930\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8290 - val_loss: 19.2511\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7772 - val_loss: 19.2119\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7480 - val_loss: 19.1758\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7195 - val_loss: 19.1445\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6648 - val_loss: 19.1175\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6234 - val_loss: 19.0920\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6386 - val_loss: 19.0692\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5675 - val_loss: 19.0486\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5650 - val_loss: 19.0280\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5604 - val_loss: 19.0079\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5569 - val_loss: 18.9885\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5382 - val_loss: 18.9698\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5187 - val_loss: 18.9515\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5041 - val_loss: 18.9347\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4960 - val_loss: 18.9182\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3204 - val_loss: 18.9021\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4551 - val_loss: 18.8864\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4423 - val_loss: 18.8720\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4223 - val_loss: 18.8567\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4359 - val_loss: 18.8421\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3951 - val_loss: 18.8278\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4046 - val_loss: 18.8130\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4016 - val_loss: 18.7989\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3777 - val_loss: 18.7859\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3876 - val_loss: 18.7724\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3720 - val_loss: 18.7589\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3329 - val_loss: 18.7461\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2883 - val_loss: 18.7336\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2299 - val_loss: 18.7213\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3270 - val_loss: 18.7087\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2828 - val_loss: 18.6966\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2693 - val_loss: 18.6845\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2843 - val_loss: 18.6727\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2561 - val_loss: 18.6605\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2663 - val_loss: 18.6491\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2563 - val_loss: 18.6367\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2435 - val_loss: 18.6246\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2274 - val_loss: 18.6126\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2185 - val_loss: 18.6008\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2249 - val_loss: 18.5884\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9425 - val_loss: 18.5772\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1971 - val_loss: 18.5652\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1854 - val_loss: 18.5536\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1517 - val_loss: 18.5420\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1643 - val_loss: 18.5300\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1395 - val_loss: 18.5184\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1126 - val_loss: 18.5065\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1393 - val_loss: 18.4944\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1278 - val_loss: 18.4824\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0724 - val_loss: 18.4711\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1054 - val_loss: 18.4596\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0548 - val_loss: 18.4483\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9889 - val_loss: 18.4363\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0693 - val_loss: 18.4249\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0113 - val_loss: 18.4137\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0458 - val_loss: 18.4012\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0167 - val_loss: 18.3894\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0139 - val_loss: 18.3775\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0128 - val_loss: 18.3653\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9989 - val_loss: 18.3533\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9908 - val_loss: 18.3405\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9442 - val_loss: 18.3288\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8498 - val_loss: 18.3174\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8824 - val_loss: 18.3060\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8624 - val_loss: 18.2948\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8794 - val_loss: 18.2827\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9130 - val_loss: 18.2707\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8969 - val_loss: 18.2595\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8789 - val_loss: 18.2474\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8755 - val_loss: 18.2350\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8519 - val_loss: 18.2233\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8463 - val_loss: 18.2106\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8425 - val_loss: 18.1981\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7804 - val_loss: 18.1862\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7973 - val_loss: 18.1748\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7797 - val_loss: 18.1629\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7987 - val_loss: 18.1498\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 717us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_70 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_483 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_484 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_485 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_486 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_487 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_488 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_489 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1424\n",
      "Model:                       QuantReg   Bandwidth:                    0.005485\n",
      "Method:                 Least Squares   Sparsity:                       0.2023\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:57   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0172      0.007      2.450      0.014       0.003       0.031\n",
      "three_month_yield_change     -0.1409      0.189     -0.744      0.457      -0.512       0.230\n",
      "term_spread_change           -0.3455      0.177     -1.949      0.051      -0.693       0.002\n",
      "TED_spread                    0.3725      0.721      0.517      0.605      -1.041       1.786\n",
      "credit_spread_change         -0.1258      0.249     -0.504      0.614      -0.615       0.363\n",
      "market_return                 0.0376      0.115      0.328      0.743      -0.187       0.262\n",
      "real_estate_excess_return     0.2231      0.120      1.862      0.063      -0.012       0.458\n",
      "equity_volatility             2.3729      0.210     11.311      0.000       1.961       2.784\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.2288\n",
      "Model:                       QuantReg   Bandwidth:                    0.009608\n",
      "Method:                 Least Squares   Sparsity:                        1.327\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:57   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0630      0.022      2.913      0.004       0.021       0.105\n",
      "three_month_yield_change     -0.3791      0.567     -0.669      0.504      -1.491       0.733\n",
      "term_spread_change           -0.7181      0.542     -1.324      0.185      -1.781       0.345\n",
      "TED_spread                    3.2081      2.277      1.409      0.159      -1.257       7.673\n",
      "credit_spread_change         -1.6988      0.764     -2.224      0.026      -3.197      -0.201\n",
      "market_return                 0.2570      0.521      0.494      0.622      -0.764       1.278\n",
      "real_estate_excess_return    -0.4016      0.513     -0.783      0.434      -1.407       0.604\n",
      "equity_volatility             4.8855      0.798      6.124      0.000       3.321       6.450\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4201\n",
      "Model:                       QuantReg   Bandwidth:                    0.002164\n",
      "Method:                 Least Squares   Sparsity:                      0.07728\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:57   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0095      0.003      3.562      0.000       0.004       0.015\n",
      "three_month_yield_change      0.0413      0.079      0.522      0.602      -0.114       0.196\n",
      "term_spread_change           -0.0861      0.071     -1.221      0.222      -0.224       0.052\n",
      "TED_spread                   -0.4064      0.287     -1.416      0.157      -0.969       0.157\n",
      "credit_spread_change         -0.0874      0.091     -0.957      0.339      -0.266       0.092\n",
      "market_return                -0.0925      0.037     -2.534      0.011      -0.164      -0.021\n",
      "real_estate_excess_return    -0.0049      0.047     -0.104      0.917      -0.098       0.088\n",
      "equity_volatility             0.7562      0.074     10.232      0.000       0.611       0.901\n",
      "institution                   0.3637      0.028     13.111      0.000       0.309       0.418\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5353\n",
      "Model:                       QuantReg   Bandwidth:                    0.003424\n",
      "Method:                 Least Squares   Sparsity:                       0.3361\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:04:57   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0318      0.005      6.009      0.000       0.021       0.042\n",
      "three_month_yield_change     -0.3696      0.155     -2.387      0.017      -0.673      -0.066\n",
      "term_spread_change           -0.4610      0.172     -2.680      0.007      -0.798      -0.124\n",
      "TED_spread                   -0.1074      0.620     -0.173      0.862      -1.322       1.108\n",
      "credit_spread_change         -0.4914      0.191     -2.567      0.010      -0.867      -0.116\n",
      "market_return                -0.2213      0.122     -1.810      0.070      -0.461       0.018\n",
      "real_estate_excess_return    -0.0805      0.104     -0.772      0.440      -0.285       0.124\n",
      "equity_volatility             1.0512      0.197      5.329      0.000       0.664       1.438\n",
      "institution                   0.3709      0.097      3.810      0.000       0.180       0.562\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 29\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 41.2234 - val_loss: 34.6424\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 40.1787 - val_loss: 33.8069\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39.2800 - val_loss: 32.9712\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 38.2267 - val_loss: 32.0013\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 37.2144 - val_loss: 31.0713\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 36.1416 - val_loss: 30.2611\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 35.0998 - val_loss: 29.4868\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 34.3715 - val_loss: 28.7179\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.3439 - val_loss: 27.9588\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 32.3031 - val_loss: 27.2330\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.4204 - val_loss: 26.5090\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 30.5586 - val_loss: 25.6185\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.5264 - val_loss: 24.7851\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 28.6313 - val_loss: 24.0770\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.7223 - val_loss: 23.4226\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.0591 - val_loss: 22.8128\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.2780 - val_loss: 22.2955\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.8878 - val_loss: 21.8237\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.3595 - val_loss: 21.4019\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.8896 - val_loss: 21.0601\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4321 - val_loss: 20.7574\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2050 - val_loss: 20.5466\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.9408 - val_loss: 20.4294\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.7371 - val_loss: 20.3366\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.5367 - val_loss: 20.2502\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2300 - val_loss: 20.1938\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.2407 - val_loss: 20.1691\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9511 - val_loss: 20.1662\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.0258 - val_loss: 20.1691\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9672 - val_loss: 20.1735\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7853 - val_loss: 20.1766\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8312 - val_loss: 20.1789\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7181 - val_loss: 20.1799\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7805 - val_loss: 20.1801\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7539 - val_loss: 20.1790\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5933 - val_loss: 20.1772\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7143 - val_loss: 20.1752\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5822 - val_loss: 20.1725\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6675 - val_loss: 20.1697\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5974 - val_loss: 20.1665\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.6086 - val_loss: 20.1629\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5917 - val_loss: 20.1593\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5322 - val_loss: 20.1557\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4518 - val_loss: 20.1523\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5434 - val_loss: 20.1489\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4978 - val_loss: 20.1457\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3394 - val_loss: 20.1418\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.5128 - val_loss: 20.1388\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4799 - val_loss: 20.1352\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4534 - val_loss: 20.1315\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4658 - val_loss: 20.1281\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4570 - val_loss: 20.1235\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4321 - val_loss: 20.1190\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3629 - val_loss: 20.1139\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4065 - val_loss: 20.1082\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3528 - val_loss: 20.1026\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3752 - val_loss: 20.0968\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3412 - val_loss: 20.0905\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3684 - val_loss: 20.0841\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3682 - val_loss: 20.0777\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3134 - val_loss: 20.0700\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3115 - val_loss: 20.0629\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3214 - val_loss: 20.0555\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.3124 - val_loss: 20.0481\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2371 - val_loss: 20.0397\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1957 - val_loss: 20.0317\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1594 - val_loss: 20.0238\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0890 - val_loss: 20.0150\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1160 - val_loss: 20.0068\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2447 - val_loss: 19.9986\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2255 - val_loss: 19.9904\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 22.2052 - val_loss: 19.9822\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2035 - val_loss: 19.9736\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1858 - val_loss: 19.9645\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1498 - val_loss: 19.9556\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1647 - val_loss: 19.9464\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1506 - val_loss: 19.9377\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1412 - val_loss: 19.9290\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1359 - val_loss: 19.9196\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1000 - val_loss: 19.9096\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0136 - val_loss: 19.8993\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1059 - val_loss: 19.8897\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9839 - val_loss: 19.8792\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0599 - val_loss: 19.8691\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0599 - val_loss: 19.8588\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0593 - val_loss: 19.8487\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0453 - val_loss: 19.8384\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9432 - val_loss: 19.8273\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0136 - val_loss: 19.8170\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8965 - val_loss: 19.8061\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9985 - val_loss: 19.7957\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8810 - val_loss: 19.7847\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9479 - val_loss: 19.7742\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9422 - val_loss: 19.7632\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9200 - val_loss: 19.7518\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9216 - val_loss: 19.7410\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8004 - val_loss: 19.7294\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8419 - val_loss: 19.7182\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8874 - val_loss: 19.7063\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8616 - val_loss: 19.6946\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 662us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_71 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_490 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_491 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_492 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_493 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_494 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_495 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_496 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.8435 - val_loss: 25.3605\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.6952 - val_loss: 24.6985\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.1072 - val_loss: 24.1710\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.6679 - val_loss: 23.7835\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.2975 - val_loss: 23.3883\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.6460 - val_loss: 22.7594\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9452 - val_loss: 22.2388\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1832 - val_loss: 21.8002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8429 - val_loss: 21.3870\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3314 - val_loss: 21.0337\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.8424 - val_loss: 20.7250\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6302 - val_loss: 20.4775\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3973 - val_loss: 20.2817\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9845 - val_loss: 20.1286\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8667 - val_loss: 19.9890\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6608 - val_loss: 19.8829\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4905 - val_loss: 19.7930\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.4132 - val_loss: 19.7119\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3150 - val_loss: 19.6353\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2007 - val_loss: 19.5627\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0615 - val_loss: 19.4923\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0046 - val_loss: 19.4258\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9662 - val_loss: 19.3684\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9096 - val_loss: 19.3172\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8383 - val_loss: 19.2697\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7676 - val_loss: 19.2262\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6962 - val_loss: 19.1857\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6255 - val_loss: 19.1502\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6712 - val_loss: 19.1196\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6470 - val_loss: 19.0935\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6415 - val_loss: 19.0697\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5579 - val_loss: 19.0477\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5858 - val_loss: 19.0257\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4496 - val_loss: 19.0050\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4525 - val_loss: 18.9841\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5273 - val_loss: 18.9640\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4713 - val_loss: 18.9445\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4884 - val_loss: 18.9256\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4676 - val_loss: 18.9072\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4551 - val_loss: 18.8892\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4036 - val_loss: 18.8714\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3483 - val_loss: 18.8546\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4052 - val_loss: 18.8380\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3737 - val_loss: 18.8222\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3428 - val_loss: 18.8071\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3590 - val_loss: 18.7919\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3554 - val_loss: 18.7763\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3389 - val_loss: 18.7609\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2964 - val_loss: 18.7458\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3212 - val_loss: 18.7307\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2947 - val_loss: 18.7160\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2904 - val_loss: 18.7011\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2483 - val_loss: 18.6869\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2182 - val_loss: 18.6730\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2359 - val_loss: 18.6591\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2026 - val_loss: 18.6452\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2132 - val_loss: 18.6313\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1913 - val_loss: 18.6172\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2165 - val_loss: 18.6030\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1947 - val_loss: 18.5886\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1790 - val_loss: 18.5745\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1667 - val_loss: 18.5607\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1567 - val_loss: 18.5465\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0238 - val_loss: 18.5335\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1283 - val_loss: 18.5201\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1229 - val_loss: 18.5065\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1047 - val_loss: 18.4931\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0969 - val_loss: 18.4794\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0247 - val_loss: 18.4660\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9990 - val_loss: 18.4527\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0324 - val_loss: 18.4389\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0444 - val_loss: 18.4250\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0195 - val_loss: 18.4118\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0071 - val_loss: 18.3984\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9994 - val_loss: 18.3844\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8859 - val_loss: 18.3706\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9157 - val_loss: 18.3570\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9609 - val_loss: 18.3427\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8875 - val_loss: 18.3283\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9372 - val_loss: 18.3143\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8272 - val_loss: 18.3012\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9181 - val_loss: 18.2869\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8342 - val_loss: 18.2731\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8844 - val_loss: 18.2590\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8822 - val_loss: 18.2446\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8299 - val_loss: 18.2300\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8491 - val_loss: 18.2155\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8216 - val_loss: 18.2015\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7718 - val_loss: 18.1876\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8125 - val_loss: 18.1734\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7922 - val_loss: 18.1592\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7563 - val_loss: 18.1452\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7664 - val_loss: 18.1310\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7566 - val_loss: 18.1166\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7149 - val_loss: 18.1025\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6530 - val_loss: 18.0883\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6985 - val_loss: 18.0740\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6905 - val_loss: 18.0592\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6724 - val_loss: 18.0450\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.6115 - val_loss: 18.0310\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 697us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_72 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_497 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_498 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_499 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_500 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_501 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_502 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_503 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.08561\n",
      "Model:                       QuantReg   Bandwidth:                    0.005317\n",
      "Method:                 Least Squares   Sparsity:                       0.2246\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:18   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0290      0.008      3.578      0.000       0.013       0.045\n",
      "three_month_yield_change     -0.0970      0.211     -0.460      0.645      -0.510       0.316\n",
      "term_spread_change           -0.2672      0.189     -1.414      0.157      -0.638       0.103\n",
      "TED_spread                   -0.4905      0.795     -0.617      0.537      -2.049       1.068\n",
      "credit_spread_change         -0.3865      0.291     -1.330      0.184      -0.956       0.183\n",
      "market_return                -0.1203      0.106     -1.136      0.256      -0.328       0.087\n",
      "real_estate_excess_return     0.0195      0.137      0.143      0.887      -0.249       0.288\n",
      "equity_volatility             1.9552      0.197      9.929      0.000       1.569       2.341\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1904\n",
      "Model:                       QuantReg   Bandwidth:                    0.008418\n",
      "Method:                 Least Squares   Sparsity:                       0.8439\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:18   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0408      0.017      2.472      0.014       0.008       0.073\n",
      "three_month_yield_change     -0.1545      0.409     -0.378      0.705      -0.956       0.647\n",
      "term_spread_change           -0.3317      0.386     -0.859      0.391      -1.089       0.426\n",
      "TED_spread                   -0.4864      1.438     -0.338      0.735      -3.306       2.333\n",
      "credit_spread_change         -0.3864      0.585     -0.660      0.509      -1.534       0.762\n",
      "market_return                -0.5615      0.167     -3.370      0.001      -0.888      -0.235\n",
      "real_estate_excess_return    -0.2557      0.268     -0.954      0.340      -0.782       0.270\n",
      "equity_volatility             3.1790      0.291     10.932      0.000       2.609       3.749\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 29\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4070\n",
      "Model:                       QuantReg   Bandwidth:                    0.001949\n",
      "Method:                 Least Squares   Sparsity:                      0.07278\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:18   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0118      0.003      4.575      0.000       0.007       0.017\n",
      "three_month_yield_change     -0.0091      0.075     -0.122      0.903      -0.156       0.138\n",
      "term_spread_change           -0.1913      0.068     -2.818      0.005      -0.324      -0.058\n",
      "TED_spread                   -0.4743      0.287     -1.653      0.098      -1.037       0.088\n",
      "credit_spread_change         -0.1356      0.086     -1.576      0.115      -0.304       0.033\n",
      "market_return                 0.0641      0.040      1.590      0.112      -0.015       0.143\n",
      "real_estate_excess_return     0.0315      0.048      0.660      0.509      -0.062       0.125\n",
      "equity_volatility             0.6791      0.081      8.417      0.000       0.521       0.837\n",
      "institution                   0.4247      0.030     14.166      0.000       0.366       0.483\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4464\n",
      "Model:                       QuantReg   Bandwidth:                    0.004012\n",
      "Method:                 Least Squares   Sparsity:                       0.3426\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:19   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0231      0.005      4.574      0.000       0.013       0.033\n",
      "three_month_yield_change     -0.2040      0.140     -1.455      0.146      -0.479       0.071\n",
      "term_spread_change           -0.4859      0.151     -3.210      0.001      -0.783      -0.189\n",
      "TED_spread                   -0.9207      0.645     -1.427      0.154      -2.186       0.345\n",
      "credit_spread_change         -0.3302      0.181     -1.822      0.069      -0.685       0.025\n",
      "market_return                 0.0569      0.133      0.428      0.669      -0.204       0.318\n",
      "real_estate_excess_return     0.0275      0.111      0.247      0.805      -0.191       0.246\n",
      "equity_volatility             1.8046      0.215      8.389      0.000       1.383       2.226\n",
      "institution                   0.3532      0.110      3.220      0.001       0.138       0.568\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 34.7534 - val_loss: 33.7886\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 34.1581 - val_loss: 33.3018\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.6403 - val_loss: 32.8060\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.1308 - val_loss: 32.3168\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 32.5204 - val_loss: 31.8176\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 31.9454 - val_loss: 31.2809\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.1426 - val_loss: 30.7093\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.8100 - val_loss: 30.1210\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.1174 - val_loss: 29.5149\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 29.4055 - val_loss: 28.8579\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 28.7273 - val_loss: 28.0928\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.8351 - val_loss: 27.1799\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 27.0026 - val_loss: 26.2819\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.9797 - val_loss: 25.3776\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.9563 - val_loss: 24.6026\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.0932 - val_loss: 23.9683\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.4092 - val_loss: 23.4028\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.0931 - val_loss: 22.9483\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.8096 - val_loss: 22.6315\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5103 - val_loss: 22.3902\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4215 - val_loss: 22.2032\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2887 - val_loss: 22.0589\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.2404 - val_loss: 21.9642\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9904 - val_loss: 21.9127\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.1190 - val_loss: 21.8753\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.0767 - val_loss: 21.8495\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0494 - val_loss: 21.8301\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9978 - val_loss: 21.8113\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0169 - val_loss: 21.7960\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9681 - val_loss: 21.7839\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9574 - val_loss: 21.7747\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.9755 - val_loss: 21.7663\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9253 - val_loss: 21.7580\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7133 - val_loss: 21.7501\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8253 - val_loss: 21.7428\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.9129 - val_loss: 21.7361\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8610 - val_loss: 21.7296\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8754 - val_loss: 21.7229\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8334 - val_loss: 21.7167\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8783 - val_loss: 21.7105\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7673 - val_loss: 21.7036\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8630 - val_loss: 21.6967\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7965 - val_loss: 21.6892\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8215 - val_loss: 21.6817\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7221 - val_loss: 21.6736\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7875 - val_loss: 21.6655\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.8022 - val_loss: 21.6574\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7740 - val_loss: 21.6491\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7884 - val_loss: 21.6404\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7492 - val_loss: 21.6319\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.6695 - val_loss: 21.6229\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7491 - val_loss: 21.6138\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6825 - val_loss: 21.6043\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6599 - val_loss: 21.5947\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 21.6188 - val_loss: 21.5848\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6250 - val_loss: 21.5749\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5363 - val_loss: 21.5650\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5359 - val_loss: 21.5551\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6775 - val_loss: 21.5453\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5808 - val_loss: 21.5351\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6544 - val_loss: 21.5250\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.5670 - val_loss: 21.5147\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6084 - val_loss: 21.5046\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.6210 - val_loss: 21.4935\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4756 - val_loss: 21.4828\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5961 - val_loss: 21.4724\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5964 - val_loss: 21.4620\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5758 - val_loss: 21.4512\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5645 - val_loss: 21.4399\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5549 - val_loss: 21.4291\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.5060 - val_loss: 21.4181\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2686 - val_loss: 21.4067\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4950 - val_loss: 21.3954\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4711 - val_loss: 21.3842\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3253 - val_loss: 21.3725\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4551 - val_loss: 21.3610\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4566 - val_loss: 21.3495\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4505 - val_loss: 21.3383\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4375 - val_loss: 21.3266\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3869 - val_loss: 21.3148\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3399 - val_loss: 21.3031\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4126 - val_loss: 21.2917\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3906 - val_loss: 21.2799\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3919 - val_loss: 21.2682\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3860 - val_loss: 21.2563\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2914 - val_loss: 21.2442\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3577 - val_loss: 21.2324\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3378 - val_loss: 21.2204\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3156 - val_loss: 21.2083\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3197 - val_loss: 21.1963\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2649 - val_loss: 21.1841\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.3034 - val_loss: 21.1716\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2386 - val_loss: 21.1591\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1846 - val_loss: 21.1468\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.2547 - val_loss: 21.1347\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1922 - val_loss: 21.1222\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2309 - val_loss: 21.1099\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.2113 - val_loss: 21.0972\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.0735 - val_loss: 21.0844\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1748 - val_loss: 21.0715\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 749us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_73 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_504 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_505 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_506 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_507 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_508 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_509 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_510 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 27.8115 - val_loss: 26.0152\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 26.6496 - val_loss: 25.1742\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.7253 - val_loss: 24.5291\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.0635 - val_loss: 23.9893\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.4475 - val_loss: 23.5036\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.8654 - val_loss: 23.0437\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 23.3141 - val_loss: 22.6335\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.7480 - val_loss: 22.2718\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.4433 - val_loss: 21.9492\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0560 - val_loss: 21.6400\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7355 - val_loss: 21.3385\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.4272 - val_loss: 21.0644\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.1202 - val_loss: 20.8143\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7621 - val_loss: 20.5877\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5034 - val_loss: 20.4004\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2288 - val_loss: 20.2463\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0660 - val_loss: 20.1091\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.8727 - val_loss: 19.9846\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6933 - val_loss: 19.8907\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.5623 - val_loss: 19.8105\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3423 - val_loss: 19.7361\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3346 - val_loss: 19.6645\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.2016 - val_loss: 19.5950\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1351 - val_loss: 19.5296\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0308 - val_loss: 19.4658\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0097 - val_loss: 19.4081\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8774 - val_loss: 19.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8881 - val_loss: 19.3115\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8173 - val_loss: 19.2695\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7708 - val_loss: 19.2299\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6569 - val_loss: 19.1922\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7197 - val_loss: 19.1562\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6833 - val_loss: 19.1251\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6571 - val_loss: 19.0989\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6018 - val_loss: 19.0764\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6145 - val_loss: 19.0554\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5619 - val_loss: 19.0355\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4553 - val_loss: 19.0165\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5134 - val_loss: 18.9968\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4573 - val_loss: 18.9777\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5155 - val_loss: 18.9589\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4665 - val_loss: 18.9407\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4562 - val_loss: 18.9230\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4432 - val_loss: 18.9055\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4556 - val_loss: 18.8878\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4420 - val_loss: 18.8704\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4104 - val_loss: 18.8536\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4062 - val_loss: 18.8367\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3557 - val_loss: 18.8208\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3797 - val_loss: 18.8051\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3291 - val_loss: 18.7896\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3568 - val_loss: 18.7747\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3495 - val_loss: 18.7601\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3220 - val_loss: 18.7461\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3157 - val_loss: 18.7321\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2945 - val_loss: 18.7182\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2862 - val_loss: 18.7044\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2658 - val_loss: 18.6904\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2470 - val_loss: 18.6773\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2535 - val_loss: 18.6636\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2144 - val_loss: 18.6503\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2349 - val_loss: 18.6364\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2256 - val_loss: 18.6229\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2173 - val_loss: 18.6092\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1984 - val_loss: 18.5961\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1892 - val_loss: 18.5823\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1822 - val_loss: 18.5690\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1633 - val_loss: 18.5557\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1604 - val_loss: 18.5421\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1451 - val_loss: 18.5293\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1346 - val_loss: 18.5162\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1226 - val_loss: 18.5034\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0978 - val_loss: 18.4908\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1001 - val_loss: 18.4774\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0884 - val_loss: 18.4642\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0151 - val_loss: 18.4523\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0614 - val_loss: 18.4393\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0476 - val_loss: 18.4266\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0254 - val_loss: 18.4136\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0053 - val_loss: 18.4013\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0174 - val_loss: 18.3881\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0000 - val_loss: 18.3751\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9394 - val_loss: 18.3625\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9222 - val_loss: 18.3502\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9606 - val_loss: 18.3369\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9427 - val_loss: 18.3240\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9366 - val_loss: 18.3111\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8833 - val_loss: 18.2982\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9056 - val_loss: 18.2851\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9086 - val_loss: 18.2718\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8581 - val_loss: 18.2595\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8810 - val_loss: 18.2469\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8524 - val_loss: 18.2343\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8423 - val_loss: 18.2217\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8388 - val_loss: 18.2084\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8215 - val_loss: 18.1960\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8282 - val_loss: 18.1830\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7658 - val_loss: 18.1711\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7812 - val_loss: 18.1580\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7829 - val_loss: 18.1449\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 716us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_511 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_512 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_513 (Conv1D)         (None, 5, 32)             2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_514 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_515 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_516 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_517 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  125\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1110\n",
      "Model:                       QuantReg   Bandwidth:                    0.004482\n",
      "Method:                 Least Squares   Sparsity:                       0.1758\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:40   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0081      0.007      1.222      0.222      -0.005       0.021\n",
      "three_month_yield_change      0.0803      0.171      0.469      0.639      -0.255       0.416\n",
      "term_spread_change           -0.0811      0.158     -0.513      0.608      -0.391       0.229\n",
      "TED_spread                   -0.4490      0.667     -0.673      0.501      -1.758       0.860\n",
      "credit_spread_change          0.0614      0.231      0.266      0.790      -0.391       0.514\n",
      "market_return                -0.1457      0.094     -1.545      0.123      -0.331       0.039\n",
      "real_estate_excess_return     0.0675      0.096      0.700      0.484      -0.122       0.257\n",
      "equity_volatility             1.9922      0.159     12.520      0.000       1.680       2.304\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 127\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1841\n",
      "Model:                       QuantReg   Bandwidth:                    0.007361\n",
      "Method:                 Least Squares   Sparsity:                       0.8990\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:40   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0390      0.016      2.491      0.013       0.008       0.070\n",
      "three_month_yield_change     -0.2236      0.469     -0.477      0.633      -1.143       0.696\n",
      "term_spread_change           -0.8906      0.425     -2.093      0.036      -1.725      -0.056\n",
      "TED_spread                   -1.1585      1.930     -0.600      0.548      -4.943       2.626\n",
      "credit_spread_change          0.1772      0.530      0.335      0.738      -0.861       1.216\n",
      "market_return                -0.0311      0.338     -0.092      0.927      -0.693       0.631\n",
      "real_estate_excess_return     0.0281      0.292      0.096      0.923      -0.544       0.600\n",
      "equity_volatility             2.3744      0.512      4.641      0.000       1.371       3.378\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4535\n",
      "Model:                       QuantReg   Bandwidth:                    0.001858\n",
      "Method:                 Least Squares   Sparsity:                      0.06109\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:40   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0113      0.002      5.573      0.000       0.007       0.015\n",
      "three_month_yield_change     -0.1268      0.056     -2.258      0.024      -0.237      -0.017\n",
      "term_spread_change           -0.1151      0.051     -2.254      0.024      -0.215      -0.015\n",
      "TED_spread                   -0.8392      0.221     -3.801      0.000      -1.272      -0.406\n",
      "credit_spread_change         -0.0522      0.076     -0.685      0.493      -0.202       0.097\n",
      "market_return                -0.0170      0.032     -0.539      0.590      -0.079       0.045\n",
      "real_estate_excess_return    -0.0353      0.038     -0.935      0.350      -0.109       0.039\n",
      "equity_volatility             0.5595      0.057      9.873      0.000       0.448       0.671\n",
      "institution                   0.5051      0.027     18.673      0.000       0.452       0.558\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5192\n",
      "Model:                       QuantReg   Bandwidth:                    0.003997\n",
      "Method:                 Least Squares   Sparsity:                       0.2794\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:05:40   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0353      0.004      8.103      0.000       0.027       0.044\n",
      "three_month_yield_change     -0.6728      0.131     -5.131      0.000      -0.930      -0.416\n",
      "term_spread_change           -0.5681      0.131     -4.347      0.000      -0.824      -0.312\n",
      "TED_spread                   -1.4926      0.448     -3.335      0.001      -2.370      -0.615\n",
      "credit_spread_change         -0.5342      0.159     -3.359      0.001      -0.846      -0.222\n",
      "market_return                -0.0123      0.107     -0.115      0.909      -0.223       0.198\n",
      "real_estate_excess_return    -0.0151      0.088     -0.173      0.863      -0.187       0.157\n",
      "equity_volatility             1.5311      0.173      8.852      0.000       1.192       1.870\n",
      "institution                   0.4448      0.100      4.444      0.000       0.249       0.641\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 34.1320 - val_loss: 29.0337\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 33.1063 - val_loss: 28.2093\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 31.8046 - val_loss: 27.2973\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 30.4778 - val_loss: 26.4752\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 29.2830 - val_loss: 25.6573\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 27.9715 - val_loss: 24.8552\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 26.7643 - val_loss: 24.0590\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 25.4594 - val_loss: 23.3846\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 24.2698 - val_loss: 22.7889\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 23.3748 - val_loss: 22.2631\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 22.5760 - val_loss: 21.8007\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.0993 - val_loss: 21.5955\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.7097 - val_loss: 21.4847\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.4990 - val_loss: 21.4363\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.3170 - val_loss: 21.4027\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.1315 - val_loss: 21.3963\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 21.0505 - val_loss: 21.4087\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.9649 - val_loss: 21.4217\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9221 - val_loss: 21.4318\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8602 - val_loss: 21.4394\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.8376 - val_loss: 21.4463\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7696 - val_loss: 21.4507\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.7496 - val_loss: 21.4541\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7126 - val_loss: 21.4556\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7084 - val_loss: 21.4555\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.7090 - val_loss: 21.4554\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6945 - val_loss: 21.4547\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5171 - val_loss: 21.4529\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6749 - val_loss: 21.4499\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6528 - val_loss: 21.4463\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6486 - val_loss: 21.4427\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6255 - val_loss: 21.4382\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.6224 - val_loss: 21.4329\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.6253 - val_loss: 21.4274\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5921 - val_loss: 21.4211\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5913 - val_loss: 21.4151\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5861 - val_loss: 21.4085\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5382 - val_loss: 21.4015\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5585 - val_loss: 21.3943\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5764 - val_loss: 21.3866\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5638 - val_loss: 21.3792\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5593 - val_loss: 21.3721\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5187 - val_loss: 21.3646\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5252 - val_loss: 21.3568\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3576 - val_loss: 21.3487\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.5143 - val_loss: 21.3414\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4771 - val_loss: 21.3332\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4527 - val_loss: 21.3242\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4739 - val_loss: 21.3157\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4364 - val_loss: 21.3072\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4607 - val_loss: 21.2986\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4633 - val_loss: 21.2904\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4195 - val_loss: 21.2812\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4347 - val_loss: 21.2731\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.4167 - val_loss: 21.2644\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3895 - val_loss: 21.2552\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3892 - val_loss: 21.2453\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.4096 - val_loss: 21.2358\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.3939 - val_loss: 21.2263\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3343 - val_loss: 21.2169\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3713 - val_loss: 21.2072\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2506 - val_loss: 21.1967\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3463 - val_loss: 21.1858\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3214 - val_loss: 21.1757\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2933 - val_loss: 21.1660\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2928 - val_loss: 21.1560\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.3097 - val_loss: 21.1470\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2937 - val_loss: 21.1371\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2987 - val_loss: 21.1269\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2778 - val_loss: 21.1166\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2664 - val_loss: 21.1059\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2598 - val_loss: 21.0958\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1194 - val_loss: 21.0850\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.2080 - val_loss: 21.0743\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2229 - val_loss: 21.0647\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1334 - val_loss: 21.0539\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1513 - val_loss: 21.0431\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2062 - val_loss: 21.0323\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1641 - val_loss: 21.0217\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1735 - val_loss: 21.0113\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 20.1554 - val_loss: 21.0003\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1543 - val_loss: 20.9895\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1244 - val_loss: 20.9792\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1270 - val_loss: 20.9684\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0993 - val_loss: 20.9571\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.1091 - val_loss: 20.9465\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0829 - val_loss: 20.9349\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0931 - val_loss: 20.9240\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0711 - val_loss: 20.9121\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9712 - val_loss: 20.9006\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0480 - val_loss: 20.8888\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.0229 - val_loss: 20.8771\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.9414 - val_loss: 20.8650\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.0235 - val_loss: 20.8541\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9889 - val_loss: 20.8424\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9835 - val_loss: 20.8314\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9810 - val_loss: 20.8203\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9542 - val_loss: 20.8082\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9311 - val_loss: 20.7952\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.9358 - val_loss: 20.7833\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 680us/step\n",
      "a.shape (2448, 1, 1)\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_518 (Conv1D)         (None, 6, 32)             96        \n",
      "                                                                 \n",
      " conv1d_519 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_520 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_521 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_522 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_523 (Conv1D)         (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_524 (Conv1D)         (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                117\n",
      "   random_state  VaR_QRCNN_95_失败天数\n",
      "0             1                124\n",
      "0             1                132\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                121\n",
      "0             1                125\n",
      "0             1                118\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                127\n",
      "0             1                120\n",
      "0             1                125\n",
      "0             1                124\n",
      "0             1                125\n",
      "0             1                127\n",
      "0             1                119\n",
      "0             1                119\n",
      "0             1                124\n",
      "0             1                121\n",
      "0             1                128\n",
      "0             1                119\n",
      "0             1                117\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 26.6607 - val_loss: 25.2382\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 25.5360 - val_loss: 24.3530\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 24.5474 - val_loss: 23.2470\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 22.9229 - val_loss: 21.9458\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 21.7626 - val_loss: 21.2394\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.9114 - val_loss: 20.7518\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 20.5876 - val_loss: 20.3994\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 20.2041 - val_loss: 20.1618\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.6553 - val_loss: 19.9826\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.6292 - val_loss: 19.8587\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3908 - val_loss: 19.7518\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.3331 - val_loss: 19.6568\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.1935 - val_loss: 19.5697\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0865 - val_loss: 19.4921\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 19.0310 - val_loss: 19.4270\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.9356 - val_loss: 19.3718\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8698 - val_loss: 19.3213\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8425 - val_loss: 19.2742\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.8133 - val_loss: 19.2334\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.7791 - val_loss: 19.1998\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.7253 - val_loss: 19.1729\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6774 - val_loss: 19.1483\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6629 - val_loss: 19.1258\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6130 - val_loss: 19.1040\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6469 - val_loss: 19.0839\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5523 - val_loss: 19.0658\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.6087 - val_loss: 19.0473\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5888 - val_loss: 19.0295\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5762 - val_loss: 19.0120\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4967 - val_loss: 18.9952\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5159 - val_loss: 18.9787\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.5174 - val_loss: 18.9624\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4922 - val_loss: 18.9473\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4707 - val_loss: 18.9327\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4812 - val_loss: 18.9180\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3009 - val_loss: 18.9037\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4517 - val_loss: 18.8906\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.4207 - val_loss: 18.8769\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4504 - val_loss: 18.8643\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4431 - val_loss: 18.8514\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4236 - val_loss: 18.8387\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4129 - val_loss: 18.8254\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.4029 - val_loss: 18.8121\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3814 - val_loss: 18.8000\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3800 - val_loss: 18.7873\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 18.3408 - val_loss: 18.7753\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3626 - val_loss: 18.7631\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3647 - val_loss: 18.7503\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3295 - val_loss: 18.7379\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.3362 - val_loss: 18.7262\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 18.3289 - val_loss: 18.7137\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2666 - val_loss: 18.7020\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2963 - val_loss: 18.6897\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2602 - val_loss: 18.6779\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2843 - val_loss: 18.6655\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2527 - val_loss: 18.6537\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2559 - val_loss: 18.6419\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2530 - val_loss: 18.6296\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2378 - val_loss: 18.6174\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2271 - val_loss: 18.6049\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.2050 - val_loss: 18.5928\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1763 - val_loss: 18.5810\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1824 - val_loss: 18.5687\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1537 - val_loss: 18.5566\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1660 - val_loss: 18.5445\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0001 - val_loss: 18.5325\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1252 - val_loss: 18.5205\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1451 - val_loss: 18.5079\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0463 - val_loss: 18.4959\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.1142 - val_loss: 18.4843\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0704 - val_loss: 18.4721\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0926 - val_loss: 18.4596\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0154 - val_loss: 18.4477\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0715 - val_loss: 18.4349\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0414 - val_loss: 18.4225\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0531 - val_loss: 18.4103\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0201 - val_loss: 18.3982\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18.0175 - val_loss: 18.3863\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9973 - val_loss: 18.3744\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9427 - val_loss: 18.3628\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9899 - val_loss: 18.3500\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9663 - val_loss: 18.3380\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9553 - val_loss: 18.3260\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9185 - val_loss: 18.3135\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9202 - val_loss: 18.3008\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9135 - val_loss: 18.2884\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8923 - val_loss: 18.2762\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.9008 - val_loss: 18.2634\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8848 - val_loss: 18.2508\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8659 - val_loss: 18.2388\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8555 - val_loss: 18.2263\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8326 - val_loss: 18.2139\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8250 - val_loss: 18.2018\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8284 - val_loss: 18.1892\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.8138 - val_loss: 18.1765\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7765 - val_loss: 18.1636\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7787 - val_loss: 18.1507\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7642 - val_loss: 18.1385\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7743 - val_loss: 18.1253\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 17.7543 - val_loss: 18.1125\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "77/77 [==============================] - 0s 684us/step\n",
      "a2.shape (2448, 1, 1)\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 8, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_525 (Conv1D)         (None, 7, 32)             96        \n",
      "                                                                 \n",
      " conv1d_526 (Conv1D)         (None, 6, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_527 (Conv1D)         (None, 5, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_528 (Conv1D)         (None, 4, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_529 (Conv1D)         (None, 3, 32)             2080      \n",
      "                                                                 \n",
      " conv1d_530 (Conv1D)         (None, 2, 32)             2080      \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_531 (Conv1D)         (None, 1, 1)              33        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,529\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  126\n",
      "   random_state  CoVaR_QRCNN_95_失败天数\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  127\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  124\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  125\n",
      "0             1                  128\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  124\n",
      "0             1                  127\n",
      "0             1                  125\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "0             1                  125\n",
      "0             1                  126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:              0.05295\n",
      "Model:                       QuantReg   Bandwidth:                    0.004158\n",
      "Method:                 Least Squares   Sparsity:                       0.1678\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:06:00   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0134      0.006      2.233      0.026       0.002       0.025\n",
      "three_month_yield_change     -0.1084      0.150     -0.724      0.469      -0.402       0.185\n",
      "term_spread_change           -0.4033      0.144     -2.805      0.005      -0.685      -0.121\n",
      "TED_spread                   -0.2532      0.540     -0.469      0.639      -1.311       0.805\n",
      "credit_spread_change          0.3266      0.218      1.499      0.134      -0.101       0.754\n",
      "market_return                 0.0253      0.087      0.290      0.772      -0.146       0.196\n",
      "real_estate_excess_return     0.1478      0.091      1.627      0.104      -0.030       0.326\n",
      "equity_volatility             1.0913      0.174      6.286      0.000       0.751       1.432\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_95 126\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:            institution   Pseudo R-squared:               0.1382\n",
      "Model:                       QuantReg   Bandwidth:                    0.007126\n",
      "Method:                 Least Squares   Sparsity:                        1.033\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:06:00   Df Residuals:                     2440\n",
      "                                        Df Model:                            7\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0335      0.017      2.031      0.042       0.001       0.066\n",
      "three_month_yield_change      0.2809      0.480      0.586      0.558      -0.660       1.221\n",
      "term_spread_change           -0.7357      0.442     -1.664      0.096      -1.603       0.131\n",
      "TED_spread                   -3.4017      1.773     -1.918      0.055      -6.879       0.075\n",
      "credit_spread_change          0.4311      0.539      0.800      0.424      -0.626       1.488\n",
      "market_return                 0.0987      0.353      0.280      0.780      -0.594       0.791\n",
      "real_estate_excess_return    -0.0464      0.326     -0.142      0.887      -0.686       0.593\n",
      "equity_volatility             2.4050      0.585      4.110      0.000       1.257       3.553\n",
      "=============================================================================================\n",
      "sxc_VaR_linear_99 28\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.4079\n",
      "Model:                       QuantReg   Bandwidth:                    0.002019\n",
      "Method:                 Least Squares   Sparsity:                      0.07436\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:06:00   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0065      0.003      2.336      0.020       0.001       0.012\n",
      "three_month_yield_change      0.0967      0.072      1.335      0.182      -0.045       0.239\n",
      "term_spread_change           -0.1046      0.063     -1.649      0.099      -0.229       0.020\n",
      "TED_spread                   -0.7498      0.290     -2.588      0.010      -1.318      -0.182\n",
      "credit_spread_change          0.1377      0.101      1.363      0.173      -0.060       0.336\n",
      "market_return                -0.0764      0.040     -1.904      0.057      -0.155       0.002\n",
      "real_estate_excess_return    -0.0967      0.045     -2.136      0.033      -0.185      -0.008\n",
      "equity_volatility             0.5211      0.072      7.268      0.000       0.380       0.662\n",
      "institution                   0.4908      0.037     13.207      0.000       0.418       0.564\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_95 128\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  SP500   Pseudo R-squared:               0.5170\n",
      "Model:                       QuantReg   Bandwidth:                    0.003627\n",
      "Method:                 Least Squares   Sparsity:                       0.2999\n",
      "Date:                Tue, 12 Sep 2023   No. Observations:                 2448\n",
      "Time:                        20:06:00   Df Residuals:                     2439\n",
      "                                        Df Model:                            8\n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     0.0149      0.004      3.741      0.000       0.007       0.023\n",
      "three_month_yield_change      0.0614      0.117      0.525      0.600      -0.168       0.291\n",
      "term_spread_change           -0.0220      0.118     -0.186      0.853      -0.254       0.210\n",
      "TED_spread                   -0.8791      0.526     -1.672      0.095      -1.910       0.152\n",
      "credit_spread_change         -0.3428      0.157     -2.187      0.029      -0.650      -0.035\n",
      "market_return                -0.1409      0.107     -1.320      0.187      -0.350       0.068\n",
      "real_estate_excess_return    -0.1074      0.091     -1.182      0.238      -0.286       0.071\n",
      "equity_volatility             1.8555      0.194      9.568      0.000       1.475       2.236\n",
      "institution                   0.4419      0.112      3.948      0.000       0.222       0.661\n",
      "=============================================================================================\n",
      "sxc_CoVaR_linear_99 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'E:\\华为电脑备份\\研究生的森活\\居超QRCDCNN论文\\数据\\日数据\\数据合并过程.xlsx', sheet_name='损失率+滞后',index_col='DATE')\n",
    "SP500=df.iloc[:,0]\n",
    "state_variable=df.iloc[:,39:]\n",
    "three_month_yield_change=df.iloc[:,39]\n",
    "term_spread_change=df.iloc[:,40]\n",
    "TED_spread=df.iloc[:,41]\n",
    "credit_spread_change=df.iloc[:,42]\n",
    "market_return=df.iloc[:,43]\n",
    "real_estate_excess_return=df.iloc[:,44]\n",
    "equity_volatility=df.iloc[:,45]\n",
    "\n",
    "VaR1_QRCNN_95=pd.DataFrame()\n",
    "VaR1_QRCNN_99=pd.DataFrame()\n",
    "CoVaR1_QRCNN_95=pd.DataFrame()\n",
    "CoVaR1_QRCNN_99=pd.DataFrame()\n",
    "concat_result1=pd.DataFrame()\n",
    "Dict2_VaR_QRCNN_95=pd.DataFrame()\n",
    "Dict2_CoVaR_QRCNN_95=pd.DataFrame()\n",
    "# Dict2_VaR_QRCNN_test_95=pd.DataFrame()\n",
    "# Dict2_CoVaR_QRCNN_test_95=pd.DataFrame()\n",
    "\n",
    "column_index=[]\n",
    "for i in range(1,39):\n",
    "# for i in range(1,2):\n",
    "    institution = df.iloc[:,i]\n",
    "\n",
    "    # VaR_95和VaR_95的估计\n",
    "\n",
    "    x = state_variable.to_numpy()\n",
    "    y=institution.to_numpy() #UNUM\n",
    "\n",
    "\n",
    "    for j in list(range(1,2)):\n",
    "#     for j in list(range(1,10000)):\n",
    "        # 首先将数据拆分为训练集和临时集（包含验证集和测试集）\n",
    "        x_train_95, x_temp, y_train_95, y_temp = train_test_split(x, y, test_size=0.1, random_state=j)\n",
    "\n",
    "        # 接着将临时集拆分为验证集和测试集\n",
    "        x_val_95, x_test_95, y_val_95, y_test_95 = train_test_split(x_temp, y_temp, test_size=0.5, random_state=j)\n",
    "\n",
    "        model_VaR_95,history_VaR_95 = qrcnn_VaR_95.model(x_train_95,y_train_95,x_val_95,y_val_95)\n",
    "\n",
    "        a_test = model_VaR_95.predict(x_test_95)\n",
    "        b_test=a_test.reshape(a_test.shape[0],1)\n",
    "        VaR_QRCNN_test_95 = pd.DataFrame(b_test)\n",
    " \n",
    "        sxc_VaR_QRCNN_test_95 = 0\n",
    "        for k in range(len(y_test_95)):\n",
    "            if y_test_95[k] > VaR_QRCNN_test_95[0][k]:\n",
    "                sxc_VaR_QRCNN_test_95+=1\n",
    "        Dict1_VaR_QRCNN_test_95=pd.DataFrame([sxc_VaR_QRCNN_test_95])\n",
    "#         Dict2_VaR_QRCNN_test_95=pd.concat([ Dict2_VaR_QRCNN_test_95, Dict1_VaR_QRCNN_test_95],axis=0)\n",
    "\n",
    "        \n",
    "        # a = model.predict([[-57642]])\n",
    "        a = model_VaR_95.predict(x)\n",
    "        print('a.shape',np.shape(a))\n",
    "        print(model_VaR_95.summary())\n",
    "        b=a.reshape(a.shape[0],1)\n",
    "        b.shape\n",
    "        VaR_QRCNN_95 = pd.DataFrame(b)\n",
    " \n",
    "        sxc_VaR_QRCNN_95 = 0\n",
    "        for k in range(len(y)):\n",
    "            if y[k] > VaR_QRCNN_95[0][k]:\n",
    "                sxc_VaR_QRCNN_95+=1\n",
    "#         print(sxc_VaR_QRCNN_95)\n",
    "\n",
    "        Dict_VaR_QRCNN_95 =[j,sxc_VaR_QRCNN_95]\n",
    "#         print(Dict_VaR_QRCNN_95)\n",
    "        if 122<= Dict_VaR_QRCNN_95[1]<=123:\n",
    "            Dict1_VaR_QRCNN_95=pd.DataFrame([Dict_VaR_QRCNN_95],columns=['random_state','VaR_QRCNN_95_失败天数'])\n",
    "            VaR1_QRCNN_95=pd.concat([VaR1_QRCNN_95,VaR_QRCNN_95],axis=1)\n",
    "            break\n",
    "        else:\n",
    "            Dict1_VaR_QRCNN_95=pd.DataFrame([Dict_VaR_QRCNN_95],columns=['random_state','VaR_QRCNN_95_失败天数'])\n",
    "            print(Dict1_VaR_QRCNN_95)\n",
    "            Dict2_VaR_QRCNN_95=pd.concat([ Dict2_VaR_QRCNN_95, Dict1_VaR_QRCNN_95],axis=0)\n",
    "            print(Dict2_VaR_QRCNN_95)\n",
    "    sxc1_VaR_QRCNN_95_random=Dict1_VaR_QRCNN_95.iloc[0,0]\n",
    "    sxc1_VaR_QRCNN_95=Dict1_VaR_QRCNN_95.iloc[0,1]\n",
    " \n",
    " \n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "#         x_train_99, x_test_99, y_train_99, y_test_99 = train_test_split(x,y,random_state=j)\n",
    "#         model_VaR_99,history_VaR_99 = qrcnn_VaR_99.model(x_train_99,y_train_99,x_test_99,y_test_99)\n",
    "\n",
    "\n",
    "#         # a = model.predict([[-57642]])\n",
    "#         a = model_VaR_99.predict(x)\n",
    "#         print('a.shape',np.shape(a))\n",
    "#         print(model_VaR_99.summary())\n",
    "#         b=a.reshape(a.shape[0],1)\n",
    "#         b.shape\n",
    "#         VaR_QRCNN_99 = pd.DataFrame(b)\n",
    "\n",
    "#         sxc_VaR_QRCNN_99 = 0\n",
    "#         for k in range(len(y)):\n",
    "#             if y[k] > VaR_QRCNN_99[0][k]:\n",
    "#                 sxc_VaR_QRCNN_99+=1\n",
    "# #         print('sxc_VaR_QRCNN_99',sxc_VaR_QRCNN_99)\n",
    "\n",
    "#         Dict_VaR_QRCNN_99 =[j,sxc_VaR_QRCNN_99]\n",
    "# #         print(Dict_VaR_QRCNN_99)\n",
    "#         if 24<= Dict_VaR_QRCNN_99[1]<=25:\n",
    "#             Dict1_VaR_QRCNN_99=pd.DataFrame([Dict_VaR_QRCNN_99],columns=['random_state','VaR_QRCNN_99_失败天数'])\n",
    "#             VaR1_QRCNN_99=pd.concat([VaR1_QRCNN_99,VaR_QRCNN_99],axis=1)\n",
    "#             break\n",
    "#         else:\n",
    "#             Dict1_VaR_QRCNN_99=pd.DataFrame([Dict_VaR_QRCNN_99],columns=['random_state','VaR_QRCNN_99_失败天数'])\n",
    "#             print(Dict1_VaR_QRCNN_99)\n",
    "#             Dict2_VaR_QRCNN_99=pd.concat([ Dict2_VaR_QRCNN_99, Dict1_VaR_QRCNN_99],axis=0)\n",
    "#             print(Dict2_VaR_QRCNN_99)\n",
    "#     sxc1_VaR_QRCNN_99_random=Dict1_VaR_QRCNN_99.iloc[0,0]\n",
    "#     sxc1_VaR_QRCNN_99=Dict1_VaR_QRCNN_99.iloc[0,1]\n",
    "\n",
    "\n",
    "    # CoVaR_95和CoVaR_99的估计\n",
    "\n",
    "    concat = pd.concat([state_variable,institution],axis=1)\n",
    "     # 把两个数据框合并起来，合并方式为按列合并\n",
    "    x2=concat.to_numpy()[:,0:]\n",
    "    y2=SP500.to_numpy()\n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "    for j in list(range(1,2)):        \n",
    "        # 首先将数据拆分为训练集和临时集（包含验证集和测试集）\n",
    "        x2_train_95, x2_temp, y2_train_95, y2_temp = train_test_split(x2, y2, test_size=0.1, random_state=j)\n",
    "\n",
    "        # 接着将临时集拆分为验证集和测试集\n",
    "        x2_val_95, x2_test_95, y2_val_95, y2_test_95 = train_test_split(x2_temp, y2_temp, test_size=0.5, random_state=j)\n",
    "\n",
    "        model_CoVaR_95,history_CoVaR_95 = qrcnn_CoVaR_95.model(x2_train_95,y2_train_95,x2_val_95,y2_val_95)\n",
    "\n",
    "        a2_test = model_CoVaR_95.predict(x2_test_95)\n",
    "        a2 = model_CoVaR_95.predict(x2)\n",
    "        print('a2.shape',np.shape(a2))\n",
    "        print(model_CoVaR_95.summary())\n",
    "        \n",
    "        \n",
    "        b2_test=a2_test.reshape(a2_test.shape[0],1)\n",
    "        b2=a2.reshape(a2.shape[0],1)\n",
    "        b2.shape\n",
    "        CoVaR_QRCNN_95 = pd.DataFrame(b2)\n",
    "        CoVaR_QRCNN_test_95 = pd.DataFrame(b2_test)\n",
    "        \n",
    "        sxc_CoVaR_QRCNN_test_95 = 0\n",
    "        for k in range(len(y2_test_95)):\n",
    "            if  y2_test_95[k] > CoVaR_QRCNN_test_95[0][k]:\n",
    "                sxc_CoVaR_QRCNN_test_95+=1        \n",
    "        Dict1_CoVaR_QRCNN_test_95=pd.DataFrame([sxc_CoVaR_QRCNN_test_95])\n",
    "#         Dict2_CoVaR_QRCNN_test_95=pd.concat([ Dict2_CoVaR_QRCNN_test_95, Dict1_CoVaR_QRCNN_test_95],axis=0)\n",
    "\n",
    "\n",
    "        sxc_CoVaR_QRCNN_95 = 0\n",
    "        for k in range(len(y2)):\n",
    "            if  y2[k] > CoVaR_QRCNN_95[0][k]:\n",
    "                sxc_CoVaR_QRCNN_95+=1\n",
    "#         print('sxc_CoVaR_QRCNN_95',sxc_CoVaR_QRCNN_95)\n",
    "\n",
    "        Dict_CoVaR_QRCNN_95 =[j,sxc_CoVaR_QRCNN_95]\n",
    "#         print(Dict_CoVaR_QRCNN_95)\n",
    "        if 122<= Dict_CoVaR_QRCNN_95[1]<=123:\n",
    "            Dict1_CoVaR_QRCNN_95=pd.DataFrame([Dict_CoVaR_QRCNN_95],columns=['random_state','CoVaR_QRCNN_95_失败天数'])\n",
    "            CoVaR1_QRCNN_95=pd.concat([CoVaR1_QRCNN_95,CoVaR_QRCNN_95],axis=1)\n",
    "            break\n",
    "        else:\n",
    "            Dict1_CoVaR_QRCNN_95=pd.DataFrame([Dict_CoVaR_QRCNN_95],columns=['random_state','CoVaR_QRCNN_95_失败天数'])\n",
    "            print(Dict1_CoVaR_QRCNN_95)\n",
    "            Dict2_CoVaR_QRCNN_95=pd.concat([ Dict2_CoVaR_QRCNN_95, Dict1_CoVaR_QRCNN_95],axis=0)\n",
    "            print(Dict2_CoVaR_QRCNN_95)\n",
    "    sxc1_CoVaR_QRCNN_95_random=Dict1_CoVaR_QRCNN_95.iloc[0,0]   \n",
    "    sxc1_CoVaR_QRCNN_95=Dict1_CoVaR_QRCNN_95.iloc[0,1]\n",
    "    \n",
    "\n",
    "\n",
    "#     for j in list(range(1,10000)):\n",
    "#         x2_train_99, x2_test_99, y2_train_99, y2_test_99 = train_test_split(x2,y2,random_state=j)\n",
    "#         model_CoVaR_99,history_CoVaR_99 = qrcnn_CoVaR_99.model(x2_train_99,y2_train_99,x2_test_99,y2_test_99)\n",
    "\n",
    "\n",
    "#         a2 = model_CoVaR_99.predict(x2)\n",
    "#         print('a2.shape',np.shape(a2))\n",
    "#         print(model_CoVaR_99.summary())\n",
    "#         b2=a2.reshape(a2.shape[0],1)\n",
    "#         b2.shape\n",
    "#         CoVaR_QRCNN_99 = pd.DataFrame(b2)\n",
    "        \n",
    "\n",
    "#         sxc_CoVaR_QRCNN_99 = 0\n",
    "#         for k in range(len(y2)):\n",
    "#             if  y2[k] > CoVaR_QRCNN_99[0][k]:\n",
    "#                 sxc_CoVaR_QRCNN_99+=1\n",
    "#         print('sxc_CoVaR_QRCNN_99',sxc_CoVaR_QRCNN_99)\n",
    "\n",
    "#         Dict_CoVaR_QRCNN_99 =[j,sxc_CoVaR_QRCNN_99]\n",
    "#         print(Dict_CoVaR_QRCNN_99)\n",
    "#         if 24<= Dict_CoVaR_QRCNN_99[1]<=25:\n",
    "#             Dict1_CoVaR_QRCNN_99=pd.DataFrame([Dict_CoVaR_QRCNN_99],columns=['random_state','CoVaR_QRCNN_99_失败天数'])\n",
    "#             CoVaR1_QRCNN_99=pd.concat([CoVaR1_QRCNN_99,CoVaR_QRCNN_99],axis=1)\n",
    "#             break\n",
    "#         else:\n",
    "#             Dict1_CoVaR_QRCNN_99=pd.DataFrame([Dict_CoVaR_QRCNN_99],columns=['random_state','CoVaR_QRCNN_99_失败天数'])\n",
    "#             print(Dict1_CoVaR_QRCNN_99)\n",
    "#             Dict2_CoVaR_QRCNN_99=pd.concat([ Dict2_CoVaR_QRCNN_99, Dict1_CoVaR_QRCNN_99],axis=0)\n",
    "#             print(Dict2_CoVaR_QRCNN_99)\n",
    "            \n",
    "    \n",
    "#     sxc1_CoVaR_QRCNN_99_random=Dict1_CoVaR_QRCNN_99.iloc[0,0]\n",
    "#     sxc1_CoVaR_QRCNN_99=Dict1_CoVaR_QRCNN_99.iloc[0,1]\n",
    "\n",
    "\n",
    "    ## 线性分位数回归\n",
    "\n",
    "    import statsmodels.formula.api as smf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    mod_VaR_95 = smf.quantreg('institution ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility',df)\n",
    "    res_VaR_95 = mod_VaR_95.fit(q=0.95)\n",
    "    print(res_VaR_95.summary())\n",
    "\n",
    "    VaR_linear_95= res_VaR_95.params['Intercept']+ three_month_yield_change*res_VaR_95.params['three_month_yield_change'] + term_spread_change*res_VaR_95.params['term_spread_change']+ TED_spread*res_VaR_95.params['TED_spread']+ credit_spread_change*res_VaR_95.params['credit_spread_change']+ market_return*res_VaR_95.params['market_return']+ real_estate_excess_return*res_VaR_95.params['real_estate_excess_return']+ equity_volatility*res_VaR_95.params['equity_volatility']\n",
    "\n",
    "    sxc_VaR_linear_95 = 0\n",
    "    for k in range(len(y)):\n",
    "        if   y[k] > VaR_linear_95[k]:\n",
    "            sxc_VaR_linear_95+=1\n",
    "    print('sxc_VaR_linear_95',sxc_VaR_linear_95)\n",
    "\n",
    "    mod_VaR_99 = smf.quantreg('institution ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility',df)\n",
    "    res_VaR_99 = mod_VaR_99.fit(q=0.99)\n",
    "    print(res_VaR_99.summary())\n",
    "\n",
    "    VaR_linear_99= res_VaR_99.params['Intercept']+ three_month_yield_change*res_VaR_99.params['three_month_yield_change'] + term_spread_change*res_VaR_99.params['term_spread_change']+ TED_spread*res_VaR_99.params['TED_spread']+ credit_spread_change*res_VaR_99.params['credit_spread_change']+ market_return*res_VaR_99.params['market_return']+ real_estate_excess_return*res_VaR_99.params['real_estate_excess_return']+ equity_volatility*res_VaR_99.params['equity_volatility']\n",
    "\n",
    "    sxc_VaR_linear_99 = 0\n",
    "    for k in range(len(y)):\n",
    "        if   y[k] > VaR_linear_99[k]:\n",
    "            sxc_VaR_linear_99+=1\n",
    "    print('sxc_VaR_linear_99',sxc_VaR_linear_99)\n",
    "\n",
    "    mod_CoVaR_95 = smf.quantreg('SP500 ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility+institution',df)\n",
    "    res_CoVaR_95 = mod_CoVaR_95.fit(q=0.95)\n",
    "    print(res_CoVaR_95.summary())\n",
    "\n",
    "    CoVaR_linear_95= res_CoVaR_95.params['Intercept']+ three_month_yield_change*res_CoVaR_95.params['three_month_yield_change'] + term_spread_change*res_CoVaR_95.params['term_spread_change']+ TED_spread*res_CoVaR_95.params['TED_spread']+ credit_spread_change*res_CoVaR_95.params['credit_spread_change']+ market_return*res_CoVaR_95.params['market_return']+ real_estate_excess_return*res_CoVaR_95.params['real_estate_excess_return']+ equity_volatility*res_CoVaR_95.params['equity_volatility']+institution*res_CoVaR_95.params['institution']\n",
    "\n",
    "    sxc_CoVaR_linear_95 = 0\n",
    "    for k in range(len(y)):\n",
    "        if y2[k] > CoVaR_linear_95[k]:\n",
    "            sxc_CoVaR_linear_95+=1\n",
    "    print('sxc_CoVaR_linear_95',sxc_CoVaR_linear_95)\n",
    "\n",
    "    mod_CoVaR_99 = smf.quantreg('SP500 ~ three_month_yield_change+term_spread_change+TED_spread+credit_spread_change+market_return+real_estate_excess_return+equity_volatility+institution',df)\n",
    "    res_CoVaR_99 = mod_CoVaR_99.fit(q=0.99)\n",
    "    print(res_CoVaR_99.summary())\n",
    "\n",
    "    CoVaR_linear_99= res_CoVaR_99.params['Intercept']+ three_month_yield_change*res_CoVaR_99.params['three_month_yield_change'] + term_spread_change*res_CoVaR_99.params['term_spread_change']+ TED_spread*res_CoVaR_99.params['TED_spread']+ credit_spread_change*res_CoVaR_99.params['credit_spread_change']+ market_return*res_CoVaR_99.params['market_return']+ real_estate_excess_return*res_CoVaR_99.params['real_estate_excess_return']+ equity_volatility*res_CoVaR_99.params['equity_volatility']+institution*res_CoVaR_99.params['institution']\n",
    "\n",
    "    sxc_CoVaR_linear_99 = 0\n",
    "    for k in range(len(y)):\n",
    "        if y2[k] > CoVaR_linear_99[k]:\n",
    "            sxc_CoVaR_linear_99+=1\n",
    "    print('sxc_CoVaR_linear_99',sxc_CoVaR_linear_99)\n",
    "\n",
    "    Dict_95={'VaR_QRCNN_95_random':[sxc1_VaR_QRCNN_95_random],'VaR_QRCNN_test_95_失败天数':[sxc_VaR_QRCNN_test_95],'VaR_QRCNN_95_失败天数':[sxc1_VaR_QRCNN_95],'CoVaR_QRCNN_95_random':[sxc1_CoVaR_QRCNN_95_random],'CoVaR_QRCNN_test_95_失败天数':[sxc_CoVaR_QRCNN_test_95],'CoVaR_QRCNN_95_失败天数':[sxc1_CoVaR_QRCNN_95],'VaR_linear_95_失败天数':[sxc_VaR_linear_95],'CoVaR_linear_95_失败天数':[sxc_CoVaR_linear_95]}\n",
    "    result_95 = pd.DataFrame(Dict_95)\n",
    "    result_95\n",
    "\n",
    "#     Dict_99={'VaR_QRCNN_99_random':[sxc1_VaR_QRCNN_99_random],'VaR_QRCNN_99_失败天数':[sxc1_VaR_QRCNN_99],'CoVaR_QRCNN_99_random':[sxc1_CoVaR_QRCNN_99_random],'CoVaR_QRCNN_99_失败天数':[sxc1_CoVaR_QRCNN_99],'VaR_linear_99_失败天数':[sxc_VaR_linear_99],'CoVaR_linear_99_失败天数':[sxc_CoVaR_linear_99]}\n",
    "#     result_99 = pd.DataFrame(Dict_99)\n",
    "#     result_99\n",
    "\n",
    "#     concat_result = pd.concat([result_95,result_99],axis=1)\n",
    "    concat_result = pd.concat([result_95],axis=1)\n",
    "    concat_result1= pd.concat([concat_result1,concat_result],axis=0)\n",
    "    column_index.append(df.columns.values[i])\n",
    "    concat_result1.index=column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sxc_VaR_QRCNN_test_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_95))\n",
    "print(len(x2_test_95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.22063231, -0.13935998, -0.21550132, -0.25991362,\n",
       "          -0.0214998 ,  0.28224203, -0.02810246, -0.00558514,\n",
       "          -0.13903856,  0.07303968, -0.1644541 ,  0.21494254,\n",
       "          -0.19711567,  0.194861  ,  0.01575649,  0.26556703,\n",
       "           0.17626616, -0.13220893,  0.08973728,  0.2206656 ,\n",
       "           0.21045806, -0.11795963, -0.28413868, -0.17356591,\n",
       "           0.01071426,  0.16734275, -0.11592609, -0.06661885,\n",
       "          -0.19470221, -0.05038563, -0.0529907 ,  0.1691921 ]],\n",
       " \n",
       "        [[ 0.18305889, -0.24778992,  0.1924185 , -0.12395585,\n",
       "           0.1407613 ,  0.24541529,  0.13902293,  0.20800027,\n",
       "          -0.1418237 , -0.04809571,  0.2979335 , -0.22183926,\n",
       "           0.19792256, -0.0022632 ,  0.12504588,  0.22427617,\n",
       "           0.24629834,  0.26643956,  0.25704947, -0.24113208,\n",
       "          -0.10091009, -0.00188806, -0.23041028,  0.1703861 ,\n",
       "          -0.03174114, -0.15250336, -0.09928463,  0.18460526,\n",
       "           0.1848019 ,  0.09137291, -0.07938626,  0.06127884]]],\n",
       "       dtype=float32),\n",
       " array([[[ 1.07664064e-01,  1.30774900e-01,  1.44046634e-01, ...,\n",
       "          -1.05549283e-01,  1.49041355e-01, -1.80757866e-06],\n",
       "         [ 9.97755826e-02, -3.97004411e-02, -1.83883622e-01, ...,\n",
       "           8.05303454e-02,  9.09106731e-02, -6.65142143e-04],\n",
       "         [ 9.14399028e-02,  1.68646321e-01, -1.94474623e-01, ...,\n",
       "           1.13056429e-01,  6.21937625e-02,  5.88619299e-02],\n",
       "         ...,\n",
       "         [-1.84532087e-02,  2.09903732e-01, -1.99586317e-01, ...,\n",
       "          -1.27057850e-01,  8.22815597e-02, -2.04663813e-01],\n",
       "         [-1.59007162e-01,  1.46559505e-02, -1.07910231e-01, ...,\n",
       "          -8.37612748e-02, -6.07522242e-02,  1.00451179e-01],\n",
       "         [-6.82770386e-02, -1.31277412e-01, -2.42752098e-02, ...,\n",
       "           1.75785664e-02,  5.62697873e-02, -5.56645729e-02]],\n",
       " \n",
       "        [[ 1.82645008e-01, -1.10020868e-01, -3.37908409e-06, ...,\n",
       "          -1.07868202e-01,  6.58390820e-02,  1.15554027e-01],\n",
       "         [ 8.83484706e-02, -1.26310632e-01,  4.08444181e-03, ...,\n",
       "          -4.50973548e-02,  1.15249798e-01,  1.05855931e-02],\n",
       "         [ 1.74638361e-01, -1.79183528e-01, -4.61304421e-03, ...,\n",
       "          -2.05439061e-01, -8.07780102e-02, -1.84413671e-01],\n",
       "         ...,\n",
       "         [ 9.72546637e-03,  1.89138517e-01,  2.41602808e-02, ...,\n",
       "          -1.31540552e-01, -1.15029819e-01, -1.76063165e-01],\n",
       "         [-1.39756519e-02,  5.16706370e-02, -6.53882232e-03, ...,\n",
       "           1.65766925e-01, -8.72010067e-02,  1.94304883e-01],\n",
       "         [-7.39345327e-03, -9.45848525e-02,  2.93074120e-02, ...,\n",
       "           4.06988058e-03, -1.65180475e-01,  4.00417048e-06]]],\n",
       "       dtype=float32),\n",
       " array([[[ 6.73226193e-02, -1.31898493e-01,  1.34326577e-01, ...,\n",
       "          -2.08150804e-01,  9.44600627e-02,  1.98942944e-01],\n",
       "         [-1.57215804e-01, -1.33402556e-01,  1.23117000e-01, ...,\n",
       "           1.18243486e-01,  5.39826453e-02, -5.58184907e-02],\n",
       "         [-1.33474112e-01, -2.02958524e-01, -5.29503915e-03, ...,\n",
       "           6.93887696e-02, -1.48471922e-01,  1.61608920e-01],\n",
       "         ...,\n",
       "         [ 2.01435983e-01,  1.36693120e-06, -1.94577202e-01, ...,\n",
       "           7.25604147e-02, -1.51368752e-01,  1.89727917e-01],\n",
       "         [-8.21088403e-02,  4.02538516e-02, -2.69667860e-02, ...,\n",
       "          -9.62067470e-02, -1.07394978e-02, -1.74901169e-03],\n",
       "         [ 1.78014234e-01,  5.81950359e-02,  1.35539398e-01, ...,\n",
       "           1.60164207e-01, -7.36376420e-02, -7.11877868e-02]],\n",
       " \n",
       "        [[ 1.98348597e-01, -1.15787361e-06,  4.69712690e-02, ...,\n",
       "           6.18827902e-02, -5.79200452e-03, -2.02537313e-01],\n",
       "         [ 1.67137999e-02,  2.01258302e-01, -6.70630698e-07, ...,\n",
       "           1.33518904e-01, -3.14217573e-07, -1.86857969e-01],\n",
       "         [-4.21174280e-02, -1.74589947e-01,  1.65704221e-01, ...,\n",
       "           1.46863043e-01,  1.05361447e-01, -1.86258793e-01],\n",
       "         ...,\n",
       "         [ 1.88623101e-01,  8.56723785e-02,  7.83565268e-03, ...,\n",
       "          -1.94297209e-01, -9.91233289e-02,  3.90487958e-06],\n",
       "         [-1.84658188e-06, -1.85037330e-01,  1.75857350e-01, ...,\n",
       "          -4.38221544e-02,  1.89214811e-01,  6.81349710e-02],\n",
       "         [ 1.63881347e-01,  2.01125965e-01,  5.08262701e-02, ...,\n",
       "           1.51807770e-01, -1.21466003e-01, -7.88251311e-02]]],\n",
       "       dtype=float32),\n",
       " array([[[-4.47661392e-02,  1.13139443e-01, -7.80544430e-02, ...,\n",
       "           8.56175274e-02,  3.51707749e-02,  9.06218290e-02],\n",
       "         [ 1.82637066e-01, -2.02011093e-01,  3.50708638e-06, ...,\n",
       "          -1.95482105e-01, -1.93007186e-01,  1.48750409e-01],\n",
       "         [-1.74871325e-01,  2.54609305e-02, -1.38592953e-02, ...,\n",
       "          -1.97781950e-01, -2.74829213e-02, -1.46405622e-01],\n",
       "         ...,\n",
       "         [-2.75739748e-02,  1.80513173e-01,  9.34856851e-03, ...,\n",
       "           1.48968011e-01,  3.47474813e-02, -1.61735147e-01],\n",
       "         [-2.11034175e-02,  8.94586593e-02, -1.76899061e-01, ...,\n",
       "           1.51430815e-01, -1.40305161e-01, -1.38285086e-01],\n",
       "         [ 1.15167797e-01, -2.00525269e-01, -1.63533717e-01, ...,\n",
       "           4.50258143e-02,  1.98997147e-02,  1.04194760e-06]],\n",
       " \n",
       "        [[ 1.89671263e-01, -6.48700893e-02,  1.36034086e-01, ...,\n",
       "           1.58178911e-01,  2.10678604e-06, -1.09597392e-01],\n",
       "         [-1.92759112e-01,  4.57109213e-02, -1.65672100e-06, ...,\n",
       "          -6.76927641e-02, -5.56349121e-02, -2.87380926e-02],\n",
       "         [-2.52798145e-07,  1.78890258e-01,  1.00926146e-01, ...,\n",
       "           1.21152140e-01, -1.76555291e-01, -5.98372668e-02],\n",
       "         ...,\n",
       "         [ 6.83993176e-02, -1.92989707e-01,  4.78266366e-02, ...,\n",
       "           1.24218553e-01,  2.29141787e-01, -1.45870313e-01],\n",
       "         [ 1.42138749e-01, -1.35070980e-01,  1.91915810e-01, ...,\n",
       "          -1.05548270e-01,  1.99672163e-01,  1.09776966e-01],\n",
       "         [-1.08607665e-01,  5.19288657e-03, -9.03408602e-02, ...,\n",
       "           1.55249894e-01,  3.59412934e-06,  1.60439983e-01]]],\n",
       "       dtype=float32),\n",
       " array([[[-2.4324208e-07, -1.8597339e-01, -1.8851590e-01, ...,\n",
       "          -2.0646778e-01,  3.6797341e-02,  4.1128851e-02],\n",
       "         [-7.9718113e-02, -8.8557288e-02, -1.2212227e-01, ...,\n",
       "          -2.0350875e-02,  1.9218643e-01, -1.9412717e-01],\n",
       "         [ 1.8255091e-01, -1.8601950e-01,  2.1342698e-01, ...,\n",
       "          -1.5021814e-01,  1.5834821e-02, -8.0800407e-02],\n",
       "         ...,\n",
       "         [-1.4588962e-01,  2.2763681e-02,  8.1913546e-02, ...,\n",
       "           2.0013170e-01,  1.9053067e-01, -1.7689046e-02],\n",
       "         [-1.8651186e-01,  1.3313992e-01, -1.2784091e-01, ...,\n",
       "           2.1665861e-01, -1.5129513e-01, -1.1669417e-01],\n",
       "         [-7.5506284e-03, -8.5933536e-02, -9.1483071e-02, ...,\n",
       "           6.8332285e-02,  1.7350800e-01,  2.0807419e-02]],\n",
       " \n",
       "        [[-5.3203877e-02,  2.0622259e-01, -1.0471445e-01, ...,\n",
       "          -2.0484334e-01,  3.5175357e-02, -5.1078733e-02],\n",
       "         [-1.5157941e-01,  1.3210505e-01, -1.5473467e-01, ...,\n",
       "           7.5200580e-02,  6.6598125e-02,  5.3346593e-02],\n",
       "         [ 1.8138605e-06,  1.5953097e-01,  7.0253462e-02, ...,\n",
       "          -1.6388719e-01,  5.1760409e-02,  1.0579443e-01],\n",
       "         ...,\n",
       "         [-2.3514456e-03,  2.8679574e-06, -3.8915243e-02, ...,\n",
       "          -1.7688880e-03,  2.4197409e-02, -6.4303011e-02],\n",
       "         [-1.2769317e-02,  1.2749395e-03,  1.6473742e-01, ...,\n",
       "           8.0114819e-02,  1.7740145e-01,  1.1206342e-01],\n",
       "         [-8.4371343e-02, -7.8724317e-02,  9.4307095e-02, ...,\n",
       "           1.0279194e-02,  1.9334951e-01, -9.3259260e-02]]], dtype=float32),\n",
       " array([[[ 7.38380328e-02,  2.20478494e-02, -2.20107540e-06, ...,\n",
       "          -1.84742585e-01, -1.41186669e-01, -8.52267593e-02],\n",
       "         [-1.47765249e-01,  1.12119883e-01, -1.45242542e-01, ...,\n",
       "           1.04340985e-01,  4.31571826e-02,  1.90790683e-01],\n",
       "         [ 9.44737568e-02,  1.12350553e-01, -2.00395107e-01, ...,\n",
       "           1.59448698e-01,  1.92613587e-01, -5.63776679e-02],\n",
       "         ...,\n",
       "         [-3.31789784e-06,  1.83450297e-01,  7.58104101e-02, ...,\n",
       "           7.04395697e-02,  1.59036249e-01,  1.26154229e-01],\n",
       "         [-1.76958486e-01, -9.92564037e-02, -2.05910638e-01, ...,\n",
       "          -4.67851423e-02,  1.81782767e-01, -1.19983248e-01],\n",
       "         [-1.71772122e-01,  2.77851522e-03, -1.19770192e-01, ...,\n",
       "           1.28045667e-06,  1.86573088e-01, -1.71017691e-01]],\n",
       " \n",
       "        [[ 8.19934439e-03, -1.91929564e-01,  3.04003642e-03, ...,\n",
       "          -1.19215317e-01, -1.89351708e-01, -7.12824911e-02],\n",
       "         [-1.46559179e-01, -1.53931931e-01,  6.06008507e-02, ...,\n",
       "          -3.12930383e-02,  1.55257627e-01, -8.33926052e-02],\n",
       "         [-3.44183184e-02,  1.35023847e-01,  1.69300139e-01, ...,\n",
       "           1.36075810e-01, -8.41298886e-03, -6.11508042e-02],\n",
       "         ...,\n",
       "         [ 2.13629915e-03,  1.06366649e-01, -1.21108942e-01, ...,\n",
       "           1.22304112e-01,  1.25657573e-01, -1.08514920e-01],\n",
       "         [-1.49170771e-01,  5.66905104e-02, -1.12975687e-01, ...,\n",
       "           2.25576367e-02, -1.04805484e-01, -1.47576407e-01],\n",
       "         [ 4.24803682e-02,  1.98217332e-01, -4.66795787e-02, ...,\n",
       "          -1.03998385e-01,  1.67451546e-01,  5.77882640e-02]]],\n",
       "       dtype=float32),\n",
       " array([[[-0.06712859],\n",
       "         [ 0.06796926],\n",
       "         [ 0.20643918],\n",
       "         [ 0.37892085],\n",
       "         [-0.16439082],\n",
       "         [ 0.05643456],\n",
       "         [ 0.04524026],\n",
       "         [ 0.33688828],\n",
       "         [ 0.28992116],\n",
       "         [-0.16583951],\n",
       "         [ 0.25244105],\n",
       "         [-0.06644829],\n",
       "         [ 0.11300502],\n",
       "         [-0.29704586],\n",
       "         [-0.22432908],\n",
       "         [ 0.0789994 ],\n",
       "         [-0.21830092],\n",
       "         [ 0.40740928],\n",
       "         [-0.12454242],\n",
       "         [-0.19341765],\n",
       "         [ 0.39757174],\n",
       "         [ 0.3017223 ],\n",
       "         [-0.10183369],\n",
       "         [ 0.10036241],\n",
       "         [ 0.17460927],\n",
       "         [-0.0456676 ],\n",
       "         [ 0.36884552],\n",
       "         [ 0.02773009],\n",
       "         [-0.12091349],\n",
       "         [ 0.24607843],\n",
       "         [ 0.3187277 ],\n",
       "         [ 0.10503288]]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers = [layer for layer in model_VaR_95.layers if isinstance(layer, tf.keras.layers.Conv1D)]\n",
    "conv_weights = [layer.get_weights()[0] for layer in conv_layers]\n",
    "conv_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1d_518', (2, 1, 32)),\n",
       " ('conv1d_519', (2, 32, 32)),\n",
       " ('conv1d_520', (2, 32, 32)),\n",
       " ('conv1d_521', (2, 32, 32)),\n",
       " ('conv1d_522', (2, 32, 32)),\n",
       " ('conv1d_523', (2, 32, 32)),\n",
       " ('conv1d_524', (1, 32, 1))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers_dimensions = [(layer.name, layer.get_weights()[0].shape) for layer in conv_layers]\n",
    "conv_layers_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VaR_QRCNN_95_random</th>\n",
       "      <th>VaR_QRCNN_test_95_失败天数</th>\n",
       "      <th>VaR_QRCNN_95_失败天数</th>\n",
       "      <th>CoVaR_QRCNN_95_random</th>\n",
       "      <th>CoVaR_QRCNN_test_95_失败天数</th>\n",
       "      <th>CoVaR_QRCNN_95_失败天数</th>\n",
       "      <th>VaR_linear_95_失败天数</th>\n",
       "      <th>CoVaR_linear_95_失败天数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>纽约梅隆银行(BNY MELLON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国银行(BANK OF AMERICA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>花旗集团(CITIGROUP):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>联信银行(COMERICA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>亨廷顿银行(HUNTINGTON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩根大通(JPMORGAN CHASE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>制造商和贸易商银行(M&amp;T BANK):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNC金融服务:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>道富银行(STATE STREET):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>富国银行(WELLS FARGO):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>齐昂银行(ZIONS BANCORP):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>高盛集团(GOLDMAN SACHS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩根士丹利(MORGAN STANLEY):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嘉信理财(CHARLES SCHWAB):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>普信金融(T ROWE PRICE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国家庭人寿保险(AFLAC):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好事达保险(ALLSTATE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>怡安保险(AON):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERKLEY W R:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信诺保险(CIGNA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN金融:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丘博保险(CHUBB):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>辛辛那提金融(CINCINNATI):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>哈门那(HUMANA):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>林肯国民(LINCOLN NATIONAL):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>洛斯保险(LOEWS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>威达信(MARSH &amp; MCLENNAN):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBIA:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>前进保险(THE PROGRESSIVE):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNUM保险:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国运通(AMERICAN EXPRESS):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>五三银行(FIFTH THIRD):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEI INVESTMENTS:收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>联合太平洋(UNION PACIFIC):收盘价(前复权)</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         VaR_QRCNN_95_random  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                1   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                             1   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                   1   \n",
       "联信银行(COMERICA):收盘价(前复权)                                    1   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                 1   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                              1   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                               1   \n",
       "PNC金融服务:收盘价(前复权)                                           1   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                1   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                         1   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                 1   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                               1   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                               1   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                             1   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                              1   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                1   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                   1   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                   1   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                    1   \n",
       "怡安保险(AON):收盘价(前复权)                                         1   \n",
       "BERKLEY W R:收盘价(前复权)                                       1   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                       1   \n",
       "CAN金融:收盘价(前复权)                                             1   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                       1   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                1   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                      1   \n",
       "哈门那(HUMANA):收盘价(前复权)                                       1   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                            1   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                       1   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                             1   \n",
       "MBIA:收盘价(前复权)                                              1   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                             1   \n",
       "UNUM保险:收盘价(前复权)                                            1   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                            1   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                 1   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                        1   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                   1   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                              1   \n",
       "\n",
       "                                         VaR_QRCNN_test_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                   2   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                                5   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                      5   \n",
       "联信银行(COMERICA):收盘价(前复权)                                       5   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                    4   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                 6   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                  5   \n",
       "PNC金融服务:收盘价(前复权)                                              7   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                   4   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                            4   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                    5   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                  5   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                  7   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                                6   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                 4   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                   6   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                      7   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                      5   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                       5   \n",
       "怡安保险(AON):收盘价(前复权)                                            9   \n",
       "BERKLEY W R:收盘价(前复权)                                          4   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                          7   \n",
       "CAN金融:收盘价(前复权)                                                4   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                          5   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                   5   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                         4   \n",
       "哈门那(HUMANA):收盘价(前复权)                                          5   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                               4   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                          4   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                                5   \n",
       "MBIA:收盘价(前复权)                                                 4   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                                9   \n",
       "UNUM保险:收盘价(前复权)                                               3   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                               4   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                    4   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                           8   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                      5   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                 2   \n",
       "\n",
       "                                         VaR_QRCNN_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                            124   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                         132   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                               121   \n",
       "联信银行(COMERICA):收盘价(前复权)                                124   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                             121   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                          122   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                           124   \n",
       "PNC金融服务:收盘价(前复权)                                       125   \n",
       "道富银行(STATE STREET):收盘价(前复权)                            123   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                     118   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                             121   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                           123   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                           125   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                         123   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                          118   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                            125   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                               127   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                               123   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                127   \n",
       "怡安保险(AON):收盘价(前复权)                                     127   \n",
       "BERKLEY W R:收盘价(前复权)                                   120   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                   125   \n",
       "CAN金融:收盘价(前复权)                                         124   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                   123   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                            125   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                  122   \n",
       "哈门那(HUMANA):收盘价(前复权)                                   127   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                        119   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                   119   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                         122   \n",
       "MBIA:收盘价(前复权)                                          124   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                         122   \n",
       "UNUM保险:收盘价(前复权)                                        121   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                        128   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                             119   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                    123   \n",
       "SEI INVESTMENTS:收盘价(前复权)                               122   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                          117   \n",
       "\n",
       "                                         CoVaR_QRCNN_95_random  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                  1   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                               1   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                     1   \n",
       "联信银行(COMERICA):收盘价(前复权)                                      1   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                   1   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                1   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                 1   \n",
       "PNC金融服务:收盘价(前复权)                                             1   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                  1   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                           1   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                   1   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                 1   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                 1   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                               1   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                1   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                  1   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                     1   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                     1   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                      1   \n",
       "怡安保险(AON):收盘价(前复权)                                           1   \n",
       "BERKLEY W R:收盘价(前复权)                                         1   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                         1   \n",
       "CAN金融:收盘价(前复权)                                               1   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                         1   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                  1   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                        1   \n",
       "哈门那(HUMANA):收盘价(前复权)                                         1   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                              1   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                         1   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                               1   \n",
       "MBIA:收盘价(前复权)                                                1   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                               1   \n",
       "UNUM保险:收盘价(前复权)                                              1   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                              1   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                   1   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                          1   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                     1   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                1   \n",
       "\n",
       "                                         CoVaR_QRCNN_test_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                                     5   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                                  6   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                        6   \n",
       "联信银行(COMERICA):收盘价(前复权)                                         5   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                      6   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                                   6   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                                    6   \n",
       "PNC金融服务:收盘价(前复权)                                                5   \n",
       "道富银行(STATE STREET):收盘价(前复权)                                     6   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                              6   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                      5   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                                    6   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                                    5   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                                  6   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                                   6   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                                     5   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                        6   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                        6   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                         6   \n",
       "怡安保险(AON):收盘价(前复权)                                              6   \n",
       "BERKLEY W R:收盘价(前复权)                                            6   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                            5   \n",
       "CAN金融:收盘价(前复权)                                                  5   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                            5   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                                     5   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                           5   \n",
       "哈门那(HUMANA):收盘价(前复权)                                            7   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                                 5   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                            6   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                                  5   \n",
       "MBIA:收盘价(前复权)                                                   6   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                                  6   \n",
       "UNUM保险:收盘价(前复权)                                                 6   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                                 5   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                      5   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                             7   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                        6   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                                   6   \n",
       "\n",
       "                                         CoVaR_QRCNN_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                              124   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                           124   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                 127   \n",
       "联信银行(COMERICA):收盘价(前复权)                                  122   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                               127   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                            123   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                             125   \n",
       "PNC金融服务:收盘价(前复权)                                         122   \n",
       "道富银行(STATE STREET):收盘价(前复权)                              125   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                       127   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                               126   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                             126   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                             124   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                           125   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                            126   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                              123   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                 125   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                 127   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                  126   \n",
       "怡安保险(AON):收盘价(前复权)                                       124   \n",
       "BERKLEY W R:收盘价(前复权)                                     124   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                     123   \n",
       "CAN金融:收盘价(前复权)                                           126   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                     124   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                              123   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                    125   \n",
       "哈门那(HUMANA):收盘价(前复权)                                     128   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                          125   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                     126   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                           125   \n",
       "MBIA:收盘价(前复权)                                            126   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                           124   \n",
       "UNUM保险:收盘价(前复权)                                          127   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                          125   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                               125   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                      126   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                 125   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                            126   \n",
       "\n",
       "                                         VaR_linear_95_失败天数  \\\n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                             125   \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                          126   \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                125   \n",
       "联信银行(COMERICA):收盘价(前复权)                                 127   \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                              125   \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                           126   \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                            126   \n",
       "PNC金融服务:收盘价(前复权)                                        127   \n",
       "道富银行(STATE STREET):收盘价(前复权)                             127   \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                      126   \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                              127   \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                            125   \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                            124   \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                          126   \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                           127   \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                             124   \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                126   \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                125   \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                 126   \n",
       "怡安保险(AON):收盘价(前复权)                                      126   \n",
       "BERKLEY W R:收盘价(前复权)                                    125   \n",
       "信诺保险(CIGNA):收盘价(前复权)                                    126   \n",
       "CAN金融:收盘价(前复权)                                          126   \n",
       "丘博保险(CHUBB):收盘价(前复权)                                    125   \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                             126   \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                   126   \n",
       "哈门那(HUMANA):收盘价(前复权)                                    126   \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                         127   \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                    124   \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                          126   \n",
       "MBIA:收盘价(前复权)                                           125   \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                          127   \n",
       "UNUM保险:收盘价(前复权)                                         125   \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                         126   \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                              125   \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                     125   \n",
       "SEI INVESTMENTS:收盘价(前复权)                                127   \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                           126   \n",
       "\n",
       "                                         CoVaR_linear_95_失败天数  \n",
       "纽约梅隆银行(BNY MELLON):收盘价(前复权)                               126  \n",
       "美国银行(BANK OF AMERICA):收盘价(前复权)                            126  \n",
       "花旗集团(CITIGROUP):收盘价(前复权)                                  127  \n",
       "联信银行(COMERICA):收盘价(前复权)                                   127  \n",
       "亨廷顿银行(HUNTINGTON):收盘价(前复权)                                128  \n",
       "摩根大通(JPMORGAN CHASE):收盘价(前复权)                             127  \n",
       "制造商和贸易商银行(M&T BANK):收盘价(前复权)                              126  \n",
       "PNC金融服务:收盘价(前复权)                                          127  \n",
       "道富银行(STATE STREET):收盘价(前复权)                               127  \n",
       "西诺乌斯金融(SYNOVUS FINANCIAL):收盘价(前复权)                        127  \n",
       "富国银行(WELLS FARGO):收盘价(前复权)                                126  \n",
       "齐昂银行(ZIONS BANCORP):收盘价(前复权)                              127  \n",
       "高盛集团(GOLDMAN SACHS):收盘价(前复权)                              127  \n",
       "摩根士丹利(MORGAN STANLEY):收盘价(前复权)                            125  \n",
       "嘉信理财(CHARLES SCHWAB):收盘价(前复权)                             128  \n",
       "普信金融(T ROWE PRICE):收盘价(前复权)                               126  \n",
       "美国家庭人寿保险(AFLAC):收盘价(前复权)                                  125  \n",
       "好事达保险(ALLSTATE):收盘价(前复权)                                  128  \n",
       "美国国际集团(AMERICAN INTERNATIONAL):收盘价(前复权)                   127  \n",
       "怡安保险(AON):收盘价(前复权)                                        127  \n",
       "BERKLEY W R:收盘价(前复权)                                      125  \n",
       "信诺保险(CIGNA):收盘价(前复权)                                      125  \n",
       "CAN金融:收盘价(前复权)                                            127  \n",
       "丘博保险(CHUBB):收盘价(前复权)                                      126  \n",
       "辛辛那提金融(CINCINNATI):收盘价(前复权)                               127  \n",
       "哈特福德金融服务(HARTFORD FINANCIAL):收盘价(前复权)                     126  \n",
       "哈门那(HUMANA):收盘价(前复权)                                      126  \n",
       "林肯国民(LINCOLN NATIONAL):收盘价(前复权)                           125  \n",
       "洛斯保险(LOEWS):收盘价(前复权)                                      126  \n",
       "威达信(MARSH & MCLENNAN):收盘价(前复权)                            127  \n",
       "MBIA:收盘价(前复权)                                             127  \n",
       "前进保险(THE PROGRESSIVE):收盘价(前复权)                            126  \n",
       "UNUM保险:收盘价(前复权)                                           127  \n",
       "美国运通(AMERICAN EXPRESS):收盘价(前复权)                           125  \n",
       "五三银行(FIFTH THIRD):收盘价(前复权)                                126  \n",
       "富兰克林资源(FRANKLIN RESOURCES):收盘价(前复权)                       126  \n",
       "SEI INVESTMENTS:收盘价(前复权)                                  126  \n",
       "联合太平洋(UNION PACIFIC):收盘价(前复权)                             128  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VaR_QRCNN_95_random           1.000000\n",
       "VaR_QRCNN_test_95_失败天数        5.052632\n",
       "VaR_QRCNN_95_失败天数           123.026316\n",
       "CoVaR_QRCNN_95_random         1.000000\n",
       "CoVaR_QRCNN_test_95_失败天数      5.657895\n",
       "CoVaR_QRCNN_95_失败天数         125.026316\n",
       "VaR_linear_95_失败天数          125.763158\n",
       "CoVaR_linear_95_失败天数        126.447368\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VaR_QRCNN_95_random         0.000000\n",
       "VaR_QRCNN_test_95_失败天数      1.593015\n",
       "VaR_QRCNN_95_失败天数           3.114802\n",
       "CoVaR_QRCNN_95_random       0.000000\n",
       "CoVaR_QRCNN_test_95_失败天数    0.582461\n",
       "CoVaR_QRCNN_95_失败天数         1.460967\n",
       "VaR_linear_95_失败天数          0.883305\n",
       "CoVaR_linear_95_失败天数        0.891321\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_result1.to_excel(\"concat_result1_QRCNN.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('VaR_CoVaR_QRCNN.xlsx') as writer:\n",
    "    VaR1_QRCNN_95.to_excel(writer,sheet_name=\"VaR1_QRCNN_95\", index=False)\n",
    "    VaR1_QRCNN_99.to_excel(writer,sheet_name='VaR1_QRCNN_99', index=False)\n",
    "    CoVaR1_QRCNN_95.to_excel(writer,sheet_name='CoVaR1_QRCNN_95', index=False)\n",
    "    CoVaR1_QRCNN_99.to_excel(writer,sheet_name='CoVaR1_QRCNN_99', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
